file_name,libraries,binary_libraries,num_lib,num_lines,comments,num_comm,functions,no_dots_all_func,functions_unique,functions_unique_count,binary_func,all_func_string,tfidf
rohitmahor_titanic-problem.py,"['numpy', 'pandas', 'matplotlib', 'os\n', 'sklearn', 're\n']","[1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,162,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# data preprocessing', '# 1. completeing dataset', ""# print(data_train.info(), '\\n', data_test.info())"", '# 2. creating new features familySize, isAlone', ""# print(data_train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())"", ""# print(pd.crosstab(data_train['Title'], data_train['Sex']))"", ""# print(data_train[['isAlone', 'Survived']].groupby(['isAlone'], as_index=False).mean())"", '# 3. Creating dummy variable dataset', '# 4. categorical variables fare, Age', '# print(data_train)', '# get_dummies of title', '# for d in data:', '#     print(d.head(10))', '# data[0] = data[0].append(cat_title)', '# from sklearn.preprocessing import OneHotEncoder', '# onehotencoder = OneHotEncoder(categorical_features=[4, 6])', '# data_train = onehotencoder.fit_transform(data_train)', '# print(data_train)', '# split dataset in training and test dataset', '# print(X_train, y_train)', '# classifier models', '#     print(score, name)', '# predict data using KNN']",31,"['print', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'Imputer', 'imputer.fit_transform', 'imputer.fit_transform', 'd.fillna', 're.search', 'title.group', 'd.apply', 'd.replace', 'd.replace', 'd.replace', 'LabelEncoder', 'le.fit_transform', 'le.fit_transform', 'le.fit_transform', 'pd.qcut', 'pd.cut', 'pd.cut', 'print', 'print', 'print', 'print', 'data_train.drop', 'data_test.drop', 'pd.get_dummies', 'pd.get_dummies', 'print', 'train_test_split', 'LogisticRegression', 'KNeighborsClassifier', 'SVC', 'SVC', 'GaussianNB', 'DecisionTreeClassifier', 'RandomForestClassifier', 'clf.fit', 'clf.score', 'print', 'KNeighborsClassifier', 'classifier.fit', 'classifier.predict']","['print', 'read_csv', 'read_csv', 'print', 'print', 'print', 'Imputer', 'fit_transform', 'fit_transform', 'fillna', 'search', 'group', 'apply', 'replace', 'replace', 'replace', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'qcut', 'cut', 'cut', 'print', 'print', 'print', 'print', 'drop', 'drop', 'get_dummies', 'get_dummies', 'print', 'train_test_split', 'LogisticRegression', 'KNeighborsClassifier', 'SVC', 'SVC', 'GaussianNB', 'DecisionTreeClassifier', 'RandomForestClassifier', 'fit', 'score', 'print', 'KNeighborsClassifier', 'fit', 'predict']","['print', 'read_csv', 'Imputer', 'fit_transform', 'fillna', 'search', 'group', 'apply', 'replace', 'LabelEncoder', 'qcut', 'cut', 'drop', 'get_dummies', 'train_test_split', 'LogisticRegression', 'KNeighborsClassifier', 'SVC', 'GaussianNB', 'DecisionTreeClassifier', 'RandomForestClassifier', 'fit', 'score', 'predict']",24,"[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv print print print imputer fit transform fit transform fillna search group apply replace replace replace labelencoder fit transform fit transform fit transform qcut cut cut print print print print drop drop get dummies get dummies print train test split logisticregression kneighborsclassifier svc svc gaussiannb decisiontreeclassifier randomforestclassifier fit score print kneighborsclassifier fit predict,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08413820214507549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08867292267002697, 0.0, 0.0, 0.0, 0.2200093161896674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09727182951034521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11348025008660528, 0.0, 0.0, 0.0, 0.16024461907087026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05771630955074639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34202454870245536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11987093782050762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.116426411121993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15444520127010733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22348311965012518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1985036389692784, 0.0, 0.0, 0.0, 0.0, 0.11563728854848733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07419222795990861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05069392362582468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47296789661677124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11272488802495655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07169195519092325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08831662086368891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2626699326948173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07456211268100114, 0.0, 0.15444520127010733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07724857931005337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18954311348271968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0805496902507198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07928060950570574, 0.0, 0.0, 0.0, 0.45092201781276714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
shuanggao_titanic-tiro.py,"['numpy', 'pandas', 'os\n', 're\n', 'sklearn', 'matplotlib', 'xgboost']","[1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,441,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# loc[è¡Œæ\xa0‡ç\xad¾ï¼Œåˆ—æ\xa0‡ç\xad¾] æŒ‰ç…§è¡Œåˆ—æ\xa0‡ç\xad¾è¿›è¡Œåˆ‡ç‰‡ï¼Œ', '        # æ•°æ®é›†çš„åå\xad—å¦‚Todoroff, Mr. Lalio æˆ‘ä»¬è¦æ‰¾å‡ºå…¶ä¸\xadçš„Mr åˆ™è¿”å›žgroup(1)', '# print(titanic[features])', '# print(predictions)', '# print(predictions)', '# n_estimators=10 éšæœºæ£®æž—é‡Œè¦æž„å»ºæ\xa0‘çš„ä¸ªæ•°  min_samples_split=2 æ•°æ®æœ€å°åˆ‡åˆ†ä¸ªæ•°  min_samples_leaf=1 å¶å\xadç»“ç‚¹çš„æœ€å°ä¸ªæ•°', ""# features = ['Pclass','Age','Sex','Fare','Embarked','FamilySize','titles']"", '#         test_predictions = model_i.predict(titanic[features].iloc[test,:])', ""# print('æµ‹è¯•æ•°æ®é›†ï¼š\\n',titanic_test)"", '# print(titanic_test.describe())', '# print(titanic_test.describe())', ""# print(titanic['Sex'].unique())"", ""# print(titanic_test['Embarked'].unique())"", '# print(titanic_test.head())', '        # æ•°æ®é›†çš„åå\xad—å¦‚Todoroff, Mr. Lalio æˆ‘ä»¬è¦æ‰¾å‡ºå…¶ä¸\xadçš„Mr åˆ™è¿”å›žgroup(1)', '# print(titles)', '# print(pd.value_counts(titles))', '# print(pd.value_counts(titles))', '    # ç”¨æ•´ä¸ªè®\xadç»ƒé›†å¯¹æ¨¡åž‹è¿›è¡Œè®\xadç»ƒ.', '    # ä½¿ç”¨æµ‹è¯•æ•°æ®é›†è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬å¿…é¡»å°†æ‰€æœ‰åˆ—éƒ½è½¬æ¢ä¸ºæµ®ç‚¹æ•°ä»¥é¿å…é”™è¯¯.']",28,"['os.walk', 'print', 'pd.read_csv', 'print', 'print', 'titanic.fillna', 'print', 'print', 'print', 'titanic.fillna', 'print', 'titanic.apply', 're.search', 'title_search.group', 'titanic.apply', 'print', 'print', 'titles_mapping.items', 'print', 'print', 'print', 'SelectKBest', 'selector.fit', 'np.log10', 'print', 'plt.bar', 'plt.xticks', 'plt.show', 'train_test_split', 'print', 'print', 'print', 'print', 'XGBClassifier', 'None.fit', 'model.predict', 'print', 'print', 'round', 'accuracy_score', 'print', 'LinearRegression', 'KFold', 'kf.split', 'model.fit', 'model.predict', 'predictions.append', 'np.concatenate', 'print', 'print', 'sum', 'len', 'print', 'RandomForestClassifier', 'KFold', 'cross_val_score', 'print', 'train_test_split', 'KNN', 'None.fit', 'model.predict', 'print', 'print', 'round', 'accuracy_score', 'print', 'GradientBoostingClassifier', 'LogisticRegression', 'KFold', 'kf.split', 'model_i.fit', 'model_i.predict_proba', 'full_test_predictions.append', 'predictions.append', 'np.concatenate', 'print', 'print', 'sum', 'len', 'print', 'pd.read_csv', 'titanic_test.fillna', 'titanic_test.fillna', 'titanic_test.apply', 're.search', 'title_search.group', 'titanic_test.apply', 'titles_mapping.items', 'print', 'GradientBoostingClassifier', 'LogisticRegression', 'model_i.fit', 'model_i.predict_proba', 'full_predictions.append', 'print', 'pd.DataFrame', 'print', 'test.to_csv', 'print']","['walk', 'print', 'read_csv', 'print', 'print', 'fillna', 'print', 'print', 'print', 'fillna', 'print', 'apply', 'search', 'group', 'apply', 'print', 'print', 'items', 'print', 'print', 'print', 'SelectKBest', 'fit', 'log10', 'print', 'bar', 'xticks', 'show', 'train_test_split', 'print', 'print', 'print', 'print', 'XGBClassifier', 'fit', 'predict', 'print', 'print', 'round', 'accuracy_score', 'print', 'LinearRegression', 'KFold', 'split', 'fit', 'predict', 'append', 'concatenate', 'print', 'print', 'sum', 'len', 'print', 'RandomForestClassifier', 'KFold', 'cross_val_score', 'print', 'train_test_split', 'KNN', 'fit', 'predict', 'print', 'print', 'round', 'accuracy_score', 'print', 'GradientBoostingClassifier', 'LogisticRegression', 'KFold', 'split', 'fit', 'predict_proba', 'append', 'append', 'concatenate', 'print', 'print', 'sum', 'len', 'print', 'read_csv', 'fillna', 'fillna', 'apply', 'search', 'group', 'apply', 'items', 'print', 'GradientBoostingClassifier', 'LogisticRegression', 'fit', 'predict_proba', 'append', 'print', 'DataFrame', 'print', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'fillna', 'apply', 'search', 'group', 'items', 'SelectKBest', 'fit', 'log10', 'bar', 'xticks', 'show', 'train_test_split', 'XGBClassifier', 'predict', 'round', 'accuracy_score', 'LinearRegression', 'KFold', 'split', 'append', 'concatenate', 'sum', 'len', 'RandomForestClassifier', 'cross_val_score', 'KNN', 'GradientBoostingClassifier', 'LogisticRegression', 'predict_proba', 'DataFrame', 'to_csv']",34,"[1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv print print fillna print print print fillna print apply search group apply print print items print print print selectkbest fit log10 print bar xticks show train test split print print print print xgbclassifier fit predict print print round accuracy score print linearregression kfold split fit predict append concatenate print print sum len print randomforestclassifier kfold cross val score print train test split knn fit predict print print round accuracy score print gradientboostingclassifier logisticregression kfold split fit predict proba append append concatenate print print sum len print read csv fillna fillna apply search group apply items print gradientboostingclassifier logisticregression fit predict proba append print dataframe print csv print,"[0.0, 0.0, 0.11179594137275886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18143840278354964, 0.156940617721787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07085464845547138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17583821554442625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0580982904802068, 0.0, 0.0, 0.06202466405376832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025904669507345122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10765660594812425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1367075900488405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12844547349129493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1440411410841813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1887801655461502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20037236715800494, 0.0, 0.0, 0.10421419151495234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09654836347665911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08791910777221312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0986815403882939, 0.0, 0.0, 0.0, 0.06919433615961326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11819743418780178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7498816372398756, 0.0, 0.1440411410841813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03343124599318735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041183626105859926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10178450364509167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10430895590050383, 0.0, 0.1440411410841813, 0.0, 0.0, 0.0, 0.08308587279540751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045061426901548844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14408959837466412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07317064489770449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07512353379888843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07393994352132395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0580982904802068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043912917061018235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057524163532369756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06125813792600988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
andreoliveira1992_titanic-andre.py,"['random\n', 'time\n', 'warnings\n', 'sys', 'os', 'scipy', 'numpy', 'pandas', 'IPython\n', 'IPython', 'matplotlib', 'seaborn', 'sklearn', 'xgboost', 'subprocess']","[1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",15,329,"['# This Python 2.7.14 environment on ANACONDA 4.5.0 with pip 9.0.3; running in ubuntu LTS with a API_key to kaggle', '# Input data files are available in the /home/ghillaz/.kaggle/competitions/titanic', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# pandas.DataFrame ; pandas.DataFrame.info ; pandas.DataFrame.describe', '# Indexing and Selecting Data', '# pandas.isnull ; pandas.DataFrame.sum ;pandas.DataFrame.mode ; pandas.DataFrame.copy ;', '# pandas.DataFrame.fillna ; pandas.DataFrame.drop ; pandas.Series.value_counts ; pandas.DataFrame.loc', ""    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1"", '    # Age Buckets (6 buckets): 0-13.33;13.33-26.67...', 'cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%']",10,"['warnings.filterwarnings', 'print', 'print', 'os.getcwd', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'pd.read_csv', 'pd.read_csv', 'train.copy', 'print', 'print', 'print', 'print', 'mpl.style.use', 'sns.set_style', 'print', 'print', 'print', 'print', 'print', 'print', 'train.describe', 'dataset.fillna', 'dataset.fillna', 'dataset.fillna', 'train1.drop', 'print', 'print', 'print', 'dataset.str.split', 'None.str.split', 'pd.qcut', 'pd.cut', 'train1.value_counts', 'train1.apply', 'print', 'print', 'train1.info', 'test.info', 'train1.sample', 'LabelEncoder', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'print', 'print', 'pd.get_dummies', 'train1_dummy.columns.tolist', 'print', 'train1_dummy.head', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'train.describe', 'model_selection.train_test_split', 'model_selection.train_test_split', 'model_selection.train_test_split', 'print', 'print', 'print', 'train1_x_bin.head', 'print', 'print', 'print', 'print', 'ensemble.AdaBoostClassifier', 'ensemble.BaggingClassifier', 'ensemble.ExtraTreesClassifier', 'ensemble.GradientBoostingClassifier', 'ensemble.RandomForestClassifier', 'gaussian_process.GaussianProcessClassifier', 'linear_model.LogisticRegressionCV', 'linear_model.PassiveAggressiveClassifier', 'linear_model.RidgeClassifierCV', 'linear_model.SGDClassifier', 'linear_model.Perceptron', 'naive_bayes.BernoulliNB', 'naive_bayes.GaussianNB', 'neighbors.KNeighborsClassifier', 'svm.SVC', 'svm.NuSVC', 'svm.LinearSVC', 'tree.DecisionTreeClassifier', 'tree.ExtraTreeClassifier', 'discriminant_analysis.LinearDiscriminantAnalysis', 'discriminant_analysis.QuadraticDiscriminantAnalysis', 'XGBClassifier', 'model_selection.ShuffleSplit', 'pd.DataFrame', 'str', 'model_selection.cross_validate', 'cv_results.mean', 'cv_results.mean', 'cv_results.mean', 'cv_results.std', 'alg.fit', 'alg.predict', 'MLA_compare.sort_values']","['filterwarnings', 'print', 'print', 'getcwd', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'read_csv', 'read_csv', 'copy', 'print', 'print', 'print', 'print', 'style', 'set_style', 'print', 'print', 'print', 'print', 'print', 'print', 'describe', 'fillna', 'fillna', 'fillna', 'drop', 'print', 'print', 'print', 'str', 'str', 'qcut', 'cut', 'value_counts', 'apply', 'print', 'print', 'info', 'info', 'sample', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'print', 'print', 'get_dummies', 'columns', 'print', 'head', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'describe', 'train_test_split', 'train_test_split', 'train_test_split', 'print', 'print', 'print', 'head', 'print', 'print', 'print', 'print', 'AdaBoostClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 'GaussianProcessClassifier', 'LogisticRegressionCV', 'PassiveAggressiveClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'KNeighborsClassifier', 'SVC', 'NuSVC', 'LinearSVC', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'XGBClassifier', 'ShuffleSplit', 'DataFrame', 'str', 'cross_validate', 'mean', 'mean', 'mean', 'std', 'fit', 'predict', 'sort_values']","['filterwarnings', 'print', 'getcwd', 'read_csv', 'copy', 'style', 'set_style', 'describe', 'fillna', 'drop', 'str', 'qcut', 'cut', 'value_counts', 'apply', 'info', 'sample', 'LabelEncoder', 'fit_transform', 'get_dummies', 'columns', 'head', 'train_test_split', 'AdaBoostClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 'GaussianProcessClassifier', 'LogisticRegressionCV', 'PassiveAggressiveClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'KNeighborsClassifier', 'SVC', 'NuSVC', 'LinearSVC', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'XGBClassifier', 'ShuffleSplit', 'DataFrame', 'cross_validate', 'mean', 'std', 'fit', 'predict', 'sort_values']",53,"[1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",filterwarnings print print getcwd print print print print print print print print print read csv read csv copy print print print print style set style print print print print print print describe fillna fillna fillna drop print print print str str qcut cut value counts apply print print info info sample labelencoder fit transform fit transform fit transform fit transform fit transform print print get dummies columns print head print print print print print print print print describe train test split train test split train test split print print print head print print print print adaboostclassifier baggingclassifier extratreesclassifier gradientboostingclassifier randomforestclassifier gaussianprocessclassifier logisticregressioncv passiveaggressiveclassifier ridgeclassifiercv sgdclassifier perceptron bernoullinb gaussiannb kneighborsclassifier svc nusvc linearsvc decisiontreeclassifier extratreeclassifier lineardiscriminantanalysis quadraticdiscriminantanalysis xgbclassifier shufflesplit dataframe str cross validate mean mean mean std fit predict sort values,"[0.0, 0.0, 0.0, 0.05948135756560258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03396260886655968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085420399313032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09020955508258383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06857988401307039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037073629456246184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040618225067883255, 0.0, 0.0, 0.05029085635161508, 0.0, 0.0, 0.03579306085604401, 0.0, 0.0, 0.0, 0.04440367254261722, 0.0, 0.0, 0.0, 0.022423517151056106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039264032451017714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06400365738031952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022903302242691943, 0.0, 0.0, 0.0, 0.03234158314371203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09020955508258383, 0.07388130759752842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06989202513907093, 0.0, 0.047942265850099, 0.0, 0.0, 0.0, 0.1183363867765434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048386222570407936, 0.085420399313032, 0.0, 0.0, 0.0, 0.0, 0.023497915107905325, 0.085420399313032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05559227993607311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04265097822322015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059015690417249564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04006326066533952, 0.0, 0.0, 0.0, 0.0, 0.04667729879217106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07388130759752842, 0.0, 0.05862745806932224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085420399313032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09651251754404826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09020955508258383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085420399313032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05862745806932224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020462736974656188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8400248922215651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04550170058206325, 0.07388130759752842, 0.0, 0.0, 0.0, 0.0, 0.028938648211545584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035649238685156126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09020955508258383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07610425682044607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03217083918134942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05862745806932224, 0.0, 0.0, 0.0, 0.0, 0.0817056415003294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03684713085490436, 0.0, 0.0, 0.0, 0.09354478290661854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05133165714187559, 0.0, 0.0, 0.14938164725890526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08880734508523444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038254790704131514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09754228951519789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09600548607047928, 0.0, 0.0, 0.0, 0.18201587067297714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085420399313032, 0.040618225067883255, 0.03684713085490436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04979388241963509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
cuijamm_titanic-starter-code-score-0-82296.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'scipy', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,262,[],0,"['get_ipython', 'None.run_line_magic', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'print', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'train.drop', 'test.drop', 'sns.countplot', 'sns.countplot', 'train.drop', 'test.drop', 'sns.lmplot', 'sns.lmplot', 'test.isnull', 'train.drop', 'test.drop', 'plt.subplots', 'figure.set_size_inches', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'plt.subplots', 'figure.set_size_inches', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'train.drop', 'test.drop', 'sns.countplot', 'train.drop', 'test.drop', 'train.str.split', 'None.str.str.split', 'train.str.split', 'None.str.str.split', 'test.str.split', 'None.str.str.split', 'sns.countplot', 'train.drop', 'test.drop', 'train.drop', 'test.drop', 'list', 'print', 'Xtrain.head', 'DecisionTreeClassifier', 'model.fit', 'model.predict', 'submission.to_csv', 'submission.head']","['get_ipython', 'run_line_magic', 'walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'print', 'isnull', 'sum', 'isnull', 'sum', 'drop', 'drop', 'countplot', 'countplot', 'drop', 'drop', 'lmplot', 'lmplot', 'isnull', 'drop', 'drop', 'subplots', 'set_size_inches', 'countplot', 'countplot', 'countplot', 'subplots', 'set_size_inches', 'countplot', 'countplot', 'countplot', 'drop', 'drop', 'countplot', 'drop', 'drop', 'str', 'str', 'str', 'str', 'str', 'str', 'countplot', 'drop', 'drop', 'drop', 'drop', 'list', 'print', 'head', 'DecisionTreeClassifier', 'fit', 'predict', 'to_csv', 'head']","['get_ipython', 'run_line_magic', 'walk', 'print', 'read_csv', 'isnull', 'sum', 'drop', 'countplot', 'lmplot', 'subplots', 'set_size_inches', 'str', 'list', 'head', 'DecisionTreeClassifier', 'fit', 'predict', 'to_csv']",19,"[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic walk print read csv read csv read csv print isnull sum isnull sum drop drop countplot countplot drop drop lmplot lmplot isnull drop drop subplots set size inches countplot countplot countplot subplots set size inches countplot countplot countplot drop drop countplot drop drop str str str str str str countplot drop drop drop drop list print head decisiontreeclassifier fit predict csv head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5851147879027564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10526111592340262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057734317387233516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4714821717720581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029000547006722836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03455162407148306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06271452420704059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23135603846609049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043602487016027654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14042959804793292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044255286450942705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06746901107624734, 0.0, 0.24028196515945305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044035746610973175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030088660724801774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08421701985467676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07862862010274875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043818158262061806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09460879710848613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1700244514745093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43930523159751794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12200593866100683, 0.09313259312566316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05589295875856229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ristola_titanic.py,"['pandas', 'numpy', 're\n', 'matplotlib', 'sklearn', 'seaborn', 'IPython', 'xgboost', 'scipy']","[1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,1615,"['    width = 0.4 # the width of the bars ', '    ind = np.arange(len(y)) # the x locations for the groups', '    # Our priors Beta distribution parameters', '        # Update our parameters', '        # Run CV', '        # Update best result', '        # Update our parameters', '        # Run CV', '        # Update best result', '# The real work begins with reading the data', '# Combine the train and test data into one file for some preprocessing', 'SibSp    # of siblings / spouses aboard the Titanic  - Interval', 'Parch    # of parents / children aboard the Titanic  - Intervall', '# Filling the missing value in Fare with the median Fare of 3rd class alone passenger', '    # Parameters that we are going to tune.', '    # Initial xgboost parameters to be tuned']",16,"['get_ipython', 'None.run_line_magic', 'pd.DataFrame', 'preprocessing.StandardScaler', 'pd.DataFrame', 'dfcol.astype', 'pd.concat', 'None.drop', 'pd.concat', 'df_encode.columns.str.startswith', 'None.tolist', 'pd.DataFrame', 'pd.concat', 'scale', 'scale', 'list', 'list', 'list', 'pd.option_context', 'display', 'SelectKBest', 'selector.fit', 'selector.get_support', 'pd.DataFrame', 'features_df.sort_values', 'features_df.reset_index', 'plt.subplots', 'np.arange', 'ax.barh', 'ax.set_yticks', 'ax.set_yticklabels', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'fig.set_size_inches', 'plt.plot', 'model.predict', 'metrics.roc_curve', 'metrics.auc', 'plt.figure', 'plt.title', 'plt.plot', 'plt.legend', 'plt.plot', 'plt.xlim', 'plt.ylim', 'plt.ylabel', 'plt.xlabel', 'plt.show', 'model.predict', 'np.where', 'confusion_matrix', 'None.ravel', 'stats.beta', 'posterior_distr.interval', 'proportion_confint', 'print', 'print', 'print', 'print', 'print', 'print', 'pd.DataFrame', 'plt.figure', 'sns.heatmap', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'model.predict', 'np.where', 'testtarget.copy', 'submissiontarget.astype', 'submission.sort_values', 'None.reset_index', 'model.predict', 'np.where', 'plt.hist', 'plt.ylabel', 'plt.legend', 'plt.title', 'plt.show', 'model.predict', 'pd.concat', 'df.sort_values', 'df.reset_index', 'float', 'float', 'print', 'xgb.cv', 'cv_resultsresult_col.min', 'cv_resultsresult_col.argmin', 'cv_resultsresult_col.max', 'cv_resultsresult_col.argmin', 'print', 'print', 'float', 'float', 'print', 'xgb.cv', 'cv_resultsresult_col.min', 'cv_resultsresult_col.argmin', 'cv_resultsresult_col.max', 'cv_resultsresult_col.argmax', 'print', 'print', 'xgb.train', 'print', 'range', 'range', 'range', 'range', 'range', 'print', 'range', 'range', 'range', 'range', 'range', 'xgb.cv', 'print', 'range', 'two_values', 'one_value', 'two_values', 'two_values', 'one_value', 'params.startswith', 'one_value', 'print', 'print', 'print', 'xgb.train', 'xgb.train', 'pd.read_csv', 'pd.read_csv', 'pd.concat', 'train.isnull', 'None.sum', 'None.sort_values', 'test.isnull', 'None.sum', 'None.sort_values', 'train.dropna', 'None.copy', 'test.dropna', 'None.copy', 'scale_data', 'plt.subplots', 'ax1.set_ylim', 'ax1.set_title', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'ax2.set_title', 'ax2.set_ylim', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'plt.show', 'df.isnull', 'dfcolumn.fillna', 'df.head', 'ticket.upper', 'ticket.replace', 'ticket.replace', 'ticket.split', 'len', 'pd.Series', 'ticket.isdigit', 'pd.Series', 'pd.Series', 'dfcolumn.apply', 'dfcategory.value_counts', 'None.head', 'None.index.tolist', 'dfcategory.isin', 'dfcolumn.apply', 'dfcolumn.str.extract', 'extracted_titles.map', 'dfcolumn.str.split', 'dfcolumn.str.split', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'plt.show', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'plt.show', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'pd.concat', 'np.where', 'np.where', 'df.groupby', 'None.transform', 'np.where', 'calculate_familygroup', 'None.copy', 'calculate_familygroup', 'None.copy', 'df.groupby', 'None.median', 'df.isna', 'df.groupby', 'None.median', 'df.groupby', 'None.median', 'df.groupby', 'None.median', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'df.groupby', 'group.value_counts', 'None.keys', 'None.tolist', 'values.extend', 'find_families', 'len', 'df.isin', 'df.isin', 'None.apply', 'find_families', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'plt.show', 'print', 'print', 'print', 'print', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'ax.set_title', 'plt.show', 'df.groupby', 'None.agg', 'grouped_median_train.reset_index', 'print', 'dftarget.notnull', 'None.copy', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'MinMaxScaler', 'scale_data', 'select_kbest', 'features_dffeatures_df.tolist', 'tr_trainselected_columns.copy', 'tr_testselected_columns.copy', 'train_test_split', 'xgb.DMatrix', 'xgb.DMatrix', 'xgb.DMatrix', 'xgb.DMatrix', 'draw_features', 'hyperparameter_grid', 'xgb.plot_importance', 'draw_true_vs_predicted', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'predict_and_store', 'df.apply', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.DataFrame', 'temp_group_df.reset_index', 'temp_group_df.drop', 'temp_group_df.sort_values', 'None.reset_index', 'pd.DataFrame', 'None.reset_index', 'temp_df.sort_values', 'None.reset_index', 'pd.merge', 'temp_group_dfcol_name.fillna', 'pd.merge', 'df.reset_index', 'df.str.startswith', 'create_groupvalue', 'None.copy', 'df.str.startswith', 'create_groupvalue', 'None.copy', 'create_groupvalue', 'None.copy', 'create_familygroup', 'None.copy', 'create_familygroup', 'None.copy', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'dfcolumn.fillna', 'dfcolumn.str.map', 'dfdftargettarget.copy', 'dfdftargetfeatures.copy', 'dfdftargetfeatures.copy', 'MinMaxScaler', 'len', 'scale_data', 'select_kbest', 'features_dffeatures_df.tolist', 'tr_trainselected_columns.copy', 'tr_testselected_columns.copy', 'train_test_split', 'xgb.DMatrix', 'xgb.DMatrix', 'xgb.DMatrix', 'xgb.DMatrix', 'draw_features', 'hyperparameter_grid', 'xgb.plot_importance', 'draw_true_vs_predicted', 'model.predict', 'proportion_confint', 'print', 'print', 'print', 'print', 'print', 'dfdftarget.copy', 'dfdftarget.copy', 'predict_and_store', 'dftarget.map', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'scale_data', 'plt.subplots', 'ax1.set_ylim', 'ax1.set_title', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'ax2.set_title', 'ax2.set_ylim', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'plt.show', 'dftarget.notnull', 'None.copy', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'MinMaxScaler', 'scale_data', 'select_kbest', 'features_dffeatures_df.tolist', 'tr_trainselected_columns.copy', 'tr_testselected_columns.copy', 'train_test_split', 'xgb.DMatrix', 'xgb.DMatrix', 'xgb.DMatrix', 'xgb.DMatrix', 'draw_features', 'hyperparameter_grid', 'xgb.plot_importance', 'draw_true_vs_predicted', 'draw_results', 'draw_confusion', 'dftarget.notnull', 'None.copy', 'dftarget.isnull', 'None.copy', 'create_submission', 'submission.to_csv', 'print']","['get_ipython', 'run_line_magic', 'DataFrame', 'StandardScaler', 'DataFrame', 'astype', 'concat', 'drop', 'concat', 'columns', 'tolist', 'DataFrame', 'concat', 'scale', 'scale', 'list', 'list', 'list', 'option_context', 'display', 'SelectKBest', 'fit', 'get_support', 'DataFrame', 'sort_values', 'reset_index', 'subplots', 'arange', 'barh', 'set_yticks', 'set_yticklabels', 'title', 'xlabel', 'ylabel', 'set_size_inches', 'plot', 'predict', 'roc_curve', 'auc', 'figure', 'title', 'plot', 'legend', 'plot', 'xlim', 'ylim', 'ylabel', 'xlabel', 'show', 'predict', 'where', 'confusion_matrix', 'ravel', 'beta', 'interval', 'proportion_confint', 'print', 'print', 'print', 'print', 'print', 'print', 'DataFrame', 'figure', 'heatmap', 'xlabel', 'ylabel', 'show', 'predict', 'where', 'copy', 'astype', 'sort_values', 'reset_index', 'predict', 'where', 'hist', 'ylabel', 'legend', 'title', 'show', 'predict', 'concat', 'sort_values', 'reset_index', 'float', 'float', 'print', 'cv', 'min', 'argmin', 'max', 'argmin', 'print', 'print', 'float', 'float', 'print', 'cv', 'min', 'argmin', 'max', 'argmax', 'print', 'print', 'train', 'print', 'range', 'range', 'range', 'range', 'range', 'print', 'range', 'range', 'range', 'range', 'range', 'cv', 'print', 'range', 'two_values', 'one_value', 'two_values', 'two_values', 'one_value', 'startswith', 'one_value', 'print', 'print', 'print', 'train', 'train', 'read_csv', 'read_csv', 'concat', 'isnull', 'sum', 'sort_values', 'isnull', 'sum', 'sort_values', 'dropna', 'copy', 'dropna', 'copy', 'scale_data', 'subplots', 'set_ylim', 'set_title', 'kdeplot', 'kdeplot', 'kdeplot', 'kdeplot', 'kdeplot', 'set_title', 'set_ylim', 'kdeplot', 'kdeplot', 'kdeplot', 'kdeplot', 'kdeplot', 'show', 'isnull', 'fillna', 'head', 'upper', 'replace', 'replace', 'split', 'len', 'Series', 'isdigit', 'Series', 'Series', 'apply', 'value_counts', 'head', 'index', 'isin', 'apply', 'str', 'map', 'str', 'str', 'notnull', 'copy', 'isnull', 'copy', 'crosstab', 'plot', 'crosstab', 'plot', 'subplots', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'set_title', 'show', 'subplots', 'distplot', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'distplot', 'set_title', 'show', 'crosstab', 'plot', 'crosstab', 'concat', 'where', 'where', 'groupby', 'transform', 'where', 'calculate_familygroup', 'copy', 'calculate_familygroup', 'copy', 'groupby', 'median', 'isna', 'groupby', 'median', 'groupby', 'median', 'groupby', 'median', 'crosstab', 'plot', 'crosstab', 'groupby', 'value_counts', 'keys', 'tolist', 'extend', 'find_families', 'len', 'isin', 'isin', 'apply', 'find_families', 'notnull', 'copy', 'isnull', 'copy', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'subplots', 'distplot', 'distplot', 'set_title', 'show', 'print', 'print', 'print', 'print', 'subplots', 'distplot', 'distplot', 'set_title', 'distplot', 'distplot', 'set_title', 'show', 'groupby', 'agg', 'reset_index', 'print', 'notnull', 'copy', 'notnull', 'copy', 'isnull', 'copy', 'MinMaxScaler', 'scale_data', 'select_kbest', 'tolist', 'copy', 'copy', 'train_test_split', 'DMatrix', 'DMatrix', 'DMatrix', 'DMatrix', 'draw_features', 'hyperparameter_grid', 'plot_importance', 'draw_true_vs_predicted', 'notnull', 'copy', 'isnull', 'copy', 'predict_and_store', 'apply', 'notnull', 'copy', 'isnull', 'copy', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'DataFrame', 'reset_index', 'drop', 'sort_values', 'reset_index', 'DataFrame', 'reset_index', 'sort_values', 'reset_index', 'merge', 'fillna', 'merge', 'reset_index', 'str', 'create_groupvalue', 'copy', 'str', 'create_groupvalue', 'copy', 'create_groupvalue', 'copy', 'create_familygroup', 'copy', 'create_familygroup', 'copy', 'notnull', 'copy', 'isnull', 'copy', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'fillna', 'str', 'copy', 'copy', 'copy', 'MinMaxScaler', 'len', 'scale_data', 'select_kbest', 'tolist', 'copy', 'copy', 'train_test_split', 'DMatrix', 'DMatrix', 'DMatrix', 'DMatrix', 'draw_features', 'hyperparameter_grid', 'plot_importance', 'draw_true_vs_predicted', 'predict', 'proportion_confint', 'print', 'print', 'print', 'print', 'print', 'copy', 'copy', 'predict_and_store', 'map', 'notnull', 'copy', 'isnull', 'copy', 'scale_data', 'subplots', 'set_ylim', 'set_title', 'kdeplot', 'kdeplot', 'kdeplot', 'kdeplot', 'set_title', 'set_ylim', 'kdeplot', 'kdeplot', 'kdeplot', 'kdeplot', 'show', 'notnull', 'copy', 'notnull', 'copy', 'isnull', 'copy', 'MinMaxScaler', 'scale_data', 'select_kbest', 'tolist', 'copy', 'copy', 'train_test_split', 'DMatrix', 'DMatrix', 'DMatrix', 'DMatrix', 'draw_features', 'hyperparameter_grid', 'plot_importance', 'draw_true_vs_predicted', 'draw_results', 'draw_confusion', 'notnull', 'copy', 'isnull', 'copy', 'create_submission', 'to_csv', 'print']","['get_ipython', 'run_line_magic', 'DataFrame', 'StandardScaler', 'astype', 'concat', 'drop', 'columns', 'tolist', 'scale', 'list', 'option_context', 'display', 'SelectKBest', 'fit', 'get_support', 'sort_values', 'reset_index', 'subplots', 'arange', 'barh', 'set_yticks', 'set_yticklabels', 'title', 'xlabel', 'ylabel', 'set_size_inches', 'plot', 'predict', 'roc_curve', 'auc', 'figure', 'legend', 'xlim', 'ylim', 'show', 'where', 'confusion_matrix', 'ravel', 'beta', 'interval', 'proportion_confint', 'print', 'heatmap', 'copy', 'hist', 'float', 'cv', 'min', 'argmin', 'max', 'argmax', 'train', 'range', 'two_values', 'one_value', 'startswith', 'read_csv', 'isnull', 'sum', 'dropna', 'scale_data', 'set_ylim', 'set_title', 'kdeplot', 'fillna', 'head', 'upper', 'replace', 'split', 'len', 'Series', 'isdigit', 'apply', 'value_counts', 'index', 'isin', 'str', 'map', 'notnull', 'crosstab', 'distplot', 'groupby', 'transform', 'calculate_familygroup', 'median', 'isna', 'keys', 'extend', 'find_families', 'agg', 'MinMaxScaler', 'select_kbest', 'train_test_split', 'DMatrix', 'draw_features', 'hyperparameter_grid', 'plot_importance', 'draw_true_vs_predicted', 'predict_and_store', 'merge', 'create_groupvalue', 'create_familygroup', 'draw_results', 'draw_confusion', 'create_submission', 'to_csv']",107,"[1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1
 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic dataframe standardscaler dataframe astype concat drop concat columns tolist dataframe concat scale scale list list list option context display selectkbest fit get support dataframe sort values reset index subplots arange barh set yticks set yticklabels title xlabel ylabel set size inches plot predict roc curve auc figure title plot legend plot xlim ylim ylabel xlabel show predict confusion matrix ravel beta interval proportion confint print print print print print print dataframe figure heatmap xlabel ylabel show predict copy astype sort values reset index predict hist ylabel legend title show predict concat sort values reset index float float print cv min argmin max argmin print print float float print cv min argmin max argmax print print train print range range range range range print range range range range range cv print range two values one value two values two values one value startswith one value print print print train train read csv read csv concat isnull sum sort values isnull sum sort values dropna copy dropna copy scale data subplots set ylim set title kdeplot kdeplot kdeplot kdeplot kdeplot set title set ylim kdeplot kdeplot kdeplot kdeplot kdeplot show isnull fillna head upper replace replace split len series isdigit series series apply value counts head index isin apply str map str str notnull copy isnull copy crosstab plot crosstab plot subplots distplot distplot set title distplot distplot set title show subplots distplot distplot distplot set title distplot distplot distplot set title distplot distplot distplot set title distplot distplot distplot set title distplot distplot distplot set title distplot distplot distplot set title show crosstab plot crosstab concat groupby transform calculate familygroup copy calculate familygroup copy groupby median isna groupby median groupby median groupby median crosstab plot crosstab groupby value counts keys tolist extend find families len isin isin apply find families notnull copy isnull copy crosstab plot crosstab plot crosstab plot crosstab plot subplots distplot distplot set title show print print print print subplots distplot distplot set title distplot distplot set title show groupby agg reset index print notnull copy notnull copy isnull copy minmaxscaler scale data select kbest tolist copy copy train test split dmatrix dmatrix dmatrix dmatrix draw features hyperparameter grid plot importance draw true vs predicted notnull copy isnull copy predict store apply notnull copy isnull copy crosstab plot crosstab plot crosstab plot dataframe reset index drop sort values reset index dataframe reset index sort values reset index merge fillna merge reset index str create groupvalue copy str create groupvalue copy create groupvalue copy create familygroup copy create familygroup copy notnull copy isnull copy crosstab plot crosstab plot crosstab plot crosstab plot crosstab plot fillna str copy copy copy minmaxscaler len scale data select kbest tolist copy copy train test split dmatrix dmatrix dmatrix dmatrix draw features hyperparameter grid plot importance draw true vs predicted predict proportion confint print print print print print copy copy predict store map notnull copy isnull copy scale data subplots set ylim set title kdeplot kdeplot kdeplot kdeplot set title set ylim kdeplot kdeplot kdeplot kdeplot show notnull copy notnull copy isnull copy minmaxscaler scale data select kbest tolist copy copy train test split dmatrix dmatrix dmatrix dmatrix draw features hyperparameter grid plot importance draw true vs predicted draw results draw confusion notnull copy isnull copy create submission csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018106816949855584, 0.0, 0.0, 0.0, 0.0, 0.035056860784642895, 0.01608770980881721, 0.0, 0.02327901123850755, 0.06983703371552266, 0.0, 0.0, 0.0, 0.0, 0.015380022436054427, 0.018559439347451957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02327901123850755, 0.0, 0.0, 0.0, 0.0, 0.02502086479937666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05004172959875332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017697370186720168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05409306815507878, 0.0, 0.05004172959875332, 0.028340974861041975, 0.0, 0.020301292908321066, 0.0, 0.39224819227785396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020963458183068568, 0.11783442551287782, 0.0, 0.0, 0.0, 0.21495205255627614, 0.013854858254743217, 0.0, 0.0, 0.018559439347451957, 0.0, 0.06983703371552266, 0.08043854904408607, 0.0, 0.04050547806181968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017697370186720168, 0.3529120752382117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27934813486209065, 0.1763451717535214, 0.0, 0.011820615450735015, 0.02013133620316647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019065428139003693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05004172959875332, 0.0, 0.10008345919750664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0609038787249632, 0.0, 0.02039985427340357, 0.0, 0.0, 0.0, 0.018035974539559636, 0.0, 0.0, 0.042169070560084135, 0.0, 0.0, 0.005089545993166771, 0.0, 0.07423775738980783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012127500892287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05719628441701108, 0.0, 0.0, 0.0, 0.05603815824765411, 0.0, 0.07506259439812997, 0.0, 0.0, 0.011006290857800385, 0.011107698212160295, 0.0, 0.010942449398160215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07506259439812997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05891721275643891, 0.0, 0.0, 0.0, 0.0, 0.020301292908321066, 0.12371733177292209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02502086479937666, 0.0, 0.007652161286236618, 0.0, 0.021084535280042067, 0.0, 0.0609038787249632, 0.0, 0.015827270103215888, 0.0, 0.09858060924177629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07506259439812997, 0.33406990825413524, 0.0, 0.0, 0.0, 0.022043146469190176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017725953549710734, 0.03234996701159727, 0.0, 0.0, 0.0, 0.0, 0.007766726461422562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035522085315125546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007728197598067041, 0.0, 0.0, 0.01617613588993619, 0.0, 0.01338724505879999, 0.0, 0.031163442034530947, 0.0, 0.0, 0.0, 0.0, 0.04620388578036589, 0.0, 0.0, 0.04060258581664213, 0.03332270517725298, 0.05093914785331293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20415383282197153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07506259439812997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01697971595110431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19498548904681806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04224406459538002, 0.07506259439812997, 0.0, 0.0, 0.0, 0.0, 0.14287277041010235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05004172959875332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11450479401474858, 0.0, 0.020301292908321066, 0.0, 0.00919945816422951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018240591130681546, 0.0, 0.0, 0.12455880710756727, 0.0, 0.0, 0.020301292908321066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017323574578134583, 0.0, 0.0, 0.0, 0.0, 0.0076900112180272135, 0.0, 0.0, 0.0, 0.0, 0.14210905035824747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05093914785331293, 0.0, 0.018559439347451957, 0.0, 0.0, 0.0, 0.0, 0.0338386761241884, 0.182640488313279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09059101291424912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014919499027757379, 0.0, 0.0, 0.0, 0.06656006015604171, 0.0, 0.0, 0.0, 0.032186243842179454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014170487430520988, 0.02327901123850755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05004172959875332, 0.07709731063817642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02327901123850755, 0.0, 0.0, 0.07494141149777468, 0.01634460950223001, 0.0, 0.0, 0.02327901123850755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025171258762725413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15601811701939913, 0.0, 0.0, 0.0, 0.0, 0.09053408474927792, 0.0, 0.0, 0.0, 0.0, 0.0495493584276539, 0.0, 0.0, 0.0, 0.009394014847105727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07506259439812997, 0.0, 0.07506259439812997, 0.0, 0.0, 0.0, 0.0, 0.022043146469190176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052408645457671425, 0.09508580022291674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07506259439812997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035522085315125546, 0.018106816949855584, 0.0, 0.0, 0.0, 0.04583432835709263, 0.0, 0.09819535459406485, 0.022043146469190176, 0.017697370186720168, 0.0, 0.0, 0.0, 0.0]"
nazimonderorhan_getting-started-with-titanic.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,82,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'sum', 'len', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",12,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head sum len print sum len print get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29651471721459643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12383969942746267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3572295914637062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10892390691892337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2595466825772223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23555110859145806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615584966167075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1130107814636607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4217505198327656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1598212034362369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19688218283721298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3497991228367539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20992981393866597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
crystaliu_titanic-survival-analytics.py,"['pandas', 'numpy', 'seaborn', 'sklearn', 'matplotlib', 'some']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,913,"['sibsp    # of siblings / spouses aboard the Titanic  ', 'parch    # of parents / children aboard the Titanic  ', ""age = td['Age'].dropna() # do it since seaborn can't create plot with NaN in the variable"", ""nuvar[0] = 'Age_all'   # replace age with age_all because seaborn.pairplot() doesn't work well with NaN"", ""td['Pclass'] = td['Pclass'].astype('category') # Convert Pclass from int type to category"", ""td['Embarked'] = td['Embarked'].fillna('S')  # Use the mode to fill the missing values"", ""# 'PassengerId',"", ""# 'Survived',"", ""# 'Name',"", ""# 'Age',"", ""# 'Ticket',"", ""# 'Cabin',"", 'td[feature_list].info()   # no missing values', ""# 'Pclass_3',"", ""# 'Sex_male',"", '# plot TPR against FPR', '# plot 45 degree line', '# import some data to play with', '# Split the data into a training set and a test set', '# Run classifier', '# Compute confusion matrix', '# Show confusion matrix in a separate window', ""# 'Name',"", ""# 'Ticket',"", ""# 'Cabin',"", ""# 'PassengerId',"", ""# 'Pclass_3',"", ""# 'Sex_male',"", ""# 'Embarked_S'""]",29,"['pd.read_csv', 'td.head', 'td.info', 'td.value_counts', 'td.dropna', 'sns.distplot', 'td.interpolate', 'td.interpolate', 'td.interpolate', 'sns.distplot', 'td.interpolate', 'td.value_counts', 'sns.distplot', 'td.apply', 'td.value_counts', 'td.astype', 'td.value_counts', 'sns.distplot', 'td.apply', 'td.value_counts', 'td.astype', 'td.value_counts', 'sns.distplot', 'sns.pairplot', 'td.corr', 'sns.heatmap', 'list', 'td.value_counts', 'td.value_counts', 'td.astype', 'sns.barplot', 'td.value_counts', 'sns.barplot', 'td.value_counts', 'td.value_counts', 'num.append', 'td.value_counts', 'td.fillna', 'sns.barplot', 'list', 'tdfeature_list.info', 'pd.get_dummies', 'list', 'list', 'StandardScaler', 'scaler.fit_transform', 'train_test_split', 'LogisticRegression', 'lr.fit', 'lr.predict', 'lr.predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print_results', 'print', 'print_results', 'lr.predict_proba', 'roc_curve', 'get_ipython', 'None.run_line_magic', 'plt.style.use', 'plt.plot', 'np.linspace', 'plt.plot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'pd.DataFrame', 'None.sort_values', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'rf.predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print_results', 'print', 'print_results', 'rf.predict_proba', 'confusion_matrix', 'confusion_matrix', 'print', 'plt.matshow', 'plt.title', 'plt.colorbar', 'plt.ylabel', 'plt.xlabel', 'plt.show', 'pd.DataFrame', 'None.sort_values', 'pd.read_csv', 'testd.info', 'list', 'testd.interpolate', 'testd.fillna', 'testd.astype', 'testd.info', 'pd.get_dummies', 'list', 'rf.predict', 'pd.DataFrame', 'my_submission.to_csv']","['read_csv', 'head', 'info', 'value_counts', 'dropna', 'distplot', 'interpolate', 'interpolate', 'interpolate', 'distplot', 'interpolate', 'value_counts', 'distplot', 'apply', 'value_counts', 'astype', 'value_counts', 'distplot', 'apply', 'value_counts', 'astype', 'value_counts', 'distplot', 'pairplot', 'corr', 'heatmap', 'list', 'value_counts', 'value_counts', 'astype', 'barplot', 'value_counts', 'barplot', 'value_counts', 'value_counts', 'append', 'value_counts', 'fillna', 'barplot', 'list', 'info', 'get_dummies', 'list', 'list', 'StandardScaler', 'fit_transform', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print_results', 'print', 'print_results', 'predict_proba', 'roc_curve', 'get_ipython', 'run_line_magic', 'style', 'plot', 'linspace', 'plot', 'xlabel', 'ylabel', 'title', 'show', 'DataFrame', 'sort_values', 'RandomForestClassifier', 'fit', 'predict', 'predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print_results', 'print', 'print_results', 'predict_proba', 'confusion_matrix', 'confusion_matrix', 'print', 'matshow', 'title', 'colorbar', 'ylabel', 'xlabel', 'show', 'DataFrame', 'sort_values', 'read_csv', 'info', 'list', 'interpolate', 'fillna', 'astype', 'info', 'get_dummies', 'list', 'predict', 'DataFrame', 'to_csv']","['read_csv', 'head', 'info', 'value_counts', 'dropna', 'distplot', 'interpolate', 'apply', 'astype', 'pairplot', 'corr', 'heatmap', 'list', 'barplot', 'append', 'fillna', 'get_dummies', 'StandardScaler', 'fit_transform', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'print_results', 'predict_proba', 'roc_curve', 'get_ipython', 'run_line_magic', 'style', 'plot', 'linspace', 'xlabel', 'ylabel', 'title', 'show', 'DataFrame', 'sort_values', 'RandomForestClassifier', 'confusion_matrix', 'matshow', 'colorbar', 'to_csv']",43,"[1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv head info value counts dropna distplot interpolate interpolate interpolate distplot interpolate value counts distplot apply value counts astype value counts distplot apply value counts astype value counts distplot pairplot corr heatmap list value counts value counts astype barplot value counts barplot value counts value counts append value counts fillna barplot list info get dummies list list standardscaler fit transform train test split logisticregression fit predict predict print print print print print print print results print print results predict proba roc curve get ipython run line magic style plot linspace plot xlabel ylabel title show dataframe sort values randomforestclassifier fit predict predict print print print print print print print results print print results predict proba confusion matrix confusion matrix print matshow title colorbar ylabel xlabel show dataframe sort values read csv info list interpolate fillna astype info get dummies list predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034795280476883045, 0.06019445418464597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10563319534776602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12198653782377972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06373504623564615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09732585717250052, 0.0, 0.0, 0.0, 0.0, 0.040662179274593244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4319441826480643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047579025148494915, 0.0, 0.0, 0.06373504623564615, 0.0, 0.0, 0.0, 0.0, 0.05961429734879189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21641728475097388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034566551814247184, 0.0, 0.0, 0.05732138989828715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0412916090715707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05243409185808188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062470650294633265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018898374125756786, 0.03814499166004363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10459789137383275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3997127364222082, 0.0, 0.0, 0.0, 0.02627831823205751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02667174696666385, 0.0, 0.0, 0.0, 0.0, 0.06373504623564615, 0.24397307564755943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026539434840128183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026539434840128183, 0.0, 0.0, 0.0, 0.0, 0.09194638553644503, 0.06547266440506008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059490957998990276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06087276926373511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1269366999612834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3214537686208961, 0.0, 0.11049373952466882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025645057786632897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03159189674124277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27886701056686386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059490957998990276, 0.0, 0.0, 0.0, 0.0, 0.026408298836941506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06913310362849437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06530690674546734, 0.0, 0.0, 0.0, 0.027632727759563575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04866292858625026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03934996341120815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028813574070813225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05953138343885403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02835960892290903, 0.0, 0.0, 0.0, 0.03226002463812733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4319441826480643, 0.06530690674546734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08132435854918649, 0.0, 0.0, 0.0, 0.0, 0.0786999268224163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
valentindb_homework-1-titanic.py,"['pandas', 'numpy', 'seaborn', 'matplotlib\n', 'pydot\n', 're\n', 'fastai', 'matplotlib', 'warnings\n', 'keras\n', 'keras', 'sklearn\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",13,589,"['# Ignore warnings', '# Display some statistics', '# Display missing data', ""# Let's plot some histograms to have a previzualisation of some of the data ..."", '    # Introducing a new feature : the size of families (including the passenger)', '    # Introducing other features based on the family size', '    # Deal with missing values', '    # Replacing missing cabins with U (for Uknown)', ""   # processed_df.Cabin.fillna('U', inplace=True)"", '    # Mapping each Cabin value with the cabin letter', ""   # processed_df['Cabin'] = processed_df['Cabin'].map(lambda c: c[0])"", '    # Dummy encoding ...', ""   # cabin_dummies = pd.get_dummies(processed_df['Cabin'], prefix='Cabin')    "", '   # processed_df = pd.concat([processed_df, cabin_dummies], axis=1)', '    # Get Title and Status from Name', '    # fills the missing values of the Age variable', ""# Let's divide the train dataset in two datasets to evaluate perfomance of machine learning models used"", '# Split dataset for prediction', '# Create and train model on train data sample', '# Predict for test data sample', '# Compute error between predicted data and true response and display it in confusion matrix', '# Predicting the Test set results', 'm_prediction = (m_prediction > 0.5) # convert probabilities to binary output', '# Compute error between predicted data and true response and display it in confusion matrix', '    # Initializing our ANN', '    # Adding the input layer and the first hidden layer of our ANN with dropout', '    # Dropout will disable some neurons (here 50% of all neurons) to avoid overfitting', '    # Add other layers, it is not necessary to pass the shape because there is a layer before', '    # Adding the output layer', '    # Compilling the ANN', '# Training the ANN', '# Predicting the Test set results', 'ann_prediction = (ann_prediction > 0.5) # convert probabilities to binary output', '# Compute error between predicted data and true response and display it in confusion matrix', 'm_prediction = (m_prediction > 0.5) # convert probabilities to binary output', '# Number of trees in random forest', '# Number of features to consider at every split', '# Maximum number of levels in tree', '# Minimum number of samples required to split a node', '# Minimum number of samples required at each leaf node', '# Method of selecting samples for training each tree', '# Create the random grid', '# Use the random grid to search for best hyperparameters', '# First create the base model to tune', '# Random search of parameters, using 3 fold cross validation, ', '# search across 100 different combinations, and use all available cores', '# Fit the random search model', '# Create the parameter grid based on the results of random search ', '# Instantiate the grid search model', '# Fit the grid search to the data', '# Create and train model on train data sample', '# Predict for test data sample']",52,"['get_ipython', 'None.system', 'get_ipython', 'None.system', 'get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'metrics.confusion_matrix', 'plt.figure', 'sns.heatmap', 'plt.ylabel', 'plt.xlabel', '.format', 'plt.title', 'print', 'pd.read_csv', 'pd.read_csv', 'train_df_raw.head', 'train_df_raw.describe', 'train_df_raw.info', 'df.isnull', 'None.sum', 'None.sort_values', 'df.isnull', 'None.sum', 'df.isnull', 'None.count', 'None.sort_values', 'pd.concat', 'draw_missing_data_table', 'train_df_raw.value_counts', 'train_df_raw.drop', 'None.hist', 'plt.show', 'train_cats', 'proc_df', 'processed_df.map', 'processed_df.map', 'processed_df.map', 'processed_df.fillna', 'pd.get_dummies', 'pd.concat', 'pd.Series', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'processed_df.replace', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'processed_df.groupby', 'grouped_train.median', 'grouped_median_train.reset_index', 'np.isnan', 'print', 'processed_df.apply', 'processed_df.drop', 'train_df_raw.copy', 'train_df.drop', 'X1.append', 'preprocess_data', 'StandardScaler', 'pd.DataFrame', 'X1.copy', 'X1.copy', 'train_test_split', 'X_train.head', 'DecisionTreeClassifier', 'dt.fit', 'dt.predict', 'metrics.accuracy_score', 'display_confusion_matrix', 'RandomForestClassifier', 'm.fit', 'm.score', 'm.predict', 'metrics.accuracy_score', 'display_confusion_matrix', 'Sequential', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.add', 'ann.compile', 'build_ann', 'ann.fit', 'ann.predict', 'metrics.accuracy_score', 'display_confusion_matrix', 'cross_val_score', 'cross_val_score', 'cross_val_score', 'acc.mean', 'accuracies.items', 'acc.std', 'accuracies.items', 'print', 'plt.figure', 'plt.plot', 'plt.plot', 'plt.plot', 'plt.title', 'plt.ylabel', 'plt.xlabel', 'plt.xticks', 'plt.legend', 'plt.show', 'print', 'int', 'np.linspace', 'int', 'np.linspace', 'max_depth.append', 'RandomizedSearchCV', 'rf_random.fit', 'model.predict', 'abs', 'np.mean', 'print', 'print', 'print', 'evaluate', 'GridSearchCV', 'grid_search.fit', 'evaluate', 'pd.DataFrame', 'model_test.fit', 'model_test.predict', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'system', 'get_ipython', 'system', 'get_ipython', 'run_line_magic', 'filterwarnings', 'confusion_matrix', 'figure', 'heatmap', 'ylabel', 'xlabel', 'format', 'title', 'print', 'read_csv', 'read_csv', 'head', 'describe', 'info', 'isnull', 'sum', 'sort_values', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'concat', 'draw_missing_data_table', 'value_counts', 'drop', 'hist', 'show', 'train_cats', 'proc_df', 'map', 'map', 'map', 'fillna', 'get_dummies', 'concat', 'Series', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'get_dummies', 'concat', 'get_dummies', 'concat', 'get_dummies', 'concat', 'groupby', 'median', 'reset_index', 'isnan', 'print', 'apply', 'drop', 'copy', 'drop', 'append', 'preprocess_data', 'StandardScaler', 'DataFrame', 'copy', 'copy', 'train_test_split', 'head', 'DecisionTreeClassifier', 'fit', 'predict', 'accuracy_score', 'display_confusion_matrix', 'RandomForestClassifier', 'fit', 'score', 'predict', 'accuracy_score', 'display_confusion_matrix', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'compile', 'build_ann', 'fit', 'predict', 'accuracy_score', 'display_confusion_matrix', 'cross_val_score', 'cross_val_score', 'cross_val_score', 'mean', 'items', 'std', 'items', 'print', 'figure', 'plot', 'plot', 'plot', 'title', 'ylabel', 'xlabel', 'xticks', 'legend', 'show', 'print', 'int', 'linspace', 'int', 'linspace', 'append', 'RandomizedSearchCV', 'fit', 'predict', 'abs', 'mean', 'print', 'print', 'print', 'evaluate', 'GridSearchCV', 'fit', 'evaluate', 'DataFrame', 'fit', 'predict', 'DataFrame', 'to_csv']","['get_ipython', 'system', 'run_line_magic', 'filterwarnings', 'confusion_matrix', 'figure', 'heatmap', 'ylabel', 'xlabel', 'format', 'title', 'print', 'read_csv', 'head', 'describe', 'info', 'isnull', 'sum', 'sort_values', 'count', 'concat', 'draw_missing_data_table', 'value_counts', 'drop', 'hist', 'show', 'train_cats', 'proc_df', 'map', 'fillna', 'get_dummies', 'Series', 'replace', 'groupby', 'median', 'reset_index', 'isnan', 'apply', 'copy', 'append', 'preprocess_data', 'StandardScaler', 'DataFrame', 'train_test_split', 'DecisionTreeClassifier', 'fit', 'predict', 'accuracy_score', 'display_confusion_matrix', 'RandomForestClassifier', 'score', 'Sequential', 'add', 'compile', 'build_ann', 'cross_val_score', 'mean', 'items', 'std', 'plot', 'xticks', 'legend', 'int', 'linspace', 'RandomizedSearchCV', 'abs', 'evaluate', 'GridSearchCV', 'to_csv']",69,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0
 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0
 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython system get ipython system get ipython run line magic filterwarnings confusion matrix figure heatmap ylabel xlabel format title print read csv read csv head describe info isnull sum sort values isnull sum isnull count sort values concat draw missing data table value counts drop hist show train cats proc df map map map fillna get dummies concat series replace replace replace replace replace replace replace replace replace replace get dummies concat get dummies concat get dummies concat groupby median reset index isnan print apply drop copy drop append preprocess data standardscaler dataframe copy copy train test split head decisiontreeclassifier fit predict accuracy score display confusion matrix randomforestclassifier fit score predict accuracy score display confusion matrix sequential add add add add add add add add add add compile build ann fit predict accuracy score display confusion matrix cross val score cross val score cross val score mean items std items print figure plot plot plot title ylabel xlabel xticks legend show print int linspace int linspace append randomizedsearchcv fit predict abs mean print print print evaluate gridsearchcv fit evaluate dataframe fit predict dataframe csv,"[0.0, 0.07544593913684232, 0.14390301498067923, 0.0, 0.0, 0.38168377885362953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09612077122225852, 0.0, 0.07784878077334129, 0.03366882522117276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08942922362910151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09612077122225852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0608024311254824, 0.0, 0.0, 0.1731710537896722, 0.0, 0.0, 0.2177507758166586, 0.0, 0.0, 0.0, 0.11025880450302256, 0.0, 0.0, 0.0, 0.05088762760874569, 0.0, 0.0, 0.0, 0.04026686895515133, 0.0, 0.0, 0.14956748988675267, 0.0, 0.0, 0.05322516512915135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12360588544181159, 0.0, 0.06668864716216552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03892439038667064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03172500620197629, 0.0, 0.0, 0.0, 0.0, 0.07324221888802336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20395996116757645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08468149505514094, 0.0, 0.06811555171394601, 0.0, 0.0, 0.0, 0.12824728683476666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13310134258973272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07836858323258626, 0.0, 0.0, 0.0, 0.023095814851433926, 0.0, 0.047527555258080285, 0.0, 0.0, 0.0, 0.11731275236654491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06955959450465281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16306257271251615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04709887175351483, 0.0, 0.0, 0.030753938658962008, 0.0, 0.0, 0.0, 0.0, 0.04228203837201592, 0.04267160736520781, 0.0, 0.042036783446346024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047527555258080285, 0.0, 0.0, 0.029252596197367624, 0.0, 0.0, 0.0, 0.0, 0.10513477360521435, 0.0, 0.0, 0.0, 0.0, 0.08819019449341706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049855829962250894, 0.09467742485978851, 0.0, 0.0, 0.16199774134354078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03404823013732471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02983684789995181, 0.0, 0.0, 0.0, 0.0, 0.14259679973765382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02968883446837202, 0.0, 0.0, 0.09321396380204999, 0.0, 0.20571508297751281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06378510943438195, 0.04437449674785576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07324221888802336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10214469041197415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10142865017429356, 0.0, 0.0, 0.07798994746198393, 0.0, 0.0, 0.13248430710785594, 0.0, 0.0, 0.0, 0.09612077122225852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028688322872948625, 0.0, 0.07324221888802336, 0.0, 0.0, 0.0, 0.0, 0.035340865340300814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35036752348277717, 0.0, 0.0, 0.05316757610855231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02954213672914336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20885793529966265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06655067129486636, 0.04333183088430855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0773370375923674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07305679098621767, 0.0, 0.0, 0.0, 0.03091186701243669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05443769395416465, 0.0, 0.0, 0.0, 0.0, 0.05088762760874569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06278985491820982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16199774134354078, 0.07324221888802336, 0.0, 0.0, 0.0, 0.03223284279351362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06659589396820721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06345001240395258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14956748988675267, 0.0, 0.0, 0.04026686895515133, 0.07305679098621767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09097501260888459, 0.0, 0.0, 0.052567386802607176, 0.0, 0.08803914304048623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
anguscc_a-journey-through-titanic-2268c7.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,392,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'Series', 'to_csv']",41,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.044764016066123576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07897384780955316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1732356411821898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21339166879300978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043103979172050215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18506069532415897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06242267235247362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10428359245311382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5858319377150814, 0.04535058319335513, 0.0, 0.0, 0.22561334511846506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04823520168412464, 0.11936239924507572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05417371574841149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022930805650467657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19124039398817919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14427333625349464, 0.0, 0.0, 0.0, 0.0, 0.024794266220561655, 0.0, 0.0, 0.09860179309752698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06861510803983897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03447659643832888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1169422069820771, 0.07402535820362174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38306838410884264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03993189140675432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03499276659771594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03481917589262651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03481917589262651, 0.0, 0.0, 0.03644056157127717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22442224336144118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07986378281350864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02379117991130804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02219686999123949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11466446370321208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04144789879819887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03464712823643796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03499276659771594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05081973301840498, 0.1870185361345343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11936239924507572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05162631780355789, 0.0, 0.0, 0.0, 0.0, 0.24117600842062317, 0.07364017624197197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07810391304771432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061651227475622745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
peterabdou_titanic-learn-from-others.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,76,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction""]",6,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'print', 'print']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'print', 'print']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot']",10,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2403636640518332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30760831928183147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3447110947593138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15645028066562766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15779720531951444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14320855992673556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3963122249390821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19913248019470747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2021138140460668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20111117598969602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3846189790069582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23939784489192578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20011745038949655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21603910356679326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.298187111536146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
bhavikjain_bhavik-titanic.py,"['pandas', 'sklearn', 'numpy']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,262,[],0,"['pd.read_csv', 'pd.read_csv', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'dataset.str.extract', 'dataset.map', 'dataset.map', 'train.drop', 'test.drop', 'train.fillna', 'test.fillna', 'train.groupby', 'None.transform', 'traintrain.value_counts', 'traintrain.value_counts', 'traintrain.value_counts', 'pd.DataFrame', 'df.plot', 'dataset.fillna', 'dataset.map', 'train.fillna', 'test.fillna', 'train.head', 'dataset.map', 'train.fillna', 'test.fillna', 'dataset.map', 'train.drop', 'test.drop', 'train.drop', 'train.drop', 'KFold', 'KNeighborsClassifier', 'cross_val_score', 'np.mean', 'SVC', 'cross_val_score', 'SVC', 'clf.fit', 'test.drop', 'None.copy', 'clf.predict', 'pd.DataFrame', 'submission.to_csv', 'pd.read_csv']","['read_csv', 'read_csv', 'isnull', 'sum', 'isnull', 'sum', 'str', 'map', 'map', 'drop', 'drop', 'fillna', 'fillna', 'groupby', 'transform', 'value_counts', 'value_counts', 'value_counts', 'DataFrame', 'plot', 'fillna', 'map', 'fillna', 'fillna', 'head', 'map', 'fillna', 'fillna', 'map', 'drop', 'drop', 'drop', 'drop', 'KFold', 'KNeighborsClassifier', 'cross_val_score', 'mean', 'SVC', 'cross_val_score', 'SVC', 'fit', 'drop', 'copy', 'predict', 'DataFrame', 'to_csv', 'read_csv']","['read_csv', 'isnull', 'sum', 'str', 'map', 'drop', 'fillna', 'groupby', 'transform', 'value_counts', 'DataFrame', 'plot', 'head', 'KFold', 'KNeighborsClassifier', 'cross_val_score', 'mean', 'SVC', 'fit', 'copy', 'predict', 'to_csv']",22,"[0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv isnull sum isnull sum str map map drop drop fillna fillna groupby transform value counts value counts value counts dataframe plot fillna map fillna fillna head map fillna fillna map drop drop drop drop kfold kneighborsclassifier cross val score mean svc cross val score svc fit drop copy predict dataframe csv read csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0902111702640178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29650867782547224, 0.0, 0.0, 0.24474523113055754, 0.0, 0.0, 0.17419033175404003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10912617692418754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3901138383182897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3968255451538861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04799127255904914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.075486455956723, 0.0, 0.0, 0.0, 0.0, 0.05189125956716363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1549257010845061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14068165318613546, 0.09748583244265438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3813274049828922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07828122289321983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08357239224435255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04979192694006689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13011780561994868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1464708588947399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12116333013376912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154119564013348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18617057397617948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08857975299889048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24474523113055754, 0.0, 0.0, 0.29650867782547224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mihoku91_ensemble-learning-titanic.py,"['numpy', 'pandas', 'os\n', 'category_encoders', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,432,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '  # This is added back by InteractiveShellApp.init_path()']",9,"['print', 'pd.read_csv', 'dataset.head', 'dataset.info', 'dataset.describe', 'dataset.dropna', 'np.median', 'np.median', 'np.median', 'np.median', 'np.median', 'np.median', 'dataset.query', 'dataset1.fillna', 'dataset.query', 'dataset2.fillna', 'dataset.query', 'dataset3.fillna', 'dataset.query', 'dataset4.fillna', 'dataset.query', 'dataset5.fillna', 'dataset.query', 'dataset6.fillna', 'pd.concat', 'dataset.sort_values', 'dataset.info', 'pd.cut', 'dataset.head', 'dataset.value_counts', 'None.idxmax', 'dataset.fillna', 'dataset.info', 'dataset.mean', 'dataset.LogFare.mask', 'np.log', 'dataset.info', 'ce.OneHotEncoder', 'ohe.fit_transform', 'df_OHE.head', 'df_OHE.info', 'df_OHE.drop', 'KNeighborsClassifier', 'np.arange', 'GridSearchCV', 'knn_gs.fit', 'print', 'RandomForestClassifier', 'GridSearchCV', 'rf_gs.fit', 'print', 'LogisticRegression', 'log_reg.fit', 'svm.SVC', 'GridSearchCV', 'svm_gs.fit', 'print', 'DecisionTreeClassifier', 'GridSearchCV', 'dtree_gs.fit', 'print', 'pd.read_csv', 'test_dataset.head', 'test_dataset.query', 'test_dataset1.fillna', 'test_dataset.query', 'test_dataset2.fillna', 'test_dataset.query', 'test_dataset3.fillna', 'test_dataset.query', 'test_dataset4.fillna', 'test_dataset.query', 'test_dataset5.fillna', 'test_dataset.query', 'test_dataset6.fillna', 'pd.concat', 'test_dataset.sort_values', 'test_dataset.info', 'pd.cut', 'test_dataset.head', 'test_dataset.fillna', 'test_dataset.info', 'test_dataset.fillna', 'test_dataset.info', 'test_dataset.LogFare.mask', 'np.log', 'test_dataset.info', 'ohe.fit_transform', 'X_test_OHE.head', 'VotingClassifier', 'ensemble.fit', 'pd.DataFrame', 'pd.read_csv', 'pd.DataFrame', 'accuracy_score', 'pd.concat', 'finalresult.head', 'finalresult.to_csv']","['print', 'read_csv', 'head', 'info', 'describe', 'dropna', 'median', 'median', 'median', 'median', 'median', 'median', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'concat', 'sort_values', 'info', 'cut', 'head', 'value_counts', 'idxmax', 'fillna', 'info', 'mean', 'LogFare', 'log', 'info', 'OneHotEncoder', 'fit_transform', 'head', 'info', 'drop', 'KNeighborsClassifier', 'arange', 'GridSearchCV', 'fit', 'print', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print', 'LogisticRegression', 'fit', 'SVC', 'GridSearchCV', 'fit', 'print', 'DecisionTreeClassifier', 'GridSearchCV', 'fit', 'print', 'read_csv', 'head', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'query', 'fillna', 'concat', 'sort_values', 'info', 'cut', 'head', 'fillna', 'info', 'fillna', 'info', 'LogFare', 'log', 'info', 'fit_transform', 'head', 'VotingClassifier', 'fit', 'DataFrame', 'read_csv', 'DataFrame', 'accuracy_score', 'concat', 'head', 'to_csv']","['print', 'read_csv', 'head', 'info', 'describe', 'dropna', 'median', 'query', 'fillna', 'concat', 'sort_values', 'cut', 'value_counts', 'idxmax', 'mean', 'LogFare', 'log', 'OneHotEncoder', 'fit_transform', 'drop', 'KNeighborsClassifier', 'arange', 'GridSearchCV', 'fit', 'RandomForestClassifier', 'LogisticRegression', 'SVC', 'DecisionTreeClassifier', 'VotingClassifier', 'DataFrame', 'accuracy_score', 'to_csv']",32,"[1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv head info describe dropna median median median median median median query fillna query fillna query fillna query fillna query fillna query fillna concat sort values info cut head value counts idxmax fillna info mean logfare log info onehotencoder fit transform head info drop kneighborsclassifier arange gridsearchcv fit print randomforestclassifier gridsearchcv fit print logisticregression fit svc gridsearchcv fit print decisiontreeclassifier gridsearchcv fit print read csv head query fillna query fillna query fillna query fillna query fillna query fillna concat sort values info cut head fillna info fillna info logfare log info fit transform head votingclassifier fit dataframe read csv dataframe accuracy score concat head csv,"[0.0, 0.0, 0.037285084951574114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04803918743291708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0807631126743465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031299280906552825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0551622856176686, 0.0, 0.0, 0.0, 0.06843248408177625, 0.0, 0.0, 0.0, 0.034557884351217184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03025577752731806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02465972415147903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017648651298367877, 0.030056889533429654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2692843082507488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12158232927855946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14643908062848057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11502982494702371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0747143022913156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20464136508413922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030871640685954216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13902597665290264, 0.0, 0.1494286045826312, 0.0, 0.0, 0.023077015768191395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024789958961864245, 0.20695274425408813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05693089238571659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0735568125408738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.834155859917416, 0.0, 0.0, 0.022299321989459834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04120547613220458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023192066033910306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0567867599975492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029478083748586497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056102558456192914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031299280906552825, 0.0567867599975492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04975213062658993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
dcdanko_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,454,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', 'X_train = ica_df.transpose()[:n_train, :] # ', 'X_test  = ica_df.transpose()[n_train:, :] # test_df.drop(""PassengerId"",axis=1).copy()', '----> 4 X_train = ica_df.transpose()[:n_train, :] #', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview', '      6 # preview']",83,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'ica_df.transpose', 'ica_df.transpose', 'titanic_df.drop', 'print', 'test_df.drop', 'print', 'pd.concat', 'print', 'df.fillna', 'print', 'df.as_matrix', 'df.mean', 'PCA', 'pca.fit', 'np.matrix', 'FastICA', 'ica.fit', 'print', 'titanic_df.tolist', 'plt.scatter', 'LogisticRegression', 'logreg.fit', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'transpose', 'transpose', 'drop', 'print', 'drop', 'print', 'concat', 'print', 'fillna', 'print', 'as_matrix', 'mean', 'PCA', 'fit', 'matrix', 'FastICA', 'fit', 'print', 'tolist', 'scatter', 'LogisticRegression', 'fit', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'transpose', 'concat', 'as_matrix', 'PCA', 'fit', 'matrix', 'FastICA', 'tolist', 'scatter', 'LogisticRegression', 'score', 'RandomForestClassifier', 'predict', 'Series', 'to_csv']",49,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join transpose transpose drop print drop print concat print fillna print matrix mean pca fit matrix fastica fit print tolist scatter logisticregression fit score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04203598154667785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07416097796696194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16267821468932925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20038703047437573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03814369708550267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17378261955251265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05861847380330744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09792828153544127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5501298294341851, 0.042586801761284404, 0.0, 0.0, 0.21186388634287995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04529562416604977, 0.11208814697549763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10586069383107817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07630834481488466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08613337299760172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17958571145161892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13548094727405743, 0.0, 0.0, 0.0, 0.0, 0.02328323972923646, 0.0, 0.0, 0.09259274567756448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06443352649872618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03237550378708353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981544746711251, 0.0695140620724723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3597232094128647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03749833901897327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03286021720651599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03269720556642911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03269720556642911, 0.0, 0.0, 0.03421977982266047, 0.0, 0.11328010136936163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2458696022965278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10586069383107817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07499667803794655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022341284085148926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12506481312589937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10767651573460206, 0.03159531208044517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03892195701243605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03253564293786585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08309087996491171, 0.0, 0.06572043441303198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04772264749912462, 0.17562114449751984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11208814697549763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048480076928477764, 0.0, 0.0, 0.0, 0.0, 0.22647812083024885, 0.06915235409238164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07334405927178826, 0.0, 0.0, 0.0, 0.0, 0.0766080717334675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15704614066625097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057894042765670416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
nptumis103035_titanic-data-science-solutions-8954f2.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,948,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', '    384             # Python 3 and no explicit encoding', '    387             # Python 3 and binary mode']",26,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score', 'to_csv']",48,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14739731056786123, 0.0, 0.0386075088739669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11408479331718284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035482800489506514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044290428976480785, 0.05138577160738971, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.06438397294899055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03757921331973189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0612572612591073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21920521835808165, 0.03733218432362304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03887529754869338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19853387909934528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066892959232493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16988786089570734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04630997037753964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022489619870565202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2969112193682155, 0.0, 0.0, 0.0, 0.0, 0.22451453910645058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05648332789475356, 0.0, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.028380818116478954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038344146661578926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1314862676876251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053884920424318535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.239980289670821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30790388882723707, 0.042840970987036014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05019161346595868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1762621307304402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05481677964674111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04354922319089523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027696891186176718, 0.0, 0.0, 0.1544300354958676, 0.0, 0.0, 0.0, 0.034119530308222235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1353037082864551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3794657982870925, 0.0, 0.02852119832929571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04183433832000622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03661327812332207, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055334378413763305, 0.0, 0.0]"
jayashreebiswal_titanic-disaster-prediction-logistic-regression.py,"['numpy', 'pandas', 'os\n', 'warnings\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,784,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ']",11,"['os.walk', 'print', 'warnings.filterwarnings', 'pd.read_csv', 'train.head', 'pd.read_csv', 'test.head', 'print', 'print', 'print', 'print', 'train.astype', 'print', 'train.replace', 'None.astype', 'train.value_counts', 'train.replace', 'None.astype', 'train.value_counts', 'print', 'print', 'print', 'print', 'test.astype', 'print', 'test.replace', 'None.astype', 'test.value_counts', 'test.replace', 'None.astype', 'test.value_counts', 'train.isnull', 'None.sum', 'train.describe', 'train.notnull', 'None.head', 'pd.Series', 'print', 'train.Cabin.value_counts', 'train.describe', 'train.fillna', 'print', 'train.value_counts', 'train.fillna', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'test.describe', 'test.fillna', 'test.isnull', 'None.sum', 'test.describe', 'pd.Series', 'print', 'test.Cabin.value_counts', 'test.fillna', 'test.isnull', 'None.sum', 'print', 'print', 'sns.pairplot', 'plt.figure', 'sns.heatmap', 'plt.figure', 'sns.heatmap', 'plt.figure', 'plt.subplot', 'train.Pclass.value_counts', 'None.plot.pie', 'plt.title', 'plt.subplot', 'sns.barplot', 'plt.title', 'plt.show', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.title', 'plt.subplot', 'sns.barplot', 'plt.ylabel', 'plt.title', 'plt.show', 'plt.figure', 'sns.distplot', 'sns.distplot', 'plt.title', 'plt.legend', 'plt.show', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.title', 'plt.subplot', 'sns.barplot', 'plt.ylabel', 'plt.title', 'plt.show', 'plt.figure', 'sns.barplot', 'plt.title', 'plt.ylabel', 'plt.show', 'plt.figure', 'sns.barplot', 'plt.title', 'plt.ylabel', 'plt.show', 'plt.figure', 'sns.countplot', 'plt.show', 'plt.figure', 'sns.barplot', 'plt.title', 'plt.show', 'plt.figure', 'train.groupby', 'None.sum', 'None.plot', 'plt.show', 'plt.figure', 'sns.barplot', 'plt.ylabel', 'plt.show', 'train.drop', 'test.drop', 'train.map', 'test.map', 'train.map', 'test.map', 'train.map', 'test.map', 'train.map', 'test.map', 'StandardScaler', 'scaler.fit_transform', 'scaler.transform', 'train.head', 'test.head', 'train.drop', 'test.drop', 'None.copy', 'LogisticRegression', 'LR.fit', 'LR.predict', 'print', 'pd.DataFrame', 'pd.Series', 'coeff.sort_values', 'RandomForestClassifier', 'RF.fit', 'RF.predict', 'print', 'pd.Series', 'None.sort_values', 'pd.DataFrame', 'Submit_file.to_csv']","['walk', 'print', 'filterwarnings', 'read_csv', 'head', 'read_csv', 'head', 'print', 'print', 'print', 'print', 'astype', 'print', 'replace', 'astype', 'value_counts', 'replace', 'astype', 'value_counts', 'print', 'print', 'print', 'print', 'astype', 'print', 'replace', 'astype', 'value_counts', 'replace', 'astype', 'value_counts', 'isnull', 'sum', 'describe', 'notnull', 'head', 'Series', 'print', 'Cabin', 'describe', 'fillna', 'print', 'value_counts', 'fillna', 'isnull', 'sum', 'isnull', 'sum', 'describe', 'fillna', 'isnull', 'sum', 'describe', 'Series', 'print', 'Cabin', 'fillna', 'isnull', 'sum', 'print', 'print', 'pairplot', 'figure', 'heatmap', 'figure', 'heatmap', 'figure', 'subplot', 'Pclass', 'plot', 'title', 'subplot', 'barplot', 'title', 'show', 'figure', 'subplot', 'countplot', 'title', 'subplot', 'barplot', 'ylabel', 'title', 'show', 'figure', 'distplot', 'distplot', 'title', 'legend', 'show', 'figure', 'subplot', 'countplot', 'title', 'subplot', 'barplot', 'ylabel', 'title', 'show', 'figure', 'barplot', 'title', 'ylabel', 'show', 'figure', 'barplot', 'title', 'ylabel', 'show', 'figure', 'countplot', 'show', 'figure', 'barplot', 'title', 'show', 'figure', 'groupby', 'sum', 'plot', 'show', 'figure', 'barplot', 'ylabel', 'show', 'drop', 'drop', 'map', 'map', 'map', 'map', 'map', 'map', 'map', 'map', 'StandardScaler', 'fit_transform', 'transform', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'print', 'DataFrame', 'Series', 'sort_values', 'RandomForestClassifier', 'fit', 'predict', 'print', 'Series', 'sort_values', 'DataFrame', 'to_csv']","['walk', 'print', 'filterwarnings', 'read_csv', 'head', 'astype', 'replace', 'value_counts', 'isnull', 'sum', 'describe', 'notnull', 'Series', 'Cabin', 'fillna', 'pairplot', 'figure', 'heatmap', 'subplot', 'Pclass', 'plot', 'title', 'barplot', 'show', 'countplot', 'ylabel', 'distplot', 'legend', 'groupby', 'drop', 'map', 'StandardScaler', 'fit_transform', 'transform', 'copy', 'LogisticRegression', 'fit', 'predict', 'DataFrame', 'sort_values', 'RandomForestClassifier', 'to_csv']",42,"[1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print filterwarnings read csv head read csv head print print print print astype print replace astype value counts replace astype value counts print print print print astype print replace astype value counts replace astype value counts isnull sum describe notnull head series print cabin describe fillna print value counts fillna isnull sum isnull sum describe fillna isnull sum describe series print cabin fillna isnull sum print print pairplot figure heatmap figure heatmap figure subplot pclass plot title subplot barplot title show figure subplot countplot title subplot barplot ylabel title show figure distplot distplot title legend show figure subplot countplot title subplot barplot ylabel title show figure barplot title ylabel show figure barplot title ylabel show figure countplot show figure barplot title show figure groupby sum plot show figure barplot ylabel show drop drop map map map map map map map map standardscaler fit transform transform head head drop drop copy logisticregression fit predict print dataframe series sort values randomforestclassifier fit predict print series sort values dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15566634699882434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27963514193266764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09447926487739983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032277032856505794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10393257637972686, 0.17681513845795468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046743216872611834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390447123984576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11144569239648898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0850462155920533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07976026624340136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4129474852526609, 0.0, 0.0, 0.0, 0.08113250037501414, 0.0, 0.041739482018755214, 0.0, 0.0, 0.0, 0.05151299589664467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027008615585027557, 0.0, 0.0, 0.0, 0.0, 0.09283195668080534, 0.07494981716016903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13857879045319144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029901716633019746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026073223537828295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2182987697633839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0626154293678922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05844589591794549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05521175451519802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05980343326603949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035630524626378945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.299185459998111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025194557771832875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03103693016374849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12307941249621823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15221891100555573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3395933025001968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06415967741574004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047808079662503826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30625332639150776, 0.0, 0.0, 0.16542925505556877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29242805607346417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06338664246564488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17681513845795468, 0.06415967741574004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033093786754133714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19329356454013308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mirandora_titanic-tutorial-code.py,"['numpy', 'pandas', 'os\n', 'random\n', 'matplotlib', 'seaborn', 'sklearn', 'lightgbm']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,1039,[],0,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'np.random.seed', 'random.seed', 'print', 'print', 'pd.set_option', 'pd.set_option', 'train_df.head', 'test_df.head', 'train_df.describe', 'test_df.describe', 'train_df.value_counts', 'train_df.value_counts', 'train_df.value_counts', 'train_df.isnull', 'None.sum', 'test_df.isnull', 'None.sum', 'get_ipython', 'None.run_line_magic', 'plt.style.use', 'train_df.dropna', 'train_df.dropna', 'None.groupby', 'None.count', 'train_df.dropna', 'None.groupby', 'None.count', 'None.unstack', 'embarked_df.plot.bar', 'train_df.dropna', 'None.groupby', 'None.count', 'None.unstack', 'sex_df.plot.bar', 'train_df.dropna', 'None.groupby', 'None.count', 'None.unstack', 'ticket_df.plot.bar', 'plt.hist', 'plt.legend', 'pd.get_dummies', 'pd.get_dummies', 'train_df_corr.head', 'train_df_corr.corr', 'plt.figure', 'sns.heatmap', 'pd.concat', 'None.reset_index', 'all_df.isnull', 'None.sum', 'all_df.groupby', 'None.mean', 'None.reset_index', 'pd.merge', 'all_df.isnull', 'all_df.drop', 'all_df.head', 'all_df.str.split', 'name_df.str.strip', 'name_df.str.strip', 'name_df.str.strip', 'name_df.value_counts', 'pd.concat', 'plt.figure', 'sns.boxplot', 'all_df.groupby', 'None.mean', 'pd.concat', 'pd.concat', 'train_df.dropna', 'None.groupby', 'None.count', 'None.unstack', 'honorific_df.plot.bar', 'all_df.groupby', 'None.mean', 'None.reset_index', 'pd.merge', 'all_df.isnull', 'all_df.drop', 'all_df.value_counts', 'all_df.fillna', 'all_df.drop', 'all_df.head', 'print', 'all_df.honorific.value_counts', 'all_df.fillna', 'all_df.head', 'LabelEncoder', 'print', 'le.fit', 'le.transform', 'all_df.head', 'all_df.isnull', 'None.drop', 'None.reset_index', 'all_df.isnull', 'None.drop', 'None.reset_index', 'train_test_split', 'lgb.Dataset', 'lgb.Dataset', 'lgb.train', 'model_lgb.feature_importance', 'pd.DataFrame', 'None.sort_values', 'importance.plot.barh', 'model_lgb.predict', 'accuracy_score', 'lgb.Dataset', 'lgb.Dataset', 'lgb.train', 'model_lgb.predict', 'accuracy_score', 'KFold', 'kf.split', 'lgb.Dataset', 'lgb.Dataset', 'lgb.train', 'model_lgb.predict', 'print', 'models.append', 'model.predict', 'preds.append', 'np.array', 'np.mean', 'preds_mean.astype', 'submission.to_csv', 'pd.read_csv', 'pd.read_csv', 'pd.concat', 'None.reset_index', 'all_df.Pclass.value_counts', 'all_df.Pclass.value_counts', 'None.plot.bar', 'all_df.groupby', 'None.describe', 'plt.figure', 'sns.boxplot', 'all_df.groupby', 'None.describe', 'plt.figure', 'sns.boxplot', 'all_dfall_df.groupby', 'None.describe', 'plt.figure', 'sns.boxplot', 'all_df.plot.scatter', 'all_df.groupby', 'None.describe', 'plt.figure', 'sns.boxplot', 'all_df.dropna', 'None.groupby', 'None.count', 'None.unstack', 'Pclass_gender_df.plot.bar', 'all_df.dropna', 'None.groupby', 'None.count', 'None.unstack', 'Pclass_emb_df.fillna', 'Pclass_emb_df.plot.bar', 'Pclass_emb_df.copy', 'Pclass_emb_df_ratio.drop', 'Pclass_emb_df_ratio.plot.bar', 'len', 'len', 'all_df.plot.scatter', 'C_young10.plot.scatter', 'all_dfall_df.plot.scatter', 'C_young10.plot.scatter', 'all_df.plot.scatter', 'C_young20.plot.scatter', 'all_dfall_df.plot.scatter', 'C_young20.plot.scatter', 'all_df.plot.scatter', 'C_all.plot.scatter', 'all_dfall_dfall_df.groupby', 'None.mean']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'random', 'seed', 'print', 'print', 'set_option', 'set_option', 'head', 'head', 'describe', 'describe', 'value_counts', 'value_counts', 'value_counts', 'isnull', 'sum', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'style', 'dropna', 'dropna', 'groupby', 'count', 'dropna', 'groupby', 'count', 'unstack', 'plot', 'dropna', 'groupby', 'count', 'unstack', 'plot', 'dropna', 'groupby', 'count', 'unstack', 'plot', 'hist', 'legend', 'get_dummies', 'get_dummies', 'head', 'corr', 'figure', 'heatmap', 'concat', 'reset_index', 'isnull', 'sum', 'groupby', 'mean', 'reset_index', 'merge', 'isnull', 'drop', 'head', 'str', 'str', 'str', 'str', 'value_counts', 'concat', 'figure', 'boxplot', 'groupby', 'mean', 'concat', 'concat', 'dropna', 'groupby', 'count', 'unstack', 'plot', 'groupby', 'mean', 'reset_index', 'merge', 'isnull', 'drop', 'value_counts', 'fillna', 'drop', 'head', 'print', 'honorific', 'fillna', 'head', 'LabelEncoder', 'print', 'fit', 'transform', 'head', 'isnull', 'drop', 'reset_index', 'isnull', 'drop', 'reset_index', 'train_test_split', 'Dataset', 'Dataset', 'train', 'feature_importance', 'DataFrame', 'sort_values', 'plot', 'predict', 'accuracy_score', 'Dataset', 'Dataset', 'train', 'predict', 'accuracy_score', 'KFold', 'split', 'Dataset', 'Dataset', 'train', 'predict', 'print', 'append', 'predict', 'append', 'array', 'mean', 'astype', 'to_csv', 'read_csv', 'read_csv', 'concat', 'reset_index', 'Pclass', 'Pclass', 'plot', 'groupby', 'describe', 'figure', 'boxplot', 'groupby', 'describe', 'figure', 'boxplot', 'groupby', 'describe', 'figure', 'boxplot', 'plot', 'groupby', 'describe', 'figure', 'boxplot', 'dropna', 'groupby', 'count', 'unstack', 'plot', 'dropna', 'groupby', 'count', 'unstack', 'fillna', 'plot', 'copy', 'drop', 'plot', 'len', 'len', 'plot', 'plot', 'plot', 'plot', 'plot', 'plot', 'plot', 'plot', 'plot', 'plot', 'groupby', 'mean']","['walk', 'print', 'read_csv', 'random', 'seed', 'set_option', 'head', 'describe', 'value_counts', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'style', 'dropna', 'groupby', 'count', 'unstack', 'plot', 'hist', 'legend', 'get_dummies', 'corr', 'figure', 'heatmap', 'concat', 'reset_index', 'mean', 'merge', 'drop', 'str', 'boxplot', 'fillna', 'honorific', 'LabelEncoder', 'fit', 'transform', 'train_test_split', 'Dataset', 'train', 'feature_importance', 'DataFrame', 'sort_values', 'predict', 'accuracy_score', 'KFold', 'split', 'append', 'array', 'astype', 'to_csv', 'Pclass', 'copy', 'len']",54,"[1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1
 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv random seed print print set option set option head head describe describe value counts value counts value counts isnull sum isnull sum get ipython run line magic style dropna dropna groupby count dropna groupby count unstack plot dropna groupby count unstack plot dropna groupby count unstack plot hist legend get dummies get dummies head corr figure heatmap concat reset index isnull sum groupby mean reset index merge isnull drop head str str str str value counts concat figure boxplot groupby mean concat concat dropna groupby count unstack plot groupby mean reset index merge isnull drop value counts fillna drop head print honorific fillna head labelencoder print fit transform head isnull drop reset index isnull drop reset index train test split dataset dataset train feature importance dataframe sort values plot predict accuracy score dataset dataset train predict accuracy score kfold split dataset dataset train predict print append predict append array mean astype csv read csv read csv concat reset index pclass pclass plot groupby describe figure boxplot groupby describe figure boxplot groupby describe figure boxplot plot groupby describe figure boxplot dropna groupby count unstack plot dropna groupby count unstack fillna plot copy drop plot len len plot plot plot plot plot plot plot plot plot plot groupby mean,"[0.0, 0.0, 0.06621995008936427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05373559106479453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046928198309670446, 0.0, 0.0, 0.020391638284990445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17381912494799098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11953236567435031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025368935223780472, 0.0313980259299039, 0.0, 0.0, 0.24587844590422342, 0.0, 0.0, 0.0, 0.13897224735821723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07347798332419492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015344080480866726, 0.0, 0.0, 0.32299819334489294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13139026272698548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09403434185335074, 0.21352942897465138, 0.0, 0.0, 0.044261732117469144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05383303222414882, 0.0, 0.0, 0.16228316355427067, 0.0, 0.0, 0.0, 0.04782607703690032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013495972630597009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0482378252420529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31842137827847744, 0.0, 0.0, 0.0, 0.0, 0.10214901316000127, 0.029454334681622858, 0.0, 0.029016143637868082, 0.0, 0.0, 0.06634794281840191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05207701511421798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19683709224118237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020291271445943962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15248721664214418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039562104519964884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031940583828652565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023501996472702968, 0.0571883713498748, 0.0, 0.0, 0.0, 0.0, 0.020595064450429027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020492897285414258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11007014247816094, 0.0, 0.0, 0.0, 0.10766606444829764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09005038251312894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08679009809323339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47003992945405937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056009390655853274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07838407977102507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03374300247948493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06098561431975227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22019544295706125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020391638284990445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041190128900858054, 0.0, 0.0, 0.05845191336120098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04402805699126437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0252139455874812, 0.0, 0.0, 0.0, 0.04267420576992336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1362928632747001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03038477508011633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06501161482656356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02224891439534509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.087593508484657, 0.0, 0.0, 0.0, 0.02491015258299613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2650859139421023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13897224735821723, 0.0252139455874812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02601088322485011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
lhavanya_titanic-analysis.py,"['numpy', 'matplotlib', 'seaborn', 'pylab', 'pandas_profiling\n', 'sklearn', 'pandas', 'xgboost']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,231,[],0,"['pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train.profile_report', 'train.describe', 'print', 'train.append', 'len', 'len', 'len', 'titanic.head', 'titanic.info', 'titanic.Name.apply', 'titanic.Title.map', 'print', 'titanic.groupby', 'grouped.Age.median', 'grouped.Age.apply', 'titanic.Cabin.fillna', 'titanic.Embarked.value_counts', 'titanic.Embarked.value_counts', 'titanic.Embarked.fillna', 'titanic.Fare.fillna', 'titanic.info', 'titanic.Cabin.map', 'titanic.Sex.map', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'titanic_dummies.drop', 'titanic_dummies.head', 'train.Survived.astype', 'train.drop', 'train.drop', 'test.drop', 'dict', 'RandomForestClassifier', 'GridSearchCV', 'forest_cv.fit', 'print', 'print', 'forest_cv.predict', 'pd.DataFrame', 'kaggle.to_csv', 'XGBClassifier', 'xg.fit', 'xg.predict', 'xg_data.to_csv', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'print', 'pd.DataFrame', 'y_pred.to_csv']","['read_csv', 'read_csv', 'read_csv', 'profile_report', 'describe', 'print', 'append', 'len', 'len', 'len', 'head', 'info', 'Name', 'Title', 'print', 'groupby', 'Age', 'Age', 'Cabin', 'Embarked', 'Embarked', 'Embarked', 'Fare', 'info', 'Cabin', 'Sex', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'drop', 'head', 'Survived', 'drop', 'drop', 'drop', 'dict', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'DataFrame', 'to_csv', 'XGBClassifier', 'fit', 'predict', 'to_csv', 'RandomForestClassifier', 'fit', 'predict', 'print', 'DataFrame', 'to_csv']","['read_csv', 'profile_report', 'describe', 'print', 'append', 'len', 'head', 'info', 'Name', 'Title', 'groupby', 'Age', 'Cabin', 'Embarked', 'Fare', 'Sex', 'get_dummies', 'concat', 'drop', 'Survived', 'dict', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'predict', 'DataFrame', 'to_csv', 'XGBClassifier']",28,"[1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv read csv profile report describe print append len len len head info name title print groupby age age cabin embarked embarked embarked fare info cabin sex get dummies get dummies get dummies get dummies concat drop head survived drop drop drop dict randomforestclassifier gridsearchcv fit print print predict dataframe csv xgbclassifier fit predict csv randomforestclassifier fit predict print dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19828649967050366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0965026090373488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.266717898808481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08586625678368053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2639151056899137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11022443563687327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07865366264708891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18158448068590038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22516570856526438, 0.0, 0.0, 0.0, 0.3179548262303512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29949277612330766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12486323292019934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1454227871555926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2310114344653587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1167690479357161, 0.0, 0.0, 0.076246160550808, 0.0, 0.0, 0.0, 0.0, 0.10482699864489357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14504796741164644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30811015190314384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10913474708814787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15087911629271514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.234613845777267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2217158269830771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14225003801695724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13142732655915407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18158448068590038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14619247784406597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14619247784406597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08255334836672742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12238273217577299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
pcjukaria_titanic-survival.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,441,['# you could use any filename. We choose submission here'],1,"['get_ipython', 'None.run_line_magic', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train.head', 'train.info', 'train.drop', 'test.drop', 'train.drop', 'test.drop', 'train.head', 'train.drop', 'test.drop', 'train.head', 'train.info', 'train.describe', 'train.apply', 'test.apply', 'train.drop', 'test.drop', 'train.head', 'train.info', 'train.fillna', 'train.drop', 'train_test_split', 'Pipeline', 'Pipeline', 'ColumnTransformer', 'pd.concat', 'pd.concat', 'pd.concat', 'RandomForestClassifier', 'forest.fit', 'GridSearchCV', 'gsearch.fit', 'GridSearchCV', 'gsearch_svc.fit', 'SVC', 'final_model.fit', 'cross_val_predict', 'precision_recall_curve', 'plt.figure', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.plot', 'plt.xlabel', 'plt.ylabel', 'final_model.predict_proba', 'y_proba_test.astype', 'print', 'print', 'print', 'final_model.predict_proba', 'y_test_proba.astype', 'pd.read_csv', 'pd.DataFrame', 'my_submission_titanic.to_csv']","['get_ipython', 'run_line_magic', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'read_csv', 'head', 'info', 'drop', 'drop', 'drop', 'drop', 'head', 'drop', 'drop', 'head', 'info', 'describe', 'apply', 'apply', 'drop', 'drop', 'head', 'info', 'fillna', 'drop', 'train_test_split', 'Pipeline', 'Pipeline', 'ColumnTransformer', 'concat', 'concat', 'concat', 'RandomForestClassifier', 'fit', 'GridSearchCV', 'fit', 'GridSearchCV', 'fit', 'SVC', 'fit', 'cross_val_predict', 'precision_recall_curve', 'figure', 'plot', 'plot', 'legend', 'plot', 'xlabel', 'ylabel', 'predict_proba', 'astype', 'print', 'print', 'print', 'predict_proba', 'astype', 'read_csv', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'drop', 'describe', 'apply', 'fillna', 'train_test_split', 'Pipeline', 'ColumnTransformer', 'concat', 'RandomForestClassifier', 'fit', 'GridSearchCV', 'SVC', 'cross_val_predict', 'precision_recall_curve', 'figure', 'plot', 'legend', 'xlabel', 'ylabel', 'predict_proba', 'astype', 'print', 'DataFrame', 'to_csv']",29,"[1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic get ipython run line magic read csv read csv read csv head info drop drop drop drop head drop drop head info describe apply apply drop drop head info fillna drop train test split pipeline pipeline columntransformer concat concat concat randomforestclassifier fit gridsearchcv fit gridsearchcv fit svc fit cross val predict precision recall curve figure plot plot legend plot xlabel ylabel predict proba astype print print print predict proba astype read csv dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1453427525671311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12752852054452166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17482936724000897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22426524350704669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10760968805165802, 0.0, 0.0, 0.19147019918508562, 0.0, 0.0, 0.1538917028214376, 0.0, 0.0, 0.0, 0.0, 0.04798064421045911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06847580360043118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4410653644892233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08457605460679671, 0.0, 0.0, 0.0, 0.04985040733136854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1688065861933466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10055916713555141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20331804327872247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1825245698585677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18941793290072395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1269008301982904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07349029043469474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12880073994915495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12816179043364925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3161745510091439, 0.0, 0.0, 0.22047087130408421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15808727550457194, 0.0, 0.13135521458197427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12255275407175653, 0.0, 0.266793086862931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06192137363715986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15256067335053647, 0.0, 0.1538917028214376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12752852054452166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06672070987126877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08185555770558789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06957192690713226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06847580360043118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10760968805165802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09818102250780117, 0.0, 0.0, 0.0, 0.0, 0.09501260661085478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
michaelhayden_xgboosttitanic92.py,"['numpy', 'pandas', 'os\n', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,451,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', 'train_test_data = [train, test] # combining train and test dataset', '# make it numeric', '# notice there is not any more nan values']",11,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'test.describe', 'train.describe', 'train.head', 'test.head', 'train.isnull', 'None.sum', 'train.isnull', 'None.count', 'percent_null.sort_values', 'test.isnull', 'None.sum', 'test.isnull', 'None.count', 'percent_null.sort_values', 'train.value_counts', 'train.fillna', 'test.describe', 'test.isnull', 'None.sum', 'test.isnull', 'None.count', 'percent_null_test.sort_values', 'train.groupby', 'None.Survived.value_counts', 'print', 'print', 'print', 'train.groupby', 'None.mean', 'train.corr', 'None.sort_values', 'train.drop', 'train.describe', 'train.head', 'dataset.Name.str.extract', 'train.head', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train.groupby', 'None.mean', 'dataset.map', 'dataset.map', 'None.astype', 'train.tail', 'dataset.fillna', 'dataset.map', 'None.astype', 'train.isnull', 'None.sum', 'train.isnull', 'None.count', 'percent_null.sort_values', 'train.Embarked.value_counts', 'train.drop', 'test.drop', 'test.head', 'test.fillna', 'train.drop', 'test.drop', 'None.copy', 'LogisticRegression', 'clf.fit', 'clf.predict', 'round', 'print', 'SVC', 'clf.fit', 'clf.predict', 'round', 'print', 'DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'round', 'print', 'clf.predict', 'pd.DataFrame', 'submission.head', 'submission.to_csv', 'print', 'XGBClassifier', 'clf.fit', 'clf.predict', 'round', 'print', 'clf.predict', 'pd.DataFrame', 'submission.to_csv', 'print']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'describe', 'describe', 'head', 'head', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'value_counts', 'fillna', 'describe', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'groupby', 'Survived', 'print', 'print', 'print', 'groupby', 'mean', 'corr', 'sort_values', 'drop', 'describe', 'head', 'Name', 'head', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'map', 'astype', 'tail', 'fillna', 'map', 'astype', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'Embarked', 'drop', 'drop', 'head', 'fillna', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'print', 'SVC', 'fit', 'predict', 'round', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'print', 'predict', 'DataFrame', 'head', 'to_csv', 'print', 'XGBClassifier', 'fit', 'predict', 'round', 'print', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'describe', 'head', 'isnull', 'sum', 'count', 'sort_values', 'value_counts', 'fillna', 'groupby', 'Survived', 'mean', 'corr', 'drop', 'Name', 'replace', 'map', 'astype', 'tail', 'Embarked', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'SVC', 'DecisionTreeClassifier', 'DataFrame', 'to_csv', 'XGBClassifier']",32,"[1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv describe describe head head isnull sum isnull count sort values isnull sum isnull count sort values value counts fillna describe isnull sum isnull count sort values groupby survived print print print groupby mean corr sort values drop describe head name head replace replace replace replace groupby mean map map astype tail fillna map astype isnull sum isnull count sort values embarked drop drop head fillna drop drop copy logisticregression fit predict round print svc fit predict round print decisiontreeclassifier fit predict round print predict dataframe head csv print xgbclassifier fit predict round print predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0927248804726485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05767882534663421, 0.07138656935598987, 0.0, 0.0, 0.3194453556842919, 0.0, 0.0, 0.0, 0.06319347590032083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13921632006475856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06977261996640664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06108663498456773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19915264999571242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1781637769612594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06319347590032083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10873739556243653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12273780375511695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14479260483224904, 0.0, 0.0, 0.0, 0.0, 0.19906804593034597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39622288141947887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04659266275645372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14628687374871377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10010221505750533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06908284165588356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19101447299109095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29702347951597535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.083194156143586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21994202406076563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27415024496972046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28663220411328433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19708059188698956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09254057087817888, 0.0, 0.0, 0.0, 0.05951646558640071, 0.0, 0.0, 0.0, 0.08249749675727962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06319347590032083, 0.28663220411328433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05913835868174274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07746888258681366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
maheshsk_titanic-survival-prediction-end-to-end-ml-pipeline.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 're\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,892,"['# We can use the pandas library in python to read in the csv file.', '# This creates a pandas dataframe and assigns it to the titanic variable.', '# Print the first 5 rows of the dataframe.', ' # plots an axis lable', '# sets our legend for our graph.', 'titanic[""Deck""].unique() # 0 is for null values', 'titanic[""Deck""].unique() # Z is for null values', '# Create a family size variable including the passenger themselves', '# Discretize family size', '# The .apply method generates a new series', '    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.', '# Titles with very low cell counts to be combined to ""rare"" level', '# Also reassign mlle, ms, and mme accordingly', '#                \'Dr\', \'Major\', \'Rev\', \'Sir\', \'Jonkheer\']), ""Title""] = \'Rare Title\'', '# Titles with very low cell counts to be combined to ""rare"" level', '# Also reassign mlle, ms, and mme accordingly', '    # Split sets into train and test', '    # All age values are stored in a target array', '    # All the other values are stored in the feature array', '    # Create and fit a model', '    # Use the fitted model to predict the missing values', '    # Assign those predictions to the full data set', '# Import the linear regression class', '# Sklearn also has a helper that makes it easy to do cross validation', ""# The columns we'll use to predict the target"", '# Initialize our algorithm class', '# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.', '# We set random_state to ensure we get the same splits every time we run this.', ""    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds."", ""    # The target we're using to train the algorithm."", '    # Training the algorithm using the predictors and target.', '    # We can now make predictions on the test fold', '# Map predictions to outcomes (only possible outcomes are 1 and 0)', '# Initialize our algorithm', '# Compute the accuracy score for all the cross validation folds.', '# Take the mean of the scores (because we have one for each fold)', '# Initialize our algorithm with the default paramters', '# n_estimators is the number of trees we want to make', '# min_samples_split is the minimum number of rows we need to make a split', '# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)', '# Take the mean of the scores (because we have one for each fold)', '# Take the mean of the scores (because we have one for each fold)', ' #             ""FsizeD"", ""Embarked"", ""NlengthD"",""Deck"",""TicketNumber""]', '# Perform feature selection', '# Get the raw p-values for each feature, and transform from p-values into scores', '# Initialize our algorithm', '# Compute the accuracy score for all the cross validation folds.  ']",47,"['pd.read_csv', 'titanic.head', 'pd.read_csv', 'titanic_test.head', 'titanic_test.head', 'titanic.describe', 'titanic.info', 'titanic.isnull', 'None.sum', 'titanic_test.isnull', 'None.sum', 'get_ipython', 'None.run_line_magic', 'sns.set', 'titanic.hist', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'plt.subplots_adjust', 'g.fig.suptitle', 'titanic.Embarked.value_counts', 'None.plot', 'plt.title', 'sns.factorplot', 'sns.set', 'sns.factorplot', 'g.set_axis_labels', 'None.set_xticklabels', 'None.set_titles', 'None.set', 'None.despine', 'plt.subplots_adjust', 'g.fig.suptitle', 'sns.boxplot', 'sns.stripplot', 'sns.plt.title', 'titanic.Agetitanic.Pclass.plot', 'titanic.Agetitanic.Pclass.plot', 'titanic.Agetitanic.Pclass.plot', 'plt.xlabel', 'plt.title', 'plt.legend', 'titanic.corr', 'plt.figure', 'sns.heatmap', 'plt.title', 'titanic.corr', 'sns.factorplot', 'titanic.isnull', 'sns.boxplot', 'titanic.fillna', 'titanic_test.describe', 'titanic_test.isnull', 'dfdfdf.median', 'df.fillna', 'fill_missing_fare', 'titanic.unique', 'sns.factorplot', 'titanic.assign', 'None.sort', 'sns.FacetGrid', 'g.map', 'titanic.Deck.fillna', 'titanic_test.Deck.fillna', 'titanic.unique', 'print', 'print', 'print', 'sns.factorplot', 'titanic.apply', 'titanic_test.apply', 'pd.cut', 'pd.cut', 'sns.factorplot', 'print', 're.search', 'title_search.group', 'titanic.apply', 'print', 'titanic.value_counts', 'titanic_test.apply', 'print', 'titanic_test.value_counts', 'titanic.tail', 'titanic.str.extract', 'titanic.apply', 'titanic_test.str.extract', 'titanic_test.apply', 'titanic.isnull', 'titanic.TicketNumber.fillna', 'titanic_test.TicketNumber.fillna', 'LabelEncoder', 'labelEnc.fit_transform', 'labelEnc.fit_transform', 'titanic.head', 'sns.plotting_context', 'sns.set_style', 'sns.distplot', 'sns.plt.title', 'plt.ylabel', 'df.Age.notnull', 'df.Age.isnull', 'RandomForestRegressor', 'rtr.fit', 'rtr.predict', 'df.Age.isnull', 'fill_missing_age', 'fill_missing_age', 'sns.plotting_context', 'sns.set_style', 'sns.distplot', 'sns.plt.title', 'plt.ylabel', 'plt.xlim', 'preprocessing.StandardScaler', 'None.fit', 'std_scale.transform', 'preprocessing.StandardScaler', 'None.fit', 'std_scale.transform', 'titanic.corr', 'LinearRegression', 'KFold', 'alg.fit', 'alg.predict', 'predictions.append', 'np.concatenate', 'sum', 'len', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'RandomForestClassifier', 'KFold', 'ShuffleSplit', 'cross_validation.cross_val_predict', 'pd.Series', 'cross_val_score', 'print', 'RandomForestClassifier', 'rf.fit', 'KFold', 'cross_validation.cross_val_predict', 'pd.Series', 'cross_val_score', 'print', 'np.std', 'np.argsort', 'sorted_important_features.append', 'plt.figure', 'plt.title', 'plt.bar', 'plt.xticks', 'plt.xlim', 'plt.show', 'get_ipython', 'None.run_line_magic', 'SelectKBest', 'selector.fit', 'np.log10', 'np.argsort', 'sorted_important_features.append', 'plt.figure', 'plt.title', 'plt.bar', 'plt.xticks', 'plt.xlim', 'plt.show', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'AdaBoostClassifier', 'adb.fit', 'ShuffleSplit', 'cross_val_score', 'print', 'VotingClassifier', 'eclf1.fit', 'eclf1.predict', 'eclf1.predict', 'test_predictions.astype', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'head', 'read_csv', 'head', 'head', 'describe', 'info', 'isnull', 'sum', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'set', 'hist', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'subplots_adjust', 'fig', 'Embarked', 'plot', 'title', 'factorplot', 'set', 'factorplot', 'set_axis_labels', 'set_xticklabels', 'set_titles', 'set', 'despine', 'subplots_adjust', 'fig', 'boxplot', 'stripplot', 'plt', 'Agetitanic', 'Agetitanic', 'Agetitanic', 'xlabel', 'title', 'legend', 'corr', 'figure', 'heatmap', 'title', 'corr', 'factorplot', 'isnull', 'boxplot', 'fillna', 'describe', 'isnull', 'median', 'fillna', 'fill_missing_fare', 'unique', 'factorplot', 'assign', 'sort', 'FacetGrid', 'map', 'Deck', 'Deck', 'unique', 'print', 'print', 'print', 'factorplot', 'apply', 'apply', 'cut', 'cut', 'factorplot', 'print', 'search', 'group', 'apply', 'print', 'value_counts', 'apply', 'print', 'value_counts', 'tail', 'str', 'apply', 'str', 'apply', 'isnull', 'TicketNumber', 'TicketNumber', 'LabelEncoder', 'fit_transform', 'fit_transform', 'head', 'plotting_context', 'set_style', 'distplot', 'plt', 'ylabel', 'Age', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'Age', 'fill_missing_age', 'fill_missing_age', 'plotting_context', 'set_style', 'distplot', 'plt', 'ylabel', 'xlim', 'StandardScaler', 'fit', 'transform', 'StandardScaler', 'fit', 'transform', 'corr', 'LinearRegression', 'KFold', 'fit', 'predict', 'append', 'concatenate', 'sum', 'len', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'RandomForestClassifier', 'KFold', 'ShuffleSplit', 'cross_val_predict', 'Series', 'cross_val_score', 'print', 'RandomForestClassifier', 'fit', 'KFold', 'cross_val_predict', 'Series', 'cross_val_score', 'print', 'std', 'argsort', 'append', 'figure', 'title', 'bar', 'xticks', 'xlim', 'show', 'get_ipython', 'run_line_magic', 'SelectKBest', 'fit', 'log10', 'argsort', 'append', 'figure', 'title', 'bar', 'xticks', 'xlim', 'show', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'AdaBoostClassifier', 'fit', 'ShuffleSplit', 'cross_val_score', 'print', 'VotingClassifier', 'fit', 'predict', 'predict', 'astype', 'DataFrame', 'to_csv']","['read_csv', 'head', 'describe', 'info', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'set', 'hist', 'FacetGrid', 'map', 'add_legend', 'subplots_adjust', 'fig', 'Embarked', 'plot', 'title', 'factorplot', 'set_axis_labels', 'set_xticklabels', 'set_titles', 'despine', 'boxplot', 'stripplot', 'plt', 'Agetitanic', 'xlabel', 'legend', 'corr', 'figure', 'heatmap', 'fillna', 'median', 'fill_missing_fare', 'unique', 'assign', 'sort', 'Deck', 'print', 'apply', 'cut', 'search', 'group', 'value_counts', 'tail', 'str', 'TicketNumber', 'LabelEncoder', 'fit_transform', 'plotting_context', 'set_style', 'distplot', 'ylabel', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'fill_missing_age', 'xlim', 'StandardScaler', 'transform', 'LinearRegression', 'KFold', 'append', 'concatenate', 'len', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'RandomForestClassifier', 'cross_val_predict', 'Series', 'std', 'argsort', 'bar', 'xticks', 'show', 'SelectKBest', 'log10', 'AdaBoostClassifier', 'VotingClassifier', 'astype', 'DataFrame', 'to_csv']",85,"[1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0
 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv head read csv head head describe info isnull sum isnull sum get ipython run line magic set hist facetgrid map facetgrid map add legend facetgrid map add legend subplots adjust fig embarked plot title factorplot set factorplot set axis labels set xticklabels set titles set despine subplots adjust fig boxplot stripplot plt agetitanic agetitanic agetitanic xlabel title legend corr figure heatmap title corr factorplot isnull boxplot fillna describe isnull median fillna fill missing fare unique factorplot assign sort facetgrid map deck deck unique print print print factorplot apply apply cut cut factorplot print search group apply print value counts apply print value counts tail str apply str apply isnull ticketnumber ticketnumber labelencoder fit transform fit transform head plotting context set style distplot plt ylabel age age randomforestregressor fit predict age fill missing age fill missing age plotting context set style distplot plt ylabel xlim standardscaler fit transform standardscaler fit transform corr linearregression kfold fit predict append concatenate sum len logisticregression shufflesplit cross val score print randomforestclassifier kfold shufflesplit cross val predict series cross val score print randomforestclassifier fit kfold cross val predict series cross val score print std argsort append figure title bar xticks xlim show get ipython run line magic selectkbest fit log10 argsort append figure title bar xticks xlim show logisticregression shufflesplit cross val score print adaboostclassifier fit shufflesplit cross val score print votingclassifier fit predict predict astype dataframe csv,"[0.0, 0.0, 0.0, 0.0459481258561887, 0.0, 0.05948311579291685, 0.12623185658387848, 0.15580304090887323, 0.0, 0.0, 0.0, 0.19795650699425968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09099197354521053, 0.15741250272078108, 0.0, 0.0, 0.0, 0.0, 0.1393700534085434, 0.0, 0.0, 0.06311592829193924, 0.02301981951011469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0555571288356153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0947569231784116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07848873793831522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05878897378427947, 0.0, 0.0, 0.0, 0.1215426311670352, 0.0, 0.0, 0.106334304254352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06275348760880932, 0.0, 0.0, 0.27194056829615254, 0.0, 0.0, 0.041474105475262375, 0.0, 0.0, 0.0, 0.0686018483090248, 0.0, 0.0, 0.0, 0.017321705999376078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1215426311670352, 0.0, 0.0, 0.0, 0.0, 0.04944150949015936, 0.0, 0.0, 0.05878897378427947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07545941318821421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03137674380440466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12819136168806874, 0.2379158989598021, 0.0, 0.0, 0.0, 0.0, 0.03924436896915761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1215426311670352, 0.09159953414090005, 0.0, 0.0, 0.1666713865068459, 0.03599343501748474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15235404322489754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03630331266549444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0481580800899117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06589400765201683, 0.03325056372054941, 0.0, 0.03275589631829324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022794203778813683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04581303373355643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12295754884721094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13398322774686924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036057253689345474, 0.057071791210665794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07959317089208971, 0.03227955420140361, 0.0, 0.0, 0.0, 0.0, 0.04649892861203014, 0.0, 0.0, 0.05878897378427947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06598550233141989, 0.0, 0.0, 0.0, 0.04626825860252617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04626825860252617, 0.0, 0.0, 0.09684556185938761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03457748893904844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17121537363199738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026531056964029902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10840443434237028, 0.18934778487581772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0948422617459535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16222548984174653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04470902160111437, 0.057071791210665794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027538303979970213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04603963902022938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11624732153007535, 0.0, 0.0481580800899117, 0.0, 0.0, 0.0, 0.0555571288356153, 0.0, 0.0, 0.0, 0.0, 0.06753004599126171, 0.19881049499901407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06026255524932965, 0.0, 0.25246371316775695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028463651053917367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08483786402190076, 0.0, 0.0, 0.0, 0.0, 0.03965264982663368, 0.0, 0.0, 0.07692950093690341, 0.0, 0.0, 0.0, 0.0, 0.06311592829193924, 0.0686018483090248, 0.0, 0.0, 0.0, 0.0, 0.06409568084403437, 0.07339065250437236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04096155154277128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13197100466283979, 0.0, 0.0, 0.12973210716936173, 0.0607713155835176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11248281445872202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08382912556979917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27194056829615254, 0.0, 0.0, 0.06275348760880932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04987526266352538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035444768084784, 0.1626066515135554, 0.04096155154277128, 0.08192310308554256, 0.0, 0.0686018483090248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
harrygem_titanic-pipeline-and-save-load-model.py,"['necessary', 'numpy', 'pandas', 'sklearn', 'dill']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]",5,133,"['# import necessary libraries', '        # check below link to understand the data cleansing process.', '        # https://www.kaggle.com/startupsci/titanic-data-science-solutions', '        # make sure to return a narray instead of DataFrame', '# create the pipeline: preprocessing first, then RF model', '# load data', '# fit the pipeline with Training features data and label data', '# Use pickle to save model for next usage.', '# Open saved model, and directly make the prediction with new data']",9,"['dataset.drop', 'dataset.Name.str.extract', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.map', 'dataset.fillna', 'dataset.drop', 'dataset.map', 'None.astype', 'dataset.fillna', 'None.astype', 'dataset.drop', 'dataset.fillna', 'dataset.map', 'None.astype', 'dataset.fillna', 'dataset.astype', 'dataset.as_matrix', 'Pipeline', 'pd.read_csv', 'pd.read_csv', 'df_train.drop', 'df_test.drop', 'None.copy', 'pipe.fit', 'pipe.predict', 'open', 'pickle.dump', 'open', 'pickle.load', 'loaded_model.predict']","['drop', 'Name', 'replace', 'replace', 'replace', 'replace', 'map', 'fillna', 'drop', 'map', 'astype', 'fillna', 'astype', 'drop', 'fillna', 'map', 'astype', 'fillna', 'astype', 'as_matrix', 'Pipeline', 'read_csv', 'read_csv', 'drop', 'drop', 'copy', 'fit', 'predict', 'open', 'dump', 'open', 'load', 'predict']","['drop', 'Name', 'replace', 'map', 'fillna', 'astype', 'as_matrix', 'Pipeline', 'read_csv', 'copy', 'fit', 'predict', 'open', 'dump', 'load']",15,"[0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",drop name replace replace replace replace map fillna drop map astype fillna astype drop fillna map astype fillna astype matrix pipeline read csv read csv drop drop copy fit predict open dump open load predict,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34456837857547323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10716810432389867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10346638665143985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33103091336166124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24692328210735154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26938090322313274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057012160347688745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23618509545962757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2718031591819507, 0.0, 0.14996146275735203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12835693405814347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45482271625349335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21356742774651624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11830256508554401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10305064237067037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4086555098530454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
liyaoo_titanic-decisiontree.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,109,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",8,"['os.walk', 'print', 'pd.read_csv', 'train_set.head', 'train_set.info', 'features.info', 'features.fillna', 'features.replace', 'features.replace', 'features.head', 'train_test_split', 'DictVectorizer', 'vec.fit_transform', 'vec.fit_transform', 'print', 'DecisionTreeClassifier', 'dtc.fit', 'dtc.predict', 'print', 'print']","['walk', 'print', 'read_csv', 'head', 'info', 'info', 'fillna', 'replace', 'replace', 'head', 'train_test_split', 'DictVectorizer', 'fit_transform', 'fit_transform', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'print']","['walk', 'print', 'read_csv', 'head', 'info', 'fillna', 'replace', 'train_test_split', 'DictVectorizer', 'fit_transform', 'DecisionTreeClassifier', 'fit', 'predict']",13,"[1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head info info fillna replace replace head train test split dictvectorizer fit transform fit transform print decisiontreeclassifier fit predict print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08869989359646033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1946028317935903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44710218940988217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.115467729308578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29325306818225216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2113894224022897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2924972235029043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10141868557395928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37848940435233763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08834348341668066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35033310251458305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15454415077254555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16114838079836374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15860944729626295, 0.0, 0.0, 0.0, 0.3608473368956699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18839623544494757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sudeeshvarier_titanic-logistic-regression-analysis-ml.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'cufflinks', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,385,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['cf.go_offline', 'print', 'pd.read_csv', 'train.head', 'train.isnull', 'sns.heatmap', 'sns.set_style', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.distplot', 'train.plot.hist', 'train.info', 'sns.countplot', 'train.hist', 'plt.figure', 'sns.boxplot', 'pd.isnull', 'train.apply', 'sns.heatmap', 'train.drop', 'train.head', 'plt.figure', 'sns.heatmap', 'train.dropna', 'plt.figure', 'sns.heatmap', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'train.head', 'train.drop', 'train.head', 'train.drop', 'train.head', 'train.drop', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'confusion_matrix', 'train.head', 'pd.get_dummies', 'Pclass.head', 'pd.concat', 'train.head', 'train.drop', 'train.head', 'logmodel.fit', 'logmodel.predict', 'print']","['go_offline', 'print', 'read_csv', 'head', 'isnull', 'heatmap', 'set_style', 'countplot', 'countplot', 'countplot', 'distplot', 'plot', 'info', 'countplot', 'hist', 'figure', 'boxplot', 'isnull', 'apply', 'heatmap', 'drop', 'head', 'figure', 'heatmap', 'dropna', 'figure', 'heatmap', 'get_dummies', 'get_dummies', 'concat', 'head', 'drop', 'head', 'drop', 'head', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix', 'head', 'get_dummies', 'head', 'concat', 'head', 'drop', 'head', 'fit', 'predict', 'print']","['go_offline', 'print', 'read_csv', 'head', 'isnull', 'heatmap', 'set_style', 'countplot', 'distplot', 'plot', 'info', 'hist', 'figure', 'boxplot', 'apply', 'drop', 'dropna', 'get_dummies', 'concat', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'confusion_matrix']",24,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",go offline print read csv head isnull heatmap set style countplot countplot countplot distplot plot info countplot hist figure boxplot isnull apply heatmap drop head figure heatmap dropna figure heatmap get dummies get dummies concat head drop head drop head drop train test split logisticregression fit predict print confusion matrix head get dummies head concat head drop head fit predict print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.078415328026767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11729792790520344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16132745824607733, 0.0, 0.0, 0.12678641444704028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3675038137612462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04132080399265626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11277073680145484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.264404004608908, 0.09005970852244462, 0.0, 0.0, 0.22401775974426502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27378285940216374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09107453653952272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16276105834841628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18864789525030282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4431404865066808, 0.39753190876026945, 0.0, 0.09790446032736791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06812984745926456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14700367037539108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06914585460813079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11977857562424757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19722479679422056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07929896922183652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09449169458669207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1322393341447391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041154770476915375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07427836057040292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07199432043668999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1025224110934204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07507089790882057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0738881369230184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
lukego_titanic-data-preprocess.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'collections', 'math\n', 're\n']","[1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,375,"['# æŸ¥çœ‹æ•°æ®ä¸\xadç¼ºå¤±å€¼çš„æ¯”ä¾‹', '# æ•°å€¼ç±»åž‹ç‰¹å¾ç®±çº¿å›¾', '# æ•°å€¼ç±»åž‹ç‰¹å¾æ¡å½¢å›¾', '# æ˜Žæ˜¾æœ‰ååˆ†å¸ƒï¼Œè¿›è¡Œå–logå¯¹æ•°å˜æ¢', '# ç¦»æ•£ç‰¹å¾åˆ†å¸ƒ', '# å¯¹idç±»åž‹æ—\xa0æ³•ç›´æŽ¥å¯è§†åŒ–ï¼Œå…ˆæš‚æ—¶è·³è¿‡', '# è¿›ä¸€æ\xad¥çœ‹çœ‹ticketå–å€¼ä¸Žå¯¹åº”é¢‘æ•°', '# å¯¹idç±»åž‹å¦‚å–å€¼å¤ªå¤šæ—\xa0æ³•ç›´æŽ¥å¯è§†åŒ–ï¼Œé€šå¸¸æŒ‰é¢‘çŽ‡ä»Žé«˜åˆ°ä½ŽæŽ’åºåŽå¯è§†åŒ–', '# æŸ¥çœ‹ç‰¹å¾åœ¨æ\xad£è´Ÿæ\xa0·æœ¬ä¸Šçš„åˆ†å¸ƒ', '# æ•°å€¼ç±»åž‹ç‰¹å¾æŸ¥çœ‹åˆ†å¸ƒ', '# æ‰“å°pearsonç³»æ•°', '# åˆ†ç±»å˜é‡éœ€è¦å…ˆencodeæˆæ•°å€¼åž‹æ‰èƒ½æ±‚ç›¸å…³æ€§', '# æ•´ä½“æ¥çœ‹ç‰¹å¾ä¸Žlabelä¹‹é—´çš„ç›¸å…³æ€§', '# å…ˆçœ‹æ–‡æœ¬ç±»çš„ç‰¹å¾çš„ç»Ÿè®¡è¯é¢‘æƒ…å†µï¼Œæœ‰ä¸ªåˆæ\xad¥äº†è§£', '# å¯ä»¥è€ƒè™‘æŠŠå§“åä¸\xadçš„ç§°è°“æå–åšç‰¹å¾æ•°æ®', '# cabinæ•°æ®å¯çŸ¥å…¶é¦–å\xad—æ¯ä»£è¡¨å®¢èˆ±ç±»åˆ«ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶é¦–å\xad—æ¯æå‡º']",16,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'data.head', 'data.info', 'data.value_counts', 'print', 'print', 'datacol.isnull', 'datacol.apply', 'zip', 'sum', '.format', 'naCount', 'datanumeric_cols.apply', 'datastring_cols.astype', 'plt.figure', 'plt.subplot', 'datacols.plot.box', 'plt.figure', 'plt.subplot', 'datacols.plot.hist', 'plt.title', 'data.value_counts', 'plt.figure', 'plt.subplot', 'datacol.apply', 'tmp.plot.hist', 'plt.title', 'plt.figure', 'plt.subplot', 'datacols.value_counts', 'None.plot', 'plt.title', 'print', 'data.value_counts', 'plt.figure', 'plt.subplot', 'datacols.value_counts', 'None.sort_values', 'None.plot', 'plt.title', 'data.groupby', 'grouped.get_group', 'grouped.get_group', 'plt.figure', 'plt.subplot', 'group0col.value_counts', 'None.sort_values', 'None.plot', 'plt.title', 'plt.subplot', 'group1col.value_counts', 'None.sort_values', 'None.plot', 'plt.title', 'plt.figure', 'plt.subplot', 'group0col.plot.hist', 'plt.title', 'plt.subplot', 'group1col.plot.hist', 'plt.title', 'plt.figure', 'plt.subplot', 'group0col.value_counts', 'None.plot', 'plt.title', 'plt.subplot', 'group1col.value_counts', 'None.plot', 'plt.title', 'sns.set', 'datanumeric_cols.fillna', 'sns.pairplot', 'filled_numeric.corr', 'print', 'datadiscrete_cols.fillna', 'filled_discretecol.astype', 'filled_discrete.select_dtypes', 'filled_discrete.select_dtypes', 'filled_discrete.apply', 'filled_discrete.corr', 'print', 'pd.concat', 'filled.corr', 'print', 'datastring_cols.head', 'range', 's.strip', 'None.split', 'enumerate', 'datacol.apply', 'print', 'print', 'print', 're.search', 'title.group', 'data.apply', 'title.value_counts', 'title.replace', 'title.replace', 'title.replace', 'title.replace', 'title.value_counts', 'data.fillna', 'data.value_counts', 'data.apply', 'b.value_counts', 'b.map', 'cabin.value_counts']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'value_counts', 'print', 'print', 'isnull', 'apply', 'zip', 'sum', 'format', 'naCount', 'apply', 'astype', 'figure', 'subplot', 'plot', 'figure', 'subplot', 'plot', 'title', 'value_counts', 'figure', 'subplot', 'apply', 'plot', 'title', 'figure', 'subplot', 'value_counts', 'plot', 'title', 'print', 'value_counts', 'figure', 'subplot', 'value_counts', 'sort_values', 'plot', 'title', 'groupby', 'get_group', 'get_group', 'figure', 'subplot', 'value_counts', 'sort_values', 'plot', 'title', 'subplot', 'value_counts', 'sort_values', 'plot', 'title', 'figure', 'subplot', 'plot', 'title', 'subplot', 'plot', 'title', 'figure', 'subplot', 'value_counts', 'plot', 'title', 'subplot', 'value_counts', 'plot', 'title', 'set', 'fillna', 'pairplot', 'corr', 'print', 'fillna', 'astype', 'select_dtypes', 'select_dtypes', 'apply', 'corr', 'print', 'concat', 'corr', 'print', 'head', 'range', 'strip', 'split', 'enumerate', 'apply', 'print', 'print', 'print', 'search', 'group', 'apply', 'value_counts', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'fillna', 'value_counts', 'apply', 'value_counts', 'map', 'value_counts']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'value_counts', 'print', 'isnull', 'apply', 'zip', 'sum', 'format', 'naCount', 'astype', 'figure', 'subplot', 'plot', 'title', 'sort_values', 'groupby', 'get_group', 'set', 'fillna', 'pairplot', 'corr', 'select_dtypes', 'concat', 'range', 'strip', 'split', 'enumerate', 'search', 'group', 'replace', 'map']",35,"[1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv head info value counts print print isnull apply zip sum format nacount apply astype figure subplot plot figure subplot plot title value counts figure subplot apply plot title figure subplot value counts plot title print value counts figure subplot value counts sort values plot title groupby get group get group figure subplot value counts sort values plot title subplot value counts sort values plot title figure subplot plot title subplot plot title figure subplot value counts plot title subplot value counts plot title set fillna pairplot corr print fillna astype select dtypes select dtypes apply corr print concat corr print head range strip split enumerate apply print print print search group apply value counts replace replace replace replace value counts fillna value counts apply value counts map value counts,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18212669057701672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045658274253139265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026764115064277064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10545349462945827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43563572738429385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013710186283614636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10507544899939578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04698600681863046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24224207604682305, 0.0, 0.0, 0.0, 0.05354293047189524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05375323850047544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054003896682931166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14327750228126435, 0.0237655755663383, 0.0, 0.0, 0.0, 0.0, 0.032674090599323434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02260539026072132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022716773014401212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024387808446078272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023056879682661752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022942500043941317, 0.0, 0.0, 0.024010837821905953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07427879327292648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0514280471580439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28942418553993965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13163049093631538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030902492385592853, 0.0, 0.0, 0.0, 0.013655096590041986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10830074089250705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022829137126569633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04775916742708811, 0.0, 0.10081448591629097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024645458506632887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08468362570095629, 0.0, 0.0, 0.0, 0.02388761711230712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05659904270903423, 0.0, 0.0, 0.0, 0.0, 0.49404699540382246, 0.0, 0.0, 0.02426090944652517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25731496834602513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43563572738429385, 0.08468362570095629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04946212588977968, 0.0]"
yasserabdelsattar_titanic-predictions-using-g-boosting.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,216,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', ""# Change type of 'Sex' feature to numeric""]",9,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.describe', 'train.head', 'print', 'print', 'print', 'print', 'train.map', 'test.map', 'train.head', 'train.drop', 'train.head', 'print', 'train.fillna', 'train.head', 'test.head', 'print', 'test.drop', 'test.drop', 'test.head', 'train.map', 'None.astype', 'test.map', 'None.astype', 'train.head', 'print', 'test.groupby', 'None.median', 'test.fillna', 'print', 'df.corr', 'None.abs', 'plt.figure', 'sns.heatmap', 'plt.show', 'train.drop', 'train_test_split', 'GradientBoostingClassifier', 'gb.fit', 'gb.predict', 'round', 'print', 'pd.DataFrame', 'submit.to_csv']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'describe', 'head', 'print', 'print', 'print', 'print', 'map', 'map', 'head', 'drop', 'head', 'print', 'fillna', 'head', 'head', 'print', 'drop', 'drop', 'head', 'map', 'astype', 'map', 'astype', 'head', 'print', 'groupby', 'median', 'fillna', 'print', 'corr', 'abs', 'figure', 'heatmap', 'show', 'drop', 'train_test_split', 'GradientBoostingClassifier', 'fit', 'predict', 'round', 'print', 'DataFrame', 'to_csv']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'describe', 'head', 'map', 'drop', 'fillna', 'astype', 'groupby', 'median', 'corr', 'abs', 'figure', 'heatmap', 'show', 'train_test_split', 'GradientBoostingClassifier', 'fit', 'predict', 'round', 'DataFrame', 'to_csv']",25,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic read csv read csv describe head print print print print map map head drop head print fillna head head print drop drop head map astype map astype head print groupby median fillna print corr abs figure heatmap show drop train test split gradientboostingclassifier fit predict round print dataframe csv,"[0.0, 0.21568195655556624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1689078543781349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13003793803641406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1521580602532735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06354898206821134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09069423069900304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25963483493134426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11201854968916346, 0.0, 0.0, 0.0, 0.13205085899632849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05589486602109081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06659386106885991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1575503422139156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08791818005902034, 0.0, 0.0, 0.0, 0.0, 0.4230599424765092, 0.12198795417213662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08403824829173885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08529643617849705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08487330105837176, 0.0, 0.0, 0.3553020051379325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12685610901319497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05799206682470442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5410586497306952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10103111009245368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12484817833961698, 0.0, 0.08445392718906745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11054407813705494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08836965957750359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09214601446531835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09069423069900304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1077265694542922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
paultimothymooney_titanic-quick-analysis-w-minimal-dataset.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'os\n', 'itertools\n', 'sklearn', 'make_scorer,']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]",8,520,"[""# os.chdir('/Users/ptm/desktop/Current_working_directory')"", ""# trainingData = pd.read_csv('train.csv')"", ""# testingData = pd.read_csv('test.csv')"", '# Next we will need to split up our training data, setting aside 20% of the training data for cross-validation testing, such that we can avoid potentially overfitting the data.', '    # boxplot algorithm comparison', '#    predictions = model.predict(c)', '#    print(accuracy_score(d, predictions))', ""#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))"", '#    predictions = model.predict(c)', '#    print(accuracy_score(d, predictions))', ""#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))"", '#    predictions = model.predict(c)', '#    print(accuracy_score(d, predictions))', ""#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))"", '# It looks like our model can predict with about 70-75% accuracty whether or not a given', '# passenger survived the sinking of the Titanic despite using only a minimal dataset.  That is pretty good!', '#    ""PassengerId"": testingData2[""PassengerId""],', '#    ""Survived"": prediction})', ""# to finish the submission process, upload the file 'new_submission.csv' to Kaggle""]",19,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'describeTheData', 'sns.set_style', 'sns.FacetGrid', 'distributionOne.map', 'distributionOne.add_legend', 'distributionOne.set_axis_labels', 'distributionOne.fig.suptitle', 'sns.FacetGrid', 'distributionTwo.map', 'distributionTwo.set', 'distributionTwo.add_legend', 'distributionTwo.set_axis_labels', 'distributionTwo.fig.suptitle', 'plotAgeDistribution', 'trainingData.drop', 'testingData.drop', 'input.fillna', 'input.fillna', 'replaceMissingValuesWithMedianValues', 'replaceMissingValuesWithMedianValues', 'trainingData.astype', 'trainingData.astype', 'sexToBinary', 'sexToBinary', 'input.Age.fillna', 'pd.cut', 'ageToCategory', 'ageToCategory', 'input.Fare.fillna', 'pd.cut', 'fareToCategory', 'fareToCategory', 'trainingData.drop', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'describeDataAgain', 'plt.figure', 'sns.heatmap', 'heatmap.set_title', 'makeAHeatMap', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'pivotTheData', 'plt.figure', 'plt.subplot', 'sns.barplot', 'plotOne.set_title', 'plt.subplot', 'sns.barplot', 'plotTwo.set_title', 'plotTheData', 'plt.figure', 'sns.pointplot', 'plotThree.set_title', 'plotTheDataAgain', 'print', 'print', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'model.fit', 'model_selection.KFold', 'model_selection.cross_val_score', 'resultsAccuracy.append', 'names.append', 'accuracy_results.mean', 'accuracy_results.std', 'print', 'plt.figure', 'fig.suptitle', 'fig.add_subplot', 'plt.boxplot', 'ax.set_xticklabels', 'ax.set_ylabel', 'plt.show', 'compareABunchOfDifferentModelsAccuracy', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'defineModels', 'print', 'print', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'model.fit', 'model_selection.KFold', 'model_selection.cross_val_score', 'resultsF1.append', 'names.append', 'f1_results.mean', 'f1_results.std', 'print', 'plt.figure', 'fig.suptitle', 'fig.add_subplot', 'plt.boxplot', 'ax.set_xticklabels', 'ax.set_ylabel', 'plt.show', 'compareABunchOfDifferentModelsF1Score', 'defineModels', 'np.linspace', 'plt.figure', 'plt.title', 'plt.ylim', 'plt.xlabel', 'plt.ylabel', 'learning_curve', 'np.mean', 'np.std', 'np.mean', 'np.std', 'plt.grid', 'plt.fill_between', 'plt.fill_between', 'plt.plot', 'plt.plot', 'plt.legend', 'plot_learning_curve', 'plot_learning_curve', 'plot_learning_curve', 'LogisticRegression', 'make_scorer', 'GridSearchCV', 'grid_obj.fit', 'model.fit', 'print', 'print', 'print', 'model_selection.KFold', 'model_selection.cross_val_score', 'accuracy.mean', 'accuracy.std', 'print', 'selectParametersForLR', 'SVC', 'make_scorer', 'GridSearchCV', 'grid_obj.fit', 'model.fit', 'print', 'print', 'model_selection.KFold', 'model_selection.cross_val_score', 'accuracy.mean', 'accuracy.std', 'print', 'selectParametersForSVM', 'KNeighborsClassifier', 'make_scorer', 'GridSearchCV', 'grid_obj.fit', 'model.fit', 'print', 'print', 'model_selection.KFold', 'model_selection.cross_val_score', 'accuracy.mean', 'accuracy.std', 'print', 'print', 'selectParametersForKNN', 'plt.figure', 'plt.imshow', 'plt.title', 'plt.colorbar', 'np.arange', 'plt.xticks', 'plt.yticks', 'cm.astype', 'cm.sum', 'cm.max', 'itertools.product', 'plt.text', 'plt.tight_layout', 'plt.ylabel', 'plt.xlabel', 'SVC', 'classifier.fit', 'model_selection.KFold', 'model_selection.cross_val_score', 'accuracy.mean', 'accuracy.std', 'print', 'classifier.predict', 'confusion_matrix', 'np.set_printoptions', 'plt.figure', 'plot_confusion_matrix', 'plot_learning_curve', 'runSVMconfusion']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'describeTheData', 'set_style', 'FacetGrid', 'map', 'add_legend', 'set_axis_labels', 'fig', 'FacetGrid', 'map', 'set', 'add_legend', 'set_axis_labels', 'fig', 'plotAgeDistribution', 'drop', 'drop', 'fillna', 'fillna', 'replaceMissingValuesWithMedianValues', 'replaceMissingValuesWithMedianValues', 'astype', 'astype', 'sexToBinary', 'sexToBinary', 'Age', 'cut', 'ageToCategory', 'ageToCategory', 'Fare', 'cut', 'fareToCategory', 'fareToCategory', 'drop', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'describeDataAgain', 'figure', 'heatmap', 'set_title', 'makeAHeatMap', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'pivotTheData', 'figure', 'subplot', 'barplot', 'set_title', 'subplot', 'barplot', 'set_title', 'plotTheData', 'figure', 'pointplot', 'set_title', 'plotTheDataAgain', 'print', 'print', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'fit', 'KFold', 'cross_val_score', 'append', 'append', 'mean', 'std', 'print', 'figure', 'suptitle', 'add_subplot', 'boxplot', 'set_xticklabels', 'set_ylabel', 'show', 'compareABunchOfDifferentModelsAccuracy', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'defineModels', 'print', 'print', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'fit', 'KFold', 'cross_val_score', 'append', 'append', 'mean', 'std', 'print', 'figure', 'suptitle', 'add_subplot', 'boxplot', 'set_xticklabels', 'set_ylabel', 'show', 'compareABunchOfDifferentModelsF1Score', 'defineModels', 'linspace', 'figure', 'title', 'ylim', 'xlabel', 'ylabel', 'learning_curve', 'mean', 'std', 'mean', 'std', 'grid', 'fill_between', 'fill_between', 'plot', 'plot', 'legend', 'plot_learning_curve', 'plot_learning_curve', 'plot_learning_curve', 'LogisticRegression', 'make_scorer', 'GridSearchCV', 'fit', 'fit', 'print', 'print', 'print', 'KFold', 'cross_val_score', 'mean', 'std', 'print', 'selectParametersForLR', 'SVC', 'make_scorer', 'GridSearchCV', 'fit', 'fit', 'print', 'print', 'KFold', 'cross_val_score', 'mean', 'std', 'print', 'selectParametersForSVM', 'KNeighborsClassifier', 'make_scorer', 'GridSearchCV', 'fit', 'fit', 'print', 'print', 'KFold', 'cross_val_score', 'mean', 'std', 'print', 'print', 'selectParametersForKNN', 'figure', 'imshow', 'title', 'colorbar', 'arange', 'xticks', 'yticks', 'astype', 'sum', 'max', 'product', 'text', 'tight_layout', 'ylabel', 'xlabel', 'SVC', 'fit', 'KFold', 'cross_val_score', 'mean', 'std', 'print', 'predict', 'confusion_matrix', 'set_printoptions', 'figure', 'plot_confusion_matrix', 'plot_learning_curve', 'runSVMconfusion']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'describeTheData', 'set_style', 'FacetGrid', 'map', 'add_legend', 'set_axis_labels', 'fig', 'set', 'plotAgeDistribution', 'drop', 'fillna', 'replaceMissingValuesWithMedianValues', 'astype', 'sexToBinary', 'Age', 'cut', 'ageToCategory', 'Fare', 'fareToCategory', 'train_test_split', 'describeDataAgain', 'figure', 'heatmap', 'set_title', 'makeAHeatMap', 'pivotTheData', 'subplot', 'barplot', 'plotTheData', 'pointplot', 'plotTheDataAgain', 'append', 'fit', 'KFold', 'cross_val_score', 'mean', 'std', 'suptitle', 'add_subplot', 'boxplot', 'set_xticklabels', 'set_ylabel', 'show', 'compareABunchOfDifferentModelsAccuracy', 'defineModels', 'compareABunchOfDifferentModelsF1Score', 'linspace', 'title', 'ylim', 'xlabel', 'ylabel', 'learning_curve', 'grid', 'fill_between', 'plot', 'legend', 'plot_learning_curve', 'LogisticRegression', 'make_scorer', 'GridSearchCV', 'selectParametersForLR', 'SVC', 'selectParametersForSVM', 'KNeighborsClassifier', 'selectParametersForKNN', 'imshow', 'colorbar', 'arange', 'xticks', 'yticks', 'sum', 'max', 'product', 'text', 'tight_layout', 'predict', 'confusion_matrix', 'set_printoptions', 'plot_confusion_matrix', 'runSVMconfusion']",84,"[1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0
 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0
 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0
 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print print print print print print print print print print print describethedata set style facetgrid map add legend set axis labels fig facetgrid map set add legend set axis labels fig plotagedistribution drop drop fillna fillna replacemissingvalueswithmedianvalues replacemissingvalueswithmedianvalues astype astype sextobinary sextobinary age cut agetocategory agetocategory fare cut faretocategory faretocategory drop train test split print print print print print print print print describedataagain figure heatmap set title makeaheatmap print print print print print print print pivotthedata figure subplot barplot set title subplot barplot set title plotthedata figure pointplot set title plotthedataagain print print append append append append append append append append append fit kfold cross val score append append mean std print figure suptitle add subplot boxplot set xticklabels set ylabel show compareabunchofdifferentmodelsaccuracy print print print print print print print print print definemodels print print append append append append append append append append append fit kfold cross val score append append mean std print figure suptitle add subplot boxplot set xticklabels set ylabel show compareabunchofdifferentmodelsf1score definemodels linspace figure title ylim xlabel ylabel learning curve mean std mean std grid fill fill plot plot legend plot learning curve plot learning curve plot learning curve logisticregression make scorer gridsearchcv fit fit print print print kfold cross val score mean std print selectparametersforlr svc make scorer gridsearchcv fit fit print print kfold cross val score mean std print selectparametersforsvm kneighborsclassifier make scorer gridsearchcv fit fit print print kfold cross val score mean std print print selectparametersforknn figure imshow title colorbar arange xticks yticks astype sum max product text tight layout ylabel xlabel svc fit kfold cross val score mean std print predict confusion matrix set printoptions figure plot confusion matrix plot learning curve runsvmconfusion,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.07714533091124046, 0.0, 0.020206535901274726, 0.0, 0.0, 0.0, 0.0, 0.09713890285901339, 0.0, 0.0, 0.0, 0.0, 0.43270354382213816, 0.0, 0.031228786312406442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044782579979686314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07205360767285711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04596931963840475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050897129213412724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036026803836428554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048569451429506694, 0.048569451429506694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05501430957784246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15115174052631114, 0.0, 0.0, 0.01792964579660772, 0.0, 0.0, 0.18013401918214278, 0.04448583617699999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09713890285901339, 0.0, 0.0, 0.048569451429506694, 0.048569451429506694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03441852305694408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0415637483240504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025448564606706362, 0.0, 0.09713890285901339, 0.0, 0.0, 0.0, 0.0, 0.07881603356023517, 0.1583973598427778, 0.0, 0.0, 0.07205360767285711, 0.02334045063075477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08891651547853816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011770697581242414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037009008018106526, 0.07139662951915149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021561797049579924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04518823848581767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014854053962670389, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17376662777841803, 0.020068696445819857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07401801603621305, 0.0, 0.0, 0.0, 0.032342317573425365, 0.24284725714753347, 0.05161331434050687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015076443066976858, 0.0, 0.0, 0.0, 0.0, 0.036026803836428554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015001652456325114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015001652456325114, 0.11102702405431956, 0.048569451429506694, 0.03140043530561457, 0.0, 0.05197351521394962, 0.0, 0.03024658213072847, 0.0, 0.0, 0.0, 0.1289214697387523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048569451429506694, 0.12043106679451604, 0.048569451429506694, 0.0, 0.0, 0.0, 0.048569451429506694, 0.048569451429506694, 0.0, 0.0, 0.04278922972380661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010250300399295994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5068602342411587, 0.04278922972380661, 0.0, 0.0, 0.0, 0.0, 0.04518823848581767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01785760164838329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09713890285901339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014927526659895437, 0.048569451429506694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09045865840186115, 0.11822405034035276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048569451429506694, 0.048569451429506694, 0.048569451429506694, 0.0, 0.0, 0.2094973883254725, 0.0, 0.0, 0.0, 0.09713890285901339, 0.0, 0.0, 0.0, 0.0, 0.039078103965260326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015619646038672687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20570656070087437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022242918088499996, 0.0, 0.0, 0.11747188220265534, 0.0, 0.0, 0.015863734601463318, 0.0, 0.0, 0.0, 0.07401801603621305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03832557657513773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01628712995731725, 0.037009008018106526, 0.0, 0.0, 0.0, 0.0, 0.0336277950744175, 0.0, 0.10095193774551418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016030522104996076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15115174052631114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04596931963840475, 0.0, 0.05312419173545056, 0.02656209586772528, 0.0, 0.08897167235399998, 0.0, 0.03812253927912545, 0.0, 0.034353391403774296, 0.0, 0.0, 0.0, 0.0]"
hnike25_titanic-deep-learning-keras-79-acc.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'collections', 'sklearn', 'warnings\n', 'keras\n', 'keras', 'scipy', 're\n', 'xgboost']","[1 1 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",12,364,"['    # Fare feature cleaning', 'y_axis = ax.axes.get_yaxis().set_visible(False) # turn off the y axis label', '    # Convert to categorical values Title ', '    # get_x pulls left or right; get_height pushes up or down', '# Age feature cleaning ...Again this is the work of Yassine Ghouzam....', 'y_axis = ax.axes.get_yaxis().set_visible(False) # turn off the y axis label', '# Family size feature cleaning and transform ', '    # get_x pulls left or right; get_height pushes up or down', '# Standardizing the dataset to normalize them', '    # Cross validate model with Kfold stratified cross val', '# ', '# XGB classifier fitting', '    # get_width pulls left or right; get_y pushes up or down', '# This function will return 1 (Survive) or 0 (Not survive)..This will help during the evalution on the test data during submission']",14,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'train.head', 'pd.DataFrame', 'None.reset_index', 'train_isnull.style.format', 'sns.light_palette', 'train_isnull.style.background_gradient', 'pd.DataFrame', 'None.reset_index', 'test_isnull.style.format', 'sns.light_palette', 'test_isnull.style.background_gradient', 'train.Embarked.value_counts', 'train.fillna', 'test.fillna', 'df.fillna', 'df.map', 'plt.subplots', 'sns.kdeplot', 'ax.axvline', 'ax.legend', 'ax.set_xlabel', 'ax.set_title', 'ax.axes.get_yaxis', 'None.set_visible', 'sns.despine', 'df.Name.apply', 'df.replace', 'df.map', 'plt.subplots', 'sns.countplot', 'ax.text', 'ax.set_xlabel', 'ax.set_xticklabels', 'ax.set_title', 'ax.axes.get_yaxis', 'None.set_visible', 'sns.despine', 'plt.show', 'list', 'df.median', 'dfdfdf.ilocidfdf.ilocidfdf.iloci.median', 'np.isnan', 'plt.subplots', 'sns.kdeplot', 'ax.axvline', 'ax.legend', 'ax.set_xlabel', 'ax.set_title', 'ax.axes.get_yaxis', 'None.set_visible', 'sns.despine', 'pd.cut', 'plt.subplots', 'sns.countplot', 'ax.text', 'ax.set_xlabel', 'ax.set_title', 'ax.axes.get_yaxis', 'None.set_visible', 'sns.despine', 'plt.show', 'df.drop', 'plt.subplots', 'sns.heatmap', 'ax.tick_params', 'ax.tick_params', 'plt.title', 'plt.tight_layout', 'plt.show', 'pd.get_dummies', 'pd.get_dummies', 'train.dropna', 'train.Survived.astype', 'train.drop', 'train.drop', 'train_test_split', 'StandardScaler', 'sc.fit_transform', 'sc.transform', 'StratifiedKFold', 'cv_result.append', 'cv_means.append', 'LogisticRegression', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'ExtraTreesClassifier', 'MLPClassifier', 'LinearDiscriminantAnalysis', 'model_select', 'xgb.XGBClassifier', 'gbm.fit', 'gbm.predict', 'accuracy_score', 'pd.DataFrame', 'None.reset_index', 'ml_model.sort_values', 'ml_model.reset_index', 'plt.subplots', 'sns.barplot', 'ax.text', 'ax.tick_params', 'ax.axes.get_xaxis', 'None.set_visible', 'ax.set_title', 'sns.despine', 'plt.show', 'Sequential', 'classifier.add', 'classifier.add', 'classifier.add', 'classifier.add', 'classifier.add', 'classifier.add', 'classifier.compile', 'keras_model', 'clf.fit', 'clf.predict_classes', 'list', 'y_pred_1.append', 'y_pred_1.append', 'accuracy_score', 'test.drop', 'sc.transform', 'clf.predict_classes', 'y_pred_val', 'pd.DataFrame', 'submit.to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'read_csv', 'read_csv', 'head', 'DataFrame', 'reset_index', 'style', 'light_palette', 'style', 'DataFrame', 'reset_index', 'style', 'light_palette', 'style', 'Embarked', 'fillna', 'fillna', 'fillna', 'map', 'subplots', 'kdeplot', 'axvline', 'legend', 'set_xlabel', 'set_title', 'axes', 'set_visible', 'despine', 'Name', 'replace', 'map', 'subplots', 'countplot', 'text', 'set_xlabel', 'set_xticklabels', 'set_title', 'axes', 'set_visible', 'despine', 'show', 'list', 'median', 'ilocidfdf', 'isnan', 'subplots', 'kdeplot', 'axvline', 'legend', 'set_xlabel', 'set_title', 'axes', 'set_visible', 'despine', 'cut', 'subplots', 'countplot', 'text', 'set_xlabel', 'set_title', 'axes', 'set_visible', 'despine', 'show', 'drop', 'subplots', 'heatmap', 'tick_params', 'tick_params', 'title', 'tight_layout', 'show', 'get_dummies', 'get_dummies', 'dropna', 'Survived', 'drop', 'drop', 'train_test_split', 'StandardScaler', 'fit_transform', 'transform', 'StratifiedKFold', 'append', 'append', 'LogisticRegression', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'ExtraTreesClassifier', 'MLPClassifier', 'LinearDiscriminantAnalysis', 'model_select', 'XGBClassifier', 'fit', 'predict', 'accuracy_score', 'DataFrame', 'reset_index', 'sort_values', 'reset_index', 'subplots', 'barplot', 'text', 'tick_params', 'axes', 'set_visible', 'set_title', 'despine', 'show', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'add', 'compile', 'keras_model', 'fit', 'predict_classes', 'list', 'append', 'append', 'accuracy_score', 'drop', 'transform', 'predict_classes', 'y_pred_val', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'read_csv', 'head', 'DataFrame', 'reset_index', 'style', 'light_palette', 'Embarked', 'fillna', 'map', 'subplots', 'kdeplot', 'axvline', 'legend', 'set_xlabel', 'set_title', 'axes', 'set_visible', 'despine', 'Name', 'replace', 'countplot', 'text', 'set_xticklabels', 'show', 'list', 'median', 'ilocidfdf', 'isnan', 'cut', 'drop', 'heatmap', 'tick_params', 'title', 'tight_layout', 'get_dummies', 'dropna', 'Survived', 'train_test_split', 'StandardScaler', 'fit_transform', 'transform', 'StratifiedKFold', 'append', 'LogisticRegression', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'ExtraTreesClassifier', 'MLPClassifier', 'LinearDiscriminantAnalysis', 'model_select', 'XGBClassifier', 'fit', 'predict', 'accuracy_score', 'sort_values', 'barplot', 'Sequential', 'add', 'compile', 'keras_model', 'predict_classes', 'y_pred_val', 'to_csv']",71,"[0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0
 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings read csv read csv head dataframe reset index style light palette style dataframe reset index style light palette style embarked fillna fillna fillna map subplots kdeplot axvline legend set xlabel set title axes set visible despine name replace map subplots countplot text set xlabel set xticklabels set title axes set visible despine show list median ilocidfdf isnan subplots kdeplot axvline legend set xlabel set title axes set visible despine cut subplots countplot text set xlabel set title axes set visible despine show drop subplots heatmap tick params tick params title tight layout show get dummies get dummies dropna survived drop drop train test split standardscaler fit transform transform stratifiedkfold append append logisticregression svc kneighborsclassifier gaussiannb randomforestclassifier adaboostclassifier gradientboostingclassifier decisiontreeclassifier extratreesclassifier mlpclassifier lineardiscriminantanalysis model select xgbclassifier fit predict accuracy score dataframe reset index sort values reset index subplots barplot text tick params axes set visible set title despine show sequential add add add add add add compile keras model fit predict classes list append append accuracy score drop transform predict classes pred val dataframe csv,"[0.0, 0.0, 0.07364583643253081, 0.045266545902472526, 0.0, 0.17580228624925492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11952296988513825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36894091114874805, 0.0, 0.0, 0.13730268215494915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03491899161532973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10679639727959749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04667566448800989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06056593403953061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04085889172359112, 0.0, 0.0, 0.0, 0.03379211510382714, 0.0, 0.0, 0.0, 0.06825904518360523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029880742471284562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2895845837863385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06971955077814566, 0.029684319790669468, 0.0, 0.0, 0.04922523015110478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03091131111936099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05622520632636359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05318927969465331, 0.0, 0.03648505795077952, 0.0, 0.0, 0.0, 0.04502822147296495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036822918216265405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05364720122626324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04230687722239554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016229139200441115, 0.03275733538404183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0737881822297496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14594023180311808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022566728846811462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03827238399870529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10946602394701302, 0.0579169167572677, 0.0, 0.0, 0.0, 0.0, 0.03048897170697825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04913542880557469, 0.0, 0.05227500732727343, 0.0, 0.0, 0.0, 0.13730268215494915, 0.0, 0.02290458911229734, 0.0, 0.05622520632636359, 0.0, 0.0, 0.0, 0.06983798323065946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02279096495049566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02279096495049566, 0.0, 0.0, 0.04770449272598846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03406457741389808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05622520632636359, 0.0, 0.09652271497504739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03379211510382714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10679639727959749, 0.0, 0.1737507502718031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0737881822297496, 0.04671770082913267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022022911063834968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027129809496194396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026896353765570397, 0.0, 0.0, 0.16325873147815378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022678350794603515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04580917822459468, 0.0, 0.0, 0.0, 0.05007430338062034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051088365174088546, 0.0, 0.3672401307209966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11873727916267787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02804143026457239, 0.0, 0.0, 0.0, 0.02372983952554131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04178970300154087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06217968659149175, 0.0, 0.0, 0.0, 0.0, 0.13516846041530856, 0.0, 0.0, 0.0, 0.0, 0.18943471741313206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045266545902472526, 0.0, 0.0, 0.0, 0.029112688584623868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024743901319009512, 0.16867561897909075, 0.0, 0.1950200828341698, 0.0, 0.0, 0.051088365174088546, 0.0, 0.1533692425911757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024354054894737232, 0.0, 0.0, 0.0, 0.08311070999725952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03827238399870529, 0.0, 0.0, 0.0, 0.02804143026457239, 0.0, 0.0, 0.0, 0.0, 0.36894091114874805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03789417653631688, 0.0, 0.0, 0.0, 0.1396759664613189, 0.0, 0.04035394085388168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ojaswiawasthi_titanic-datatset-submission-logistic-regression.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,172,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", 'features=[""Pclass"",""Sex"",""Age"",""SibSp"",""Parch"",""Fare"",""Embarked""] # collecting all features ', 'X.info()    # Getting the information so as to analyse which columns in the dataset have object type values which have to be fixed by LabelEncoding in the preprocessing step', ' #   Column    Non-Null Count  Dtype  ', '# Fitting a Logistic regression model on the training data', '# The Cleaning Phase for test data', ' #   Column    Non-Null Count  Dtype  ']",15,"['os.walk', 'print', 'pd.read_csv', 'train.head', 'X.isnull', 'None.sum', 'X.fillna', 'X.fillna', 'X.info', 'LabelEncoder', 'Le.fit_transform', 'Le.fit_transform', 'train_test_split', 'LogisticRegression', 'log.fit', 'log.score', 'pd.read_csv', 'test.head', 'test_data_x.fillna', 'test_data_x.fillna', 'Le.fit_transform', 'Le.fit_transform', 'test_data_x.info', 'test_data_x.isnull', 'None.sum', 'test_data_x.fillna', 'log.predict', 'pd.DataFrame', 'output.to_csv', 'output.head']","['walk', 'print', 'read_csv', 'head', 'isnull', 'sum', 'fillna', 'fillna', 'info', 'LabelEncoder', 'fit_transform', 'fit_transform', 'train_test_split', 'LogisticRegression', 'fit', 'score', 'read_csv', 'head', 'fillna', 'fillna', 'fit_transform', 'fit_transform', 'info', 'isnull', 'sum', 'fillna', 'predict', 'DataFrame', 'to_csv', 'head']","['walk', 'print', 'read_csv', 'head', 'isnull', 'sum', 'fillna', 'info', 'LabelEncoder', 'fit_transform', 'train_test_split', 'LogisticRegression', 'fit', 'score', 'predict', 'DataFrame', 'to_csv']",17,"[1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head isnull sum fillna fillna info labelencoder fit transform fit transform train test split logisticregression fit score read csv head fillna fillna fit transform fit transform info isnull sum fillna predict dataframe csv head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19729017702155308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08239846052787195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42804727702016876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3623701561895981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.235090792532224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21686169946545697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23396108294773577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17152249293297178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11004785788105821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07519328986349591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07015438853960733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13099828928974128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1105965005399788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11458128312334993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23274369486524074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11947775540403643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11759535314564405, 0.0, 0.0, 0.0, 0.5350749370515119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13967971149332986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
anandrikka_project-titanic.py,"['numpy', 'pandas', 'math', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,1226,"['# Checking for kaggle/input/titanic/****.csv', '# Column datatypes', '# Columns', '# Combine dataset for exploratory analytics', '# Change Pclass, Sex, Embarked to type category', '# Check for null count', '# Describe gives a very quick brief 5-point summary of the data. Take a peek look into numerical data.', '# changing back to original data types.', '# Categorical plots (Bar)', '    _ = sns.barplot(x=_.index, y=_, ax=ax[i]) # returns ax of matplotlib', '        label_x = patch.get_x() + patch.get_width()/2 # Mid point in x', '        label_y = patch.get_y() + patch.get_height() + 10 # Mid point in y', '    ax_ = sns.barplot(x=cols[i][""col""], y=""Age"", ax=ax[i], data=train_data) # returns ax of matplotlib', '    ax_ = sns.barplot(x=cols[i][""col""], y=""Survived"", ax=ax[i], data=train_data) # returns ax of matplotlib', '    ax_ = sns.barplot(x=cols[i][""col""], y=""Survived"", hue=""Sex"", ax=ax[i], data=train_data) # returns ax of matplotlib', '# ax = sns.FacetGrid(train_data, col=""Sex"", row=""Pclass"", hue=""Survived"", legend_out=True)', '# ax.map(sns.kdeplot, ""Age"")', '    label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle', '    label_x = patch.get_x() + patch.get_width()/2  # find midpoint of rectangle', '# Check for survival rate against each category', '# Correlation Coefficents', '# _ = df.groupby([""Sex"", ""Pclass""]).describe()', '# When grouped by sex and by pclass mean and median are most consistent and they values are pretty much closer.', '# So replacing the values based on these stats should be easy.', '# Comparing Age distributions before and after imputing the values.', '# Data distribution remains almost same before and after imputing values.', '# deck_x_pclass.plot.bar(stacked=True)', '# now stack and reset', '# plot grouped bar chart', '# Plot percentage of passengers', '# Replace Deck T with A as it has only one passenger', ""# plt.title('Survival Percentage in Decks')"", ""# plt.title('Random Forest Classifier Mean Feature Importance Between Folds')""]",33,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_data.sample', 'train_data.info', 'print', 'test_data.info', 'print', 'pd.concat', 'None.reset_index', 'data.loc.drop', 'concat_df', 'df.info', 'train_datacol.astype', 'test_datacol.astype', 'train_data.info', 'print', 'test_data.info', 'print', 'print', 'print', 'print', 'print', 'train_data.describe', 'None.transpose', 'train_data.astype', 'train_data.astype', 'train_data.astype', 'test_data.astype', 'test_data.astype', 'test_data.astype', 'train_data.info', 'print', 'test_data.info', 'len', 'len', 'print', 'sns.color_palette', 'plt.subplots', 'ax.flatten', 'train_data.unique', 'unique_sibsp.sort', 'train_data.unique', 'unique_parch.sort', 'range', 'train_datacolsi.value_counts', 'sns.barplot', '_.set_xticklabels', '_.set_ylabel', '_.set_title', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', '_.text', 'plt.subplots', 'ax.flatten', 'range', 'sns.barplot', 'ax_.set_xticklabels', 'ax_.set_ylabel', 'ax_.set_title', 'ax_.text', 'plt.subplots', 'ax.flatten', 'range', 'sns.barplot', 'ax_.set_xticklabels', 'ax_.set_ylabel', 'ax_.set_title', 'ax_.text', 'plt.subplots', 'ax.flatten', 'range', 'sns.barplot', 'ax_.set_xticklabels', 'ax_.set_ylabel', 'ax_.set_title', 'ax_.text', 'plt.subplots', 'ax.flatten', 'range', 'pd.notnull', 'sns.distplot', '_.set_title', '_.set_xlabel', 'data_.mean', 'data_.median', '_.axvline', '_.axvline', '_.legend', 'plt.subplots', 'ax.flatten', 'range', 'pd.notnull', 'sns.boxplot', '_.set_title', '_.set_xlabel', 'plt.subplots', 'ax.flatten', 'range', 'train_datacolsi.notnull', 'sns.boxplot', '_.set_title', '_.set_xlabel', 'plt.subplots', 'ax.flatten', 'range', 'train_datacolsi.notnull', 'sns.boxplot', '_.set_title', '_.set_xlabel', 'sns.FacetGrid', 'ax.map', 'sns.FacetGrid', 'ax.map', 'sns.FacetGrid', 'ax.map', 'sns.factorplot', 'sns.factorplot', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', '_.ax.text', 'sns.factorplot', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', '_.ax.text', 'sns.catplot', 'sns.catplot', '_.set_axis_labels', '_.set_titles', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', 'ax.text', 'sns.catplot', '_.set_axis_labels', '_.set_titles', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', 'ax.text', 'sns.catplot', 'plt.subplots', 'ax.flatten', 'range', 'sns.countplot', '_.set_title', '_.set_xticklabels', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', '_.text', 'sns.countplot', 'plt.subplots', 'ax.flatten', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'plt.subplots', 'sns.kdeplot', 'sns.kdeplot', 'ax.legend', 'ax.set_title', 'plt.subplots', 'sns.kdeplot', 'sns.kdeplot', 'ax.legend', 'ax.set_title', 'train_data.corr', 'plt.figure', 'sns.heatmap', 'datacolumn.unique', 'categories_.sort', 'print', 'print', 'print', 'print', 'print', 'd_col.isnull', 'None.sum', 'print', 'print', 'df.corr', 'None.abs', 'None.unstack', 'None.sort_values', 'None.reset_index', 'None.rename', 'print', 'df.groupby', 'None.describe', 'print', 'df.groupby', 'None.apply', 'concat_df', 'pd.notnull', 'plt.figure', 'sns.kdeplot', 'sns.kdeplot', 'df.isnull', 'df.fillna', 'df.isnull', 'df.groupby', 'None.describe', 'print', 'df.groupby', 'None.apply', 'print', 'df.apply', 'df.groupby', 'None.count', 'None.drop', 'None.rename', 'None.transpose', 'pd.crosstab', 'plt.figure', 'deck_x_pclass.stack', 'None.reset_index', 'None.rename', 'plt.figure', 'sns.barplot', 'deck_x_pclass.locindex.sum', 'df.groupby', 'None.count', 'None.drop', 'None.rename', 'None.transpose', 'print', 'range', 'pd.DataFrame', 'df_surv_countscol.sum', 'print', 'pd.DataFrame', 'None.transpose', 'np.arange', 'plt.figure', 'plt.bar', 'plt.bar', 'plt.xlabel', 'plt.ylabel', 'plt.xticks', 'plt.tick_params', 'plt.tick_params', 'plt.legend', 'df.replace', 'None.replace', 'None.replace', 'df.value_counts', 'df.drop', 'divide_df', 'print', 'print', 'print', 'pd.qcut', 'plt.figure', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.tick_params', 'plt.tick_params', 'plt.legend', 'pd.qcut', 'plt.figure', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.tick_params', 'plt.tick_params', 'plt.legend', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'df.map', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'df.groupby', 'None.transform', 'plt.subplots', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.tick_params', 'plt.tick_params', 'plt.legend', 'df.str.split', 'None.str.split', 'plt.figure', 'sns.countplot', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', 'ax_.text', 'sns.countplot', 'df.replace', 'df.replace', 'plt.figure', 'sns.countplot', 'patch.get_x', 'patch.get_width', 'patch.get_y', 'patch.get_height', 'ax_.text', 'plt.figure', 'sns.countplot', 'divide_df', 'LabelEncoder', 'None.fit_transform', 'OneHotEncoder', 'None.fit_transform', 'None.toarray', 'dffeature.nunique', '.format', 'range', 'pd.DataFrame', 'encoded_features.append', 'pd.concat', 'pd.concat', 'train.drop', 'test.drop', 'StandardScaler', 'std_scaler.fit_transform', 'std_scaler.fit_transform', 'print', 'RandomForestClassifier', 'pd.DataFrame', '.format', 'range', 'range', 'pd.DataFrame', '.format', 'range', 'StratifiedKFold', 'enumerate', 'print', 'print', 'rfc_model.fit', 'rfc_model.predict_proba', 'roc_curve', 'auc', 'rfc_model.predict_proba', 'roc_curve', 'auc', 'scores.append', 'fprs.append', 'tprs.append', '.format', 'rfc_model.predict_proba', '.format', 'rfc_model.predict_proba', 'print', 'print', 'imp_df.mean', 'imp_df.sort_values', 'plt.figure', 'sns.barplot', 'plt.xlabel', 'plt.tick_params', 'plt.tick_params', 'col.endswith', 'prob_dfclass_survived.sum', 'prob_df.drop', 'None.sum', 'prob_df.astype', 'pd.DataFrame', 'submission_df.to_csv', 'submission_df.head']","['walk', 'print', 'read_csv', 'read_csv', 'sample', 'info', 'print', 'info', 'print', 'concat', 'reset_index', 'loc', 'concat_df', 'info', 'astype', 'astype', 'info', 'print', 'info', 'print', 'print', 'print', 'print', 'print', 'describe', 'transpose', 'astype', 'astype', 'astype', 'astype', 'astype', 'astype', 'info', 'print', 'info', 'len', 'len', 'print', 'color_palette', 'subplots', 'flatten', 'unique', 'sort', 'unique', 'sort', 'range', 'value_counts', 'barplot', 'set_xticklabels', 'set_ylabel', 'set_title', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'subplots', 'flatten', 'range', 'barplot', 'set_xticklabels', 'set_ylabel', 'set_title', 'text', 'subplots', 'flatten', 'range', 'barplot', 'set_xticklabels', 'set_ylabel', 'set_title', 'text', 'subplots', 'flatten', 'range', 'barplot', 'set_xticklabels', 'set_ylabel', 'set_title', 'text', 'subplots', 'flatten', 'range', 'notnull', 'distplot', 'set_title', 'set_xlabel', 'mean', 'median', 'axvline', 'axvline', 'legend', 'subplots', 'flatten', 'range', 'notnull', 'boxplot', 'set_title', 'set_xlabel', 'subplots', 'flatten', 'range', 'notnull', 'boxplot', 'set_title', 'set_xlabel', 'subplots', 'flatten', 'range', 'notnull', 'boxplot', 'set_title', 'set_xlabel', 'FacetGrid', 'map', 'FacetGrid', 'map', 'FacetGrid', 'map', 'factorplot', 'factorplot', 'get_x', 'get_width', 'get_y', 'get_height', 'ax', 'factorplot', 'get_x', 'get_width', 'get_y', 'get_height', 'ax', 'catplot', 'catplot', 'set_axis_labels', 'set_titles', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'catplot', 'set_axis_labels', 'set_titles', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'catplot', 'subplots', 'flatten', 'range', 'countplot', 'set_title', 'set_xticklabels', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'countplot', 'subplots', 'flatten', 'crosstab', 'plot', 'crosstab', 'plot', 'crosstab', 'plot', 'subplots', 'kdeplot', 'kdeplot', 'legend', 'set_title', 'subplots', 'kdeplot', 'kdeplot', 'legend', 'set_title', 'corr', 'figure', 'heatmap', 'unique', 'sort', 'print', 'print', 'print', 'print', 'print', 'isnull', 'sum', 'print', 'print', 'corr', 'abs', 'unstack', 'sort_values', 'reset_index', 'rename', 'print', 'groupby', 'describe', 'print', 'groupby', 'apply', 'concat_df', 'notnull', 'figure', 'kdeplot', 'kdeplot', 'isnull', 'fillna', 'isnull', 'groupby', 'describe', 'print', 'groupby', 'apply', 'print', 'apply', 'groupby', 'count', 'drop', 'rename', 'transpose', 'crosstab', 'figure', 'stack', 'reset_index', 'rename', 'figure', 'barplot', 'locindex', 'groupby', 'count', 'drop', 'rename', 'transpose', 'print', 'range', 'DataFrame', 'sum', 'print', 'DataFrame', 'transpose', 'arange', 'figure', 'bar', 'bar', 'xlabel', 'ylabel', 'xticks', 'tick_params', 'tick_params', 'legend', 'replace', 'replace', 'replace', 'value_counts', 'drop', 'divide_df', 'print', 'print', 'print', 'qcut', 'figure', 'countplot', 'xlabel', 'ylabel', 'tick_params', 'tick_params', 'legend', 'qcut', 'figure', 'countplot', 'xlabel', 'ylabel', 'tick_params', 'tick_params', 'legend', 'subplots', 'countplot', 'countplot', 'map', 'subplots', 'countplot', 'countplot', 'groupby', 'transform', 'subplots', 'countplot', 'xlabel', 'ylabel', 'tick_params', 'tick_params', 'legend', 'str', 'str', 'figure', 'countplot', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'countplot', 'replace', 'replace', 'figure', 'countplot', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'figure', 'countplot', 'divide_df', 'LabelEncoder', 'fit_transform', 'OneHotEncoder', 'fit_transform', 'toarray', 'nunique', 'format', 'range', 'DataFrame', 'append', 'concat', 'concat', 'drop', 'drop', 'StandardScaler', 'fit_transform', 'fit_transform', 'print', 'RandomForestClassifier', 'DataFrame', 'format', 'range', 'range', 'DataFrame', 'format', 'range', 'StratifiedKFold', 'enumerate', 'print', 'print', 'fit', 'predict_proba', 'roc_curve', 'auc', 'predict_proba', 'roc_curve', 'auc', 'append', 'append', 'append', 'format', 'predict_proba', 'format', 'predict_proba', 'print', 'print', 'mean', 'sort_values', 'figure', 'barplot', 'xlabel', 'tick_params', 'tick_params', 'endswith', 'sum', 'drop', 'sum', 'astype', 'DataFrame', 'to_csv', 'head']","['walk', 'print', 'read_csv', 'sample', 'info', 'concat', 'reset_index', 'loc', 'concat_df', 'astype', 'describe', 'transpose', 'len', 'color_palette', 'subplots', 'flatten', 'unique', 'sort', 'range', 'value_counts', 'barplot', 'set_xticklabels', 'set_ylabel', 'set_title', 'get_x', 'get_width', 'get_y', 'get_height', 'text', 'notnull', 'distplot', 'set_xlabel', 'mean', 'median', 'axvline', 'legend', 'boxplot', 'FacetGrid', 'map', 'factorplot', 'ax', 'catplot', 'set_axis_labels', 'set_titles', 'countplot', 'crosstab', 'plot', 'kdeplot', 'corr', 'figure', 'heatmap', 'isnull', 'sum', 'abs', 'unstack', 'sort_values', 'rename', 'groupby', 'apply', 'fillna', 'count', 'drop', 'stack', 'locindex', 'DataFrame', 'arange', 'bar', 'xlabel', 'ylabel', 'xticks', 'tick_params', 'replace', 'divide_df', 'qcut', 'transform', 'str', 'LabelEncoder', 'fit_transform', 'OneHotEncoder', 'toarray', 'nunique', 'format', 'append', 'StandardScaler', 'RandomForestClassifier', 'StratifiedKFold', 'enumerate', 'fit', 'predict_proba', 'roc_curve', 'auc', 'endswith', 'to_csv', 'head']",94,"[1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0
 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv sample info print info print concat reset index loc concat df info astype astype info print info print print print print print describe transpose astype astype astype astype astype astype info print info len len print color palette subplots flatten unique sort unique sort range value counts barplot set xticklabels set ylabel set title get x get width get get height text subplots flatten range barplot set xticklabels set ylabel set title text subplots flatten range barplot set xticklabels set ylabel set title text subplots flatten range barplot set xticklabels set ylabel set title text subplots flatten range notnull distplot set title set xlabel mean median axvline axvline legend subplots flatten range notnull boxplot set title set xlabel subplots flatten range notnull boxplot set title set xlabel subplots flatten range notnull boxplot set title set xlabel facetgrid map facetgrid map facetgrid map factorplot factorplot get x get width get get height ax factorplot get x get width get get height ax catplot catplot set axis labels set titles get x get width get get height text catplot set axis labels set titles get x get width get get height text catplot subplots flatten range countplot set title set xticklabels get x get width get get height text countplot subplots flatten crosstab plot crosstab plot crosstab plot subplots kdeplot kdeplot legend set title subplots kdeplot kdeplot legend set title corr figure heatmap unique sort print print print print print isnull sum print print corr abs unstack sort values reset index rename print groupby describe print groupby apply concat df notnull figure kdeplot kdeplot isnull fillna isnull groupby describe print groupby apply print apply groupby count drop rename transpose crosstab figure stack reset index rename figure barplot locindex groupby count drop rename transpose print range dataframe sum print dataframe transpose arange figure bar bar xlabel ylabel xticks tick params tick params legend replace replace replace value counts drop divide df print print print qcut figure countplot xlabel ylabel tick params tick params legend qcut figure countplot xlabel ylabel tick params tick params legend subplots countplot countplot map subplots countplot countplot groupby transform subplots countplot xlabel ylabel tick params tick params legend str str figure countplot get x get width get get height text countplot replace replace figure countplot get x get width get get height text figure countplot divide df labelencoder fit transform onehotencoder fit transform toarray nunique format range dataframe append concat concat drop drop standardscaler fit transform fit transform print randomforestclassifier dataframe format range range dataframe format range stratifiedkfold enumerate print print fit predict proba roc curve auc predict proba roc curve auc append append append format predict proba format predict proba print print mean sort values figure barplot xlabel tick params tick params endswith sum drop sum astype dataframe csv head,"[0.0, 0.024751035758308018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051078639319918656, 0.033136507008467785, 0.020275270780038757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08722518956391503, 0.04678076155862238, 0.0, 0.0, 0.0630673744102548, 0.0, 0.0, 0.04678076155862238, 0.05867687345946814, 0.0, 0.0, 0.0, 0.0, 0.03989407950106569, 0.0, 0.0895366595985063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04956739591502763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0839929211331139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02657274821303873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05681104899334479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029845553199502103, 0.0, 0.0, 0.0333887152843318, 0.0, 0.0, 0.16824017817277256, 0.02642015527373464, 0.0, 0.0, 0.0, 0.0, 0.06020069733142239, 0.0174612176669183, 0.0, 0.0, 0.04678076155862238, 0.0, 0.0, 0.0, 0.0, 0.04375618116675827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031223420581196436, 0.0, 0.0, 0.0, 0.0, 0.09611230502027321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015884769829252094, 0.0, 0.0, 0.0, 0.0630673744102548, 0.0, 0.0, 0.0, 0.0, 0.044692410895988716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0315336872051274, 0.0, 0.0, 0.019947039750532844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04047785799965814, 0.0500830729264977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14140416243208492, 0.0, 0.0, 0.0, 0.007576886785361154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032071663519925325, 0.2778088173009785, 0.0, 0.0, 0.0, 0.0, 0.1140997136900459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2445477869985111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07062464738536847, 0.0, 0.0, 0.0, 0.0, 0.006935590275983929, 0.013998983800109967, 0.23470749383787257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04677612472544298, 0.0, 0.0, 0.0671769009639882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03106017838758424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14034228467586712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015180642184470676, 0.048056152510136604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07818979787305053, 0.027180348588252697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01831044460483082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0315336872051274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040773427571823236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0209255467228591, 0.014557639129801271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11695190389655595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020998230283278473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024028076255068302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02281994273800918, 0.0, 0.2475103575830802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03350991337416451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026620005541477063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19868902824425055, 0.0, 0.08110108312015503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029596615622370946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009411582828683918, 0.0, 0.0, 0.18366713837579457, 0.0, 0.0, 0.0, 0.011594037157928129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09611230502027321, 0.0, 0.057471344392327185, 0.0, 0.0, 0.052326974486664936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04366565155934995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024751035758308018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2929576541200274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059918110463419876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02933843672973407, 0.0, 0.0, 0.017859003745920508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03238846855100659, 0.02657274821303873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2023892899982907, 0.04119808069512564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2162526862956147, 0.0, 0.2778088173009785, 0.0, 0.0, 0.0, 0.0, 0.12016213920879765, 0.051171262509409045, 0.0, 0.027780881730097847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05919618050059056, 0.0, 0.09356152311724476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05293997031261214, 0.020998230283278473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02642015527373464, 0.023967244185367952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012362388654407941, 0.0, 0.0, 0.0, 0.23470749383787257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23470749383787257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13430498939775945, 0.0, 0.08622712404124463, 0.017245424808248925, 0.0, 0.11552960980834417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
lobodemonte_titanic-who-d-survive.py,"['numpy', 'pandas', 'os\n', 'statsmodels', 'matplotlib', 'sklearn', 'warnings\n']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,518,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ""# Let's check for missing values, we will have to address these missing values later "", ""# Let's first check the easier label columns "", '# We can see that Pclass, Sex, and Embarking Port were very important', '# for determining survival ', ""# Now let's look at numeric columns, but first we must cut them"", ""# print(train_raw[['Survived','age_range','Pclass']].groupby(['age_range','Pclass']).mean())"", ""del train_raw['age_range'] # let's clean that up "", '# Looks like being young is an advantage to survive the titanic ', '# What about your family size?', '# Small families had higher survival rates, followed by solo travelers, and finally large families ', '# What about Fare paid?', '# Of course the more you paid, the richer you were, the more likely you survived', ""# For cabin, let's separate the number and letter"", '# We see that D, E, B cabins had higher survival rates, and those with missing cabins had the lowest', '# But what about cabin numbers?', '# Looks like certain cabin numbers also had higher survival rates', ""# Let's do something similar to ticket"", '# Does the ticket length tell us anything?', ""# Let's examine the info we can extract from Name"", '# We can get the title from Name', '# We can see certain nobility titles seem to have way better odds of survival', '# What about how long the name is?', '# We see that long names have higher survival rates, maybe people with longer names were also richer? ', '# These functions transform our columns into the final form we need them in ', 'cols = list(train.columns[2:]) # features relevant to our ML model', '# We will use these functions to select the best features from our data', '        lr = ensemble.RandomForestClassifier() # NOTE: using different classifier yields diff results ', ""# We'll use this function to save our results to CSV"", '# We use this function to tune our model', '# save_results(gbc_tuned, test[cols]) # Uncomment whichever model you want to use', '#     ""min_samples_split"" : [2, 4, 10, 12, 16],', '#     ""n_estimators"": n_estimators,', '# Best score:  0.8293955181721173', ""# Best params:  {'criterion': 'gini', 'max_leaf_nodes': 14, 'min_samples_leaf': 1}"", '# IS Score:  0.856341189674523', '# save_results(log_tuned, test[cols])']",45,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train_raw.head', 'set', 'null_cols.update', 'print', 'print', 'print', 'print', 'pd.cut', 'get_age_range', 'print', 'data.apply', 'get_family_size', 'print', 'pd.qcut', 'print', 'data.apply', 'data.apply', 'raw_num.replace', 'raw_num.apply', 'get_cabin_letter', 'print', 'pd.qcut', 'print', 'data.apply', 'data.apply', 'get_ticket_len', 'print', 'get_ticket_letter', 'print', 'print', 'data.apply', 'data.apply', 'get_title', 'print', 'pd.qcut', 'print', 'get_title', 'get_name_len', 'data.apply', 'train.groupby', 'newAges.transform', 'get_ticket_len', 'get_ticket_letter', 'data.apply', 'get_family_size', 'train.mean', 'train.fillna', 'test.fillna', 'train.fillna', 'test.fillna', 'data.apply', 'get_cabin_letter', 'get_cabin_num', 'pd.qcut', 'pd.concat', 'pd.concat', 'set', 'vals.intersection', 'str', 'pd.concat', 'pd.concat', 'zip', 'str', 'colsbytype.get', 'curr.add', 'colsbytype.keys', 'list', 'columns.sort', 'list', 'cols.remove', 'cols.remove', 'get_cols_by_type', 'num_cols.extend', 'MinMaxScaler', 'train.copy', 'test.copy', 'scaler.fit_transform', 'scaler.transform', 'train_raw.copy', 'test_raw.copy', 'trans_name', 'trans_age', 'trans_ticket', 'trans_family', 'trans_fare', 'trans_embarked', 'trans_cabin', 'get_dummies', 'scale_data', 'print', 'list', 'print', 'train.head', 'SelectKBest', 'selector.fit_transform', 'pd.DataFrame', 'selected_features.var', 'warnings.filterwarnings', 'ensemble.GradientBoostingRegressor', 'lr.fit', 'print', 'range', 'ensemble.RandomForestClassifier', 'select_cols', 'lr.fit', 'lr.score', 'lr.score', 'print', 'find_best_cols', 'print', 'print', 'model.predict', 'test.copy', 'test_res.to_csv', 'GridSearchCV', 'grid.fit', 'print', 'print', 'print', 'ensemble.GradientBoostingClassifier', 'get_tuned_model', 'range', 'RandomForestClassifier', 'get_tuned_model', 'save_results', 'LogisticRegression', 'get_tuned_model']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'set', 'update', 'print', 'print', 'print', 'print', 'cut', 'get_age_range', 'print', 'apply', 'get_family_size', 'print', 'qcut', 'print', 'apply', 'apply', 'replace', 'apply', 'get_cabin_letter', 'print', 'qcut', 'print', 'apply', 'apply', 'get_ticket_len', 'print', 'get_ticket_letter', 'print', 'print', 'apply', 'apply', 'get_title', 'print', 'qcut', 'print', 'get_title', 'get_name_len', 'apply', 'groupby', 'transform', 'get_ticket_len', 'get_ticket_letter', 'apply', 'get_family_size', 'mean', 'fillna', 'fillna', 'fillna', 'fillna', 'apply', 'get_cabin_letter', 'get_cabin_num', 'qcut', 'concat', 'concat', 'set', 'intersection', 'str', 'concat', 'concat', 'zip', 'str', 'get', 'add', 'keys', 'list', 'sort', 'list', 'remove', 'remove', 'get_cols_by_type', 'extend', 'MinMaxScaler', 'copy', 'copy', 'fit_transform', 'transform', 'copy', 'copy', 'trans_name', 'trans_age', 'trans_ticket', 'trans_family', 'trans_fare', 'trans_embarked', 'trans_cabin', 'get_dummies', 'scale_data', 'print', 'list', 'print', 'head', 'SelectKBest', 'fit_transform', 'DataFrame', 'var', 'filterwarnings', 'GradientBoostingRegressor', 'fit', 'print', 'range', 'RandomForestClassifier', 'select_cols', 'fit', 'score', 'score', 'print', 'find_best_cols', 'print', 'print', 'predict', 'copy', 'to_csv', 'GridSearchCV', 'fit', 'print', 'print', 'print', 'GradientBoostingClassifier', 'get_tuned_model', 'range', 'RandomForestClassifier', 'get_tuned_model', 'save_results', 'LogisticRegression', 'get_tuned_model']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'set', 'update', 'cut', 'get_age_range', 'apply', 'get_family_size', 'qcut', 'replace', 'get_cabin_letter', 'get_ticket_len', 'get_ticket_letter', 'get_title', 'get_name_len', 'groupby', 'transform', 'mean', 'fillna', 'get_cabin_num', 'concat', 'intersection', 'str', 'zip', 'get', 'add', 'keys', 'list', 'sort', 'remove', 'get_cols_by_type', 'extend', 'MinMaxScaler', 'copy', 'fit_transform', 'trans_name', 'trans_age', 'trans_ticket', 'trans_family', 'trans_fare', 'trans_embarked', 'trans_cabin', 'get_dummies', 'scale_data', 'SelectKBest', 'DataFrame', 'var', 'filterwarnings', 'GradientBoostingRegressor', 'fit', 'range', 'RandomForestClassifier', 'select_cols', 'score', 'find_best_cols', 'predict', 'to_csv', 'GridSearchCV', 'GradientBoostingClassifier', 'get_tuned_model', 'save_results', 'LogisticRegression']",66,"[1 1 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic read csv read csv head set update print print print print cut get age range print apply get family size print qcut print apply apply replace apply get cabin letter print qcut print apply apply get ticket len print get ticket letter print print apply apply get title print qcut print get title get name len apply groupby transform get ticket len get ticket letter apply get family size mean fillna fillna fillna fillna apply get cabin letter get cabin num qcut concat concat set intersection str concat concat zip str get add keys list sort list remove remove get cols type extend minmaxscaler copy copy fit transform transform copy copy trans name trans age trans ticket trans family trans fare trans embarked trans cabin get dummies scale data print list print head selectkbest fit transform dataframe var filterwarnings gradientboostingregressor fit print range randomforestclassifier select cols fit score score print find best cols print print predict copy csv gridsearchcv fit print print print gradientboostingclassifier get tuned model range randomforestclassifier get tuned model save results logisticregression get tuned model,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.02707552790835841, 0.0, 0.05673474936345053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.262720449273743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06343846855281517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1526293838944229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2045557685174165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09827397357853464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13035727059321572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037756371208899714, 0.0, 0.0, 0.0, 0.031226193075063347, 0.0, 0.04384119507211929, 0.0, 0.01576899017325294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02274371604352077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028564135930846182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05195588210557025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18021170741706363, 0.0, 0.03572650803866833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06553397489979096, 0.0, 0.033714653860091925, 0.057458223401735176, 0.0, 0.0, 0.06934852174939636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3304908769952168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03909440745246228, 0.06818525617247218, 0.0, 0.0, 0.0, 0.03341055835394871, 0.0, 0.0, 0.021815942164311614, 0.0, 0.0, 0.0, 0.0, 0.029993638016322845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06343846855281517, 0.0, 0.0, 0.02085317920698395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060070569139021215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08815805550860645, 0.2727410246898887, 0.0, 0.0, 0.0, 0.02116538487537845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09680250888261019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021060388487803713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021060388487803713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022623643003841027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046272033007056686, 0.0, 0.0, 0.0, 0.1337902462458816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062452386150126694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05195588210557025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014390101967389874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32221879576037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12799345696061945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040701309808001615, 0.0, 0.0, 0.0851021240451758, 0.0, 0.0, 0.0, 0.025069773431314685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12014113827804243, 0.0, 0.0, 0.024854044593491234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05532378151936421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02095632541379758, 0.0, 0.0, 0.06343846855281517, 0.0, 0.05532378151936421, 0.0, 0.0, 0.0423307697507569, 0.0, 0.0, 0.0, 0.046272033007056686, 0.0, 0.050576993899707184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045247286007682054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08131532393699918, 0.0, 0.0, 0.0, 0.025912172495035468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07003354890973085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23604547242956622, 0.0, 0.0, 0.0, 0.0472411741241365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4772967932073052, 0.0, 0.10239986730656385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2045557685174165, 0.0, 0.05351913662160756, 0.0, 0.0, 0.06818525617247218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06818525617247218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02673117900298725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0454044495881566, 0.0]"
neilslab_titanic-voting-ensemble.py,"['numpy', 'pandas', 're', 'numpy\n', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,326,"['    # Mapping Sex', '    # Mapping titles', '    # Mapping Embarked', '    # Mapping Fare', '    # Mapping Age', '# Feature Selection']",6,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'dataset.fillna', 'print', 'dataset.fillna', 'pd.qcut', 'print', 'dataset.mean', 'dataset.std', 'dataset.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'dataset.astype', 'pd.cut', 'print', 're.search', 'title_search.group', 'dataset.apply', 'print', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'print', 'dataset.map', 'None.astype', 'dataset.map', 'dataset.fillna', 'dataset.map', 'None.astype', 'dataset.astype', 'train.drop', 'train.drop', 'test.drop', 'print', 'pd.DataFrame', 'X.drop', 'print', 'print', 'print', 'train_test_split', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'models.append', 'KFold', 'cross_val_score', 'scores.append', 'names.append', 'cv_scores.mean', 'cv_scores.std', 'print', 'pd.DataFrame', 'sharpe_ratios.sort_values', 'AdaBoostClassifier', 'estimators.append', 'GradientBoostingClassifier', 'estimators.append', 'QuadraticDiscriminantAnalysis', 'estimators.append', 'SVC', 'estimators.append', 'MLPClassifier', 'estimators.append', 'VotingClassifier', 'cross_val_score', 'print', 'train.drop', 'ensemble.fit', 'print', 'print', 'ensemble.predict', 'pd.DataFrame', 'pd.DataFrame', 'pd.concat', 'sub.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'print', 'fillna', 'print', 'fillna', 'qcut', 'print', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'cut', 'print', 'search', 'group', 'apply', 'print', 'replace', 'replace', 'replace', 'replace', 'print', 'map', 'astype', 'map', 'fillna', 'map', 'astype', 'astype', 'drop', 'drop', 'drop', 'print', 'DataFrame', 'drop', 'print', 'print', 'print', 'train_test_split', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'append', 'KFold', 'cross_val_score', 'append', 'append', 'mean', 'std', 'print', 'DataFrame', 'sort_values', 'AdaBoostClassifier', 'append', 'GradientBoostingClassifier', 'append', 'QuadraticDiscriminantAnalysis', 'append', 'SVC', 'append', 'MLPClassifier', 'append', 'VotingClassifier', 'cross_val_score', 'print', 'drop', 'fit', 'print', 'print', 'predict', 'DataFrame', 'DataFrame', 'concat', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'fillna', 'qcut', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'cut', 'search', 'group', 'apply', 'replace', 'map', 'drop', 'DataFrame', 'train_test_split', 'append', 'KFold', 'cross_val_score', 'sort_values', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'QuadraticDiscriminantAnalysis', 'SVC', 'MLPClassifier', 'VotingClassifier', 'fit', 'predict', 'concat', 'to_csv']",36,"[1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0
 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print print fillna print fillna qcut print mean std isnull sum random isnan astype cut print search group apply print replace replace replace replace print map astype map fillna map astype astype drop drop drop print dataframe drop print print print train test split append append append append append append append append append append append kfold cross val score append append mean std print dataframe sort values adaboostclassifier append gradientboostingclassifier append quadraticdiscriminantanalysis append svc append mlpclassifier append votingclassifier cross val score print drop fit print print predict dataframe dataframe concat csv,"[0.0, 0.0, 0.0, 0.068607160177295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8151846179846256, 0.039173250946349256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13748760498531992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040296464769318044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1160132511556484, 0.0, 0.0, 0.06192680429354458, 0.0, 0.0, 0.0, 0.05121621293245669, 0.0, 0.0, 0.0, 0.10345519308123363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13208596691999927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08061506260248369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022748649814149546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027103033481751183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06412140896395414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07190693968456087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034202724104606584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0580066255778242, 0.036718660844496535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06668540951210067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03471479395419648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03454258220458487, 0.0, 0.0, 0.1084532641615712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0742131655054628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0852163923606017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023602189505135783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3303081649841294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05248270362239009, 0.0852163923606017, 0.0, 0.0, 0.0, 0.056876800812675224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041118648409691025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1630592672085358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03437190124632998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06942958790839296, 0.0, 0.07190693968456087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04250032467480322, 0.0, 0.0, 0.0, 0.035965565051460945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11841421809562798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03652759975196752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044123951785945734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03750250361187246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03691164218117662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1160132511556484, 0.0, 0.0, 0.0, 0.04250032467480322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0744709402327074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
arindamkumar_solution-2-0-titanic.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,776,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# save the passenger id for the final submission', '# merge train and test', '# normalize the titles', '# view value counts for the normalized titles', '# view value counts for the normalized titles', '# ## map the first letter of the cabin to the cabin.', '# titanic.Cabin=titanic.Cabin.map(lambda x:x[0])', '# ## view the normalized count', '# titanic.Cabin.value_counts(normalize=True)', '# create X and y for data and target values', '# The parameters that we are going to optimise', '# Perform grid search using the parameters and f1_scorer as the scoring method', '# here cv is used for the cross-validation strategy.', 'clf1=grid_search.best_estimator_        # get the best estimator(classifier)', '# Print the tuned parameters and score', '# create param grid object', '# build and fit model', '# random forrest prediction on test set']",26,"['print', 'pd.read_csv', 'pd.read_csv', 'train.append', 'len', 'len', 'len', 'len', 'len', 'titanic.head', 'titanic.info', 'titanic.drop', 'titanic.head', 'titanic.Name.apply', 'titanic.head', 'print', 'print', 'titanic.head', 'titanic.head', 'type', 'print', 'titanic.Title.map', 'titanic.head', 'print', 'titanic.groupby', 'grouped.Age.median', 'titanic.Embarked.value_counts', 'titanic.groupby', 'grouped1.Age.median', 'grouped.Age.apply', 'titanic.info', 'titanic.head', 'titanic.Embarked.value_counts', 'titanic.Embarked.value_counts', 'titanic.Embarked.value_counts', 'titanic.info', 'titanic.Embarked.fillna', 'titanic.info', 'titanic.head', 'titanic.info', 'titanic.Survived.value_counts', 'titanic.Survived.value_counts', 'titanic.groupby', 'groupbysex.Survived.value_counts', 'groupbysex.Survived.mean', 'titanic.groupby', 'group_class_sex.Survived.mean', 'titanic.describe', 'titanic.drop', 'titanic.head', 'titanic.info', 'titanic.str.slice', 'titanic.fillna', 'titanic.str.slice', 'None.str.extract', 'None.astype', 'titanic.fillna', 'titanic.Room.astype', 'titanic.drop', 'titanic.head', 'titanic.Deck.value_counts', 'titanic.apply', 'titanic.groupby', 'None.Survived.mean', 'titanic.apply', 'titanic.groupby', 'None.Survived.mean', 'titanic.map', 'titanic.head', 'titanic.drop', 'titanic.info', 'titanic.apply', 'titanic.groupby', 'None.Survived.mean', 'titanic.drop', 'titanic.value_counts', 'type', 'titanic.head', 'titanic.info', 'titanic.fillna', 'titanic.info', 'titanic.astype', 'titanic.head', 'dfcolumn.values.tolist', 'set', 'list', 'handle_non_numeric_data', 'titanic.head', 'titanic.drop', 'titanic.head', 'train.Survived.astype', 'train.head', 'train.drop', 'train.drop', 'test.head', 'test.drop', 'test.drop', 'dict', 'LogisticRegression', 'GridSearchCV', 'grid_search.fit', 'print', 'print', 'print', 'grid_search.predict', 'print', 'dict', 'RandomForestClassifier', 'GridSearchCV', 'forest_cv.fit', 'print', 'print', 'forest_cv.predict', 'pd.DataFrame', 'sub.head', 'sub.to_csv']","['print', 'read_csv', 'read_csv', 'append', 'len', 'len', 'len', 'len', 'len', 'head', 'info', 'drop', 'head', 'Name', 'head', 'print', 'print', 'head', 'head', 'type', 'print', 'Title', 'head', 'print', 'groupby', 'Age', 'Embarked', 'groupby', 'Age', 'Age', 'info', 'head', 'Embarked', 'Embarked', 'Embarked', 'info', 'Embarked', 'info', 'head', 'info', 'Survived', 'Survived', 'groupby', 'Survived', 'Survived', 'groupby', 'Survived', 'describe', 'drop', 'head', 'info', 'str', 'fillna', 'str', 'str', 'astype', 'fillna', 'Room', 'drop', 'head', 'Deck', 'apply', 'groupby', 'Survived', 'apply', 'groupby', 'Survived', 'map', 'head', 'drop', 'info', 'apply', 'groupby', 'Survived', 'drop', 'value_counts', 'type', 'head', 'info', 'fillna', 'info', 'astype', 'head', 'values', 'set', 'list', 'handle_non_numeric_data', 'head', 'drop', 'head', 'Survived', 'head', 'drop', 'drop', 'head', 'drop', 'drop', 'dict', 'LogisticRegression', 'GridSearchCV', 'fit', 'print', 'print', 'print', 'predict', 'print', 'dict', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'DataFrame', 'head', 'to_csv']","['print', 'read_csv', 'append', 'len', 'head', 'info', 'drop', 'Name', 'type', 'Title', 'groupby', 'Age', 'Embarked', 'Survived', 'describe', 'str', 'fillna', 'astype', 'Room', 'Deck', 'apply', 'map', 'value_counts', 'values', 'set', 'list', 'handle_non_numeric_data', 'dict', 'LogisticRegression', 'GridSearchCV', 'fit', 'predict', 'RandomForestClassifier', 'DataFrame', 'to_csv']",35,"[1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv append len len len len len head info drop head name head print print head head type print title head print groupby age embarked groupby age age info head embarked embarked embarked info embarked info head info survived survived groupby survived survived groupby survived describe drop head info str fillna str str astype fillna room drop head deck apply groupby survived apply groupby survived map head drop info apply groupby survived drop value counts type head info fillna info astype head values set list handle non numeric data head drop head survived head drop drop head drop drop dict logisticregression gridsearchcv fit print print print predict print dict randomforestclassifier gridsearchcv fit print print predict dataframe head csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12689893793032136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041173011827815235, 0.10684151443009109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062497510321162554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04259304398322112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056299927413902655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06537323427197526, 0.0, 0.02351372692128367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08249534539666326, 0.0, 0.0, 0.0, 0.0, 0.0335577267264996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15494669098811056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2401683870119001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2129652199161056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07329010797122901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04136326257786301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09963944891726724, 0.0, 0.0, 0.22771393136928123, 0.0, 0.0, 0.09459545661874327, 0.0, 0.40252164872238305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2784823935680358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21909291805897146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048115272107947214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03140392747522448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032866279094881726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0465625362620702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10167356793821532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07747334549405528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04291523100883917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2202165230115154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03034561736829625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03738247027652141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10167356793821532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03373495434471375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15664443882890106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5613595540586473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03522153465730173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15960874472708908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04259304398322112, 0.038638602807865956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
anupchandratre_titanic-basic-solution-with-logistic-regression.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'os\n', 're\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,271,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['get_ipython', 'None.run_line_magic', 'print', 'pd.read_csv', 'train.head', 'pd.read_csv', 'test.head', 'train.info', 'test.info', 'pd.concat', 'all.info', 'all.fillna', 'all.fillna', 'all.info', 'sns.catplot', 'all.fillna', 'all.info', 're.search', 'title_search.group', 'all.apply', 'all.value_counts', 'all.replace', 'all.replace', 'all.replace', 'all.replace', 'all.value_counts', 'all.fillna', 'all.value_counts', 'all.head', 'all.drop', 'all_1.head', 'pd.get_dummies', 'all_dummies.head', 'all_dummies.notna', 'all_train.info', 'all_dummies.isna', 'all_test.info', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'confusion_matrix', 'all_test.head', 'all_test.drop', 'TestForPred.info', 'logmodel.predict', 'None.astype', 'pd.DataFrame', 'logSub.head', 'logSub.to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'read_csv', 'head', 'info', 'info', 'concat', 'info', 'fillna', 'fillna', 'info', 'catplot', 'fillna', 'info', 'search', 'group', 'apply', 'value_counts', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'fillna', 'value_counts', 'head', 'drop', 'head', 'get_dummies', 'head', 'notna', 'info', 'isna', 'info', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix', 'head', 'drop', 'info', 'predict', 'astype', 'DataFrame', 'head', 'to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'info', 'concat', 'fillna', 'catplot', 'search', 'group', 'apply', 'value_counts', 'replace', 'drop', 'get_dummies', 'notna', 'isna', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'confusion_matrix', 'astype', 'DataFrame', 'to_csv']",26,"[1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic print read csv head read csv head info info concat info fillna fillna info catplot fillna info search group apply value counts replace replace replace replace value counts fillna value counts head drop head get dummies head notna info isna info train test split logisticregression fit predict print confusion matrix head drop info predict astype dataframe head csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07816776532012103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06858697313402044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14860209042266223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08040906805596972, 0.0, 0.0, 0.12638614081793892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2804586565155509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12357105392331454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051609587272940724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10542770502682515, 0.0, 0.0, 0.0, 0.07443683997279889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21448306833688435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04539350391054987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10816480682527321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14348578814275514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3435766917476484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5433180539063547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06824939075848886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14116293443231637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06927119402636349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06892755628112136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06892755628112136, 0.0, 0.0, 0.0, 0.0, 0.11940042623527075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18805232057470764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09419337765993686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08788123017638046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08204968394303865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3253745406498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06858697313402044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14348578814275514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07176702930268668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07483389380331829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07365486687714871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2804586565155509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
evan8899_titanic-data-science-solutions.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,949,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
qwordy_titanic.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'sklearn', 'keras']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,384,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Train, predict, write result', '# formal_process()']",10,"['print', 'pd.read_csv', 'train_data.head', 'train_data.describe', 'train_data.describe', 'train_data.info', 'sns.set', 'train_data.hist', 'train_datacate.groupby', 'None.mean', 'cate_survived', 'cate_survived', 'cate_survived', 'cate_survived', 'train_data.groupby', 'None.Survived.mean', 'None.unstack', 'train_data.groupby', 'None.Sex.describe', 'train_data.pivot_table', 'train_data.groupby', 'None.Survived.describe', 'sns.FacetGrid', 'g.map', 'train_data.corr', 'X.fillna', 'pd.get_dummies', 'preprocess_X', 'train_test_split', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'nn_model', 'model.fit', 'print', 'model.evaluate', 'nn_model', 'model.fit', 'pd.read_csv', 'preprocess_X', 'model.predict_classes', 'test_y.squeeze', 'pd.DataFrame', 'output.to_csv', 'GradientBoostingClassifier', 'cross_val_score', 'print', 'GradientBoostingClassifier', 'model.fit', 'pd.read_csv', 'preprocess_X', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'train_test_split', 'X_test.info', 'X_train.drop', 'SimpleImputer', 'imputer.fit_transform', 'pd.DataFrame', 'X_train.reset_index', 'None.drop', 'pd.get_dummies', 'pd.concat', 'X_test.drop', 'X_test_num.fillna', 'pd.get_dummies', 'pd.concat', 'RandomForestClassifier', 'model.fit', 'model.score', 'DecisionTreeClassifier', 'model.fit', 'model.score', 'LogisticRegression', 'model.fit', 'model.score', 'AdaBoostClassifier', 'model.fit', 'model.score', 'GradientBoostingClassifier', 'model.fit', 'model.score', 'svm.SVC', 'model.fit', 'model.score', 'svm.LinearSVC', 'model.fit', 'model.score']","['print', 'read_csv', 'head', 'describe', 'describe', 'info', 'set', 'hist', 'groupby', 'mean', 'cate_survived', 'cate_survived', 'cate_survived', 'cate_survived', 'groupby', 'Survived', 'unstack', 'groupby', 'Sex', 'pivot_table', 'groupby', 'Survived', 'FacetGrid', 'map', 'corr', 'fillna', 'get_dummies', 'preprocess_X', 'train_test_split', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'compile', 'nn_model', 'fit', 'print', 'evaluate', 'nn_model', 'fit', 'read_csv', 'preprocess_X', 'predict_classes', 'squeeze', 'DataFrame', 'to_csv', 'GradientBoostingClassifier', 'cross_val_score', 'print', 'GradientBoostingClassifier', 'fit', 'read_csv', 'preprocess_X', 'predict', 'DataFrame', 'to_csv', 'train_test_split', 'info', 'drop', 'SimpleImputer', 'fit_transform', 'DataFrame', 'reset_index', 'drop', 'get_dummies', 'concat', 'drop', 'fillna', 'get_dummies', 'concat', 'RandomForestClassifier', 'fit', 'score', 'DecisionTreeClassifier', 'fit', 'score', 'LogisticRegression', 'fit', 'score', 'AdaBoostClassifier', 'fit', 'score', 'GradientBoostingClassifier', 'fit', 'score', 'SVC', 'fit', 'score', 'LinearSVC', 'fit', 'score']","['print', 'read_csv', 'head', 'describe', 'info', 'set', 'hist', 'groupby', 'mean', 'cate_survived', 'Survived', 'unstack', 'Sex', 'pivot_table', 'FacetGrid', 'map', 'corr', 'fillna', 'get_dummies', 'preprocess_X', 'train_test_split', 'Sequential', 'add', 'compile', 'nn_model', 'fit', 'evaluate', 'predict_classes', 'squeeze', 'DataFrame', 'to_csv', 'GradientBoostingClassifier', 'cross_val_score', 'predict', 'drop', 'SimpleImputer', 'fit_transform', 'reset_index', 'concat', 'RandomForestClassifier', 'score', 'DecisionTreeClassifier', 'LogisticRegression', 'AdaBoostClassifier', 'SVC', 'LinearSVC']",46,"[1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv head describe describe info set hist groupby mean cate survived cate survived cate survived cate survived groupby survived unstack groupby sex pivot table groupby survived facetgrid map corr fillna get dummies preprocess x train test split sequential add add add add add add add add compile nn model fit print evaluate nn model fit read csv preprocess x predict classes squeeze dataframe csv gradientboostingclassifier cross val score print gradientboostingclassifier fit read csv preprocess x predict dataframe csv train test split info drop simpleimputer fit transform dataframe reset index drop get dummies concat drop fillna get dummies concat randomforestclassifier fit score decisiontreeclassifier fit score logisticregression fit score adaboostclassifier fit score gradientboostingclassifier fit score svc fit score linearsvc fit score,"[0.0, 0.0, 0.0, 0.06430508160985403, 0.0, 0.3329900007189714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4192902272994196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07585680446547825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06630685761980562, 0.0, 0.0, 0.07553927167028156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04960547708666536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05436926382107688, 0.0, 0.0, 0.09673937320932197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07272595109089203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04244820418414189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06919412366523864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07428203289881677, 0.0, 0.0, 0.0, 0.10489310744906229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07257548430825476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04485142658935722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05037334457258584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23454391013063633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07621053438510064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18030184134033644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13415233530380327, 0.0, 0.0, 0.0, 0.0, 0.023054909534969473, 0.0, 0.0, 0.04584236128682187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05183021108171143, 0.0, 0.0, 0.06380165053155623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06338193393733564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03237655606121461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0338841989900296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03477977846642994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13711894601032662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2096451136497098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08227603817378502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044244382608953435, 0.0, 0.0, 0.2551510645091921, 0.0, 0.0, 0.061919174181866064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031285468440593135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057810395478527614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05798082138762485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2603037528473766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07257548430825476, 0.0, 0.03477977846642994, 0.0, 0.06430508160985403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0923476862967123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06742061877512613, 0.0, 0.1048225568248549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3858304896591242, 0.0, 0.0, 0.0, 0.04135711656352041, 0.0, 0.0, 0.0798728157685697, 0.0, 0.0, 0.0, 0.07030174544765387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06919412366523864, 0.0, 0.0, 0.0, 0.03935534055356882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06980116764564243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05436926382107688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29257567609361995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
imsanjoykb_titanic-data-science-competition.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,454,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Save to csv file']",17,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train_df.head', 'test_df.head', 'train_df.info', 'test_df.info', 'train_df.describe', 'test_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.pairplot', 'sns.pairplot', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'train_df.drop', 'test_df.drop', 'None.copy', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv', 'print']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'head', 'info', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'pairplot', 'pairplot', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'drop', 'drop', 'copy', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'pairplot', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'copy', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'KNeighborsClassifier', 'to_csv']",41,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic read csv read csv head head info info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend pairplot pairplot print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend drop drop copy zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head drop drop copy logisticregression fit predict round dataframe series sort values kneighborsclassifier fit predict round dataframe sort values dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.12472165466442557, 0.0, 0.04355748754330897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12871192958903757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08006430279502227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04996903101747965, 0.057974087735078984, 0.0, 0.0, 0.0, 0.047947141078524054, 0.0, 0.0, 0.0, 0.0726388254903805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06911122918966599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29677217245680565, 0.042118650000161094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043859610166701105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1791907785405063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07546949605104136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04259325942054377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02537307808602066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3349790524252205, 0.0, 0.0, 0.0, 0.0, 0.25330018759680106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06372521623220631, 0.0, 0.0, 0.0, 0.0, 0.05725762028362491, 0.0, 0.0, 0.0, 0.0, 0.03201960363754573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043260358911598615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11125837241175487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03249898865870543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06079365953955909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032337768986628226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032337768986628226, 0.0, 0.0, 0.23690524032740132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3473811233433965, 0.04833373389106075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05662682317729767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047947141078524054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14497707793352982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044191377892669303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06184499508688207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04913279312712352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1742299501732359, 0.0, 0.0, 0.0, 0.03849409246360528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15265138207932313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09513737533953645, 0.0, 0.03217798239725939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04719803798283799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397875779248507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.397875779248507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041045144624915486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06242895666597799, 0.0, 0.0]"
davidcoxon_deeply-titanic.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn', 'warnings\n', 'data\n', 'scipy', '__future__', 'keras\n', 'keras']","[1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",11,862,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', '# for handling data', 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# for visualisation', '# for machine learning', '# Any results you write to the current directory are saved as output.', '# import data', 'df_data = df_train.append(df_test) # The entire data: train + test.', '# exporting the submission', '# Get a statistical overview of the training data', '# Get a statistical overview of the training data', '# Get title', '# Age in df_train and df_test:', '# convert Title categories to Columns', '# convert Embarked categories to Columns', '# Fill the na values in Fare based on average fare', '# convert FareBand categories to Columns', '# Age in df_train and df_test:', '# convert Pclass categories to Columns', '# sort Age into band categories', '# convert AgeGroup categories to Columns', '# convert categories to Columns', '# People with parents or siblings', 'df_data[""Alone""] = np.where(df_data[\'SibSp\'] + df_data[\'Parch\'] + 1 == 1, 1,0) # People travelling alone', '# Age in df_train and df_test:', '# get last name', '# Set survival value', '# Find Family groups by Fare', '        # A Family group is found.', '# Find Family groups by Ticket', '# Family_Survival in df_train and df_test:', '# check if cabin inf exists', '# split Embanked into df_train and df_test:', '# convert categories to Columns', '# convert SibSp categories to Columns', '# convert SibSp categories to Columns', '# define columns to be used', '# create test and training data', '# write data frame to csv file', '# DecisionTree with RandomizedSearch', '# Import necessary modules', '# Setup the parameters and distributions to sample from: param_dist', '# Instantiate a Decision Tree classifier: tree', '# Instantiate the RandomizedSearchCV object: tree_cv', '# Fit it to the data', '# Print the tuned parameters and score', '# Select columns', '# select classifier', '# train model', '# make predictions', '# create test and training data', '# Import necessary modules', '# create model', '# choose loss function and optimizing method', '# define 10-fold cross validation test harness', '    # create model', '    # Compile model', '    # Fit the model', '    # evaluate the model']",61,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'df_train.append', 'pd.DataFrame', 'print', 'print', 'df_train.describe', 'df_test.describe', 'df_data.Name.str.extract', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'df_data.fillna', 'print', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'df_data.fillna', 'print', 'df_data.groupby', 'None.median', 'df_data.isnull', 'pd.qcut', 'None.astype', 'pd.qcut', 'None.astype', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'df_data.groupby', 'None.median', 'df_data.isnull', 'print', 'df_train.astype', 'df_test.astype', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'pd.cut', 'pd.cut', 'print', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'np.where', 'print', 'df_data.apply', 'df_data.groupby', 'len', 'grp_df.iterrows', 'grp_df.drop', 'None.max', 'grp_df.drop', 'None.min', 'print', 'df_data.groupby', 'len', 'grp_df.iterrows', 'grp_df.drop', 'None.max', 'grp_df.drop', 'None.min', 'print', 'df_data.notnull', 'None.astype', 'print', 'df_data.Cabin.str.extract', 'df_data.map', 'df_data.fillna', 'df_data.astype', 'print', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'print', 'df_train.astype', 'pd.get_dummies', 'pd.concat', 'df_test.astype', 'pd.get_dummies', 'pd.concat', 'print', 'df_train.astype', 'pd.get_dummies', 'pd.concat', 'df_test.astype', 'pd.get_dummies', 'pd.concat', 'print', 'df_data.drop', 'df_train.drop', 'df_test.drop', 'print', 'print', 'print', 'df_train.head', 'df_train.describe', 'df_trainREVISED_NUMERIC_COLUMNS.fillna', 'train_test_split', 'print', 'print', 'print', 'SVC', 'clf.fit', 'clf.predict', 'round', 'print', 'df_testREVISED_NUMERIC_COLUMNS.fillna', 'clf.predict', 'Submission.set_index', 'Submission.to_csv', 'print', 'df_train.drop', 'df_trainREVISED_NUMERIC_COLUMNS.fillna', 'train_test_split', 'print', 'np.arange', 'np.arange', 'np.arange', 'DecisionTreeClassifier', 'RandomizedSearchCV', 'tree_cv.fit', 'tree_cv.predict', 'print', 'print', 'round', 'print', 'df_testREVISED_NUMERIC_COLUMNS.fillna', 'DecisionTreeClassifier', 'tree.fit', 'tree.predict', 'print', 'Submission.to_csv', 'print', 'df_train.drop', 'df_trainREVISED_NUMERIC_COLUMNS.fillna', 'df_testREVISED_NUMERIC_COLUMNS.fillna', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'print', 'model.fit', 'print', 'print', 'print', 'df_test.set_index', 'model.predict_classes', 'print', 'pd.DataFrame', 'print', 'print', 'print', 'submission.to_csv', 'print', 'StratifiedKFold', 'kfold.split', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'model.fit', 'model.evaluate', 'print', 'cvscores.append', 'print', 'model.predict_classes', 'print', 'pd.DataFrame', 'print', 'print', 'print', 'submission.to_csv', 'print']","['get_ipython', 'run_line_magic', 'filterwarnings', 'read_csv', 'read_csv', 'append', 'DataFrame', 'print', 'print', 'describe', 'describe', 'Name', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'fillna', 'print', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'fillna', 'print', 'groupby', 'median', 'isnull', 'qcut', 'astype', 'qcut', 'astype', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'groupby', 'median', 'isnull', 'print', 'astype', 'astype', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'cut', 'cut', 'print', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'where', 'print', 'apply', 'groupby', 'len', 'iterrows', 'drop', 'max', 'drop', 'min', 'print', 'groupby', 'len', 'iterrows', 'drop', 'max', 'drop', 'min', 'print', 'notnull', 'astype', 'print', 'Cabin', 'map', 'fillna', 'astype', 'print', 'get_dummies', 'concat', 'get_dummies', 'concat', 'print', 'astype', 'get_dummies', 'concat', 'astype', 'get_dummies', 'concat', 'print', 'astype', 'get_dummies', 'concat', 'astype', 'get_dummies', 'concat', 'print', 'drop', 'drop', 'drop', 'print', 'print', 'print', 'head', 'describe', 'fillna', 'train_test_split', 'print', 'print', 'print', 'SVC', 'fit', 'predict', 'round', 'print', 'fillna', 'predict', 'set_index', 'to_csv', 'print', 'drop', 'fillna', 'train_test_split', 'print', 'arange', 'arange', 'arange', 'DecisionTreeClassifier', 'RandomizedSearchCV', 'fit', 'predict', 'print', 'print', 'round', 'print', 'fillna', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'to_csv', 'print', 'drop', 'fillna', 'fillna', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'compile', 'print', 'fit', 'print', 'print', 'print', 'set_index', 'predict_classes', 'print', 'DataFrame', 'print', 'print', 'print', 'to_csv', 'print', 'StratifiedKFold', 'split', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'compile', 'fit', 'evaluate', 'print', 'append', 'print', 'predict_classes', 'print', 'DataFrame', 'print', 'print', 'print', 'to_csv', 'print']","['get_ipython', 'run_line_magic', 'filterwarnings', 'read_csv', 'append', 'DataFrame', 'print', 'describe', 'Name', 'replace', 'get_dummies', 'concat', 'fillna', 'groupby', 'median', 'isnull', 'qcut', 'astype', 'cut', 'where', 'apply', 'len', 'iterrows', 'drop', 'max', 'min', 'notnull', 'Cabin', 'map', 'head', 'train_test_split', 'SVC', 'fit', 'predict', 'round', 'set_index', 'to_csv', 'arange', 'DecisionTreeClassifier', 'RandomizedSearchCV', 'Sequential', 'add', 'compile', 'predict_classes', 'StratifiedKFold', 'split', 'evaluate']",47,"[1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1
 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings read csv read csv append dataframe print print describe describe name replace replace replace replace replace replace get dummies concat get dummies concat print fillna print get dummies concat get dummies concat print fillna print groupby median isnull qcut astype qcut astype get dummies concat get dummies concat print groupby median isnull print astype astype get dummies concat get dummies concat print cut cut print get dummies concat get dummies concat print get dummies concat get dummies concat print print apply groupby len iterrows drop max drop min print groupby len iterrows drop max drop min print notnull astype print cabin map fillna astype print get dummies concat get dummies concat print astype get dummies concat astype get dummies concat print astype get dummies concat astype get dummies concat print drop drop drop print print print head describe fillna train test split print print print svc fit predict round print fillna predict set index csv print drop fillna train test split print arange arange arange decisiontreeclassifier randomizedsearchcv fit predict print print round print fillna decisiontreeclassifier fit predict print csv print drop fillna fillna train test split print print print print print print print print print sequential add add add add add compile print fit print print print set index predict classes print dataframe print print print csv print stratifiedkfold split sequential add add add add add add add compile fit evaluate print append print predict classes print dataframe print print print csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.2672729166679848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04542781190673509, 0.01964707788708157, 0.10819331128829172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17238993563199698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03138881596077351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08118149427841082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07096119880625021, 0.0, 0.0, 0.36378752668907705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062117935982370455, 0.0, 0.0, 0.0, 0.05137428731373179, 0.0, 0.0, 0.0, 0.03891543694715016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04542781190673509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055538350125718734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11924427487928979, 0.0, 0.0, 0.0, 0.3367679114177312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03883492262585867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12129581095979174, 0.0, 0.02773418953004833, 0.0, 0.0, 0.0, 0.05704715385208446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25827350402720783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07178450975915684, 0.0, 0.0, 0.0, 0.0, 0.012336612514136196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05546837906009666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017154143917080065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03683198979370835, 0.0, 0.0, 0.0, 0.0, 0.09453202542114052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048346775860379464, 0.0, 0.0, 0.0, 0.0, 0.017410969071374703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01732459743828447, 0.0, 0.0, 0.018131332619537588, 0.0, 0.0, 0.0, 0.0698602851685105, 0.0, 0.0, 0.0, 0.0, 0.05178851284997715, 0.0, 0.0, 0.0, 0.07470078830475803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025687143656865894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0416054081556201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07102510682324839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6516110103314119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052644686916892836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04273970266746208, 0.0, 0.0, 0.0, 0.0, 0.020622778768684524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1226719015781014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050968782966257946, 0.0, 0.017238993563199696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07766984525171734, 0.0, 0.03722110898913249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07215313927217525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04726601271057026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022130068260395402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05642737773529237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055538350125718734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
hudanivy_ai-camp-logistic-regression-titanic-homework.py,"['numpy', 'pandas', 'patsy', 'sklearn', 'matplotlib']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,212,"['import numpy as np # æ•°ç»„å¸¸ç”¨åº“', 'import pandas as pd # è¯»å…¥csvå¸¸ç”¨åº“', 'from patsy import dmatrices,dmatrix # å¯æ\xa0¹æ®ç¦»æ•£å˜é‡è‡ªåŠ¨ç”Ÿæˆå“‘å˜é‡', 'from sklearn.linear_model import LogisticRegression # sk-learnåº“Logistic Regressionæ¨¡åž‹', 'from sklearn.model_selection import train_test_split, cross_val_score # sk-learnåº“è®\xadç»ƒä¸Žæµ‹è¯•', 'from sklearn import metrics # ç”Ÿæˆå„é¡¹æµ‹è¯•æŒ‡æ\xa0‡åº“', 'import matplotlib.pyplot as plt # ç”»å›¾å¸¸ç”¨åº“']",7,"['pd.read_csv', 'pd.read_csv', 'pd.concat', 'all_data.drop', 'all_data.fillna', 'all_data.fillna', 'all_data.locall_data.fillna', 'all_data.locall_data.fillna', 'all_data.head', 'data.value_counts', 'None.plot', 'plt.show', 'data.locdata.value_counts', 'None.sort_index', 'None.plot', 'plt.show', 'data.locdata.value_counts', 'None.plot', 'plt.show', 'data.Surviveddata.Pclass.value_counts', 'None.sort_index', 'highclass.plot', 'plt.show', 'data.Surviveddata.Pclass.value_counts', 'None.sort_index', 'lowclass.plot', 'plt.show', 'all_data.isnull', 'None.any', 'all_data.Age.plot', 'pd.qcut', 'dmatrices', 'np.ravel', 'len', 'len', 'len', 'print', 'LogisticRegression', 'model.fit', 'model.predict', 'metrics.accuracy_score', 'metrics.accuracy_score', 'pd.DataFrame', 'print', 'GridSearchCV', 'gs.fit', 'print', 'LogisticRegression', 'model.fit', 'model.predict', 'prediction.astype', 'pd.DataFrame', 'df.to_csv']","['read_csv', 'read_csv', 'concat', 'drop', 'fillna', 'fillna', 'locall_data', 'locall_data', 'head', 'value_counts', 'plot', 'show', 'locdata', 'sort_index', 'plot', 'show', 'locdata', 'plot', 'show', 'Surviveddata', 'sort_index', 'plot', 'show', 'Surviveddata', 'sort_index', 'plot', 'show', 'isnull', 'any', 'Age', 'qcut', 'dmatrices', 'ravel', 'len', 'len', 'len', 'print', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'accuracy_score', 'DataFrame', 'print', 'GridSearchCV', 'fit', 'print', 'LogisticRegression', 'fit', 'predict', 'astype', 'DataFrame', 'to_csv']","['read_csv', 'concat', 'drop', 'fillna', 'locall_data', 'head', 'value_counts', 'plot', 'show', 'locdata', 'sort_index', 'Surviveddata', 'isnull', 'any', 'Age', 'qcut', 'dmatrices', 'ravel', 'len', 'print', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'DataFrame', 'GridSearchCV', 'astype', 'to_csv']",28,"[1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0
 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv concat drop fillna fillna locall data locall data head value counts plot show locdata sort index plot show locdata plot show surviveddata sort index plot show surviveddata sort index plot show isnull age qcut dmatrices ravel len len len print logisticregression fit predict accuracy score accuracy score dataframe print gridsearchcv fit print logisticregression fit predict astype dataframe csv,"[0.0, 0.0, 0.17715363351411856, 0.0, 0.0, 0.0, 0.0, 0.07384436247954235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0545523337093525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06395532727878186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07435656035350963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09828527287928003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22824989176932936, 0.0, 0.08209790573536509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17749604357304805, 0.0, 0.0, 0.0, 0.04192725734955767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08529718825801248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10831451485953439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08697249602453658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03903888009743066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26329230129153924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058276922925914305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2294881172300722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3549920871460961, 0.3549920871460961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10964644976154514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31436629477647643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07491901649129878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10484774242776027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0832963513266048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1440157724178398, 0.0, 0.06526023142122543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.110193091203702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35702528235454273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20235935258279444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31274468868717387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07435656035350963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
someshugar_titanic-data-eda-and-prediction-model.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'datasets\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,636,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# import datasets', '# view first five lines of training data', '# Data Munging', '# Drop low corrlations and high cardinality', '# label', '# Creade dummy variables for Sex and drop original, as well as an unnecessary column (male or female)', '# Split training data into training and validation set', '# Initialize model', '# Fit data', '# Calc accuracy', '  # This is added back by InteractiveShellApp.init_path()']",19,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'df_train.head', 'df_test.head', 'df_train.info', 'df_test.info', 'pd.concat', 'total_df.info', 'total_df.tail', 'male_df.info', 'female_df.info', 'total_df.describe', 'get_ipython', 'None.run_line_magic', 'total_df.Fare.plot', 'get_ipython', 'None.run_line_magic', 'total_df.Age.plot', 'total_df.Sex.value_counts', 'total_df.Survived.value_counts', 'total_dftotal_df.Survived.Survived.value_counts', 'total_df.Pclass.value_counts', 'total_df.Pclass.value_counts', 'None.plot', 'total_df.Age.plot', 'total_df.Age.plot', 'total_df.Fare.plot', 'total_df.Fare.plot', 'total_df.Age.skew', 'total_df.Fare.skew', 'total_df.plot.scatter', 'total_df.plot.scatter', 'total_df.groupby', 'None.median', 'total_df.groupby', 'None.agg', 'total_df.groupby', 'None.agg', 'pd.crosstab', 'pd.crosstab', 'None.plot', 'total_df.pivot_table', 'total_df.info', 'total_df.Embarked.isnull', 'total_df.Embarked.value_counts', 'pd.crosstab', 'total_df.pivot_table', 'total_df.Embarked.fillna', 'total_df.info', 'total_df.Fare.isnull', 'total_dftotal_df.Pclasstotal_df.Embarked.Fare.median', 'total_df.Age.isnull', 'None.count', 'print', 'print', 'print', 'total_dftotal_df.Sex.Age.median', 'total_dftotal_df.Sex.Age.median', 'total_dftotal_df.Sex.Age.median', 'total_df.Age.notnull', 'None.boxplot', 'total_df.groupby', 'None.Age.transform', 'total_df.info', 'total_df.loc.split', 'name.split', 'name.split', 'None.split', 'None.strip', 'total_df.Name.map', 'None.unique', 'name.split', 'None.split', 'None.strip', 'None.lower', 'total_df.Name.map', 'total_df.head', 'total_df.Age.notnull', 'None.boxplot', 'total_df.groupby', 'None.Age.transform', 'Median_Age_title.unique', 'total_df.Age.fillna', 'total_df.info', 'total_df.plot', 'total_df.Fare.plot', 'total_df.Fare.max', 'np.log', 'pd.qcut', 'total_df.isnull', 'None.sum', 'total_df.fillna', 'LabelEncoder', 'le.fit_transform', 'plt.subplots', 'sns.diverging_palette', 'sns.heatmap', 'plt.title', 'correlation_heatmap', 'total_df.drop', 'total_df.info', 'total_df.notnull', 'None.astype', 'total_df.Cabin.str.extract', 'total_df.sample', 'total_df.fillna', 'total_df.drop', 'le.fit_transform', 'total_df.info', 'total_df.head', 'total_df.join', 'total_df.drop', 'train_test_split', 'RandomForestClassifier', 'model.fit', 'accuracy_score', 'print', 'pd.DataFrame', 'y_pred.to_csv', 'sns.barplot']","['walk', 'print', 'read_csv', 'read_csv', 'head', 'head', 'info', 'info', 'concat', 'info', 'tail', 'info', 'info', 'describe', 'get_ipython', 'run_line_magic', 'Fare', 'get_ipython', 'run_line_magic', 'Age', 'Sex', 'Survived', 'Survived', 'Pclass', 'Pclass', 'plot', 'Age', 'Age', 'Fare', 'Fare', 'Age', 'Fare', 'plot', 'plot', 'groupby', 'median', 'groupby', 'agg', 'groupby', 'agg', 'crosstab', 'crosstab', 'plot', 'pivot_table', 'info', 'Embarked', 'Embarked', 'crosstab', 'pivot_table', 'Embarked', 'info', 'Fare', 'Pclasstotal_df', 'Age', 'count', 'print', 'print', 'print', 'Sex', 'Sex', 'Sex', 'Age', 'boxplot', 'groupby', 'Age', 'info', 'loc', 'split', 'split', 'split', 'strip', 'Name', 'unique', 'split', 'split', 'strip', 'lower', 'Name', 'head', 'Age', 'boxplot', 'groupby', 'Age', 'unique', 'Age', 'info', 'plot', 'Fare', 'Fare', 'log', 'qcut', 'isnull', 'sum', 'fillna', 'LabelEncoder', 'fit_transform', 'subplots', 'diverging_palette', 'heatmap', 'title', 'correlation_heatmap', 'drop', 'info', 'notnull', 'astype', 'Cabin', 'sample', 'fillna', 'drop', 'fit_transform', 'info', 'head', 'join', 'drop', 'train_test_split', 'RandomForestClassifier', 'fit', 'accuracy_score', 'print', 'DataFrame', 'to_csv', 'barplot']","['walk', 'print', 'read_csv', 'head', 'info', 'concat', 'tail', 'describe', 'get_ipython', 'run_line_magic', 'Fare', 'Age', 'Sex', 'Survived', 'Pclass', 'plot', 'groupby', 'median', 'agg', 'crosstab', 'pivot_table', 'Embarked', 'Pclasstotal_df', 'count', 'boxplot', 'loc', 'split', 'strip', 'Name', 'unique', 'lower', 'log', 'qcut', 'isnull', 'sum', 'fillna', 'LabelEncoder', 'fit_transform', 'subplots', 'diverging_palette', 'heatmap', 'title', 'correlation_heatmap', 'drop', 'notnull', 'astype', 'Cabin', 'sample', 'join', 'train_test_split', 'RandomForestClassifier', 'fit', 'accuracy_score', 'DataFrame', 'to_csv', 'barplot']",56,"[1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 1 0 1 0
 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv head head info info concat info tail info info describe get ipython run line magic fare get ipython run line magic age sex survived survived pclass pclass plot age age fare fare age fare plot plot groupby median groupby agg groupby agg crosstab crosstab plot pivot table info embarked embarked crosstab pivot table embarked info fare pclasstotal df age count print print print sex sex sex age boxplot groupby age info loc split split split strip name unique split split strip lower name head age boxplot groupby age unique age info plot fare fare log qcut isnull sum fillna labelencoder fit transform subplots diverging palette heatmap title correlation heatmap drop info notnull astype cabin sample fillna drop fit transform info head join drop train test split randomforestclassifier fit accuracy score print dataframe csv barplot,"[0.0, 0.0, 0.05147816207325563, 0.0, 0.0, 0.0, 0.0, 0.42916106031944995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1493005583020436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0317041634479438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048816487038079955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10809901334481727, 0.0, 0.05772704467981026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03716889840526871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09597405729162256, 0.0, 0.05461181355897656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14769971968613643, 0.057120422610925495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023856407647338315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034046785147475445, 0.0, 0.0, 0.0, 0.0, 0.0786024145851722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09087886854155398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07310055480026997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12964133975099273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3783465467068604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049572141360442606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06294911416965988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049998921926512944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16502325252423308, 0.0, 0.0, 0.0, 0.0, 0.09075285702920756, 0.09158901584518259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3453277633853226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06309623361280643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03386878184772602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058421689760489594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049660035950702716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06404088582112123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05989847638194331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09597405729162256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10315532249793578, 0.06372319437785691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047622022425561523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09448224434013093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07651633812892755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0746502791510218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13493802788941714, 0.0, 0.0, 0.10315532249793578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1619348260289112, 0.0, 0.18270016540849082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1015572184558298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04840931556010189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030787863645424334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03792726915502158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0634083268958876, 0.0, 0.0809674130144556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032020442910560616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25312915970192007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1990448206022801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1572048291703444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04413805114531025, 0.03369254975446265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12656457985096004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1572048291703444, 0.056414505101692033, 0.0, 0.0, 0.03459178750971362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03573484082563177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034046785147475445, 0.0, 0.0, 0.0, 0.07745876402543286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11545408935962052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0404407572192483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kerneler_starter-titanic-07c21d6b-d.py,"['libraries', 'mpl_toolkits', 'sklearn', 'matplotlib', 'numpy', 'os', 'pandas']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,151,"['import matplotlib.pyplot as plt # plotting', 'import numpy as np # linear algebra', 'import os # accessing directory structure', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Distribution graphs (histogram/bar graph) of column data', '    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values', '# Correlation matrix', ""    df = df.dropna('columns') # drop columns with NaN"", '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '# Scatter and density plots', '    df = df.select_dtypes(include =[np.number]) # keep only numerical columns', '    # Remove rows and columns that would lead to df being singular', '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots', ""nRowsRead = 1000 # specify 'None' if want to read whole file"", '# titanic.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows']",16,"['os.walk', 'print', 'df.nunique', 'list', 'plt.figure', 'range', 'plt.subplot', 'np.issubdtype', 'columnDf.value_counts', 'valueCounts.plot.bar', 'columnDf.hist', 'plt.ylabel', 'plt.xticks', 'plt.title', 'plt.tight_layout', 'plt.show', 'df.dropna', 'dfcol.nunique', 'print', 'df.corr', 'plt.figure', 'plt.matshow', 'plt.xticks', 'plt.yticks', 'plt.gca', 'None.xaxis.tick_bottom', 'plt.colorbar', 'plt.title', 'plt.show', 'df.select_dtypes', 'df.dropna', 'dfcol.nunique', 'list', 'len', 'pd.plotting.scatter_matrix', 'df.corr', 'df.corr', 'zip', 'axij.annotate', 'plt.suptitle', 'plt.show', 'pd.read_csv', 'print', 'df1.head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['walk', 'print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'nunique', 'print', 'corr', 'figure', 'matshow', 'xticks', 'yticks', 'gca', 'xaxis', 'colorbar', 'title', 'show', 'select_dtypes', 'dropna', 'nunique', 'list', 'len', 'plotting', 'corr', 'corr', 'zip', 'annotate', 'suptitle', 'show', 'read_csv', 'print', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['walk', 'print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'corr', 'matshow', 'yticks', 'gca', 'xaxis', 'colorbar', 'select_dtypes', 'len', 'plotting', 'zip', 'annotate', 'suptitle', 'read_csv', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']",34,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print nunique list figure range subplot issubdtype value counts plot hist ylabel xticks title tight layout show dropna nunique print corr figure matshow xticks yticks gca xaxis colorbar title show select dtypes dropna nunique list len plotting corr corr zip annotate suptitle show read csv print head plotpercolumndistribution plotcorrelationmatrix plotscattermatrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1543884081863955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29549374335041534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719323031194817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03841763880099134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16746437717682094, 0.0, 0.14721720635317656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16969806951294641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04577842287583891, 0.0, 0.0, 0.0910257746807462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16887817770593153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1385989983982722, 0.0, 0.0, 0.08970206154581574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1969958289002769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41579699519481655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0737274898474115, 0.0, 0.16887817770593153, 0.16887817770593153, 0.16887817770593153, 0.0, 0.0, 0.15062322702083364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12294830892833276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08659260829584371, 0.0, 0.0, 0.0, 0.03826327066145258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1412473333957713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2511965657652314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12585280241810667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14410775310320456, 0.0, 0.14420567755261537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719323031194817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08159805194038416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16887817770593153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22765714759109046, 0.0, 0.09531927208129282, 0.0, 0.0, 0.0, 0.14721720635317656, 0.0, 0.0, 0.1385989983982722, 0.0]"
hamdi1_titanic-or-dietanic.py,"['numpy', 'pandas', 'os\n', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,427,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# data analysis and wrangling', '# visualization', '# machine learning']",12,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'os.getcwd', 'pd.read_csv', 'pd.read_csv', 'test_df.head', 'train_df.head', 'train_df.tail', 'train_df.describe', 'train_df.describe', 'sns.heatmap', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'train_df.fillna', 'test_df.fillna', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'X_test.isna', 'None.sum', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'RandomForestClassifier', 'rfc.fit', 'rfc.predict', 'round', 'pd.DataFrame', 'X_submit.to_csv', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'GradientBoostingClassifier', 'clf.fit', 'clf.predict', 'clf.score']","['walk', 'print', 'get_ipython', 'run_line_magic', 'getcwd', 'read_csv', 'read_csv', 'head', 'head', 'tail', 'describe', 'describe', 'heatmap', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'fillna', 'fillna', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'drop', 'drop', 'copy', 'isna', 'sum', 'LogisticRegression', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'round', 'DataFrame', 'to_csv', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'GradientBoostingClassifier', 'fit', 'predict', 'score']","['walk', 'print', 'get_ipython', 'run_line_magic', 'getcwd', 'read_csv', 'head', 'tail', 'describe', 'heatmap', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'groupby', 'mean', 'fillna', 'astype', 'cut', 'sort_values', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'isna', 'sum', 'LogisticRegression', 'fit', 'predict', 'round', 'RandomForestClassifier', 'DataFrame', 'to_csv', 'score', 'GradientBoostingClassifier']",39,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic getcwd read csv read csv head head tail describe describe heatmap facetgrid map facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head fillna fillna cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna fillna head qcut groupby mean sort values astype drop head drop drop copy isna sum logisticregression fit predict round randomforestclassifier fit predict round dataframe csv randomforestclassifier fit predict score round gradientboostingclassifier fit predict score,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.11978321511528019, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13906742891013807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057670576315845726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07198570938911829, 0.08351784589012302, 0.0, 0.0, 0.0, 0.06907296166120006, 0.0, 0.0, 0.0, 0.03488132066097946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09956208392817811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35627659315926763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06318443818283612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19360754621269047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21744368861477636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12272025020897583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03655262045743417, 0.13287729660582911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08647760873827821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2895437941658977, 0.0, 0.0, 0.0, 0.0, 0.3317326264846291, 0.06695781439406664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04612764817074053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09540765275524898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10685302076716613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046818253333899024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08757973927460863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04658599923119491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04658599923119491, 0.0, 0.0, 0.29253190458824024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3002636963304214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08157696785122771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06907296166120006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12732476983088195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059396200044228784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0707810196737166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09003210878670383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05545483866424399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2199105686953476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2055832776957289, 0.0, 0.04635580963671269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09363650666779805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2292729687548512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0492631015215964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08248569824393205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2292729687548512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0591299009134263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mayurrathod1124_titanic-project.py,"['numpy', 'pandas', 'os\n', 'warnings\n', 'seaborn', 'matplotlib', 'sklearn', 'IterativeImputer\n']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,346,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'display', 'display', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'train.drop', 'test.drop', 'get_ipython', 'None.run_line_magic', 'train.apply', 'test.apply', 'sns.catplot', 'sns.FacetGrid', 'g.map', 'train.head', 'train.corr', 'train.drop', 'test.drop', 'print', 'print', 'train.value_counts', 'train.drop', 'train_test_split', 'print', 'print', 'make_column_transformer', 'make_pipeline', 'log_model.fit', 'log_model.predict', 'accuracy_score', 'cross_val_score', 'print', 'make_pipeline', 'rf_model.fit', 'rf_model.predict', 'print', 'accuracy_score', 'print', 'cross_val_score', 'print', 'make_pipeline', 'svc_model.fit', 'svc_model.predict', 'print', 'accuracy_score', 'print', 'cross_val_score', 'print', 'make_pipeline', 'knn_model.fit', 'knn_model.predict', 'print', 'accuracy_score', 'print', 'cross_val_score', 'print', 'pd.DataFrame', 'models.sort_values', 'models.sort_values', 'test.head', 'test.drop', 'x_test.head', 'pd.read_csv', 'sub_data.head', 'svc_model.predict', 'print', 'accuracy_score', 'print', 'pd.DataFrame', 'df.to_csv', 'pd.set_option', 'pd.read_csv']","['walk', 'print', 'filterwarnings', 'read_csv', 'read_csv', 'display', 'display', 'isnull', 'sum', 'isnull', 'sum', 'drop', 'drop', 'get_ipython', 'run_line_magic', 'apply', 'apply', 'catplot', 'FacetGrid', 'map', 'head', 'corr', 'drop', 'drop', 'print', 'print', 'value_counts', 'drop', 'train_test_split', 'print', 'print', 'make_column_transformer', 'make_pipeline', 'fit', 'predict', 'accuracy_score', 'cross_val_score', 'print', 'make_pipeline', 'fit', 'predict', 'print', 'accuracy_score', 'print', 'cross_val_score', 'print', 'make_pipeline', 'fit', 'predict', 'print', 'accuracy_score', 'print', 'cross_val_score', 'print', 'make_pipeline', 'fit', 'predict', 'print', 'accuracy_score', 'print', 'cross_val_score', 'print', 'DataFrame', 'sort_values', 'sort_values', 'head', 'drop', 'head', 'read_csv', 'head', 'predict', 'print', 'accuracy_score', 'print', 'DataFrame', 'to_csv', 'set_option', 'read_csv']","['walk', 'print', 'filterwarnings', 'read_csv', 'display', 'isnull', 'sum', 'drop', 'get_ipython', 'run_line_magic', 'apply', 'catplot', 'FacetGrid', 'map', 'head', 'corr', 'value_counts', 'train_test_split', 'make_column_transformer', 'make_pipeline', 'fit', 'predict', 'accuracy_score', 'cross_val_score', 'DataFrame', 'sort_values', 'to_csv', 'set_option']",28,"[1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print filterwarnings read csv read csv display display isnull sum isnull sum drop drop get ipython run line magic apply apply catplot facetgrid map head corr drop drop print print value counts drop train test split print print make column transformer make pipeline fit predict accuracy score cross val score print make pipeline fit predict print accuracy score print cross val score print make pipeline fit predict print accuracy score print cross val score print make pipeline fit predict print accuracy score print cross val score print dataframe sort values sort values head drop head read csv head predict print accuracy score print dataframe csv set option read csv,"[0.0, 0.0, 0.2917721912251202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08191873043446195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07786646156173344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10301815582574822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055337225795841154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0489861282909049, 0.0, 0.0, 0.24260580928708408, 0.0, 0.0, 0.10791728762692283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054086129369718614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1654165336286919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16573015193118265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050033860496990115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057819020441308676, 0.0, 0.0, 0.0, 0.09514352099219694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02833880313876129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10287531212816403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03576220594873373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07678571491945756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03629762375244909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03611755996461845, 0.4455092764668827, 0.0, 0.03779940604434832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07935432567091541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3564074211735062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12339168648412199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3914178024181342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08598692713852521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03593909676496305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3266786137720418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03879846676534699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08887627542530475, 0.0, 0.0, 0.0, 0.03760542407380043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07638616977685925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03921243973605828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03859463782919606, 0.0, 0.0, 0.0, 0.0, 0.11693445635811989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24260580928708408, 0.0, 0.0, 0.0489861282909049, 0.08887627542530475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04584269474062418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
jandersonff_titanic-xgboost-jj.py,"['pandas', 'numpy', 'matplotlib', 'subprocess', 'xgboost', 'sklearn']","[1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,111,"['# Correct the age colums', '# plots a bar graph of those who surived vs those who did not.               ', '# convert str features to Number ', '#    print(joined_df[f], le.fit_transform(joined_df[f]))', '#    joined_df[f] = le.fit_transform(joined_df[f])', '    381             # Python 3 and no explicit encoding', '    384             # Python 3 and binary mode']",7,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.Age.mean', 'np.mean', 'plt.figure', 'plt.subplots', 'train.Survivedtrain.Parch.value_counts', 'None.plot', 'train.Survivedtrain.Parch.value_counts', 'None.plot', 'train.withparttrain.Survived.value_counts', 'None.plot', 'trainfeatures.append', 'joined_df.map', 'None.astype', 'joined_dftrain.shape.as_matrix', 'joined_dftrain.shape.as_matrix', 'xgb.XGBClassifier', 'None.fit', 'gbm.predict', 'pd.DataFrame', 'submission.to_csv', 'print']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'Age', 'mean', 'figure', 'subplots', 'Survivedtrain', 'plot', 'Survivedtrain', 'plot', 'withparttrain', 'plot', 'append', 'map', 'astype', 'shape', 'shape', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['get_ipython', 'run_line_magic', 'read_csv', 'Age', 'mean', 'figure', 'subplots', 'Survivedtrain', 'plot', 'withparttrain', 'append', 'map', 'astype', 'shape', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']",20,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv age mean figure subplots survivedtrain plot survivedtrain plot withparttrain plot append map astype shape shape xgbclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12689079295458025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12351110744587515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09374024840176963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1688889414525613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07053665309627995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12433580086761749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062040911531215936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07391633860498507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0932788625978422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09467539735905908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09420573546661376, 0.0, 0.0, 0.09859250874359604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10119836722599865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3241156433581358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06436871475863742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060055196855602226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11214021267680163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09374024840176963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.514035550417327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13050373920526004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5675363102019242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30500112613910646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15663438464582397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sharma98_titanic-top-4.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,342,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",8,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'titanic_train.head', 'titanic_train.describe', 'titanic_train.isnull', 'None.sum', 'titanic_train.Name.value_counts', 'titanic_train.Ticket.value_counts', 'titanic_train.Cabin.value_counts', 'titanic_train.drop', 'new_train.fillna', 'new_train.isnull', 'None.sum', 'new_train.family_size.value_counts', 'pd.qcut', 'pd.qcut', 'new_train.drop', 'new_train.dropna', 'new_train.drop', 'categorical_features.columns.tolist', 'pd.get_dummies', 'encoded_features.drop', 'new_train.drop', 'pd.concat', 'X.drop', 'X_train.isnull', 'None.sum', 'RandomForestClassifier', 'classifier.fit', 'classifier.predict', 'cross_val_score', 'X.corr', 'corr_matrix.sort_values', 'confusion_matrix', 'accuracy_score', 'classification_report', 'print', 'titanic_test.replace', 'titanic_test.drop', 'new_test.fillna', 'new_test.isnull', 'None.sum', 'new_test.fillna', 'new_test.isnull', 'None.sum', 'new_test.family_size.value_counts', 'pd.qcut', 'pd.qcut', 'new_test.drop', 'titanic_test.Parch.value_counts', 'new_test.drop', 'categorical_features_test.columns.tolist', 'pd.get_dummies', 'encoded_features_test.drop', 'new_test.drop', 'pd.concat', 'X_test.drop', 'titanic_test.Parch.value_counts', 'classifier.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'head', 'describe', 'isnull', 'sum', 'Name', 'Ticket', 'Cabin', 'drop', 'fillna', 'isnull', 'sum', 'family_size', 'qcut', 'qcut', 'drop', 'dropna', 'drop', 'columns', 'get_dummies', 'drop', 'drop', 'concat', 'drop', 'isnull', 'sum', 'RandomForestClassifier', 'fit', 'predict', 'cross_val_score', 'corr', 'sort_values', 'confusion_matrix', 'accuracy_score', 'classification_report', 'print', 'replace', 'drop', 'fillna', 'isnull', 'sum', 'fillna', 'isnull', 'sum', 'family_size', 'qcut', 'qcut', 'drop', 'Parch', 'drop', 'columns', 'get_dummies', 'drop', 'drop', 'concat', 'drop', 'Parch', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'describe', 'isnull', 'sum', 'Name', 'Ticket', 'Cabin', 'drop', 'fillna', 'family_size', 'qcut', 'dropna', 'columns', 'get_dummies', 'concat', 'RandomForestClassifier', 'fit', 'predict', 'cross_val_score', 'corr', 'sort_values', 'confusion_matrix', 'accuracy_score', 'classification_report', 'replace', 'Parch', 'DataFrame', 'to_csv']",31,"[1 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv head describe isnull sum name ticket cabin drop fillna isnull sum family size qcut qcut drop dropna drop columns get dummies drop drop concat drop isnull sum randomforestclassifier fit predict cross val score corr sort values confusion matrix accuracy score classification report print replace drop fillna isnull sum fillna isnull sum family size qcut qcut drop parch drop columns get dummies drop drop concat drop parch predict dataframe csv print,"[0.0, 0.0, 0.08470736391324857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09498990609591892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13772448469111764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24011881414261657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1223229142870035, 0.0, 0.0, 0.09613294522687932, 0.0, 0.0, 0.0, 0.0, 0.08032757514956677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08804171196224983, 0.0, 0.0, 0.125322278551095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03925574113097101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05602401685319134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48114812560053216, 0.0682857470518127, 0.0, 0.0, 0.1132376163028055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29908252663018353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12235650756730039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03452760877773107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08227327286611855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03733347781337139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2786555612835534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09081940916192707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07773531078354004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2860760415121398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07164620073621404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10026749886112864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3186302964045586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05066145846880076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09361403538392561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06187231584902652, 0.0, 0.12934034683000745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10537933760838017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20242851770345177, 0.0, 0.0, 0.0, 0.06450644742816425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2772056109108098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11752356820603331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08804171196224983, 0.0, 0.0, 0.0, 0.06450644742816425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06654530388678954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
xupanda_titanic-random-forest-82-78.py,"['os\n', 'pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,605,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.info', 'train.head', 'train.value_counts', 'sns.countplot', 'train.groupby', 'None.mean', 'sns.countplot', 'train.head', 'train.apply', 'None.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.head', 'train.apply', 'train.value_counts', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'pd.crosstab', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.replace', 'train.apply', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.corr', 'train.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'sns.countplot', 'i.apply', 'i.apply', 'None.apply', 'i.apply', 'train.groupby', 'data.transform', 'np.where', 'i.apply', 'i.apply', 'np.where', 'i.apply', 'i.apply', 'i.apply', 'i.replace', 'i.apply', 'pd.qcut', 'pd.concat', 'pd.concat', 'i.fillna', 'test.fillna', 'traincolumn.apply', 'testcolumn.apply', 'traincolumn.unique', 'testcolumn.unique', 'pd.concat', 'pd.concat', 'pd.read_csv', 'pd.read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'test.fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'rf.fit', 'print', 'pd.concat', 'None.sort_values', 'rf.predict', 'pd.DataFrame', 'pd.read_csv', 'pd.concat', 'predictions.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'countplot', 'head', 'apply', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'groupby', 'mean', 'qcut', 'value_counts', 'value_counts', 'groupby', 'mean', 'groupby', 'mean', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'value_counts', 'groupby', 'mean', 'value_counts', 'head', 'apply', 'value_counts', 'apply', 'value_counts', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'crosstab', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'replace', 'apply', 'qcut', 'value_counts', 'groupby', 'mean', 'corr', 'value_counts', 'value_counts', 'groupby', 'mean', 'countplot', 'apply', 'apply', 'apply', 'apply', 'groupby', 'transform', 'where', 'apply', 'apply', 'where', 'apply', 'apply', 'apply', 'replace', 'apply', 'qcut', 'concat', 'concat', 'fillna', 'fillna', 'apply', 'apply', 'unique', 'unique', 'concat', 'concat', 'read_csv', 'read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'print', 'concat', 'sort_values', 'predict', 'DataFrame', 'read_csv', 'concat', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'apply', 'qcut', 'crosstab', 'replace', 'corr', 'transform', 'where', 'concat', 'fillna', 'unique', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'sort_values', 'predict', 'DataFrame', 'to_csv']",35,"[1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv info head value counts countplot groupby mean countplot head apply apply value counts groupby mean apply groupby mean qcut value counts value counts groupby mean groupby mean groupby mean qcut value counts groupby mean value counts groupby mean value counts head apply value counts apply value counts groupby mean qcut value counts groupby mean crosstab apply value counts groupby mean apply replace apply qcut value counts groupby mean corr value counts value counts groupby mean countplot apply apply apply apply groupby transform apply apply apply apply apply replace apply qcut concat concat fillna fillna apply apply unique unique concat concat read csv read csv names age impute cabin num cabin embarked impute fam size fillna ticket grouped dummies drop print randomforestclassifier fit print concat sort values predict dataframe read csv concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030776142480056994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5182343878545368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279482535978527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599281135565975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03500744357704521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09107902693483415, 0.43385455930515493, 0.0, 0.0, 0.0, 0.0, 0.03530630678951032, 0.08192477963803933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017107987389869215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01747403867621555, 0.0, 0.0, 0.0, 0.024674960349160606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03098961137893964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06233719157670034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053324011424110244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015047426912689897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017927697633077517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33135768561103374, 0.06233719157670034, 0.0, 0.0, 0.0, 0.04881074583614578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12004301432041745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022512964417251976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022623891764286017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0229626078506844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02284869587186554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3190809896266202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06002150716020872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05636762824542156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015612013216585905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029131621799502194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1735772569779223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022078696457289073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06799632744671416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392896778056414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022735796457363545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044110038792367946, 0.0, 0.0, 0.0, 0.02811246093875487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0512177751573511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027773744852356484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279482535978527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43385455930515493, 0.02811246093875487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
parlads_gettingstartedwithtitanicstastices.py,"['numpy', 'pandas', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,85,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', ' #   for filename in filenames:', '  #      print(os.path.join(dirname, filename))', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",11,"['pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['read_csv', 'head', 'read_csv', 'head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['read_csv', 'head', 'sum', 'len', 'print', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",11,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv head read csv head sum len print sum len print get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31642576438630055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13215557028943178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38121765962294935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11623817809292172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27697531576143714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25136843219201777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4925522802810271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1205994874198834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3375533899430837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17055324247480638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21010287713045006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37328823292494784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
bilalyussef_tba-titanic.py,"['pandas', 'numpy', 'random', 'scipy', 'collections', 'sklearn', 'matplotlib', 'seaborn', 'IPython', 'warnings\n']","[1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",10,413,"['# General Libraries', '# Cleaning and preprocessing', '# visiualization Libraries', ""plt.style.use('bmh')                    # Use bmh's style for plotting"", ""sns.set_style({'axes.grid':False})      # Remove gridlines"", '# modeling ', '# Classification libraries and evaluation', '# Regression Libraries', '# Other models', '# To ignore unwanted warnings', '# train data ', '# test data', ""def impute_age(age_pclass): # passing age_pclass as ['Age', 'Pclass']"", ""    # Passing age_pclass[0] which is 'Age' to variable 'Age'"", ""    # Passing age_pclass[2] which is 'Pclass' to variable 'Pclass'"", '# (for train) grab age and apply the impute_age, our custom function', '# (for test) grab age and apply the impute_age, our custom function ', '# train data ', '# test data', ""et = ExtraTreesClassifier(n_estimators=100) # bootstrap=False by default #max_features='auto',""]",20,"['get_ipython', 'None.run_line_magic', 'sns.set', 'plt.style.use', 'sns.set_style', 'display', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'train.head', 'test.head', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'plt.subplots', 'sns.heatmap', 'ax.set_title', 'sns.heatmap', 'ax.set_title', 'train.Embarked.value_counts', 'train.Embarked.fillna', 'traintrain.mean', 'test.Fare.fillna', 'train.groupby', 'None.mean', 'pd.isnull', 'train.apply', 'test.apply', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'train.apply', 'train.isnull', 'None.sum', 'test.apply', 'test.isnull', 'None.sum', 'plt.subplots', 'sns.heatmap', 'ax.set_title', 'sns.heatmap', 'ax.set_title', 'pd.get_dummies', 'pd.get_dummies', 'KNeighborsClassifier', 'cross_val_score', 'None.mean', 'print', 'print', 'print', 'GridSearchCV', 'knn_gridsearch.fit', 'pd.read_csv', 'y_test.drop', 'best_knn.score', 'best_knn.predict', 'save_file.to_csv', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'rf.score', 'save_file.to_csv', 'ExtraTreesClassifier', 'et.fit', 'rf.predict', 'save_file.to_csv', 'RandomForestClassifier', 'GridSearchCV', 'gs.fit', 'gs.score', 'gs.predict', 'save_file.to_csv']","['get_ipython', 'run_line_magic', 'set', 'style', 'set_style', 'display', 'filterwarnings', 'read_csv', 'read_csv', 'head', 'head', 'isnull', 'sum', 'isnull', 'sum', 'subplots', 'heatmap', 'set_title', 'heatmap', 'set_title', 'Embarked', 'Embarked', 'mean', 'Fare', 'groupby', 'mean', 'isnull', 'apply', 'apply', 'isnull', 'sum', 'isnull', 'sum', 'apply', 'isnull', 'sum', 'apply', 'isnull', 'sum', 'subplots', 'heatmap', 'set_title', 'heatmap', 'set_title', 'get_dummies', 'get_dummies', 'KNeighborsClassifier', 'cross_val_score', 'mean', 'print', 'print', 'print', 'GridSearchCV', 'fit', 'read_csv', 'drop', 'score', 'predict', 'to_csv', 'RandomForestClassifier', 'fit', 'predict', 'score', 'to_csv', 'ExtraTreesClassifier', 'fit', 'predict', 'to_csv', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'score', 'predict', 'to_csv']","['get_ipython', 'run_line_magic', 'set', 'style', 'set_style', 'display', 'filterwarnings', 'read_csv', 'head', 'isnull', 'sum', 'subplots', 'heatmap', 'set_title', 'Embarked', 'mean', 'Fare', 'groupby', 'apply', 'get_dummies', 'KNeighborsClassifier', 'cross_val_score', 'print', 'GridSearchCV', 'fit', 'drop', 'score', 'predict', 'to_csv', 'RandomForestClassifier', 'ExtraTreesClassifier']",31,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic set style set style display filterwarnings read csv read csv head head isnull sum isnull sum subplots heatmap set title heatmap set title embarked embarked mean fare groupby mean isnull apply apply isnull sum isnull sum apply isnull sum apply isnull sum subplots heatmap set title heatmap set title get dummies get dummies kneighborsclassifier cross val score mean print print print gridsearchcv fit read csv drop score predict csv randomforestclassifier fit predict score csv extratreesclassifier fit predict csv randomforestclassifier gridsearchcv fit score predict csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24044461249540164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08901087012364503, 0.0, 0.0, 0.22172818337362807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12138101420072575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04053704806840836, 0.0, 0.0, 0.0, 0.11448412954716243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14378214325452543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1307641180168028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08991754396555258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0848540491969447, 0.0, 0.0, 0.0, 0.13963074693106456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12476839856669254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1681773850639572, 0.0, 0.0, 0.05490701572586605, 0.0, 0.0, 0.0, 0.0, 0.07548888523055625, 0.3047376328126584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05248390511986398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39441218021053037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07090882817503961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05326967368374861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05300541563519382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17081958406825587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1448697560837567, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1013712377898493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10243827384852291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09464453336484144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05274350657814269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21307869473499444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34163916813651174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15718203333305672, 0.0, 0.0, 0.0, 0.0, 0.14685740532163788, 0.33630848942475156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2377959999165763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08901087012364503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
xaxetrov_ml-training-our-first-challenge-titanic.py,"['matplotlib', 'numpy', 'os\n', 'pandas', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,119,"['# Any results you write to the current directory are saved as output.', '# Load test & train data', '# Lets understand  the csv files', '# y histogram', '# Fare histogram -> check split', ""sns.distplot(X['Fare'], kde = False, ax=ax) # sns.distplot(X['Fare'], hist = False, ax=ax)"", ""sns.distplot(train_X['Fare'], kde = False, ax=ax) # sns.distplot(train_X['Fare'], hist = False, ax=ax)"", 'print(""Skewness: %f"" % X[\'Fare\'].skew())  #  third standardized moment', 'print(""Kurtosis: %f"" % X[\'Fare\'].kurt())  #  fourth standardized moment', '# Relation between class and survival']",10,"['print', 'pd.read_csv', 'pd.read_csv', 'train.head', 'train.describe', 'train.describe', 'pd.get_dummies', 'train_test_split', 'X.describe', 'sns.distplot', 'plt.show', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'plt.show', 'print', 'print', 'train.corr', 'plt.subplots', 'sns.heatmap', 'sns.barplot', 'plt.show', 'LogisticRegression', 'model.fit', 'model.predict', 'print']","['print', 'read_csv', 'read_csv', 'head', 'describe', 'describe', 'get_dummies', 'train_test_split', 'describe', 'distplot', 'show', 'subplots', 'distplot', 'distplot', 'show', 'print', 'print', 'corr', 'subplots', 'heatmap', 'barplot', 'show', 'LogisticRegression', 'fit', 'predict', 'print']","['print', 'read_csv', 'head', 'describe', 'get_dummies', 'train_test_split', 'distplot', 'show', 'subplots', 'corr', 'heatmap', 'barplot', 'LogisticRegression', 'fit', 'predict']",15,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv head describe describe get dummies train test split describe distplot show subplots distplot distplot show print print corr subplots heatmap barplot show logisticregression fit predict print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17038290771001838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17038290771001838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1329106112105489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3564978106933418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5440998034891499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12009421603913209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07323654882983856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08725496463479787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07918808071730997, 0.15983537305570666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11120569919544335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07598441746238649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28357000233872476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1323765553857281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43452291879252913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11578682174999783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3081077705950083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12073481105255537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11883260356444726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ashithjake_titanic-survival-prediction-improved-model.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,473,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# Import Data', ' #   Column       Non-Null Count  Dtype  ', '# Explore Training Data', '# Data Cleaning', '# Feature Engineering', '# Only training data should used. Test data should not be introduced', '# Function to replace missing age values based of the mean age', '# Fill the missing age values based of the mean age in the training data', '# Convert categorical features into dummy variables', '# Function to map name title to Mr,Mrs,Miss or Others', '# Model Selection']",20,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train_data.head', 'test_data.head', 'train_data.info', 'train_data.describe', 'sns.countplot', 'sns.countplot', 'train_data.hist', 'sns.countplot', 'sns.countplot', 'train_data.hist', 'sns.heatmap', 'sns.countplot', 'plt.figure', 'sns.heatmap', 'plt.figure', 'sns.heatmap', 'train_data.drop', 'test_data.drop', 'plt.figure', 'sns.heatmap', 'plt.figure', 'sns.heatmap', 'sns.boxplot', 'pd.isnull', 'train_data.apply', 'test_data.apply', 'train_data.dropna', 'test_data.fillna', 'plt.figure', 'sns.heatmap', 'plt.figure', 'sns.heatmap', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'pd.concat', 'train_data.head', 'test_data.head', 'train_data.apply', 'test_data.apply', 'train_data.value_counts', 'train_data.apply', 'test_data.apply', 'train_data.drop', 'test_data.drop', 'train_data.head', 'test_data.head', 'train_data.apply', 'test_data.apply', 'train_data.drop', 'test_data.drop', 'train_data.head', 'test_data.head', 'train_data.drop', 'StandardScaler', 'scaler.fit_transform', 'scaler.transform', 'KFold', 'KNeighborsClassifier', 'cross_val_score', 'print', 'print', 'DecisionTreeClassifier', 'cross_val_score', 'print', 'print', 'RandomForestClassifier', 'cross_val_score', 'print', 'print', 'GaussianNB', 'cross_val_score', 'print', 'print', 'SVC', 'cross_val_score', 'print', 'print', 'SVC', 'svc_model.fit', 'svc_model.predict', 'pd.DataFrame', 'output.to_csv', 'print', 'RandomForestClassifier', 'RandForesClass_model.fit', 'RandForesClass_model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'head', 'info', 'describe', 'countplot', 'countplot', 'hist', 'countplot', 'countplot', 'hist', 'heatmap', 'countplot', 'figure', 'heatmap', 'figure', 'heatmap', 'drop', 'drop', 'figure', 'heatmap', 'figure', 'heatmap', 'boxplot', 'isnull', 'apply', 'apply', 'dropna', 'fillna', 'figure', 'heatmap', 'figure', 'heatmap', 'get_dummies', 'get_dummies', 'concat', 'concat', 'head', 'head', 'apply', 'apply', 'value_counts', 'apply', 'apply', 'drop', 'drop', 'head', 'head', 'apply', 'apply', 'drop', 'drop', 'head', 'head', 'drop', 'StandardScaler', 'fit_transform', 'transform', 'KFold', 'KNeighborsClassifier', 'cross_val_score', 'print', 'print', 'DecisionTreeClassifier', 'cross_val_score', 'print', 'print', 'RandomForestClassifier', 'cross_val_score', 'print', 'print', 'GaussianNB', 'cross_val_score', 'print', 'print', 'SVC', 'cross_val_score', 'print', 'print', 'SVC', 'fit', 'predict', 'DataFrame', 'to_csv', 'print', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'describe', 'countplot', 'hist', 'heatmap', 'figure', 'drop', 'boxplot', 'isnull', 'apply', 'dropna', 'fillna', 'get_dummies', 'concat', 'value_counts', 'StandardScaler', 'fit_transform', 'transform', 'KFold', 'KNeighborsClassifier', 'cross_val_score', 'DecisionTreeClassifier', 'RandomForestClassifier', 'GaussianNB', 'SVC', 'fit', 'predict', 'DataFrame', 'to_csv']",35,"[1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic read csv read csv head head info describe countplot countplot hist countplot countplot hist heatmap countplot figure heatmap figure heatmap drop drop figure heatmap figure heatmap boxplot isnull apply apply dropna fillna figure heatmap figure heatmap get dummies get dummies concat concat head head apply apply value counts apply apply drop drop head head apply apply drop drop head head drop standardscaler fit transform transform kfold kneighborsclassifier cross val score print print decisiontreeclassifier cross val score print print randomforestclassifier cross val score print print gaussiannb cross val score print print svc cross val score print print svc fit predict dataframe csv print randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3498971991382561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06542441616889949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08998244859271635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2562249274621127, 0.05230827246318118, 0.0, 0.0, 0.3238235806772142, 0.0, 0.0, 0.09218882294438696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05775414571956255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050564339136398746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04121205128110145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20646459081128588, 0.05023195171174734, 0.0, 0.0, 0.08329917617742315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3054117673402458, 0.0, 0.0, 0.0, 0.030002386760032407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07619697748327044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06231192302093675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09078205734446686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21970423237281758, 0.3880248665201819, 0.0, 0.10921492428111479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038000291849152365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038187529366310057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04099658655849393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07445462607771568, 0.051593587635690344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03875925816659537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038566982802054124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05270394849720143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31961876340982115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07453455648718539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04590919684776131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837641657447253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19379629083297684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0707167406234954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09852926915587464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0937602343763014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3238235806772142, 0.0, 0.0, 0.05230827246318118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04895165734876485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
samuelhei_titanic-logistic-regression.py,"['numpy', 'pandas', 'sklearn', 'os\n', 're\n']","[1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,163,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'df.describe', 'list', 'x_columns.remove', 'train_test_split', 'df.copy', 'new_df.replace', 'new_df.apply', 'None.astype', 'new_df.apply', 'new_df.apply', 'new_df.apply', 'None.astype', 'new_df.apply', 'new_df.apply', 'new_df.astype', 'new_df.astype', 'new_df.astype', 'new_df.fillna', 'new_df.apply', 'new_df.apply', 'new_df.apply', 'new_df.apply', 'new_df.drop', 'pd.get_dummies', 'transform', 'transform', 'transform', 'intersection', 'GridSearchCV', 'grid.fit', 'grid.predict', 'print', 'get_ipython', 'None.system', 'pd.read_csv', 'transform', 'result_transfcolumns.fillna', 'result_transf.describe', 'grid.predict', 'result.to_csv']","['print', 'read_csv', 'describe', 'list', 'remove', 'train_test_split', 'copy', 'replace', 'apply', 'astype', 'apply', 'apply', 'apply', 'astype', 'apply', 'apply', 'astype', 'astype', 'astype', 'fillna', 'apply', 'apply', 'apply', 'apply', 'drop', 'get_dummies', 'transform', 'transform', 'transform', 'intersection', 'GridSearchCV', 'fit', 'predict', 'print', 'get_ipython', 'system', 'read_csv', 'transform', 'fillna', 'describe', 'predict', 'to_csv']","['print', 'read_csv', 'describe', 'list', 'remove', 'train_test_split', 'copy', 'replace', 'apply', 'astype', 'fillna', 'drop', 'get_dummies', 'transform', 'intersection', 'GridSearchCV', 'fit', 'predict', 'get_ipython', 'system', 'to_csv']",21,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv describe list remove train test split copy replace apply astype apply apply apply astype apply apply astype astype astype fillna apply apply apply apply drop get dummies transform transform transform intersection gridsearchcv fit predict print get ipython system read csv transform fillna describe predict csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7420070475955077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32553071736327926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.080997588979582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11729974947397145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13983367719093612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05003859316008107, 0.0, 0.0, 0.0, 0.0706591260916326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10179896255452445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04308975660074569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10267537857513763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10379837890194045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19708770281672652, 0.0, 0.0, 0.06478569360337452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10024718722355712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08941300774592771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08342120549972037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07788561370456278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18662446853751574, 0.0, 0.0, 0.07721539731933354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0681248099002255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17850855350882727, 0.0, 0.0, 0.0, 0.0, 0.07103602920420547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06991683859546806, 0.0, 0.0, 0.0, 0.3181311761866719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
dex314_auto-feateng-for-titanic-data-forked.py,"['pandas', 'featuretools', 'LinearSVC\n', 'sklearn', 'RandomForestClassifier\n', 'lightgbm', 'seaborn', 'matplotlib', 'warnings\n', 'os\n', 'collections']","[1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",11,479,"['# Input data files are available in the ""../input/"" directory.', '# train_df.Cabin.value_counts()', '# Threshold for removing correlated variables', '# Absolute value correlation matrix', '# Select columns with correlations above threshold', '# features_positive = features_filtered.loc[:, features_filtered.ge(0).all()]', '# train_X = features_positive[:train_df.shape[0]]', ""# train_y = train_df['Survived']"", '# test_X = features_positive[train_df.shape[0]:]', '# lsvc = LinearSVC(C=0.01, penalty=""l1"", dual=False).fit(train_X, train_y)', '# model = SelectFromModel(lsvc, prefit=True)', '# X_new = model.transform(train_X)', '# X_selected_df = pd.DataFrame(X_new, columns=[train_X.columns[i] for i in range(len(train_X.columns)) if model.get_support()[i]])', '# X_selected_df.shape', '# X_selected_df.columns', '# features.head()', '# random_forest = RandomForestClassifier(n_estimators=2000,oob_score=True)', '# random_forest.fit(X_selected_df, train_y)', '# X_selected_df.shape', '# Y_pred = random_forest.predict(test_X[X_selected_df.columns])', '# print(Y_pred)']",21,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.drop', 'None.isnull', 'None.sum', 'len', 'str', 'Counter', 'str', 'None.upper', 'str', 'None.upper', 'train_df.head', 'train_df.append', 'combine.drop', 'combine.Fare.fillna', 'combine.Sex.apply', 'combine.str.extract', 'combine.replace', 'combine.drop', 'combine.groupby', 'None.median', 'titles.index', 'combine.isnull', 'combine.isnull', 'None.sum', 'train_df.Embarked.dropna', 'None.mode', 'combine.fillna', 'combine.map', 'None.astype', 'combine.map', 'None.astype', 'combine.fillna', 'combine.replace', 'combine.info', 'Counter', 'ft.EntitySet', 'es.entity_from_dataframe', 'es.normalize_entity', 'es.normalize_entity', 'es.normalize_entity', 'es.normalize_entity', 'es.normalize_entity', 'es.normalize_entity', 'es.normalize_entity', 'ft.list_primitives', 'primitivesprimitives.head', 'primitivesprimitives.head', 'ft.dfs', 'len', 'featuresfeatures.head', 'features.corr', 'None.abs', 'corr_matrix.where', 'upper.head', 'any', 'print', 'features.drop', 'print', 'featurestrain_df.shape.drop', 'featurestrain_df.shape.drop', 'train_y.head', 'train_X.head', 'range', 'print', 'train_test_split', 'lgb.Dataset', 'lgb.Dataset', 'lgb.train', 'model.predict', 'model.predict', 'print', 'print', 'print', 'print', 'pd.DataFrame', 'print', 'my_submission.to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'print', 'read_csv', 'read_csv', 'read_csv', 'print', 'drop', 'isnull', 'sum', 'len', 'str', 'Counter', 'str', 'upper', 'str', 'upper', 'head', 'append', 'drop', 'Fare', 'Sex', 'str', 'replace', 'drop', 'groupby', 'median', 'index', 'isnull', 'isnull', 'sum', 'Embarked', 'mode', 'fillna', 'map', 'astype', 'map', 'astype', 'fillna', 'replace', 'info', 'Counter', 'EntitySet', 'entity_from_dataframe', 'normalize_entity', 'normalize_entity', 'normalize_entity', 'normalize_entity', 'normalize_entity', 'normalize_entity', 'normalize_entity', 'list_primitives', 'head', 'head', 'dfs', 'len', 'head', 'corr', 'abs', 'where', 'head', 'any', 'print', 'drop', 'print', 'shape', 'shape', 'head', 'head', 'range', 'print', 'train_test_split', 'Dataset', 'Dataset', 'train', 'predict', 'predict', 'print', 'print', 'print', 'print', 'DataFrame', 'print', 'to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'print', 'read_csv', 'drop', 'isnull', 'sum', 'len', 'str', 'Counter', 'upper', 'head', 'append', 'Fare', 'Sex', 'replace', 'groupby', 'median', 'index', 'Embarked', 'mode', 'fillna', 'map', 'astype', 'info', 'EntitySet', 'entity_from_dataframe', 'normalize_entity', 'list_primitives', 'dfs', 'corr', 'abs', 'where', 'any', 'shape', 'range', 'train_test_split', 'Dataset', 'train', 'predict', 'DataFrame', 'to_csv']",43,"[1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings print read csv read csv read csv print drop isnull sum len str counter str upper str upper head append drop fare sex str replace drop groupby median index isnull isnull sum embarked mode fillna map astype map astype fillna replace info counter entityset entity dataframe normalize entity normalize entity normalize entity normalize entity normalize entity normalize entity normalize entity list primitives head head dfs len head corr abs head print drop print shape shape head head range print train test split dataset dataset train predict predict print print print print dataframe print csv,"[0.0, 0.0661478433134082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03412727717123869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05180261930223338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03988154265382572, 0.0, 0.0, 0.0, 0.0, 0.11921570781122305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06222079763025288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038979877368570226, 0.0, 0.0, 0.136756646779337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0842746711978967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07962782169641783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03530430622032245, 0.0, 0.0, 0.0, 0.6741973695831736, 0.0842746711978967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04415675597657029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04049888859404763, 0.0, 0.04167017223522928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02042377748220653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026963766890003207, 0.0, 0.0, 0.0, 0.0, 0.12974892862633114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04167017223522928, 0.0, 0.0, 0.025647452625173334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025773824427001067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08300920548663457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07264025058086948, 0.0, 0.0, 0.0, 0.0, 0.02615970007706115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03988154265382572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02602992809208179, 0.0, 0.0, 0.054484069368011236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038905702435018515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04558113257589259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5488546153650007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035571358967647, 0.0, 0.0, 0.0, 0.0, 0.0842746711978967, 0.1659381403864893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035061115969160096, 0.0, 0.0, 0.0, 0.046478088479693334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06143751754063092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02590130965111669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05169965104056088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14203284277610304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027102231863730154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1731181970559837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05505151811110734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02826040816834207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055630316578310204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1484903847851302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
carlesorf_titanic-deep-in-the-sea-compare-models-and-keras.py,"['pandas', 'numpy', 'sklearn', 'matplotlib', 'seaborn', 'random,', 'warnings\n', 'keras']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,671,"['# pandas to open data files & processing it.', '# numpy for numeric data processing', '# sklearn to do preprocessing & ML models', '# Matplotlob & seaborn to plot graphs & visulisation', '# to fix random seeds', '# ignore warnings', '# Merge both datasets to work with all data at once', 'SibSp : # of siblings / spouses aboard the Titanic of passenger', 'Parch : # of parents / children aboard the Titanic of passenger', '    # Add some random ""jitter"" to the x-axis', '# if total family size is 1, person is alone.', '# Explore Fare distribution ', '# Apply log to Fare to reduce skewness distribution', ""# Let's do another column with fare limited to 100, because it can be a problem with mean NaN values."", ""# let's see again the correlations to select features"", '# Train Random Forest', '# Predict labels on Validation data which model have never seen before.', '# Various hyper-parameters to tune', '# Root Mean Squared Error', '# evaluate predictions', '# Train Random Forest', '# Predict labels on Validation data which model have never seen before.', 'from keras.models import Sequential # intitialize the ANN', 'from keras.layers import Dense      # create layers', '# Initialising the NN', '# layers', '# Compiling the ANN', '# Train the ANN']",28,"['warnings.simplefilter', 'pd.read_csv', 'pd.read_csv', 'pd.concat', 'df.head', 'df.describe', 'None.round', 'df.isnull', 'None.sum', 'None.sort_values', 'df.isnull', 'None.sum', 'df.isnull', 'None.count', 'round', 'None.sort_values', 'pd.concat', 'missing_data.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'df.boxplot', 'df.Agedf.Pclassi.dropna', 'np.random.normal', 'plt.plot', 'sns.countplot', 'df.groupby', 'None.mean', 'None.sort_values', 'sns.countplot', 'df.groupby', 'None.mean', 'None.sort_values', 'df.map', 'None.astype', 'sns.barplot', 'plt.legend', 'sns.catplot', 'df.corr', 'corr.style.background_gradient', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'df.apply', 'sns.barplot', 'sns.barplot', 'df.str.extract', 'df.value_counts', 'df.apply', 'df.value_counts', 'sns.barplot', 'df.groupby', 'None.mean', 'None.round', 'a.unstack', 'None.plot', 'df.iloc.groupby', 'b.median', 'b_median.reset_index', 'b.head', 'df.iteritems', 'pd.isna', 'b.iteritems', 'sns.distplot', 'g.legend', 'df.map', 'sns.distplot', 'g.legend', 'df.apply', 'df.map', 'sns.distplot', 'g.legend', 'df.iteritems', 'pd.isna', 'int', 'int', 'df.fillna', 'df.fillna', 'df.fillna', 'preprocessing.LabelEncoder', 'le.fit_transform', 'le.fit_transform', 'le.fit_transform', 'train_df.astype', 'train_df.corr', 'None.round', 'corr.sort_values', 'train_test_split', 'len', 'len', 'RandomForestClassifier', 'model.fit', 'model.predict', 'accuracy_score', 'np.sqrt', 'print', 'print', 'print', 'plot_roc_curve', 'plt.show', 'pd.read_csv', 'model.predict', 'pd.DataFrame', 'submissionRF.to_csv', 'GridSearchCV', 'gs.fit', 'fitted_model.predict_proba', 'fitted_model.predict', 'RandomForestClassifier', 'algorithm_pipeline', 'print', 'np.sqrt', 'print', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LogisticRegression', 'pd.DataFrame', 'StratifiedShuffleSplit', 'sss.split', 'clf.fit', 'clf.predict', 'accuracy_score', 'pd.DataFrame', 'log.append', 'log.sort_values', 'GradientBoostingClassifier', 'model.fit', 'model.predict', 'accuracy_score', 'np.sqrt', 'print', 'print', 'print', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'keras.optimizers.Adam', 'model.compile', 'model.fit', 'model.predict', 'y_pred.astype', 'None.reshape', 'accuracy_score', 'model.predict', 'y_pred.astype', 'None.reshape']","['simplefilter', 'read_csv', 'read_csv', 'concat', 'head', 'describe', 'round', 'isnull', 'sum', 'sort_values', 'isnull', 'sum', 'isnull', 'count', 'round', 'sort_values', 'concat', 'head', 'FacetGrid', 'map', 'add_legend', 'boxplot', 'Agedf', 'random', 'plot', 'countplot', 'groupby', 'mean', 'sort_values', 'countplot', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'barplot', 'legend', 'catplot', 'corr', 'style', 'FacetGrid', 'map', 'FacetGrid', 'map', 'apply', 'barplot', 'barplot', 'str', 'value_counts', 'apply', 'value_counts', 'barplot', 'groupby', 'mean', 'round', 'unstack', 'plot', 'iloc', 'median', 'reset_index', 'head', 'iteritems', 'isna', 'iteritems', 'distplot', 'legend', 'map', 'distplot', 'legend', 'apply', 'map', 'distplot', 'legend', 'iteritems', 'isna', 'int', 'int', 'fillna', 'fillna', 'fillna', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'astype', 'corr', 'round', 'sort_values', 'train_test_split', 'len', 'len', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'sqrt', 'print', 'print', 'print', 'plot_roc_curve', 'show', 'read_csv', 'predict', 'DataFrame', 'to_csv', 'GridSearchCV', 'fit', 'predict_proba', 'predict', 'RandomForestClassifier', 'algorithm_pipeline', 'print', 'sqrt', 'print', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LogisticRegression', 'DataFrame', 'StratifiedShuffleSplit', 'split', 'fit', 'predict', 'accuracy_score', 'DataFrame', 'append', 'sort_values', 'GradientBoostingClassifier', 'fit', 'predict', 'accuracy_score', 'sqrt', 'print', 'print', 'print', 'Sequential', 'add', 'add', 'add', 'add', 'optimizers', 'compile', 'fit', 'predict', 'astype', 'reshape', 'accuracy_score', 'predict', 'astype', 'reshape']","['simplefilter', 'read_csv', 'concat', 'head', 'describe', 'round', 'isnull', 'sum', 'sort_values', 'count', 'FacetGrid', 'map', 'add_legend', 'boxplot', 'Agedf', 'random', 'plot', 'countplot', 'groupby', 'mean', 'astype', 'barplot', 'legend', 'catplot', 'corr', 'style', 'apply', 'str', 'value_counts', 'unstack', 'iloc', 'median', 'reset_index', 'iteritems', 'isna', 'distplot', 'int', 'fillna', 'LabelEncoder', 'fit_transform', 'train_test_split', 'len', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'sqrt', 'print', 'plot_roc_curve', 'show', 'DataFrame', 'to_csv', 'GridSearchCV', 'predict_proba', 'algorithm_pipeline', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LogisticRegression', 'StratifiedShuffleSplit', 'split', 'append', 'Sequential', 'add', 'optimizers', 'compile', 'reshape']",72,"[1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1
 1 0 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1
 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",simplefilter read csv read csv concat head describe round isnull sum sort values isnull sum isnull count round sort values concat head facetgrid map add legend boxplot agedf random plot countplot groupby mean sort values countplot groupby mean sort values map astype barplot legend catplot corr style facetgrid map facetgrid map apply barplot barplot str value counts apply value counts barplot groupby mean round unstack plot iloc median reset index head iteritems isna iteritems distplot legend map distplot legend apply map distplot legend iteritems isna int int fillna fillna fillna labelencoder fit transform fit transform fit transform astype corr round sort values train test split len len randomforestclassifier fit predict accuracy score sqrt print print print plot roc curve show read csv predict dataframe csv gridsearchcv fit predict proba predict randomforestclassifier algorithm pipeline print sqrt print kneighborsclassifier svc decisiontreeclassifier randomforestclassifier adaboostclassifier gradientboostingclassifier gaussiannb lineardiscriminantanalysis quadraticdiscriminantanalysis logisticregression dataframe stratifiedshufflesplit split fit predict accuracy score dataframe append sort values gradientboostingclassifier fit predict accuracy score sqrt print print print sequential add add add add optimizers compile fit predict astype reshape accuracy score predict astype reshape,"[0.0, 0.0, 0.2011636973660413, 0.06182281430854052, 0.0, 0.2000850716778259, 0.0, 0.0, 0.0, 0.08878293470465212, 0.0, 0.0, 0.0, 0.0, 0.09376061342540308, 0.0, 0.0, 0.04080964333314954, 0.10589859481982254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12389188899187768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19076254142537494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052802966176025194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06710674363275493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06374731892703034, 0.0, 0.0, 0.07262334870839476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09538127071268747, 0.0, 0.0, 0.05335230461295027, 0.0, 0.0, 0.08271796354014924, 0.08443428626001681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07440407702184502, 0.0, 0.0, 0.07475164646040272, 0.0, 0.0, 0.0, 0.0, 0.06991862629119558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04080964333314954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033261566205233746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15229500232395426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12936029384101091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07264329310330621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1639928601732872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05029092434151033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11556128979355226, 0.0, 0.0, 0.0, 0.0, 0.04938004522513719, 0.0, 0.0, 0.09673039875210868, 0.0, 0.0, 0.0, 0.0, 0.06649487204113293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09376061342540308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04982949146566487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11022684157975857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12749463785406068, 0.0, 0.09926300455439238, 0.0, 0.0, 0.0, 0.3023287726425833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041640332804714957, 0.0, 0.0, 0.0, 0.0, 0.048514729551523146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17848656256734044, 0.08686373375061424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07678961186177648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031126775104127986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19545732527302123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10031168915394625, 0.04652371860878596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10077625754752778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07678961186177648, 0.0, 0.0, 0.10709193754040426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1701459468988648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15874401677133115, 0.0, 0.06479628901890083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07678961186177648, 0.0, 0.0, 0.0, 0.05125243321570324, 0.09023341503677246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05557883226797161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05574267949540236, 0.15357922372355295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06977396773965178, 0.0, 0.0, 0.18314928821560195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12512782950603987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06977396773965178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04054137893021021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09376061342540308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22978560899180805, 0.0, 0.0, 0.0, 0.0648180873230212, 0.2663488041139564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05175399608415469, 0.0, 0.0849219471304761, 0.0, 0.0, 0.0, 0.046151603032795606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06583100104323877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039760673241279035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033793999211024835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033261566205233746, 0.0, 0.0, 0.0, 0.11350850586836767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06710674363275493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08443428626001681, 0.22978560899180805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
parakhsrivastava_titanic-survival-beginners.py,"['numpy', 'pandas', 'matplotlib\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,346,"['# Transform Pclass and Sex variable', '# Fill NAs in Age and normalizing values', '# Fill NA in Fare and Normalizing values', '# Fill NA in Embarked and transform values', ""print(test_D['Embarked'][test_D['Embarked'] == 'S'].count()) # 270"", ""print(test_D['Embarked'][test_D['Embarked'] == 'C'].count()) # 102"", ""print(test_D['Embarked'][test_D['Embarked'] == 'Q'].count()) # 46""]",7,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'train_D.isnull', 'None.sum', 'train_D.drop', 'train_D.drop', 'train_D.max', 'train_D.min', 'np.random.randint', 'np.isnan', 'train_D.isnull', 'None.sum', 'train_D.unique', 'print', 'print', 'print', 'train_D.fillna', 'plt.figure', 'plt.subplot', 'sns.countplot', 'axes0.set_title', 'axes0.set_ylabel', 'axes0.legend', 'pclass_df.groupby', 'None.mean', 'plt.subplot', 'sns.barplot', 'axes1.set_title', 'axes1.set_ylabel', 'plt.tight_layout', 'np.where', 'np.where', 'train_D.head', 'plt.figure', 'plt.subplot', 'sns.countplot', 'axes0.set_title', 'axes0.set_ylabel', 'axes0.legend', 'sex_df.groupby', 'None.mean', 'plt.subplot', 'sns.barplot', 'axes1.set_title', 'axes1.set_ylabel', 'train_D.replace', 'train_D.head', 'pd.cut', 'plt.figure', 'plt.subplot', 'sns.countplot', 'axes0.set_title', 'axes0.set_ylabel', 'axes0.legend', 'age_df.groupby', 'None.mean', 'plt.subplot', 'sns.barplot', 'axes1.set_title', 'axes1.set_ylabel', 'train_D.values.astype', 'preprocessing.MinMaxScaler', 'min_max_scaler.fit_transform', 'pd.DataFrame', 'train_D.head', 'sibsp_df.groupby', 'None.mean', 'sns.barplot', 'np.where', 'plt.figure', 'plt.subplot', 'sns.countplot', 'axes0.set_title', 'axes0.set_ylabel', 'axes0.legend', 'sibsp_df.groupby', 'None.mean', 'plt.subplot', 'sns.barplot', 'axes1.set_title', 'axes1.set_ylabel', 'np.where', 'train_D.head', 'pd.cut', 'plt.figure', 'plt.subplot', 'sns.countplot', 'axes0.set_title', 'axes0.set_ylabel', 'axes0.legend', 'fare_df.groupby', 'None.mean', 'plt.subplot', 'sns.barplot', 'axes1.set_title', 'axes1.set_ylabel', 'train_D.values.astype', 'preprocessing.MinMaxScaler', 'min_max_scaler.fit_transform', 'pd.DataFrame', 'train_D.head', 'plt.figure', 'plt.subplot', 'sns.countplot', 'axes0.set_title', 'axes0.set_ylabel', 'axes0.legend', 'embarked_df.groupby', 'None.mean', 'plt.subplot', 'sns.barplot', 'axes1.set_title', 'axes1.set_ylabel', 'np.where', 'np.where', 'train_D.head', 'final.head', 'independent_v_train.isnull', 'None.sum', 'DecisionTreeClassifier', 'dt.fit', 'dt.score', 'np.where', 'np.where', 'test_D.replace', 'test_D.min', 'test_D.max', 'test_D.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'test_D.values.astype', 'preprocessing.MinMaxScaler', 'min_max_scaler.fit_transform', 'pd.DataFrame', 'test_D.fillna', 'train_D.values.astype', 'preprocessing.MinMaxScaler', 'min_max_scaler.fit_transform', 'pd.DataFrame', 'print', 'print', 'print', 'test_D.fillna', 'np.where', 'np.where', 'test_D.count', 'final_test.head', 'dt.predict', 'pd.DataFrame', 'pd.read_csv', 'pd.DataFrame', 'prediction_df.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'print', 'isnull', 'sum', 'drop', 'drop', 'max', 'min', 'random', 'isnan', 'isnull', 'sum', 'unique', 'print', 'print', 'print', 'fillna', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'subplot', 'barplot', 'set_title', 'set_ylabel', 'tight_layout', 'where', 'where', 'head', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'subplot', 'barplot', 'set_title', 'set_ylabel', 'replace', 'head', 'cut', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'subplot', 'barplot', 'set_title', 'set_ylabel', 'values', 'MinMaxScaler', 'fit_transform', 'DataFrame', 'head', 'groupby', 'mean', 'barplot', 'where', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'subplot', 'barplot', 'set_title', 'set_ylabel', 'where', 'head', 'cut', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'subplot', 'barplot', 'set_title', 'set_ylabel', 'values', 'MinMaxScaler', 'fit_transform', 'DataFrame', 'head', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'subplot', 'barplot', 'set_title', 'set_ylabel', 'where', 'where', 'head', 'head', 'isnull', 'sum', 'DecisionTreeClassifier', 'fit', 'score', 'where', 'where', 'replace', 'min', 'max', 'isnull', 'sum', 'random', 'isnan', 'values', 'MinMaxScaler', 'fit_transform', 'DataFrame', 'fillna', 'values', 'MinMaxScaler', 'fit_transform', 'DataFrame', 'print', 'print', 'print', 'fillna', 'where', 'where', 'count', 'head', 'predict', 'DataFrame', 'read_csv', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'isnull', 'sum', 'drop', 'max', 'min', 'random', 'isnan', 'unique', 'fillna', 'figure', 'subplot', 'countplot', 'set_title', 'set_ylabel', 'legend', 'groupby', 'mean', 'barplot', 'tight_layout', 'where', 'head', 'replace', 'cut', 'values', 'MinMaxScaler', 'fit_transform', 'DataFrame', 'DecisionTreeClassifier', 'fit', 'score', 'count', 'predict', 'to_csv']",37,"[1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print print isnull sum drop drop max min random isnan isnull sum unique print print print fillna figure subplot countplot set title set ylabel legend groupby mean subplot barplot set title set ylabel tight layout head figure subplot countplot set title set ylabel legend groupby mean subplot barplot set title set ylabel replace head cut figure subplot countplot set title set ylabel legend groupby mean subplot barplot set title set ylabel values minmaxscaler fit transform dataframe head groupby mean barplot figure subplot countplot set title set ylabel legend groupby mean subplot barplot set title set ylabel head cut figure subplot countplot set title set ylabel legend groupby mean subplot barplot set title set ylabel values minmaxscaler fit transform dataframe head figure subplot countplot set title set ylabel legend groupby mean subplot barplot set title set ylabel head head isnull sum decisiontreeclassifier fit score replace min max isnull sum random isnan values minmaxscaler fit transform dataframe fillna values minmaxscaler fit transform dataframe print print print fillna count head predict dataframe read csv dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2156112815949061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034458273734117216, 0.0, 0.0, 0.16027338937313657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04805483233672259, 0.0, 0.0, 0.0, 0.05961521557913615, 0.0, 0.0, 0.0, 0.09031569231484167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026357434250816276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030749377753872494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1592005495292121, 0.0, 0.0, 0.0, 0.046917607343504315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06619806430208415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01577384475882644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1457740084490487, 0.0, 0.0, 0.0, 0.0, 0.11452418756570008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019905833076518657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06751919540401577, 0.0854803882086581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043341755492627955, 0.0, 0.13833341690692424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02020385544801981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020103628976844604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0810665447348696, 0.0, 0.0, 0.0, 0.15117106112360504, 0.0, 0.0, 0.0, 0.0, 0.08668351098525591, 0.17667970068394204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013736369158569905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10252686970586969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06620408944274858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035896305323753264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04744988359268439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02000429341942026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02020385544801981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5183007809952173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47227019994415154, 0.0, 0.0, 0.08503560138949502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045064416567017214, 0.0, 0.2705702330910402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09774790910440427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03642388299905773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09893999859040889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35769129347481693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
jingnanyang_titanic.py,"['numpy', 'pandas', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,168,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory']",7,"['os.walk', 'print', 'pd.read_csv', 'useful_df.dropna', 'train_test_split', 'print', 'list', 'list', 'list', 'list', 'list', 'list', 'list', 'range', 'train_features.append', 'list', 'list', 'list', 'list', 'list', 'list', 'list', 'range', 'val_features.append', 'DictVectorizer', 'vec.fit_transform', 'LogisticRegression', 'model.fit', 'vec.transform', 'fitted_model.predict', 'list', 'classification_report', 'print', 'extract_train_features_and_labels', 'extract_val_features_and_labels', 'create_classifier', 'classify_data', 'evaluation', 'pd.read_csv', 'useful_test_df.fillna', 'print', 'list', 'list', 'list', 'list', 'list', 'list', 'range', 'test_features.append', 'extract_test_features', 'extract_train_features_and_labels', 'create_classifier', 'classify_data', 'pd.DataFrame', 'submission.to_csv']","['walk', 'print', 'read_csv', 'dropna', 'train_test_split', 'print', 'list', 'list', 'list', 'list', 'list', 'list', 'list', 'range', 'append', 'list', 'list', 'list', 'list', 'list', 'list', 'list', 'range', 'append', 'DictVectorizer', 'fit_transform', 'LogisticRegression', 'fit', 'transform', 'predict', 'list', 'classification_report', 'print', 'extract_train_features_and_labels', 'extract_val_features_and_labels', 'create_classifier', 'classify_data', 'evaluation', 'read_csv', 'fillna', 'print', 'list', 'list', 'list', 'list', 'list', 'list', 'range', 'append', 'extract_test_features', 'extract_train_features_and_labels', 'create_classifier', 'classify_data', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'dropna', 'train_test_split', 'list', 'range', 'append', 'DictVectorizer', 'fit_transform', 'LogisticRegression', 'fit', 'transform', 'predict', 'classification_report', 'extract_train_features_and_labels', 'extract_val_features_and_labels', 'create_classifier', 'classify_data', 'evaluation', 'fillna', 'extract_test_features', 'DataFrame', 'to_csv']",24,"[1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv dropna train test split print list list list list list list list range append list list list list list list list range append dictvectorizer fit transform logisticregression fit transform predict list classification report print extract train features labels extract val features labels create classifier classify data evaluation read csv fillna print list list list list list list range append extract test features extract train features labels create classifier classify data dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09976001002613477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06662727288688669, 0.16423308548695129, 0.16423308548695129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12890782308907497, 0.0, 0.0, 0.0, 0.0, 0.04547057302786599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10559723820523442, 0.0, 0.01899083509062402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07639991410050617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03303474406391785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08211654274347564, 0.0, 0.0, 0.0, 0.0, 0.27679125504775176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26650909154754676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019730891079284153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03340699247958658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771378094871005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.816065152964935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02536334669005957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01733021901830453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06467550073650166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10248978443433003, 0.0, 0.0, 0.0, 0.030191910056545628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06257126031623668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026408190618216608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05507341606481754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08130858069577201, 0.0, 0.0, 0.0, 0.06166086007901855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042592130088512974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032192766096382254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
harityadav_titanic-competition.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'sklearn', 'statsmodels']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,378,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train.head', 'train.apply', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.distplot', 'sns.distplot', 'sns.countplot', 'sns.heatmap', 'print', 'train.drop', 'pd.DataFrame', 'vif', 'range', 'train.drop', 'train_test_split', 'sa.OLS', 'model.fit', 'res.summary', 'sa.OLS', 'model.fit', 'res.summary', 'sa.OLS', 'model.fit', 'res.summary', 'getVIF', 'pd.DataFrame', 'res.predict', 'y_pred.apply', 'accuracy_score', 'testX.apply', 'res.predict', 'test.apply', 'test.to_csv', 'sa.GLM', 'glm_binom.fit', 'print', 'sa.GLM', 'glm_binom.fit', 'print', 'sa.GLM', 'glm_binom.fit', 'print', 'sa.GLM', 'glm_binom.fit', 'print', 'pd.DataFrame', 'res.predict', 'y_pred.apply', 'accuracy_score', 'confusion_matrix', 'res.predict', 'test.apply', 'test.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'head', 'apply', 'countplot', 'countplot', 'countplot', 'countplot', 'countplot', 'distplot', 'distplot', 'countplot', 'heatmap', 'print', 'drop', 'DataFrame', 'vif', 'range', 'drop', 'train_test_split', 'OLS', 'fit', 'summary', 'OLS', 'fit', 'summary', 'OLS', 'fit', 'summary', 'getVIF', 'DataFrame', 'predict', 'apply', 'accuracy_score', 'apply', 'predict', 'apply', 'to_csv', 'GLM', 'fit', 'print', 'GLM', 'fit', 'print', 'GLM', 'fit', 'print', 'GLM', 'fit', 'print', 'DataFrame', 'predict', 'apply', 'accuracy_score', 'confusion_matrix', 'predict', 'apply', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'apply', 'countplot', 'distplot', 'heatmap', 'drop', 'DataFrame', 'vif', 'range', 'train_test_split', 'OLS', 'fit', 'summary', 'getVIF', 'predict', 'accuracy_score', 'to_csv', 'GLM', 'confusion_matrix']",22,"[1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv head apply countplot countplot countplot countplot countplot distplot distplot countplot heatmap print drop dataframe vif range drop train test split ols fit summary ols fit summary ols fit summary getvif dataframe predict apply accuracy score apply predict apply csv glm fit print glm fit print glm fit print glm fit print dataframe predict apply accuracy score confusion matrix predict apply csv,"[0.0, 0.0, 0.13536642920101696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2850437693453256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07681252799500875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33397383827665117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12516938140828823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09409883492504574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13664248516465125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06407481462297407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19311871041781362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13562807117855, 0.5425122847142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029830343831895926, 0.06021037625311259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0725668852886672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40688421353564996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11449406416912103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16023227094693204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05642586870612818, 0.0, 0.0, 0.0, 0.07479985864037543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08420061718733159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04361717916027063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35846116378803294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04548109884155128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04476453262481926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13562807117855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05317129320938748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kleytontorikai_titanic-survivors.py,"['numpy', 'pandas', 'os\n', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,162,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# Read the data', '# Select categorical columns with relatively low cardinality (arbitrary)', '# Select numeric columns', '# Keep selected columns only', '# One-hot encode the data', ""# Can't just drop NaN rows because the test set might contain NaN values"", '# Feature Scaling', '# The Euclidean distance is the minkowski metric with p=2.', '# Applying k-Fold Cross Validation', '# Read test set for submission', '# Apply the same transformations on X_sub as in X_train', '# One-hot encode', '# Select the same columns except Survived', '# Replace NaN for -1', '# Feature Scaling']",23,"['os.walk', 'print', 'pd.read_csv', 'X.head', 'Xcname.nunique', 'Xmy_cols.copy', 'pd.get_dummies', 'X.fillna', 'X.head', 'X.drop', 'X.drop', 'train_test_split', 'X_train.head', 'StandardScaler', 'sc_X.fit_transform', 'sc_X.transform', 'LogisticRegression', 'model.fit', 'model.predict', 'XGBClassifier', 'model.fit', 'model.predict', 'RandomForestClassifier', 'model.fit', 'model.predict', 'SVC', 'model.fit', 'model.predict', 'KNeighborsClassifier', 'model.fit', 'model.predict', 'eval', 'cross_val_score', 'print', 'pd.read_csv', 'pd.get_dummies', 'X_submodel_cols.copy', 'X_sub.fillna', 'sc_X.transform', 'model.predict', 'pd.DataFrame', 'pd.concat', 'submission.head', 'submission.to_csv']","['walk', 'print', 'read_csv', 'head', 'nunique', 'copy', 'get_dummies', 'fillna', 'head', 'drop', 'drop', 'train_test_split', 'head', 'StandardScaler', 'fit_transform', 'transform', 'LogisticRegression', 'fit', 'predict', 'XGBClassifier', 'fit', 'predict', 'RandomForestClassifier', 'fit', 'predict', 'SVC', 'fit', 'predict', 'KNeighborsClassifier', 'fit', 'predict', 'eval', 'cross_val_score', 'print', 'read_csv', 'get_dummies', 'copy', 'fillna', 'transform', 'predict', 'DataFrame', 'concat', 'head', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'nunique', 'copy', 'get_dummies', 'fillna', 'drop', 'train_test_split', 'StandardScaler', 'fit_transform', 'transform', 'LogisticRegression', 'fit', 'predict', 'XGBClassifier', 'RandomForestClassifier', 'SVC', 'KNeighborsClassifier', 'eval', 'cross_val_score', 'DataFrame', 'concat', 'to_csv']",25,"[1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head nunique copy get dummies fillna head drop drop train test split head standardscaler fit transform transform logisticregression fit predict xgbclassifier fit predict randomforestclassifier fit predict svc fit predict kneighborsclassifier fit predict eval cross val score print read csv get dummies copy fillna transform predict dataframe concat head csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10891439256954247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23115431159136038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15678190198530725, 0.0, 0.0, 0.16737746876842186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0699053848588886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14280223276564974, 0.0, 0.0, 0.0, 0.2016499732291508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24525541562706307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14525907132826862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36891405593055904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14650964770013786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2659291160451924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12489734044155638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09336264062202293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20128210417365833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3827558791540012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1190354649585323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09021632631921012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11113661311133105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09382809927229559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09720871777275082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1711905148162268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1192594296806198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10136279755821584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09976580104287866, 0.0, 0.0, 0.0, 0.3404610276997752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15678190198530725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11850177693085506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1552325841978316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
econundrums_titanic-notebook.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn', 'statsmodels', 'keras']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,410,"['# Exploring mean values', '# Dropping Embarked and Cabin']",2,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'dfReset.copy', 'df.head', 'df.isna', 'None.sum', 'None.sort_values', 'df.head', 'sea.pairplot', 'sea.pairplot', 'df.groupby', 'None.mean', 'df.groupby', 'None.mean', 'print', 'print', 'print', 'df.groupby', 'None.describe', 'df.groupby', 'None.mean', 'df.set_index', 'df.fillna', 'df.round', 'df.reset_index', 'df.isna', 'None.sum', 'df.drop', 'df.head', 'df.drop', 'df.head', 'np.where', 'df.drop', 'df.head', 'df.corr', 'None.sort_values', 'df.drop', 'train_test_split', 'pd.concat', 'pd.concat', 'smf.logit', 'None.fit', 'logitModel.summary', 'print', 'print', 'print', 'print', 'logitModel.predict', 'np.where', 'Results', 'plt.figure', 'sea.countplot', 'plt.legend', 'plt.figure', 'sea.countplot', 'plt.legend', 'plt.figure', 'sea.countplot', 'plt.legend', 'df.corr', 'dfdf.corr', 'None.sort_values', 'df.drop', 'df.drop', 'train_test_split', 'pd.concat', 'pd.concat', 'smf.logit', 'None.fit', 'logitModel2.summary', 'logitModel2.predict', 'np.where', 'Results', 'df.drop', 'train_test_split', 'SVC', 'svc.fit', 'svc.predict', 'Results', 'GridSearchCV', 'grid.fit', 'grid.predict', 'Results', 'print', 'print', 'print', 'df.drop', 'train_test_split', 'DecisionTreeClassifier', 'dtree.fit', 'dtree.predict', 'Results', 'RandomForestClassifier', 'rfc.fit', 'rfc.predict', 'Results', 'df.copy', 'dfScaled.apply', 'dfScaled.drop', 'train_test_split', 'range', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'errorRate.append', 'plt.figure', 'plt.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'errorRate.index', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'Results', 'Sequential', 'EarlyStopping', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'model.fit', 'pd.DataFrame', 'None.plot', 'model.predict_classes', 'Results', 'df.apply', 'df.apply', 'df.drop']","['get_ipython', 'run_line_magic', 'read_csv', 'copy', 'head', 'isna', 'sum', 'sort_values', 'head', 'pairplot', 'pairplot', 'groupby', 'mean', 'groupby', 'mean', 'print', 'print', 'print', 'groupby', 'describe', 'groupby', 'mean', 'set_index', 'fillna', 'round', 'reset_index', 'isna', 'sum', 'drop', 'head', 'drop', 'head', 'where', 'drop', 'head', 'corr', 'sort_values', 'drop', 'train_test_split', 'concat', 'concat', 'logit', 'fit', 'summary', 'print', 'print', 'print', 'print', 'predict', 'where', 'Results', 'figure', 'countplot', 'legend', 'figure', 'countplot', 'legend', 'figure', 'countplot', 'legend', 'corr', 'corr', 'sort_values', 'drop', 'drop', 'train_test_split', 'concat', 'concat', 'logit', 'fit', 'summary', 'predict', 'where', 'Results', 'drop', 'train_test_split', 'SVC', 'fit', 'predict', 'Results', 'GridSearchCV', 'fit', 'predict', 'Results', 'print', 'print', 'print', 'drop', 'train_test_split', 'DecisionTreeClassifier', 'fit', 'predict', 'Results', 'RandomForestClassifier', 'fit', 'predict', 'Results', 'copy', 'apply', 'drop', 'train_test_split', 'range', 'KNeighborsClassifier', 'fit', 'predict', 'append', 'figure', 'plot', 'title', 'xlabel', 'ylabel', 'index', 'KNeighborsClassifier', 'fit', 'predict', 'Results', 'Sequential', 'EarlyStopping', 'add', 'add', 'add', 'add', 'add', 'compile', 'fit', 'DataFrame', 'plot', 'predict_classes', 'Results', 'apply', 'apply', 'drop']","['get_ipython', 'run_line_magic', 'read_csv', 'copy', 'head', 'isna', 'sum', 'sort_values', 'pairplot', 'groupby', 'mean', 'print', 'describe', 'set_index', 'fillna', 'round', 'reset_index', 'drop', 'where', 'corr', 'train_test_split', 'concat', 'logit', 'fit', 'summary', 'predict', 'Results', 'figure', 'countplot', 'legend', 'SVC', 'GridSearchCV', 'DecisionTreeClassifier', 'RandomForestClassifier', 'apply', 'range', 'KNeighborsClassifier', 'append', 'plot', 'title', 'xlabel', 'ylabel', 'index', 'Sequential', 'EarlyStopping', 'add', 'compile', 'DataFrame', 'predict_classes']",49,"[1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv copy head isna sum sort values head pairplot pairplot groupby mean groupby mean print print print groupby describe groupby mean set index fillna round reset index isna sum drop head drop head drop head corr sort values drop train test split concat concat logit fit summary print print print print predict results figure countplot legend figure countplot legend figure countplot legend corr corr sort values drop drop train test split concat concat logit fit summary predict results drop train test split svc fit predict results gridsearchcv fit predict results print print print drop train test split decisiontreeclassifier fit predict results randomforestclassifier fit predict results copy apply drop train test split range kneighborsclassifier fit predict append figure plot title xlabel ylabel index kneighborsclassifier fit predict results sequential earlystopping add add add add add compile fit dataframe plot predict classes results apply apply drop,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.19129110483171827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03901601301648575, 0.10124423093307329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06972332816660816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06094555163638902, 0.0, 0.0, 0.13886293959378432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07367889231640948, 0.1367837328033796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11862362220983112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017783483268070225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022281874337089898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03901601301648575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03179968247744909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22758628766318026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08963972764907013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15710610407058268, 0.0, 0.0, 0.0, 0.02315017920430857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17638333553324978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02334948563558831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04720973598153519, 0.0, 0.0, 0.12330531670313956, 0.0, 0.0, 0.0, 0.0, 0.10595391110165224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14291828564328724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029465927336739625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12189110327277804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0796203854788345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10238512488157601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029907079712006682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19269405243898344, 0.0, 0.0, 0.0, 0.02975871787728648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09590287613606521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13341464473573547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06825674992105067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18300131853163107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18970879548242955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028755851215987355, 0.0, 0.0, 0.04008362431498416, 0.0, 0.0, 0.0, 0.017712026423967152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05329272522702453, 0.0, 0.0, 0.6253882000677514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043774917086665345, 0.0, 0.029611674831875177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06670732236786774, 0.0, 0.03196762537868841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10984313484728485, 0.0, 0.0, 0.0, 0.15492314635377202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06293765354976619, 0.16976164715778105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03801314635518663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16154357223032076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033376325744562556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15899841238724544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10984313484728485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045594577601126535, 0.0, 0.0, 0.0, 0.0, 0.04412318750153284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
gmayock_gs-titanic-5-trying-to-get-in-the-top-25.py,"['numpy', 'pandas', 'os\n', 'both', 'collections', 'sklearn', 'xgboost', 'yellowbrick', 'warnings\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]",9,521,"['# Step 1 is to import both data sets', '# Step two is to create columns which I will add to the respective datasets, in order to know which row came from which dataset when I combine the datasets', '# Now we append them by creating new columns in the original data. We use the same column name', '# Now we can merge the datasets while retaining the key to split them later', '# Encode gender (if == female, True)', '# Split out Title', '# Replace the title values with an aliased dictionary', '# Fill NaN of Age - first create groups to find better medians than just the overall median and fill NaN with the grouped medians', '# Fill NaN of Embarked', '# Fill NaN of Fare, adding flag for boarded free, binning other fares', '# Fill NaN of Cabin with a U for unknown. Not sure cabin will help.', '# Counting how many people are riding on a ticket', '# Finding cabin group', '# Adding a family_size feature as it may have an inverse relationship to either of its parts', '# Mapping ports to passenger pickup order', '# Encode childhood', '# One-Hot Encoding the titles', '# One-Hot Encoding the Pclass', '# One-Hot Encoding the  cabin group', '# One-Hot Encoding the ports', '# here is the expanded model set and metric tools', '# Here are the features', '# Define the classifiers I will use', '# Fit and use cross_val_score and k_fold to score accuracy', ""# So we're just going to take the features with a chi_squared over 1. "", '# rf_ stands for reduced features', '# Fit and use cross_val_score and k_fold to score accuracy', '# Fit and use cross_val_score and k_fold to score accuracy', ""# d = [['clf_name', 'feature_name', 'n_features', 'support', 'ranking']]"", '# for clf in classifiers2:', '#     for i in range (1,3):', '#         name = clf.__class__.__name__', '#         print(name, i)', '#         rfe = RFE(clf, i)', '#         fitted_clf = rfe.fit(nf3_cvs_train_data, nf3_cvs_target)', '#         n_feat = fitted_clf.n_features_', '#         n_supp = fitted_clf.support_', '#         rank = fitted_clf.ranking_', '#         d_new = [name, new_features_3, n_feat, n_supp, rank]', '#         d.append(d_new)', '# d_f = pd.DataFrame(d)', '# d_f', '# from yellowbrick.features import RFECV', '# import warnings', '# warnings.filterwarnings(""ignore"")', '# # Create RFECV visualizer with linear SVM classifier', '# for clf in classifiers2:', '#     viz = RFECV(clf)', '#     viz.fit(nf3_cvs_train_data, nf3_cvs_target);', '#     viz.poof();', '# Fit and use cross_val_score and k_fold to score accuracy']",51,"['print', 'pd.read_csv', 'pd.read_csv', 'pd.Series', 'pd.Series', 'training_data.append', 'i.find', 'i.find', 'title.append', 'pd.Series', 'title_arr.map', 'combined_data.groupby', 'grouped.Age.apply', 'np.select', 'None.astype', 'combined_data.fillna', 'combined_data.fillna', 'np.select', 'None.astype', 'combined_data.fillna', 'pd.DataFrame', 'pd.DataFrame', 'tickets_count.rename', 'tickets_count.astype', 'combined_data.merge', 'cabin_group.append', 'combined_data.map', 'pd.concat', 'pd.concat', 'pd.concat', 'pd.concat', 'KFold', 'RandomForestClassifier', 'RandomForestClassifier', 'RandomForestClassifier', 'DecisionTreeClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'SVC', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 'XGBClassifier', 'GaussianNB', 'LinearSVC', 'round', 'print', 'clf_scores.append', 'clf.fit', 'clf.predict', 'pd.DataFrame', '.format', 'submission.to_csv', 'print', 'clf_scores.copy', 'pd.DataFrame', 'df_scores.sort_values', 'SelectKBest', 'range', 'SelectKBest', 'fit_test.fit', 'np.set_printoptions', 'fit_test.transform', 'pd.DataFrame', 'pd.DataFrame', 'fit_test_scores.sort_values', 'len', 'round', 'print', 'clf_scores.append', 'clf.fit', 'clf.predict', 'pd.DataFrame', '.format', 'submission.to_csv', 'round', 'print', 'clf_scores.append', 'clf.fit', 'clf.predict', 'pd.DataFrame', '.format', 'submission.to_csv', 'new_train_data.astype', 'SelectKBest', 'range', 'SelectKBest', 'fit_test.fit', 'np.set_printoptions', 'fit_test.transform', 'pd.DataFrame', 'fit_test_scores.sort_values', 'RandomForestClassifier', 'RandomForestClassifier', 'RandomForestClassifier', 'DecisionTreeClassifier', 'LogisticRegression', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 'XGBClassifier', 'LinearSVC', 'print', 'RFE', 'rfe.fit', 'd.append', 'pd.DataFrame', 'd_f.to_csv', 'round', 'print', 'clf_scores.append', 'clf.fit', 'clf.predict', 'pd.DataFrame', '.format', 'submission.to_csv']","['print', 'read_csv', 'read_csv', 'Series', 'Series', 'append', 'find', 'find', 'append', 'Series', 'map', 'groupby', 'Age', 'select', 'astype', 'fillna', 'fillna', 'select', 'astype', 'fillna', 'DataFrame', 'DataFrame', 'rename', 'astype', 'merge', 'append', 'map', 'concat', 'concat', 'concat', 'concat', 'KFold', 'RandomForestClassifier', 'RandomForestClassifier', 'RandomForestClassifier', 'DecisionTreeClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'SVC', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 'XGBClassifier', 'GaussianNB', 'LinearSVC', 'round', 'print', 'append', 'fit', 'predict', 'DataFrame', 'format', 'to_csv', 'print', 'copy', 'DataFrame', 'sort_values', 'SelectKBest', 'range', 'SelectKBest', 'fit', 'set_printoptions', 'transform', 'DataFrame', 'DataFrame', 'sort_values', 'len', 'round', 'print', 'append', 'fit', 'predict', 'DataFrame', 'format', 'to_csv', 'round', 'print', 'append', 'fit', 'predict', 'DataFrame', 'format', 'to_csv', 'astype', 'SelectKBest', 'range', 'SelectKBest', 'fit', 'set_printoptions', 'transform', 'DataFrame', 'sort_values', 'RandomForestClassifier', 'RandomForestClassifier', 'RandomForestClassifier', 'DecisionTreeClassifier', 'LogisticRegression', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 'XGBClassifier', 'LinearSVC', 'print', 'RFE', 'fit', 'append', 'DataFrame', 'to_csv', 'round', 'print', 'append', 'fit', 'predict', 'DataFrame', 'format', 'to_csv']","['print', 'read_csv', 'Series', 'append', 'find', 'map', 'groupby', 'Age', 'select', 'astype', 'fillna', 'DataFrame', 'rename', 'merge', 'concat', 'KFold', 'RandomForestClassifier', 'DecisionTreeClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'SVC', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'ExtraTreesClassifier', 'XGBClassifier', 'GaussianNB', 'LinearSVC', 'round', 'fit', 'predict', 'format', 'to_csv', 'copy', 'sort_values', 'SelectKBest', 'range', 'set_printoptions', 'transform', 'len', 'RFE']",40,"[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0
 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv series series append find find append series map groupby age select astype fillna fillna select astype fillna dataframe dataframe rename astype merge append map concat concat concat concat kfold randomforestclassifier randomforestclassifier randomforestclassifier decisiontreeclassifier logisticregression kneighborsclassifier svc adaboostclassifier gradientboostingclassifier extratreesclassifier xgbclassifier gaussiannb linearsvc round print append fit predict dataframe format csv print copy dataframe sort values selectkbest range selectkbest fit set printoptions transform dataframe dataframe sort values len round print append fit predict dataframe format csv round print append fit predict dataframe format csv astype selectkbest range selectkbest fit set printoptions transform dataframe sort values randomforestclassifier randomforestclassifier randomforestclassifier decisiontreeclassifier logisticregression adaboostclassifier gradientboostingclassifier extratreesclassifier xgbclassifier linearsvc print rfe fit append dataframe csv round print append fit predict dataframe format csv,"[0.0, 0.0, 0.0, 0.13890772510856558, 0.0, 0.0, 0.0, 0.047101477099165276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3667755847935657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13918438243021924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16317510407247182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04328930727249529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14627914539825979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28801290624931014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09169389619839143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17253614891186772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08160995825113249, 0.0, 0.0, 0.19080843568220915, 0.0, 0.0, 0.16120578601171062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3277220362221007, 0.0, 0.0, 0.056498543232131146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1298255025703067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03622341199275698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06750839496432444, 0.04678017304258726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0487928436479601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13691360053989157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06993776598557482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07319447982956459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09186016885631212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09557388596954856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15604614719956594, 0.19948356648302648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20274260484132584, 0.0, 0.0, 0.09420295419833055, 0.0, 0.0, 0.0, 0.041626106483411626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08626807445593386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11321549202709263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20575616999829585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15366110734369495, 0.0, 0.335914217884444, 0.0, 0.0, 0.0, 0.0, 0.15311470637261365, 0.075129053343917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12907450333965528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04466849924662927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08501288996624803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12907450333965528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11628441606441732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
karthikgunasekaran_titanic-data-science-solutions.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,949,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
sebastiengclaro_kaggle-titanic.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,407,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# EDA on train data set', '# Check types of each columns and non-Null values', ' #   Column       Non-Null Count  Dtype  ', '# Remove column Cabin and missing value', '# Reorder columns to get our label at the end', '# Remove unwanted features and check Parch values', '# Count the number of Parch values', '# Map categories', '# Embarked categorical value', '# SibSp categorical value', '# Binarize gender', '# Pclass categories', '# Drop Pclass and replace by dummies', '# Checkpoint categories cols', '# Import matplotlib and seaborn', '# Histogram distributions Age', '# Histo Fare', '# Boxplot Fare', '# Remove outliers and keep 95% of data', '# Boxplot Fare', '# Histo Fare', '# Last check of preprocess', '# We need to make a function to preprocess the test dataset', '    # Remove columns and NA', '    df = df.fillna(0) # NA values in test but we can not drop them', '    # Map values', '    # Dummies Pclas', '    # Reorder cols', '# Import libraries', '# Init data', ' #   Column       Non-Null Count  Dtype  ', '# Preprocess test data', '# Fit scaler on train data', ' #   Column    Non-Null Count  Dtype  ', '# Train the model', '# Save result']",45,"['os.walk', 'print', 'pd.read_csv', 'raw_data.copy', 'df.head', 'df.info', 'df.drop', 'df.dropna', 'df_no_na.describe', 'df_no_na.head', 'df_no_na.drop', 'pd.unique', 'np.unique', 'np.unique', 'df_rm_feat.map', 'df_rm_feat.head', 'np.unique', 'df_rm_feat.map', 'df_rm_feat.head', 'np.unique', 'df_rm_feat.map', 'df_rm_feat.head', 'df_rm_feat.map', 'df_rm_feat.head', 'np.unique', 'pd.get_dummies', 'df_rm_feat.drop', 'df_rm_feat.head', 'df_rm_feat.copy', 'df_categories.describe', 'sns.set', 'plt.hist', 'plt.xlabel', 'plt.hist', 'plt.xlabel', 'plt.boxplot', 'plt.xlabel', 'df_categories.quantile', 'None.reset_index', 'plt.boxplot', 'plt.xlabel', 'plt.hist', 'plt.xlabel', 'df_no_outliers.describe', 'df.drop', 'df.fillna', 'df.map', 'df.map', 'df.map', 'df.map', 'pd.get_dummies', 'df.drop', 'df_no_outliers.copy', 'pd.read_csv', 'test_data.info', 'np.unique', 'preprocess', 'test_data_processed.head', 'StandardScaler', 'train_data.drop', 'test_data_processed.drop', 'scaler.fit', 'pd.DataFrame', 'pd.DataFrame', 'pd.concat', 'pd.concat', 'df_test_scaled.info', 'LogisticRegression', 'df_train_scaled.drop', 'logR.fit', 'logR.predict', 'result.tolist', 'response.to_csv']","['walk', 'print', 'read_csv', 'copy', 'head', 'info', 'drop', 'dropna', 'describe', 'head', 'drop', 'unique', 'unique', 'unique', 'map', 'head', 'unique', 'map', 'head', 'unique', 'map', 'head', 'map', 'head', 'unique', 'get_dummies', 'drop', 'head', 'copy', 'describe', 'set', 'hist', 'xlabel', 'hist', 'xlabel', 'boxplot', 'xlabel', 'quantile', 'reset_index', 'boxplot', 'xlabel', 'hist', 'xlabel', 'describe', 'drop', 'fillna', 'map', 'map', 'map', 'map', 'get_dummies', 'drop', 'copy', 'read_csv', 'info', 'unique', 'preprocess', 'head', 'StandardScaler', 'drop', 'drop', 'fit', 'DataFrame', 'DataFrame', 'concat', 'concat', 'info', 'LogisticRegression', 'drop', 'fit', 'predict', 'tolist', 'to_csv']","['walk', 'print', 'read_csv', 'copy', 'head', 'info', 'drop', 'dropna', 'describe', 'unique', 'map', 'get_dummies', 'set', 'hist', 'xlabel', 'boxplot', 'quantile', 'reset_index', 'fillna', 'preprocess', 'StandardScaler', 'fit', 'DataFrame', 'concat', 'LogisticRegression', 'predict', 'tolist', 'to_csv']",28,"[1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv copy head info drop dropna describe head drop unique unique unique map head unique map head unique map head map head unique get dummies drop head copy describe set hist xlabel hist xlabel boxplot xlabel quantile reset index boxplot xlabel hist xlabel describe drop fillna map map map map get dummies drop copy read csv info unique preprocess head standardscaler drop drop fit dataframe dataframe concat concat info logisticregression drop fit predict tolist csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1550251807452076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10660809965021391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16969466548445628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08191660187734655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06842511865788994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14647984818633922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27955671058318393, 0.05951308280072927, 0.0, 0.0, 0.09868998914330805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03554579240152725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060183699492696655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.071703632335649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2602979921605624, 0.0, 0.0, 0.19409110965214574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07314765135688417, 0.0, 0.0, 0.13506430299073566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04569283021380552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3825644576785513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031220909639728317, 0.0, 0.0, 0.12003103158395738, 0.0, 0.0, 0.029128713870634745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12466193811205357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0543916320232654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08182796904997118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04908448289977677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0837827537395795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10705623168966881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5795059252557299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0579962342245338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35003949121554406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
niranjana55_titanic-prb.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'warnings\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,485,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Varies with sklearn version', '# Load the data set', ""# Remove the fields from the data set that we don't want to include in our model"", '# Replace categorical data with one-hot encoded data', '# Remove the from the feature data', '# Create the X and y arrays', '# Split the data set in a training set (70%) and a test set (30%)', '    439     # Create the parser.']",16,"['print', 'plt.style.use', 'warnings.filterwarnings', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'data.head', 'pd.read_csv', 'pd.get_dummies', 'features_df.as_matrix', 'df.as_matrix', 'features_df.to_csv', 'df.to_csv', 'train_test_split', 'len', 'data.PassengerId.max', 'data.count', 'data.value_counts', 'data.value_counts', 'len', 'plt.subplots', 'data.value_counts', 'None.plot.pie', 'ax.set_title', 'ax.set_ylabel', 'sns.countplot', 'ax.set_title', 'plt.show', 'data.value_counts', 'data.groupby', 'None.mean', 'plt.subplots', 'data.groupby', 'None.mean', 'None.plot.bar', 'ax.set_title', 'sns.countplot', 'ax.set_title', 'plt.show', 'data.value_counts', 'pd.crosstab', 'pd.crosstab', 'None.style.background_gradient', 'sns.light_palette', 'pd.crosstab', 'None.style.background_gradient', 'plt.subplots', 'data.value_counts', 'None.sort_index', 'None.plot.bar', 'ax.set_title', 'ax.set_ylabel', 'sns.countplot', 'ax.set_title', 'plt.show', 'pd.crosstab', 'None.style.background_gradient', 'pd.crosstab', 'None.style.background_gradient', 'sns.factorplot', 'plt.show', 'sns.factorplot', 'plt.show', 'data.min', 'data.max', 'get_ipython', 'None.run_line_magic', 'data.value_counts', 'None.plot', 'data.value_counts', 'None.plot', 'datadata.value_counts', 'None.sort_index', 'None.plot', 'pd.cut', 'data.head', 'datadata.value_counts', 'None.sort_index', 'None.plot', 'datadata.value_counts', 'None.sort_index', 'None.plot', 'plt.subplots', 'datadata.Age.plot.hist', 'ax.set_title', 'list', 'ax.set_xticks', 'datadata.Age.plot.hist', 'ax.set_title', 'list', 'ax.set_xticks', 'plt.show', 'data.groupby', 'None.count', 'data.fillna', 'sns.heatmap', 'plt.gcf', 'fig.set_size_inches', 'plt.show', 'data.apply', 'data.drop', 'data.dropna', 'data.head', 'train_test_split', 'pd.read_csv', 'data.head', 'pd.read_csv', 'data1.head', 'pd.read_csv', 'data.head', 'pd.read_csv', 'pd.read_csv', 'Titanic.head', 'Titanic.groupby', 'None.count', 'Titanic.value_counts', 'Titanic.value_counts', 'Titanic.value_counts', 'Titanic.value_counts', 'Titanic.value_counts', 'Titanic.set_index', 'v1.mean', 'Titanic.sort_values', 'Titanic1.max', 'len', 'Titanic.PassengerId.max', 'Titanic.count']","['print', 'style', 'filterwarnings', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'read_csv', 'get_dummies', 'as_matrix', 'as_matrix', 'to_csv', 'to_csv', 'train_test_split', 'len', 'PassengerId', 'count', 'value_counts', 'value_counts', 'len', 'subplots', 'value_counts', 'plot', 'set_title', 'set_ylabel', 'countplot', 'set_title', 'show', 'value_counts', 'groupby', 'mean', 'subplots', 'groupby', 'mean', 'plot', 'set_title', 'countplot', 'set_title', 'show', 'value_counts', 'crosstab', 'crosstab', 'style', 'light_palette', 'crosstab', 'style', 'subplots', 'value_counts', 'sort_index', 'plot', 'set_title', 'set_ylabel', 'countplot', 'set_title', 'show', 'crosstab', 'style', 'crosstab', 'style', 'factorplot', 'show', 'factorplot', 'show', 'min', 'max', 'get_ipython', 'run_line_magic', 'value_counts', 'plot', 'value_counts', 'plot', 'value_counts', 'sort_index', 'plot', 'cut', 'head', 'value_counts', 'sort_index', 'plot', 'value_counts', 'sort_index', 'plot', 'subplots', 'Age', 'set_title', 'list', 'set_xticks', 'Age', 'set_title', 'list', 'set_xticks', 'show', 'groupby', 'count', 'fillna', 'heatmap', 'gcf', 'set_size_inches', 'show', 'apply', 'drop', 'dropna', 'head', 'train_test_split', 'read_csv', 'head', 'read_csv', 'head', 'read_csv', 'head', 'read_csv', 'read_csv', 'head', 'groupby', 'count', 'value_counts', 'value_counts', 'value_counts', 'value_counts', 'value_counts', 'set_index', 'mean', 'sort_values', 'max', 'len', 'PassengerId', 'count']","['print', 'style', 'filterwarnings', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'get_dummies', 'as_matrix', 'to_csv', 'train_test_split', 'len', 'PassengerId', 'count', 'value_counts', 'subplots', 'plot', 'set_title', 'set_ylabel', 'countplot', 'show', 'groupby', 'mean', 'crosstab', 'light_palette', 'sort_index', 'factorplot', 'min', 'max', 'cut', 'Age', 'list', 'set_xticks', 'fillna', 'heatmap', 'gcf', 'set_size_inches', 'apply', 'drop', 'dropna', 'set_index', 'sort_values']",42,"[1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print style filterwarnings get ipython run line magic read csv head read csv get dummies matrix matrix csv csv train test split len passengerid count value counts value counts len subplots value counts plot set title set ylabel countplot set title show value counts groupby mean subplots groupby mean plot set title countplot set title show value counts crosstab crosstab style light palette crosstab style subplots value counts sort index plot set title set ylabel countplot set title show crosstab style crosstab style factorplot show factorplot show min max get ipython run line magic value counts plot value counts plot value counts sort index plot cut head value counts sort index plot value counts sort index plot subplots age set title list set xticks age set title list set xticks show groupby count fillna heatmap gcf set size inches show apply drop dropna head train test split read csv head read csv head read csv head read csv read csv head groupby count value counts value counts value counts value counts value counts set index mean sort values max len passengerid count,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059601180273223246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025090361141196334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15168797199603262, 0.0, 0.0, 0.08819197381495152, 0.48011667884373316, 0.0, 0.0, 0.0, 0.0, 0.1709357789972314, 0.11899185131506357, 0.0, 0.0, 0.0, 0.03280384567825886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016920140818773428, 0.028816185151042024, 0.0, 0.0, 0.02389280529484723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07584398599801631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0172112430910798, 0.0, 0.035418031895971876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06036120666027165, 0.0, 0.05207825863192352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0916726285991488, 0.0, 0.0, 0.0, 0.0, 0.11028156223147154, 0.031799328673788055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05811892557431934, 0.17709015947985937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04381350432072099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09261209783875766, 0.0, 0.0, 0.06664359396834366, 0.0, 0.04446946302444588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0677955321038759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044248860705969416, 0.0, 0.0, 0.0, 0.0, 0.07665051706127189, 0.0, 0.0892152916774159, 0.0, 0.0, 0.0, 0.0712999972805538, 0.0, 0.0, 0.0, 0.0, 0.04769843553505766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05183653826624733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1332871879366873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20298478126330904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014104099008254552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09217734031763089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04403021932292945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3327333206425845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20171329605729416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042711824193470596, 0.0, 0.0, 0.0, 0.13610671426905005, 0.0, 0.0, 0.0, 0.04607169402530493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16401922839129426, 0.0, 0.0, 0.0, 0.0, 0.12259639498803612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04804050399644413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19851183036019643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04728361370409303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48011667884373316, 0.027221342853810008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07834753428206669, 0.0, 0.06560769135651771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
germanocorrea_titanic-first-draft.py,"['numpy', 'pandas', 'random', 'seaborn', 'matplotlib', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,313,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# pegando mÃ©dia, desvio padrÃ£o e NaN no dataset de treino', '# mesma coisa com dataset de teste', '# Gerando nÃºmeros aleatÃ³rios entre mÃ©dia e desvio padrÃ£o.', '# desenhando plot original', '# Completando valores nulo com os valores aleatÃ³rios', '# logistic Regression', '# correlation']",15,"['get_ipython', 'None.run_line_magic', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'test_df.head', 'train_df.head', 'train_df.info', 'train_df.describe', 'train_df.drop', 'train_df.head', 'test_df.drop', 'train_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'train_df.mean', 'train_df.std', 'train_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'train_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'train_df.astype', 'test_df.astype', 'train_df.hist', 'train_df.drop', 'test_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'sns.countplot', 'np.isnan', 'train_df.drop', 'test_df.drop', 'None.copy', 'X_test.isnull', 'None.sum', 'X_train.dropna', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'SVC', 'svc.fit', 'svc.predict', 'svc.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'pd.DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'walk', 'print', 'read_csv', 'read_csv', 'head', 'head', 'info', 'describe', 'drop', 'head', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'countplot', 'countplot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'drop', 'drop', 'head', 'head', 'drop', 'drop', 'countplot', 'isnan', 'drop', 'drop', 'copy', 'isnull', 'sum', 'dropna', 'LogisticRegression', 'fit', 'predict', 'score', 'SVC', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'walk', 'print', 'read_csv', 'head', 'info', 'describe', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'set_title', 'mean', 'std', 'isnull', 'sum', 'random', 'dropna', 'astype', 'hist', 'isnan', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'SVC', 'RandomForestClassifier', 'DataFrame', 'Series', 'to_csv']",33,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic walk print read csv read csv head head info describe drop head drop fillna factorplot subplots countplot countplot countplot countplot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist drop drop head head drop drop countplot isnan drop drop copy isnull sum dropna logisticregression fit predict score svc fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18816847225636452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07803253662299979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41877675108949153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11300579575280606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09439399103728423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06735741565888499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3856547734339797, 0.16419927402918522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10804281842893103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04903622054553844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12453715174922436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049458387217948416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22442933623062508, 0.0, 0.0, 0.17850203574628012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06210808182741556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06241410482015875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31755642603248707, 0.20101577346252372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0633485444621533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06303428755797665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06303428755797665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13542629752902902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1292098423435568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040183716301312775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20758081121845393, 0.06091003658146243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0750344804132153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06272282408545483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19004563338645988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09200061697554725, 0.13542629752902902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21608563685786206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17464351153801877, 0.19996981229700173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0805186435859573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14139405624173304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08000711026835214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ashvsmay00_titanic-data-science-solutions-83f146.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,920,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'print', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'print', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop print name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14733322090580386, 0.0, 0.03859072198561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11403518823401397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035467372252156314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04427117110390127, 0.03424228574447042, 0.0, 0.0, 0.0, 0.042479832876641116, 0.0, 0.0, 0.0, 0.06435597822471563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03756287354343091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06123062605689409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2191099059788282, 0.03731595195772744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038858394223438134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19844755480231843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06686387357865907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1698139921422646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04628983439039069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022479841183750966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29678211972835744, 0.0, 0.0, 0.0, 0.0, 0.22441691818729764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05645876844124179, 0.0, 0.0, 0.0, 0.0, 0.05072865839027071, 0.0, 0.0, 0.0, 0.0, 0.02836847788425226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03832747428545516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1314290962885757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028793199674214214, 0.0, 0.0, 0.0, 0.05608735670178646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053861490781493444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028650363530656656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028650363530656656, 0.0, 0.0, 0.2398759441057209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3077700094768943, 0.042822343351686415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05016978970585915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042479832876641116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05608735670178646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1761854903877602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07305725976431357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043530287601185935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02768484833146435, 0.0, 0.0, 0.15436288794244, 0.0, 0.0, 0.0, 0.034104694832876134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1352448770302688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3793008031818164, 0.0, 0.028508797058503493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028793199674214214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041816148377496455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05608735670178646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3525068696058366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036597358344238606, 0.0, 0.0, 0.0, 0.05072865839027071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3525068696058366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0553103185337083, 0.0, 0.0]"
clumsyeater_the-titanic-project.py,"['numpy', 'pandas', 'subprocess']","[1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,21,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,['print'],['print'],['print'],1,"[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
pankajb64_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,292,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",53,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'astype', 'DataFrame', 'plot', 'subplots', 'set_title', 'mean', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'groupby', 'barplot', 'countplot', 'set_xticklabels', 'apply', 'get_dummies', 'join', 'factorplot', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'Series', 'to_csv']",41,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.05531477696171291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.097587776104379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21406682634679805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19776564306702984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05326347373618812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11433950733010957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07713553210754556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12886296101737785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5922908060694677, 0.056039596418661505, 0.0, 0.0, 0.18585987826143321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0596041119036182, 0.07374790146289982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033471159059814355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02833553625381506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16879660860857884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1337086367194334, 0.0, 0.0, 0.0, 0.0, 0.03063820958096772, 0.0, 0.0, 0.12184197649196712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08478750860559682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04260263957478946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14450517770945442, 0.09147294050863809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31557106340003643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04934373322449825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04324046968365662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04302596410577317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04302596410577317, 0.0, 0.0, 0.04502950612601986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23109831340214793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0986874664489965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02939869846588478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02742861388933184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14169057632828372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051217059572299405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04281336526935962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04324046968365662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06279781047827461, 0.23109831340214793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14749580292579964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06379450517665779, 0.0, 0.0, 0.0, 0.0, 0.2384164476144728, 0.0909969721713276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09651280000636145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07618225970146322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ragulshan_titanic-comprehensive-eda-to-ml.py,"['numpy', 'pandas', 'os\n', 'warnings\n', 'seaborn', 'matplotlib', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,1704,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', 'test = df.iloc[891:,:] # to submit our predictions', '# Setup random seed', ""gender_ratio =train_full.groupby(['male'])['Survived'].mean().to_frame() *100 # 0 means female and 1 means male."", '# from sklearn.metrics import plot_roc_curve', '# #Plotting Roc curve for diff models', '# fig,ax = plt.subplots(1,1,figsize=(10,5))', '# plot_roc_curve(log_model,x_val,y_val,ax=ax)', '# plot_roc_curve(clf,x_val,y_val,ax=ax);', '# #Plotting Roc curve for diff curves', '# fig,ax = plt.subplots(1,1,figsize=(10,5))', '# #Model with deafult settings', '# plot_roc_curve(tree,x_val,y_val,ax=ax)', '# #Best model', '# plot_roc_curve(tr_grid,x_val,y_val,ax=ax);', '# Number of trees in random forest', '# Number of features to consider at every split', '# Maximum number of levels in tree', '# Minimum number of samples required to split a node', '# Minimum number of samples required at each leaf node', '# Create the grid', '# #Plotting Roc curve for diff curves', '# fig,ax = plt.subplots(1,1,figsize=(10,5))', '# #Model with deafult settings', '# plot_roc_curve(rf,x_val,y_val,ax=ax)', '# #Best model', '# plot_roc_curve(rf_grid,x_val,y_val,ax=ax);', '# group data by Survived vs Non-Survived', '# and find nulls for cabin', '# from sklearn.ensemble import StackingClassifier', '# #Base level estimators', ""# estimators =[('rf',rf_grid),('tr',tr_grid),('gbm',gbm), ('xgb',xgb),('log',log_model)]"", '# #create a stacking model', '# stacking1 = StackingClassifier(estimators=estimators,', ""#                               final_estimator =SVC(kernel = 'rbf')"", '#                               )', '# #Training the stackers', '# stacking1.fit(x_train,y_train)', '# #Stacking classifier', '# from sklearn.ensemble import StackingClassifier', '# #Base level estimators', ""# estimators =[('rf',rf_grid),('tr',tr_grid),('gbm',gbm), ('xgb',xgb),('log',log_model)]"", '# #create a stacking model', '# stacking2 = StackingClassifier(estimators=estimators,', '#                               final_estimator =LogisticRegression(C=100))', '# #Training the stackers', '# stacking2.fit(x_train,y_train)', '# #Stacking model assessment(train-set)', ""# print('Stacking(svm) train-set score  ',stacking1.score(x_train,y_train)*100)"", ""# print('Stacking(logit) train-set score',stacking2.score(x_train,y_train)*100)"", '# #Stacking model assessment(Test-set)', ""# print('\\nStacking(svm) test-set score   ',stacking1.score(x_val,y_val)*100)"", ""# print('Stacking(logit) test-set score ',stacking2.score(x_val,y_val)*100)"", ""# #Kaggle doesn't support latest verison of sklearn modules which makes it hard to implement latest features"", '# #Lets plot confuison matrix (https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.py#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)', '# from sklearn.metrics import plot_confusion_matrix', '# np.set_printoptions(precision=3)', '# # Plot non-normalized confusion matrix', '# titles_options = [(""Confusion matrix, without normalization"", None),', '#                   (""Normalized confusion matrix"", \'true\')]', '# #svm with default settings', '# for title, normalize in titles_options:', '#     disp = plot_confusion_matrix(svm, x_val,y_val,', ""#                                  display_labels=['Not Survived','Survived'],"", '#                                  cmap=plt.cm.Blues,', '#                                  normalize=normalize)', '#     disp.ax_.set_title(title)', '#     print(title)', '#     print(disp.confusion_matrix)', '# ## Plotting CM', '# np.set_printoptions(precision=3)', '# # Plot non-normalized confusion matrix', '# titles_options = [(""Confusion matrix, without normalization"", None),', '#                   (""Normalized confusion matrix"", \'true\')]', '# #svm with default settings', '# for title, normalize in titles_options:', '#     disp = plot_confusion_matrix(grid_svm, x_val,y_val,', ""#                                  display_labels=['Not Survived','Survived'],"", '#                                  cmap=plt.cm.Blues,', '#                                  normalize=normalize)', '#     disp.ax_.set_title(title)', '#     print(title)', '#     print(disp.confusion_matrix)', '# #compare precision-Recall score', '# from sklearn.metrics import plot_precision_recall_curve', '# #compare both models', '# fig,ax = plt.subplots(1,1,figsize=(12,5))', '# plot_precision_recall_curve(svm, x_val,y_val,ax=ax)', ""# ax.set_title('PR Curve')"", '# plot_precision_recall_curve(grid_svm, x_val,y_val,ax=ax);']",91,"['os.walk', 'print', 'warnings.filterwarnings', 'get_ipython', 'None.run_line_magic', 'plt.style.use', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'df_train.head', 'df_test.head', 'df_train.info', 'df_train.dtypes.value_counts', 'None.sort_values', 'None.plot.barh', 'ax.set', 'print', 'print', 'df_train.nunique', 'None.to_frame', 'df_train.describe', 'df_train.describe', 'None.transpose', 'df_train.groupby', 'None.describe', 'df_train.corr', 'plt.figure', 'sns.heatmap', 'plt.title', 'df_train.corr', 'None.sort_values', 'None.to_frame', 'plt.figure', 'df_train.corr', 'None.sort_values', 'None.plot.bar', 'plt.ylabel', 'plt.xlabel', 'sns.distplot', 'plt.title', 'sns.boxplot', 'plt.subplots', 'sns.violinplot', 'sns.violinplot', 'sns.violinplot', 'df_train.groupby', 'None.agg', 'plt.subplots', 'sns.stripplot', 'sns.violinplot', 'sns.swarmplot', 'df_train.groupby', 'None.agg', 'df_train.groupby', 'None.agg', 'sns.FacetGrid', 'g.map', 'df_train.groupby', 'None.mean', 'None.to_frame', 'pd.crosstab', 'plt.figure', 'sns.boxplot', 'sns.stripplot', 'sns.FacetGrid', 'g.map', 'plt.figure', 'sns.boxplot', 'plt.figure', 'sns.distplot', 'plt.title', 'df_train.skew', 'sns.swarmplot', 'sns.scatterplot', 'plt.title', 'plt.subplots', 'sns.scatterplot', 'sns.scatterplot', 'plt.subplots', 'sns.boxplot', 'sns.boxplot', 'df_train.groupby', 'None.agg', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'df_train.groupby', 'None.agg', 'plt.figure', 'sns.boxplot', 'sns.stripplot', 'df_train.groupby', 'None.agg', 'plt.subplots', 'df_train.value_counts', 'None.plot.pie', 'ax.set_title', 'ax.set_ylabel', 'sns.countplot', 'ax.set_title', 'df_train.value_counts', 'None.plot.pie', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'print', 'df_train.groupby', 'None.count', 'None.unstack', 'sns.countplot', 'plt.ylabel', 'plt.legend', 'sns.countplot', 'plt.legend', 'pd.crosstab', 'sns.factorplot', 'plt.subplots', 'sns.factorplot', 'sns.factorplot', 'pd.concat', 'df.head', 'sns.heatmap', 'round', 'print', 'print', 'np.where', 'df.cabin_NA.value_counts', 'pd.crosstab', 'None.plot.pie', 'df.fillna', 'df.astype', 'pd.to_numeric', 'df.Embarked.fillna', 'df.drop', 'df.head', 'df.corrwith', 'None.to_frame', 'df.groupby', 'None.mean', 'None.to_frame', 'pd.isnull', 'df.apply', 'sns.heatmap', 'df.isnull', 'None.sum', 'df.drop', 'df.head', 'pd.cut', 'df.value_counts', 'None.round', 'None.to_frame', 'df.dtypes.to_frame', 'pd.cut', 'df.head', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'df.head', 'df.drop', 'df.head', 'train_test_split', 'model.predict', 'model.predict', 'accuracy_score', 'accuracy_score', 'roc_auc_score', 'roc_auc_score', 'np.random.seed', 'LogisticRegression', 'log_model.fit', 'log_model.predict', 'model_eval', 'np.random.seed', 'GridSearchCV', 'clf.fit', 'clf.predict', 'print', 'print', 'model_eval', 'clf.predict_proba', 'np.arange', 'binarize', 'thresh.append', 'accuracy_score', 'acc_score.append', 'pd.DataFrame', 'None.T.sort_values', 'None.set_index', 'None.head', 'pd.DataFrame', 'None.sort_values', 'co_eff.plot.barh', 'plt.subplots', 'df_train.groupby', 'None.size', 'None.unstack', 'None.plot.bar', 'df_train.groupby', 'None.size', 'None.unstack', 'None.plot.bar', 'pd.concat', 'train_full.groupby', 'None.size', 'None.to_frame', 'print', 'train_full.groupby', 'None.mean', 'None.round', 'None.to_frame', 'train_full.groupby', 'None.mean', 'None.to_frame', 'gender_ratio.stack', 'None.to_frame', 'cross_val_score', 'None.round', 'cross_val_score', 'None.round', 'print', 'print', 'DecisionTreeClassifier', 'tree.fit', 'tree.predict', 'model_eval', 'GridSearchCV', 'tr_grid.fit', 'tr_grid.predict', 'print', 'print', 'model_eval', 'cross_val_score', 'None.round', 'cross_val_score', 'None.round', 'print', 'print', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'model_eval', 'int', 'np.linspace', 'int', 'range', 'max_depth.append', 'RandomizedSearchCV', 'rf_grid.fit', 'print', 'print', 'model_eval', 'pd.DataFrame', 'None.sort_values', 'None.plot.barh', 'pd.concat', 'print', 'train_full.cabin_NA.value_counts', 'None.plot.pie', 'train_full.groupby', 'None.mean', 'None.round', 'cab_ratio.to_frame', 'plt.subplots', 'pd.crosstab', 'None.plot.bar', 'ax1.legend', 'pd.crosstab', 'None.plot.bar', 'ax2.legend', 'XGBClassifier', 'None.fit', 'pd.DataFrame', 'None.sort_values', 'None.plot.barh', 'gbm.predict', 'model_eval', 'XGBClassifier', 'xgb.fit', 'xgb.predict', 'model_eval', 'np.random.seed', 'SVC', 'svm.fit', 'svm.predict', 'print', 'print', 'GridSearchCV', 'grid_svm.fit', 'print', 'print', 'grid_svm.predict', 'print', 'print', 'print', 'VotingClassifier', 'None.fit', 'print', 'cross_val_score', 'print', 'VotingClassifier', 'None.fit', 'print', 'cross_val_score', 'print', 'cross_val_predict', 'accuracy_score', 'np.mean', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'SVC', 'SVC', 'LogisticRegression', 'RandomForestClassifier', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'pd.DataFrame', 'print', 'models_eval.sort_values', 'recall_score', 'recall_score', 'pd.DataFrame', 'pd.DataFrame', 'submission1.to_csv', 'submission1.head']","['walk', 'print', 'filterwarnings', 'get_ipython', 'run_line_magic', 'style', 'read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'head', 'head', 'info', 'dtypes', 'sort_values', 'plot', 'set', 'print', 'print', 'nunique', 'to_frame', 'describe', 'describe', 'transpose', 'groupby', 'describe', 'corr', 'figure', 'heatmap', 'title', 'corr', 'sort_values', 'to_frame', 'figure', 'corr', 'sort_values', 'plot', 'ylabel', 'xlabel', 'distplot', 'title', 'boxplot', 'subplots', 'violinplot', 'violinplot', 'violinplot', 'groupby', 'agg', 'subplots', 'stripplot', 'violinplot', 'swarmplot', 'groupby', 'agg', 'groupby', 'agg', 'FacetGrid', 'map', 'groupby', 'mean', 'to_frame', 'crosstab', 'figure', 'boxplot', 'stripplot', 'FacetGrid', 'map', 'figure', 'boxplot', 'figure', 'distplot', 'title', 'skew', 'swarmplot', 'scatterplot', 'title', 'subplots', 'scatterplot', 'scatterplot', 'subplots', 'boxplot', 'boxplot', 'groupby', 'agg', 'FacetGrid', 'map', 'add_legend', 'groupby', 'agg', 'figure', 'boxplot', 'stripplot', 'groupby', 'agg', 'subplots', 'value_counts', 'plot', 'set_title', 'set_ylabel', 'countplot', 'set_title', 'value_counts', 'plot', 'subplots', 'countplot', 'countplot', 'countplot', 'subplots', 'countplot', 'countplot', 'countplot', 'countplot', 'print', 'groupby', 'count', 'unstack', 'countplot', 'ylabel', 'legend', 'countplot', 'legend', 'crosstab', 'factorplot', 'subplots', 'factorplot', 'factorplot', 'concat', 'head', 'heatmap', 'round', 'print', 'print', 'where', 'cabin_NA', 'crosstab', 'plot', 'fillna', 'astype', 'to_numeric', 'Embarked', 'drop', 'head', 'corrwith', 'to_frame', 'groupby', 'mean', 'to_frame', 'isnull', 'apply', 'heatmap', 'isnull', 'sum', 'drop', 'head', 'cut', 'value_counts', 'round', 'to_frame', 'dtypes', 'cut', 'head', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'get_dummies', 'concat', 'head', 'drop', 'head', 'train_test_split', 'predict', 'predict', 'accuracy_score', 'accuracy_score', 'roc_auc_score', 'roc_auc_score', 'random', 'LogisticRegression', 'fit', 'predict', 'model_eval', 'random', 'GridSearchCV', 'fit', 'predict', 'print', 'print', 'model_eval', 'predict_proba', 'arange', 'binarize', 'append', 'accuracy_score', 'append', 'DataFrame', 'T', 'set_index', 'head', 'DataFrame', 'sort_values', 'plot', 'subplots', 'groupby', 'size', 'unstack', 'plot', 'groupby', 'size', 'unstack', 'plot', 'concat', 'groupby', 'size', 'to_frame', 'print', 'groupby', 'mean', 'round', 'to_frame', 'groupby', 'mean', 'to_frame', 'stack', 'to_frame', 'cross_val_score', 'round', 'cross_val_score', 'round', 'print', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'model_eval', 'GridSearchCV', 'fit', 'predict', 'print', 'print', 'model_eval', 'cross_val_score', 'round', 'cross_val_score', 'round', 'print', 'print', 'RandomForestClassifier', 'fit', 'predict', 'model_eval', 'int', 'linspace', 'int', 'range', 'append', 'RandomizedSearchCV', 'fit', 'print', 'print', 'model_eval', 'DataFrame', 'sort_values', 'plot', 'concat', 'print', 'cabin_NA', 'plot', 'groupby', 'mean', 'round', 'to_frame', 'subplots', 'crosstab', 'plot', 'legend', 'crosstab', 'plot', 'legend', 'XGBClassifier', 'fit', 'DataFrame', 'sort_values', 'plot', 'predict', 'model_eval', 'XGBClassifier', 'fit', 'predict', 'model_eval', 'random', 'SVC', 'fit', 'predict', 'print', 'print', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'print', 'print', 'print', 'VotingClassifier', 'fit', 'print', 'cross_val_score', 'print', 'VotingClassifier', 'fit', 'print', 'cross_val_score', 'print', 'cross_val_predict', 'accuracy_score', 'mean', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'SVC', 'SVC', 'LogisticRegression', 'RandomForestClassifier', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'model_fit', 'DataFrame', 'print', 'sort_values', 'recall_score', 'recall_score', 'DataFrame', 'DataFrame', 'to_csv', 'head']","['walk', 'print', 'filterwarnings', 'get_ipython', 'run_line_magic', 'style', 'read_csv', 'head', 'info', 'dtypes', 'sort_values', 'plot', 'set', 'nunique', 'to_frame', 'describe', 'transpose', 'groupby', 'corr', 'figure', 'heatmap', 'title', 'ylabel', 'xlabel', 'distplot', 'boxplot', 'subplots', 'violinplot', 'agg', 'stripplot', 'swarmplot', 'FacetGrid', 'map', 'mean', 'crosstab', 'skew', 'scatterplot', 'add_legend', 'value_counts', 'set_title', 'set_ylabel', 'countplot', 'count', 'unstack', 'legend', 'factorplot', 'concat', 'round', 'where', 'cabin_NA', 'fillna', 'astype', 'to_numeric', 'Embarked', 'drop', 'corrwith', 'isnull', 'apply', 'sum', 'cut', 'get_dummies', 'train_test_split', 'predict', 'accuracy_score', 'roc_auc_score', 'random', 'LogisticRegression', 'fit', 'model_eval', 'GridSearchCV', 'predict_proba', 'arange', 'binarize', 'append', 'DataFrame', 'T', 'set_index', 'size', 'stack', 'cross_val_score', 'DecisionTreeClassifier', 'RandomForestClassifier', 'int', 'linspace', 'range', 'RandomizedSearchCV', 'XGBClassifier', 'SVC', 'VotingClassifier', 'cross_val_predict', 'KNeighborsClassifier', 'model_fit', 'recall_score', 'to_csv']",94,"[1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0
 1 0 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print filterwarnings get ipython run line magic style read csv read csv print print print print head head info dtypes sort values plot set print print nunique frame describe describe transpose groupby describe corr figure heatmap title corr sort values frame figure corr sort values plot ylabel xlabel distplot title boxplot subplots violinplot violinplot violinplot groupby agg subplots stripplot violinplot swarmplot groupby agg groupby agg facetgrid map groupby mean frame crosstab figure boxplot stripplot facetgrid map figure boxplot figure distplot title skew swarmplot scatterplot title subplots scatterplot scatterplot subplots boxplot boxplot groupby agg facetgrid map add legend groupby agg figure boxplot stripplot groupby agg subplots value counts plot set title set ylabel countplot set title value counts plot subplots countplot countplot countplot subplots countplot countplot countplot countplot print groupby count unstack countplot ylabel legend countplot legend crosstab factorplot subplots factorplot factorplot concat head heatmap round print print cabin na crosstab plot fillna astype numeric embarked drop head corrwith frame groupby mean frame isnull apply heatmap isnull sum drop head cut value counts round frame dtypes cut head get dummies get dummies get dummies concat get dummies concat head drop head train test split predict predict accuracy score accuracy score roc auc score roc auc score random logisticregression fit predict model eval random gridsearchcv fit predict print print model eval predict proba arange binarize append accuracy score append dataframe set index head dataframe sort values plot subplots groupby size unstack plot groupby size unstack plot concat groupby size frame print groupby mean round frame groupby mean frame stack frame cross val score round cross val score round print print decisiontreeclassifier fit predict model eval gridsearchcv fit predict print print model eval cross val score round cross val score round print print randomforestclassifier fit predict model eval int linspace int range append randomizedsearchcv fit print print model eval dataframe sort values plot concat print cabin na plot groupby mean round frame subplots crosstab plot legend crosstab plot legend xgbclassifier fit dataframe sort values plot predict model eval xgbclassifier fit predict model eval random svc fit predict print print gridsearchcv fit print print predict print print print votingclassifier fit print cross val score print votingclassifier fit print cross val score print cross val predict accuracy score mean kneighborsclassifier decisiontreeclassifier svc svc logisticregression randomforestclassifier model fit model fit model fit model fit model fit model fit model fit dataframe print sort values recall score recall score dataframe dataframe csv head,"[0.0, 0.0, 0.08103713045735297, 0.0, 0.0, 0.016120523005322292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17627215599589255, 0.0, 0.0, 0.0, 0.04931948110929025, 0.014220124134440397, 0.02610264871410853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012477205507629435, 0.06022616411837919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0405968812306262, 0.0, 0.12762742725161583, 0.0, 0.04543707333585633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07313928731414227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057635333157559344, 0.0, 0.0405968812306262, 0.021492534317724986, 0.0, 0.0, 0.16661123478885762, 0.05102048003926921, 0.0, 0.0, 0.14739726152074106, 0.0, 0.09687895613295266, 0.022479799940767195, 0.0, 0.0, 0.0, 0.03718358257234914, 0.0, 0.0, 0.0, 0.0657209930692082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032879654072860164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040197439922046704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040900520763022294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028768797084404708, 0.0, 0.0, 0.05742871330191613, 0.0541656065133134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017006826679756403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26351420980390633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05211172366215001, 0.06447760295317495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09929758236175104, 0.0, 0.0, 0.0, 0.009754583120022586, 0.0, 0.020073398199571508, 0.0, 0.0, 0.0, 0.15690002009616466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3763111385530345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0491928154058802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05967702750488843, 0.0, 0.0, 0.2078242160125703, 0.0, 0.0, 0.0, 0.0, 0.0892896960849612, 0.054067424369274156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020073398199571508, 0.0, 0.0, 0.0123549172401667, 0.0, 0.0, 0.0, 0.0, 0.04440397078577845, 0.0, 0.0, 0.0, 0.0, 0.012415793194433594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026658186524997508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016774463414455612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07190183440173611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012601677609200328, 0.0, 0.0, 0.0, 0.0, 0.030113082059189594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02507832743042155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012539163715210775, 0.0, 0.0, 0.039369182845584716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08081946739698417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39828747749525095, 0.0, 0.0, 0.0, 0.0, 0.07554137412865503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03093405955294775, 0.0, 0.0, 0.0, 0.027033396231728447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1869447694445139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11138056542395916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27178203125443934, 0.0, 0.02610264871410853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061939855517770676, 0.024233189591996423, 0.0, 0.03093405955294775, 0.01688967682200495, 0.0, 0.0, 0.0, 0.014926315036426885, 0.0, 0.06022616411837919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056215730773298125, 0.0, 0.0, 0.1475603496717649, 0.0, 0.012477205507629435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09881782867646487, 0.17642348652880457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06734955616415347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07262160619628927, 0.0405968812306262, 0.0, 0.0, 0.10799510242849314, 0.0, 0.0, 0.0, 0.013055714990249717, 0.0, 0.0, 0.03777068706432751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10263031051446395, 0.01859179128617457, 0.0, 0.0, 0.0, 0.0, 0.1737057455405, 0.013259736944414624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048051774351652546, 0.06842020700964263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01361363287013139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08438089593423755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013399146640682235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030113082059189594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08110018869518534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14739726152074106, 0.0, 0.0, 0.05102048003926921, 0.10799510242849314, 0.0, 0.0, 0.0, 0.13175710490195316, 0.0, 0.05406679246345689, 0.0, 0.0, 0.015915500799672896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04169733791211348, 0.0, 0.0, 0.0, 0.01921177771918645, 0.0, 0.0, 0.0, 0.0, 0.055775373858523714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sjessies_ml-titanic-1-0.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,249,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# load of test and training data', '# Exploring and understand the data set', '# Scan training data, null data count', '# Mapping unique values from Embarked', '# Clean data process ', '    # Fill de Nan Valuen in Fare an Age ', '    # Fill the Nan values in Age Column', '# Create classifier object', '# Train the classifier (fit the estimator) using the training data', '# Estimate the accuracy of the classifier on future data, using the test data', '# Clean data process ', '    # Fill de Nan Valuen in Fare an Age ', '    # Fill the Nan values in Age Column', ""# Add the column ['predicted_survived'] to data set""]",22,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_raw_data.head', 'print', 'train_raw_data.isnull', 'None.sum', 'dict', 'df.fillna', 'df.fillna', 'df.dropna', 'df.drop', 'clean_data', 'clean_train_data.isnull', 'None.sum', 'clean_train_data.drop', 'clean_train_data.get', 'train_test_split', 'KNeighborsClassifier', 'knn.fit', 'knn.score', 'test_raw_data.head', 'print', 'test_raw_data.isnull', 'None.sum', 'df.fillna', 'df.fillna', 'df.dropna', 'df.drop', 'clean_data', 'clean_test_data.isnull', 'None.sum', 'knn.predict', 'clean_test_data.head', 'pd.DataFrame', 'submission.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'head', 'print', 'isnull', 'sum', 'dict', 'fillna', 'fillna', 'dropna', 'drop', 'clean_data', 'isnull', 'sum', 'drop', 'get', 'train_test_split', 'KNeighborsClassifier', 'fit', 'score', 'head', 'print', 'isnull', 'sum', 'fillna', 'fillna', 'dropna', 'drop', 'clean_data', 'isnull', 'sum', 'predict', 'head', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'isnull', 'sum', 'dict', 'fillna', 'dropna', 'drop', 'clean_data', 'get', 'train_test_split', 'KNeighborsClassifier', 'fit', 'score', 'predict', 'DataFrame', 'to_csv']",19,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv head print isnull sum dict fillna fillna dropna drop clean data isnull sum drop get train test split kneighborsclassifier fit score head print isnull sum fillna fillna dropna drop clean data isnull sum predict head dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4884298758811658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1534972946619446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3564698948997857, 0.0, 0.06410831479945217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21122494269523787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19644002770354965, 0.22303408582749065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26642623571808133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05638683028324626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06717999360762406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1829072344016735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3640565772793947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11453993186368311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05850248980980505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.163746249489901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10192034552800557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08604718130548616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08914745398807737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3621622530911584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09295704684170672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09149248505515006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10867473564608736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
alexeydudchenko_titanic-1.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,96,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'pd.read_csv', 'train_x.head', 'LabelEncoder', 'label_encoder.fit_transform', 'label_encoder.fit_transform', 'train_x.replace', 'test_x.replace', 'train_x.info', 'train_x.fillna', 'train_x.astype', 'test_x.fillna', 'test_x.astype', 'RandomForestRegressor', 'rf_model.fit', 'rf_model.score', 'rf_model.predict', 'None.round', 'None.astype', 'pd.DataFrame', 'out.to_csv']","['print', 'read_csv', 'read_csv', 'head', 'LabelEncoder', 'fit_transform', 'fit_transform', 'replace', 'replace', 'info', 'fillna', 'astype', 'fillna', 'astype', 'RandomForestRegressor', 'fit', 'score', 'predict', 'round', 'astype', 'DataFrame', 'to_csv']","['print', 'read_csv', 'head', 'LabelEncoder', 'fit_transform', 'replace', 'info', 'fillna', 'astype', 'RandomForestRegressor', 'fit', 'score', 'predict', 'round', 'DataFrame', 'to_csv']",16,"[1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv head labelencoder fit transform fit transform replace replace info fillna astype fillna astype randomforestregressor fit score predict round astype dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4403870598255782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26447730344021436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11045923814876894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2295274732484083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29146513993678735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10505030341805109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1453569517752028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22993444019921885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10080034819839634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0940454501362501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.363942591863805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1756097279128446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34819716425078334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2170079553572286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14826011448883408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35864729462523215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
francoisolivier_titanic4.py,"['pandas', 'xgboost', 'sklearn', 'numpy']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,70,"['# This script shows you how to make a submission using a few', '# useful Python libraries.', '# It gets a public leaderboard score of 0.76077.', '# Maybe you can tweak it and do better...?', '# Load the data', ""# We'll impute missing values using the median for numeric columns and the most"", '# common value for string columns.', ""# This is based on some nice code by 'sveitser' at http://stackoverflow.com/a/25562948"", '# Join the features from train and test together before imputing missing values,', '# in case their distribution is slightly different', ""# XGBoost doesn't (yet) handle categorical features automatically, so we need to change"", '# them to columns of integer values.', '# See http://scikit-learn.org/stable/modules/preprocessing.py#preprocessing for more', '# details and options', '# Prepare the inputs for the model', '# You can experiment with many other options here, using the same .fit() and .predict()', '# methods; see http://scikit-learn.org', '# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost', '# Kaggle needs the submission to have a certain format;', '# see https://www.kaggle.com/c/titanic-gettingStarted/download/gendermodel.csv', ""# for an example of what it's supposed to look like.""]",21,"['pd.read_csv', 'pd.read_csv', 'pd.Series', 'X.fillna', 'train_dffeature_columns_to_use.append', 'DataFrameImputer', 'None.fit_transform', 'LabelEncoder', 'le.fit_transform', 'big_X_imputedtrain_df.shape.as_matrix', 'big_X_imputedtrain_df.shape.as_matrix', 'xgb.XGBClassifier', 'None.fit', 'gbm.predict', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'read_csv', 'Series', 'fillna', 'append', 'DataFrameImputer', 'fit_transform', 'LabelEncoder', 'fit_transform', 'shape', 'shape', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']","['read_csv', 'Series', 'fillna', 'append', 'DataFrameImputer', 'fit_transform', 'LabelEncoder', 'shape', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",13,"[0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv series fillna append dataframeimputer fit transform labelencoder fit transform shape shape xgbclassifier fit predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1621509165787931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22172497051373113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09260367904137139, 0.4004191459678461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09621236222562814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24435026642228805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19276590584563225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08450613319685299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14722269637856325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1805113972275334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.67484890531631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30067253329957266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20563663919219288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
penguincwarrior_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,394,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'print', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'print', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'info', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic print read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.044551584915690834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07859907121847379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17241353785486707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2123790018860124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04289942585694503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18418247527461015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06212644066313336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10378870648302234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5830518262901987, 0.04513536844259797, 0.0, 0.0, 0.2245426792875508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04800629774999196, 0.11879595561426769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053916630129850096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0456439714261983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19033284769376027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14358867581659754, 0.0, 0.0, 0.0, 0.0, 0.02467660308485039, 0.0, 0.0, 0.09813387055207219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06828948966108496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03431298504489221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11638724856354175, 0.07367406505822652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3812505030364552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03974239148302179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03482670567828912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03465393876151065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03465393876151065, 0.0, 0.0, 0.03626763002720912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22335722999736887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07948478296604358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047356554000759256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04418306600625309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11412031449411865, 0.03348610350698356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04125120454244409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034482707570973416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06965341135657824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050578563988042786, 0.1861310249978074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11879595561426769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051381321061813, 0.0, 0.0, 0.0, 0.0, 0.24003148874995978, 0.07329071100779717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07773326480030245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06135865673847326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
vitorishi_titanic-a-beginner-approach-with-neural-networks.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn', 'tensorflow']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,566,"[' # Mapping Age', '# Mapping titles', '# Mapping Embarked', '# Mapping Fare', '# ']",5,"['get_ipython', 'None.run_line_magic', 'sns.set', 'pd.read_csv', 'pd.read_csv', 'df.head', 'sns.pairplot', 'df.info', 'df.describe', 'None.transpose', 'sns.heatmap', 'df.isnull', 'None.sum', 'df.drop', 'df_test.drop', 'df.apply', 'df.groupby', 'None.sum', 'df.groupby', 'None.count', 'family_survival.head', 'family_survival.value_counts', 'sns.boxplot', 'sns.scatterplot', 'sns.FacetGrid', 'g.map', 'df.apply', 'df.apply', 'df.value_counts', 'df.value_counts', 'df.value_counts', 'df.isin', 'None.groupby', 'None.describe', 'df.replace', 'df.replace', 'df.replace', 'df.replace', 'df_test.apply', 'df_test.value_counts', 'df_test.value_counts', 'df_test.value_counts', 'df_test.isin', 'None.groupby', 'None.describe', 'df_test.replace', 'df_test.replace', 'df_test.replace', 'df_test.replace', 'df_test.value_counts', 'df.value_counts', 'plt.figure', 'sns.boxplot', 'df.groupby', 'None.apply', 'df_test.groupby', 'None.apply', 'df.astype', 'df_test.astype', 'df.map', 'df.fillna', 'df_test.map', 'df_test.fillna', 'df.fillna', 'df_test.fillna', 'df.map', 'None.astype', 'df_test.map', 'None.astype', 'df.fillna', 'df_test.fillna', 'df.astype', 'df_test.astype', 'df.head', 'sns.heatmap', 'df.isnull', 'None.sum', 'df_test.isnull', 'None.sum', 'df_test.isnull', 'None.sum', 'df.drop', 'df_test.drop', 'df.apply', 'df_test.apply', 'plt.figure', 'sns.heatmap', 'pd.get_dummies', 'pd.get_dummies', 'df_dummies.head', 'df_dummies.drop', 'df_dummies_test.drop', 'df_dummies_test.head', 'df_dummies.drop', 'df_dummies.drop', 'train_test_split', 'MinMaxScaler', 'scaler.fit', 'scaler.transform', 'scaler.transform', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'EarlyStopping', 'model.fit', 'RandomForestClassifier', 'rfc.fit', 'LogisticRegression', 'logreg.fit', 'pd.DataFrame', 'model_loss.plot', 'model.predict_classes', 'print', 'print', 'rfc.predict', 'print', 'print', 'logreg.predict', 'print', 'print', 'df_dummies_test.head', 'scaler.transform', 'model.predict_classes', 'pd.DataFrame', 'output.reset_index', 'output.to_csv']","['get_ipython', 'run_line_magic', 'set', 'read_csv', 'read_csv', 'head', 'pairplot', 'info', 'describe', 'transpose', 'heatmap', 'isnull', 'sum', 'drop', 'drop', 'apply', 'groupby', 'sum', 'groupby', 'count', 'head', 'value_counts', 'boxplot', 'scatterplot', 'FacetGrid', 'map', 'apply', 'apply', 'value_counts', 'value_counts', 'value_counts', 'isin', 'groupby', 'describe', 'replace', 'replace', 'replace', 'replace', 'apply', 'value_counts', 'value_counts', 'value_counts', 'isin', 'groupby', 'describe', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'value_counts', 'figure', 'boxplot', 'groupby', 'apply', 'groupby', 'apply', 'astype', 'astype', 'map', 'fillna', 'map', 'fillna', 'fillna', 'fillna', 'map', 'astype', 'map', 'astype', 'fillna', 'fillna', 'astype', 'astype', 'head', 'heatmap', 'isnull', 'sum', 'isnull', 'sum', 'isnull', 'sum', 'drop', 'drop', 'apply', 'apply', 'figure', 'heatmap', 'get_dummies', 'get_dummies', 'head', 'drop', 'drop', 'head', 'drop', 'drop', 'train_test_split', 'MinMaxScaler', 'fit', 'transform', 'transform', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'compile', 'EarlyStopping', 'fit', 'RandomForestClassifier', 'fit', 'LogisticRegression', 'fit', 'DataFrame', 'plot', 'predict_classes', 'print', 'print', 'predict', 'print', 'print', 'predict', 'print', 'print', 'head', 'transform', 'predict_classes', 'DataFrame', 'reset_index', 'to_csv']","['get_ipython', 'run_line_magic', 'set', 'read_csv', 'head', 'pairplot', 'info', 'describe', 'transpose', 'heatmap', 'isnull', 'sum', 'drop', 'apply', 'groupby', 'count', 'value_counts', 'boxplot', 'scatterplot', 'FacetGrid', 'map', 'isin', 'replace', 'figure', 'astype', 'fillna', 'get_dummies', 'train_test_split', 'MinMaxScaler', 'fit', 'transform', 'Sequential', 'add', 'compile', 'EarlyStopping', 'RandomForestClassifier', 'LogisticRegression', 'DataFrame', 'plot', 'predict_classes', 'print', 'predict', 'reset_index', 'to_csv']",44,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic set read csv read csv head pairplot info describe transpose heatmap isnull sum drop drop apply groupby sum groupby count head value counts boxplot scatterplot facetgrid map apply apply value counts value counts value counts isin groupby describe replace replace replace replace apply value counts value counts value counts isin groupby describe replace replace replace replace value counts value counts figure boxplot groupby apply groupby apply astype astype map fillna map fillna fillna fillna map astype map astype fillna fillna astype astype head heatmap isnull sum isnull sum isnull sum drop drop apply apply figure heatmap get dummies get dummies head drop drop head drop drop train test split minmaxscaler fit transform transform sequential add add add add add add add compile earlystopping fit randomforestclassifier fit logisticregression fit dataframe plot predict classes print print predict print print predict print print head transform predict classes dataframe reset index csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.28513583530593517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28745377000053746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18916605764113614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10749725990463388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14846944873129317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06488898832007252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05430780665209628, 0.0, 0.0, 0.0, 0.38675900072677855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0568024510610723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04744721295607968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10157177198946754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19384967159003966, 0.0, 0.0, 0.0, 0.06843342069931205, 0.0, 0.0, 0.0, 0.0, 0.09543979969429028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04389234840207652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0836357689636637, 0.0, 0.0, 0.0, 0.14788856620331692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08346492815282582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07458089031961847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19692554355129296, 0.0, 0.0, 0.0, 0.0, 0.1353714963341689, 0.13661875260572756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05072190241305429, 0.0, 0.0, 0.031218675599753425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03137249829489096, 0.0, 0.0, 0.0, 0.1664633698445259, 0.0, 0.0, 0.0, 0.13472097967535818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03184219510716797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03168423363004918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03168423363004918, 0.0, 0.0, 0.16579818976689797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06961381102641867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07102357015023561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036336626131616305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08659657023118073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12119025737318363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03061647722577743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03771613989505326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29913269871840226, 0.0, 0.0, 0.05674099145796361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03152767627352269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08323168492226295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07102357015023561, 0.0, 0.034036066851836105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032989466710336666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16752496927294697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0343992258341536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03385725732982252, 0.0, 0.0, 0.0, 0.11554136292308086, 0.0, 0.07609039557612694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38675900072677855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
manjureddygl_titanic-prediction.py,"['pandas', 'numpy', 'sklearn', 'xgboost', 'matplotlib', 'seaborn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,660,"['# Importing Classifier Modules', 'import matplotlib.pyplot as plt # Plot the graphes', 'sns.set() # setting seaborn default for plots', '# delete unnecessary feature from dataset', '# fill missing Fare with median fare for each Pclass', '# fill missing Fare with median fare for each Pclass', '# machine learning', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Decision Tree', '# Random Forest']",12,"['pd.read_csv', 'pd.read_csv', 'train.head', 'test.head', 'train.describe', 'test.describe', 'train.info', 'test.info', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'get_ipython', 'None.run_line_magic', 'sns.set', 'traintrainfeature.value_counts', 'traintrainfeature.value_counts', 'pd.DataFrame', 'df.plot', 'bar_chart', 'print', 'print', 'print', 'bar_chart', 'print', 'print', 'bar_chart', 'print', 'print', 'bar_chart', 'print', 'print', 'bar_chart', 'print', 'print', 'train.head', 'dataset.str.extract', 'train.value_counts', 'test.value_counts', 'dataset.map', 'dataset.head', 'test.head', 'bar_chart', 'train.drop', 'test.drop', 'dataset.map', 'bar_chart', 'train.fillna', 'test.fillna', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.show', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.xlim', 'bar_chart', 'traintrain.value_counts', 'traintrain.value_counts', 'traintrain.value_counts', 'pd.DataFrame', 'df.plot', 'plt.show', 'print', 'print', 'print', 'dataset.fillna', 'train.head', 'dataset.map', 'train.fillna', 'test.fillna', 'train.head', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.show', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.xlim', 'train.head', 'train.Cabin.value_counts', 'traintrain.value_counts', 'traintrain.value_counts', 'traintrain.value_counts', 'pd.DataFrame', 'df.plot', 'dataset.map', 'train.fillna', 'test.fillna', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.xlim', 'dataset.map', 'train.head', 'train.drop', 'test.drop', 'None.copy', 'X_train.drop', 'X_train.head', 'Y_train.head', 'X_test.drop', 'X_test.head', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'XGBClassifier', 'xgb_classifier.fit', 'xgb_classifier.predict', 'xgb_classifier.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv', 'submission.head']","['read_csv', 'read_csv', 'head', 'head', 'describe', 'describe', 'info', 'info', 'isnull', 'sum', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'set', 'value_counts', 'value_counts', 'DataFrame', 'plot', 'bar_chart', 'print', 'print', 'print', 'bar_chart', 'print', 'print', 'bar_chart', 'print', 'print', 'bar_chart', 'print', 'print', 'bar_chart', 'print', 'print', 'head', 'str', 'value_counts', 'value_counts', 'map', 'head', 'head', 'bar_chart', 'drop', 'drop', 'map', 'bar_chart', 'fillna', 'fillna', 'FacetGrid', 'map', 'set', 'add_legend', 'show', 'FacetGrid', 'map', 'set', 'add_legend', 'xlim', 'bar_chart', 'value_counts', 'value_counts', 'value_counts', 'DataFrame', 'plot', 'show', 'print', 'print', 'print', 'fillna', 'head', 'map', 'fillna', 'fillna', 'head', 'FacetGrid', 'map', 'set', 'add_legend', 'show', 'FacetGrid', 'map', 'set', 'add_legend', 'xlim', 'head', 'Cabin', 'value_counts', 'value_counts', 'value_counts', 'DataFrame', 'plot', 'map', 'fillna', 'fillna', 'FacetGrid', 'map', 'set', 'add_legend', 'xlim', 'map', 'head', 'drop', 'drop', 'copy', 'drop', 'head', 'head', 'drop', 'head', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'XGBClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv', 'head']","['read_csv', 'head', 'describe', 'info', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'set', 'value_counts', 'DataFrame', 'plot', 'bar_chart', 'print', 'str', 'map', 'drop', 'fillna', 'FacetGrid', 'add_legend', 'show', 'xlim', 'Cabin', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'Series', 'sort_values', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score', 'XGBClassifier', 'to_csv']",38,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head head describe describe info info isnull sum isnull sum get ipython run line magic set value counts value counts dataframe plot bar chart print print print bar chart print print bar chart print print bar chart print print bar chart print print head str value counts value counts map head head bar chart drop drop map bar chart fillna fillna facetgrid map set add legend show facetgrid map set add legend xlim bar chart value counts value counts value counts dataframe plot show print print print fillna head map fillna fillna head facetgrid map set add legend show facetgrid map set add legend xlim head cabin value counts value counts value counts dataframe plot map fillna fillna facetgrid map set add legend xlim map head drop drop copy drop head head drop head logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round xgbclassifier fit predict score round dataframe sort values dataframe csv head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.13999457817472655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35681938479964637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03945866962906363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5640852482232341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026960598767231753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29538291361106905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03904401996288741, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09784066859273874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028553498549279622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04654459117100119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09993411779743978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15085033261910913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11859567138050156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10039903129564277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035187316475780196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017088099287348658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20160754505331757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042917253412925835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021564359051942827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046301246879373106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029134711436332176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12488263530577488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021887212227685734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021778635028096894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021778635028096894, 0.0, 0.0, 0.22792776403642595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07492958118346493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10416604862842967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19437121214886913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02104469658732321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025924756616615533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2242538010484452, 0.0, 0.02167102297193782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04377442445537147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03178663449836403, 0.1403712180158346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0850974017356265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05359176996011053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036210991604230865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046060323964136805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027819560108505934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29538291361106905, 0.05359176996011053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036210991604230865, 0.0, 0.0, 0.0, 0.0, 0.15307906644497363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
akashadesai_eda-predicting-titanic-survivors-using-ml.py,"['warnings\n', 'pandas', 'matplotlib', 'numpy', 'seaborn', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,359,"[' #   Column       Non-Null Count  Dtype  ', '# 3rd class people not survuved mostly', '# most of parents dont have child .i.e indicates in 0', '# 88% accuracy model']",4,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'warnings.filterwarnings', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.concat', 'train.head', 'plt.figure', 'sns.heatmap', 'train.info', 'print', 'train.value_counts', 'train.value_counts', 'train.value_counts', 'train.value_counts', 'train.value_counts', 'plt.Circle', 'plt.pie', 'plt.title', 'plt.gcf', 'plt.legend', 'plt.show', 'sns.relplot', 'sns.countplot', 'sns.countplot', 'sns.distplot', 'sns.countplot', 'plt.figure', 'sns.boxplot', 'pd.isnull', 'train.apply', 'sns.heatmap', 'train.drop', 'train.head', 'train.dropna', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'train.drop', 'train.head', 'train.drop', 'np.array', 'np.array', 'train_test_split', 'np.array', 'np.array', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'confusion_matrix', 'sns.heatmap', 'plt.show']","['get_ipython', 'run_line_magic', 'filterwarnings', 'filterwarnings', 'walk', 'print', 'read_csv', 'read_csv', 'concat', 'head', 'figure', 'heatmap', 'info', 'print', 'value_counts', 'value_counts', 'value_counts', 'value_counts', 'value_counts', 'Circle', 'pie', 'title', 'gcf', 'legend', 'show', 'relplot', 'countplot', 'countplot', 'distplot', 'countplot', 'figure', 'boxplot', 'isnull', 'apply', 'heatmap', 'drop', 'head', 'dropna', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'drop', 'head', 'drop', 'array', 'array', 'train_test_split', 'array', 'array', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix', 'heatmap', 'show']","['get_ipython', 'run_line_magic', 'filterwarnings', 'walk', 'print', 'read_csv', 'concat', 'head', 'figure', 'heatmap', 'info', 'value_counts', 'Circle', 'pie', 'title', 'gcf', 'legend', 'show', 'relplot', 'countplot', 'distplot', 'boxplot', 'isnull', 'apply', 'drop', 'dropna', 'get_dummies', 'array', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'confusion_matrix']",33,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings filterwarnings walk print read csv read csv concat head figure heatmap info print value counts value counts value counts value counts value counts circle pie title gcf legend show relplot countplot countplot distplot countplot figure boxplot isnull apply heatmap drop head dropna get dummies get dummies get dummies concat drop head drop array array train test split array array logisticregression fit predict print confusion matrix heatmap show,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06123208968036059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49457797834744843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09159430205227456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17481084192760993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12597559227012922, 0.0, 0.0, 0.09900356594851593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152292196726682, 0.36615838462023875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06453226019482473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0880591593876894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12387891599356199, 0.07032482408223911, 0.0, 0.0, 0.17492849803512903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14252567724290136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1728727692002137, 0.0, 0.0, 0.0, 0.03555863585166497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14730927142247988, 0.0, 0.16946006130941943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1153448723762842, 0.23281522344430597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05320047794878773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0534626108145635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05739529601084825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061922097594161424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05426303217851004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05399384631720199, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05399384631720199, 0.0, 0.0, 0.0, 0.0, 0.09353136266810268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16264120311090044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036892812046941593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.103261581267094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06427295938255698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16264120311090044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05372705325075705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14064964816447822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056218124649701495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05862052826673122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06055758888255933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05769694701577543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36615838462023875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06853240963720832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
asyl21795_asyl-titanic.py,"['pandas', 'numpy', 'matplotlib', 'pandas:\n', 'sklearn']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,100,[],0,"['pd.read_csv', 'df.fillna', 'pd.read_csv', 'df_test.fillna', 'df_test.head', 'StandardScaler', 'sclr.fit_transform', 'sclr.fit_transform', 'RandomForestClassifier', 'classifier.fit', 'classifier.predict', 'pd.DataFrame', 'pd.concat', 'result.to_csv']","['read_csv', 'fillna', 'read_csv', 'fillna', 'head', 'StandardScaler', 'fit_transform', 'fit_transform', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'concat', 'to_csv']","['read_csv', 'fillna', 'head', 'StandardScaler', 'fit_transform', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'concat', 'to_csv']",11,"[0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv fillna read csv fillna head standardscaler fit transform fit transform randomforestclassifier fit predict dataframe concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23784514922679015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3655156871118649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15265803078231685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3172139575084823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.40281369897297503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14518271827373902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1393091507422328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19701267288787913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2426979915730307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37384254350662205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49566148255661796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
atripathi3675_titanic-basic-solution-with-logistic-regression.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'os\n', 're\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,271,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['get_ipython', 'None.run_line_magic', 'print', 'pd.read_csv', 'train.head', 'pd.read_csv', 'test.head', 'train.info', 'test.info', 'pd.concat', 'all.info', 'all.fillna', 'all.fillna', 'all.info', 'sns.catplot', 'all.fillna', 'all.info', 're.search', 'title_search.group', 'all.apply', 'all.value_counts', 'all.replace', 'all.replace', 'all.replace', 'all.replace', 'all.value_counts', 'all.fillna', 'all.value_counts', 'all.head', 'all.drop', 'all_1.head', 'pd.get_dummies', 'all_dummies.head', 'all_dummies.notna', 'all_train.info', 'all_dummies.isna', 'all_test.info', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'confusion_matrix', 'all_test.head', 'all_test.drop', 'TestForPred.info', 'logmodel.predict', 'None.astype', 'pd.DataFrame', 'logSub.head', 'logSub.to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'read_csv', 'head', 'info', 'info', 'concat', 'info', 'fillna', 'fillna', 'info', 'catplot', 'fillna', 'info', 'search', 'group', 'apply', 'value_counts', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'fillna', 'value_counts', 'head', 'drop', 'head', 'get_dummies', 'head', 'notna', 'info', 'isna', 'info', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix', 'head', 'drop', 'info', 'predict', 'astype', 'DataFrame', 'head', 'to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'info', 'concat', 'fillna', 'catplot', 'search', 'group', 'apply', 'value_counts', 'replace', 'drop', 'get_dummies', 'notna', 'isna', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'confusion_matrix', 'astype', 'DataFrame', 'to_csv']",26,"[1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic print read csv head read csv head info info concat info fillna fillna info catplot fillna info search group apply value counts replace replace replace replace value counts fillna value counts head drop head get dummies head notna info isna info train test split logisticregression fit predict print confusion matrix head drop info predict astype dataframe head csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07816776532012103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06858697313402044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14860209042266223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08040906805596972, 0.0, 0.0, 0.12638614081793892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2804586565155509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12357105392331454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051609587272940724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10542770502682515, 0.0, 0.0, 0.0, 0.07443683997279889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21448306833688435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04539350391054987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10816480682527321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14348578814275514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3435766917476484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5433180539063547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06824939075848886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14116293443231637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06927119402636349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06892755628112136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06892755628112136, 0.0, 0.0, 0.0, 0.0, 0.11940042623527075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18805232057470764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09419337765993686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08788123017638046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08204968394303865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3253745406498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06858697313402044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14348578814275514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07176702930268668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07483389380331829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07365486687714871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2804586565155509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
yasermarey_predicting-survival-of-titanic-passengers-with-dnn.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'tensorflow', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,194,"[' #   Column       Non-Null Count  Dtype  ', '# Embarked feature', '# construct model', '# ', '#', '# #']",6,"['get_ipython', 'None.run_line_magic', 'sns.set_style', 'pd.read_csv', 'train_data.head', 'train_data.info', 'train_data.describe', 'train_data.isna', 'None.sum', 'train_data.drop', 'train_data.drop', 'train_data.drop', 'train_data.drop', 'train_data.fillna', 'train_data.isna', 'None.sum', 'print', 'print', 'print', 'print', 'train_data.fillna', 'train_data.map', 'train_data.head', 'train_data.map', 'train_data.head', 'train_data.drop', 'train_test_split', 'tf.keras.Sequential', 'model.compile', 'np.array', 'None.astype', 'np.array', 'None.astype', 'None.reshape', 'print', 'model.fit', 'print', 'print', 'model.evaluate', 'print', 'pd.read_csv', 'test_data.drop', 'test_data.drop', 'test_data.drop', 'test_data.fillna', 'test_data.fillna', 'test_data.map', 'test_data.map', 'test_data.fillna', 'model.predict', 'predictions.reshape', 'np.where', 'pd.DataFrame', 'output.to_csv', 'print']","['get_ipython', 'run_line_magic', 'set_style', 'read_csv', 'head', 'info', 'describe', 'isna', 'sum', 'drop', 'drop', 'drop', 'drop', 'fillna', 'isna', 'sum', 'print', 'print', 'print', 'print', 'fillna', 'map', 'head', 'map', 'head', 'drop', 'train_test_split', 'keras', 'compile', 'array', 'astype', 'array', 'astype', 'reshape', 'print', 'fit', 'print', 'print', 'evaluate', 'print', 'read_csv', 'drop', 'drop', 'drop', 'fillna', 'fillna', 'map', 'map', 'fillna', 'predict', 'reshape', 'where', 'DataFrame', 'to_csv', 'print']","['get_ipython', 'run_line_magic', 'set_style', 'read_csv', 'head', 'info', 'describe', 'isna', 'sum', 'drop', 'fillna', 'print', 'map', 'train_test_split', 'keras', 'compile', 'array', 'astype', 'reshape', 'fit', 'evaluate', 'predict', 'where', 'DataFrame', 'to_csv']",25,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic set style read csv head info describe isna sum drop drop drop drop fillna isna sum print print print print fillna map head map head drop train test split keras compile array astype array astype reshape print fit print print evaluate print read csv drop drop drop fillna fillna map map fillna predict reshape dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3135675053838202, 0.0, 0.0, 0.13625400884815173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14021624543474323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12274234235226249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051263474969189975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07316091106381341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4188826769041387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15347223930684345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2663058354558807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04508907887938834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053719707521686526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1462596616642632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06745929615130981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06779168599638566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28043249086948646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1739855812218109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068806636687022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06846530349909076, 0.0, 0.0, 0.2866138033075195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046780841633133376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39281340283004945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08149942949164458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3378071813804235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06812700442407586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07354729403068994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07128573400160367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10151335941611449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14479943556621686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0743320310148033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07316091106381341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sandratierno_predictive-analytics-for-titanic.py,"['numpy', 'pandas', 'csv', 'subprocess', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,98,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', 'from sklearn import ensemble # random forest ', 'from sklearn import tree # tree ', '# Any results you write to the current directory are saved as output.']",10,"['os.getcwd', 'print', 'os.chdir', 'os.getcwd', 'pd.read_csv', 'train_df.info', 'train_df.describe', 'None.transpose', 'train_df.head']","['getcwd', 'print', 'chdir', 'getcwd', 'read_csv', 'info', 'describe', 'transpose', 'head']","['getcwd', 'print', 'chdir', 'read_csv', 'info', 'describe', 'transpose', 'head']",8,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",getcwd print chdir getcwd read csv info describe transpose head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4467070607756334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08245202631303605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1474372718130234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7870894350337593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09824975832274632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13594711217169864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08795731612949094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08212072105065184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3313487630032055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
psangam_titanic-survival-analysis-and-prediction-using-ml.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'IPython', 'sklearn', 'xgboost', 'fancyimpute']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,582,"['# Data Analysis', '# Data Visualization', '# allowing multiple/scrollable outputs', '# Function inspired by Helge Bjorland: An Interactive Data Science Tutorial', '# Load data', '# preliminary analysis', '# preliminary analysis', '# Grouping Family Size to Ordinals', '# to get an idea of all titles in both datasets (to make cleaning easier)', '# Variables needed for building prediction model', '# Support Vector Machines', '# Decision Tree', '# Gaussian Naive Bayes', '# Perceptron', '# Stochastic Gradient Descent', '# Random Forest', '# Model Evaluation', '# #competition submission: Random Forest Trees', '# submission = pd.DataFrame({', '#         ""PassengerId"": df_test[""PassengerId""],', '#         ""Survived"": Y_pred', '#     })', ""# submission.to_csv('submission.csv', index=False)""]",23,"['kwargs.get', 'kwargs.get', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'pd.read_csv', 'pd.read_csv', 'print', 'pd.crosstab', 'df_train.describe', 'df_train.isnull', 'None.sum', 'df_test.isnull', 'None.sum', 'pd.pivot_table', 'pd.pivot_table', 'sns.barplot', 'plot_distribution', 'plot_distribution', 'pd.pivot_table', 'plot_distribution', 'df_train.Embarked.mode', 'df_train.fillna', 'df_test.Fare.median', 'df_test.fillna', 'dataset.map', 'None.astype', 'dataset.map', 'None.astype', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'pd.pivot_table', 'pd.qcut', 'pd.cut', 'dataset.astype', 'pd.pivot_table', 'dataset.Name.str.extract', 'df_test.append', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'pd.pivot_table', 'dataset.map', 'df_train.head', 'df_test.head', 'dataset.drop', 'df_train.head', 'df_test.head', 'KNN', 'None.complete', 'pd.DataFrame', 'dataset.head', 'dataset.isnull', 'None.sum', 'pd.cut', 'None.unique', 'pd.cut', 'dataset.astype', 'pd.pivot_table', 'dataset.drop', 'df_train.head', 'df_test.head', 'df_train.drop', 'df_test.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'SVC', 'svc.fit', 'svc.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'X_train.info', 'XGBClassifier', 'xgb.fit', 'xgb.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values']","['get', 'get', 'FacetGrid', 'map', 'set', 'add_legend', 'read_csv', 'read_csv', 'print', 'crosstab', 'describe', 'isnull', 'sum', 'isnull', 'sum', 'pivot_table', 'pivot_table', 'barplot', 'plot_distribution', 'plot_distribution', 'pivot_table', 'plot_distribution', 'Embarked', 'fillna', 'Fare', 'fillna', 'map', 'astype', 'map', 'astype', 'replace', 'replace', 'replace', 'pivot_table', 'qcut', 'cut', 'astype', 'pivot_table', 'Name', 'append', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'pivot_table', 'map', 'head', 'head', 'drop', 'head', 'head', 'KNN', 'complete', 'DataFrame', 'head', 'isnull', 'sum', 'cut', 'unique', 'cut', 'astype', 'pivot_table', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'SVC', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'info', 'XGBClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values']","['get', 'FacetGrid', 'map', 'set', 'add_legend', 'read_csv', 'print', 'crosstab', 'describe', 'isnull', 'sum', 'pivot_table', 'barplot', 'plot_distribution', 'Embarked', 'fillna', 'Fare', 'astype', 'replace', 'qcut', 'cut', 'Name', 'append', 'head', 'drop', 'KNN', 'complete', 'DataFrame', 'unique', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'SGDClassifier', 'info', 'XGBClassifier', 'RandomForestClassifier', 'score', 'sort_values']",45,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0
 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get get facetgrid map set add legend read csv read csv print crosstab describe isnull sum isnull sum pivot table pivot table barplot plot distribution plot distribution pivot table plot distribution embarked fillna fare fillna map astype map astype replace replace replace pivot table qcut cut astype pivot table name append crosstab replace replace replace replace pivot table map head head drop head head knn complete dataframe head isnull sum cut unique cut astype pivot table drop head head drop drop copy logisticregression fit predict round svc fit predict round decisiontreeclassifier fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round sgdclassifier fit predict round info xgbclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.036775478580217895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03750390150748303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11385615807509697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04382750607822004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09261298381123431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0354116900597646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08840333468002246, 0.034188526883250026, 0.0, 0.0, 0.0, 0.12723942430159238, 0.0, 0.0, 0.0, 0.04283662813969414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03750390150748303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030567248352607438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2584969034755928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08750636527998995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038797388277810145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03962720019863105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04852571796823329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04450593351976346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16954739174925984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04621716141518459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04488909767163951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1425865595865452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02818506534658374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09122231027000409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03826730186044779, 0.0, 0.08616563449186425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032805689617469776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028605383737880782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1197496747866452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04241314143386412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05599930205357604, 0.0, 0.0, 0.0, 0.0, 0.5088485470661727, 0.0, 0.09841706885240933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17590888702671464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018235640781312012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04346194699134759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02764138435448381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034051151983249615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23630696006052276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3787053178397689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028747995635064253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030728682429028802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05599930205357604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035195344954434334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09074764605670338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036539902124086046, 0.0, 0.0, 0.4939854562281366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051827416413812784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035195344954434334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04756171858483631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
greenarrow2018_titanic-prediction.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,374,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# male = 1, female = 0;C = 0, Q = 1, S = 2']",10,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'test_data.head', 'train_data.drop', 'train_drop.head', 'print', 'train_drop.append', 'train.drop', 'train.drop', 'train.replace', 'train.replace', 'train.replace', 'train.replace', 'train.replace', 'train.head', 'plt.figure', 'sns.heatmap', 'plt.show', 'train.isnull', 'None.sum', 'plt.figure', 'train.isnull', 'None.sum', 'None.plot', 'plt.show', 'print', 'train.drop', 'train.fillna', 'train.fillna', 'train.fillna', 'train.isnull', 'None.sum', 'pd.get_dummies', 'None.reset_index', 'svm.SVC', 'cross_val_score', 'print', 'GaussianNB', 'cross_val_score', 'print', 'tree.DecisionTreeClassifier', 'cross_val_score', 'print', 'KNeighborsClassifier', 'cross_val_score', 'print', 'RandomForestClassifier', 'cross_val_score', 'print', 'ExtraTreesClassifier', 'cross_val_score', 'print', 'BaggingClassifier', 'cross_val_score', 'print', 'BaggingClassifier', 'cross_val_score', 'print', 'AdaBoostClassifier', 'cross_val_score', 'print', 'GradientBoostingClassifier', 'cross_val_score', 'print', 'VotingClassifier', 'cross_val_score', 'print', 'StackingClassifier', 'cross_val_score', 'print', 'blending.fit', 'Stack.fit', 'print', 'blending.predict', 'Stack.predict', 'print', 'print', 'blending.predict', 'pd.read_csv', 'summition.drop', 'summition.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'head', 'drop', 'head', 'print', 'append', 'drop', 'drop', 'replace', 'replace', 'replace', 'replace', 'replace', 'head', 'figure', 'heatmap', 'show', 'isnull', 'sum', 'figure', 'isnull', 'sum', 'plot', 'show', 'print', 'drop', 'fillna', 'fillna', 'fillna', 'isnull', 'sum', 'get_dummies', 'reset_index', 'SVC', 'cross_val_score', 'print', 'GaussianNB', 'cross_val_score', 'print', 'DecisionTreeClassifier', 'cross_val_score', 'print', 'KNeighborsClassifier', 'cross_val_score', 'print', 'RandomForestClassifier', 'cross_val_score', 'print', 'ExtraTreesClassifier', 'cross_val_score', 'print', 'BaggingClassifier', 'cross_val_score', 'print', 'BaggingClassifier', 'cross_val_score', 'print', 'AdaBoostClassifier', 'cross_val_score', 'print', 'GradientBoostingClassifier', 'cross_val_score', 'print', 'VotingClassifier', 'cross_val_score', 'print', 'StackingClassifier', 'cross_val_score', 'print', 'fit', 'fit', 'print', 'predict', 'predict', 'print', 'print', 'predict', 'read_csv', 'drop', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'drop', 'append', 'replace', 'figure', 'heatmap', 'show', 'isnull', 'sum', 'plot', 'fillna', 'get_dummies', 'reset_index', 'SVC', 'cross_val_score', 'GaussianNB', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'BaggingClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier', 'fit', 'predict', 'to_csv']",31,"[1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv head drop head print append drop drop replace replace replace replace replace head figure heatmap show isnull sum figure isnull sum plot show print drop fillna fillna fillna isnull sum get dummies reset index svc cross val score print gaussiannb cross val score print decisiontreeclassifier cross val score print kneighborsclassifier cross val score print randomforestclassifier cross val score print extratreesclassifier cross val score print baggingclassifier cross val score print baggingclassifier cross val score print adaboostclassifier cross val score print gradientboostingclassifier cross val score print votingclassifier cross val score print stackingclassifier cross val score print fit fit print predict predict print print predict read csv drop csv,"[0.0, 0.0, 0.0, 0.05550997249280601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036642495237416084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1594342903475685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5631971092063014, 0.0, 0.0, 0.06680653922066233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036642495237416084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1068706002619438, 0.0, 0.0, 0.0, 0.030182236320030534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06894848268969221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07377432014571647, 0.0, 0.0, 0.0, 0.0652255522019209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036811811541787844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04515562512089285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021929032467685596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05188055646948359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05970495777650214, 0.04017003616806693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04474131000871396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08912707572431569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03738836147195096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032052193965164906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05728951118867334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32070233669551373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02700650475958268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04990357499708939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16491382630566928, 0.0, 0.0, 0.050050691481342474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33705238680821065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07280324761681077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08418654392175973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08866331380952469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035700637420091455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5631971092063014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06025435002918344, 0.0, 0.0, 0.035473831991102545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
myndel_titanic-machine-learning-from-disaster.py,"['numpy', 'pandas', 'sklearn']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,170,"['#    Survived    Survived                   0 = No, 1 = Yes', '#    Pclass      Ticket class               1 = 1st, 2 = 2nd, 3 = 3rd', '#    Name        Name', '#    Sex         Sex', '#    Age         Age in years', '#    SibSp       # of siblings / spouses aboard the Titanic', '#    Parch       # of parents / children aboard the Titanic', '#    Ticket      Ticket number', '#    Fare        Passenger fare', '#    Cabin       Cabin number', '#    Embarked    Port of Embarkation        C = Cherbourg, Q = Queenstown, S = Southampton', '# Columns with missing values', ""    # 72% of Embarked values are 'S' which stands for Southampton"", '    # so in my opinion we can fill missing data with this value.', '    # Age we will fill with mean values for age', '    # Now we have to transform alphabetic values to numberic', ""# Let's see how our data looks like"", '# Train the best model', '# Check for empty values', '# I will fill NaN values with mean']",20,"['pd.read_csv', 'pd.read_csv', 'train.isnull', 'None.any', 'data.drop', 'data.fillna', 'data.fillna', 'preprocessing.LabelEncoder', 'le.fit_transform', 'le.fit_transform', 'pd.Series', 'pd.Series', 'prepare_data', 'train.head', 'train.drop', 'train_test_split', 'KNeighborsClassifier', 'knn_model.fit', 'knn_model.score', 'print', 'LinearRegression', 'linear_model.fit', 'linear_model.score', 'print', 'LogisticRegression', 'logistic_model.fit', 'logistic_model.score', 'print', 'DecisionTreeClassifier', 'dtc_model.fit', 'dtc_model.score', 'print', 'prepare_data', 'test.isnull', 'None.any', 'test.fillna', 'model.predict', 'pd.Series', 'pd.Series', 'pd.concat', 'submission.to_csv']","['read_csv', 'read_csv', 'isnull', 'any', 'drop', 'fillna', 'fillna', 'LabelEncoder', 'fit_transform', 'fit_transform', 'Series', 'Series', 'prepare_data', 'head', 'drop', 'train_test_split', 'KNeighborsClassifier', 'fit', 'score', 'print', 'LinearRegression', 'fit', 'score', 'print', 'LogisticRegression', 'fit', 'score', 'print', 'DecisionTreeClassifier', 'fit', 'score', 'print', 'prepare_data', 'isnull', 'any', 'fillna', 'predict', 'Series', 'Series', 'concat', 'to_csv']","['read_csv', 'isnull', 'any', 'drop', 'fillna', 'LabelEncoder', 'fit_transform', 'Series', 'prepare_data', 'head', 'train_test_split', 'KNeighborsClassifier', 'fit', 'score', 'print', 'LinearRegression', 'LogisticRegression', 'DecisionTreeClassifier', 'predict', 'concat', 'to_csv']",21,"[1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv isnull drop fillna fillna labelencoder fit transform fit transform series series prepare data head drop train test split kneighborsclassifier fit score print linearregression fit score print logisticregression fit score print decisiontreeclassifier fit score print prepare data isnull fillna predict series series concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0900112724429078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13832753033534181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32124084212026943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10116107256655346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11801755833800572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18007198409224195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3048855418734598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05494365241848499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1640388755655422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10322022895827426, 0.0, 0.0, 0.0, 0.0, 0.12026084218976148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19607737071940035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07715867373223785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052720831019734876, 0.0, 0.4648373984149572, 0.0, 0.0, 0.0, 0.19675147451076064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09184780564936572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3101733905739314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.450462493566014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08033722791670495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08377032797352546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08245050526652549, 0.0, 0.0, 0.0, 0.1875805367101177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mukultiwari_titanic-top-14-with-random-forest.py,"['pandas', 'matplotlib', 'seaborn', 'numpy', 'xgboost', 'sklearn', 'warnings\n']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,903,"['# Viewing the data', '# Information on the dataset', '# We have 7 Numeric (PassengerId, Survived, Pclass, Age, SibSp, Parch, Fare)', '# and 5 categorical Features (Name, Sex, Ticket, Cabin, Embarked)', '# Training Data contains 866 null values ( Age-177, Cabin-687, Emarked-2)', '# Test Data contains 414 null values ( Age-86, Fare-1, Cabin-327)', '# Saving the passengerId of test data for later use.', '# Since passengerId does not have significant contribution to survival directly therefore we will Drop it.', '# As seen the population of passengers as per Pclass is ( 3 > 1 > 2) ', '# Survival percentage as per classes is ( 1 > 2 > 3)', '# Inference: 1st class passengers have higher survival rate ', '# Making a new feature Title having only the title extracted from the first name', '# Making a new feature nameLength telling the length of the name', '# Title Feature', '# Name Leangth', '# Dropping the name feature ', '# Categorizing the name length by simply dividing it with 10.', '# Observations', '# Name length as seen the longer the name the higher is the survival.', '# Titles like Mrs. Ms. the lady or any royalty have high survival rates.', '# As can be seen that (number of males > number of females) but Survival ratio is inverse', '# More females survived as compared to males', '# Creating a list of age values without null values', '# Age contains 177 null values in training set and 86 in test set', '# Creating a new list of survived and dead', '# Taking care of null values in Age ', '# Null Ages in Training set (177 null values)', '# Null Ages in Test set (86 null values)', '# Observations:', '# Maximum passengers have age between 20-40 years', '# Survival rate is maximum for childrens and elderly', '# We will create a new feature of family size = SibSp + Parch + 1', '# As observed maximum passengers are alone but the survival is maximum for the family of 4', '# wheather or not the passenger was alone ?', '# Observations:', '# Making a new feature ticket length', '# Having ticket length may or may not increase acuracy as its not significant, in my case it did increase accuracy.', '# Fare has 0 null values in training data but 1 null values in test data', '# mean of fare in test data is 35 we will replace nul value with mean', '# Creating a new list of survived and dead', '# Categorizing the fare value by dividing it with 20 simply', '# Observations:', '# The most frequent fare is between 0-100', '# The survival rate is directly praportional to rate i.e. higher the rate higher the survival chances.', '# Null values in test data', '# Null values in training data', '# Making a new feature hasCabin which is 1 if cabin is available else 0', '# As observed maximum population on titanic dataset does not have cabin but survival for having cabin is more.', '# Embarked has 2 null values in the training data', '# Since ""S"" is the most frequent class constituting 72% of the total therefore we will replace null values with ""S""', '# Observations:', '# The maximum passengers are from Southampton', '# The maximum survival rate is of the passengers who boarded from Cherbourg', '# If we observe the fare as grouped by boarding ststion ', '# we observe that the most premium customers boarded from Cherbourg therefore maximum survival rate .', '# Splitting the dataset into dependent and independent features', '# Resolving the categorical data for training set', '# Splitting the dataset into training and test set', '# Feature Scaling', '# Making a list of accuracies', '# As observed Xgboost performs best.', '# We will be making three submissions', '# Random Forest', '# K-Svm', '# Xgboost', '# Since Random Forest scores best after submission we will apply Grid Search CV on RF', '# Preparing test data ', '# Taking care of categorical data', '# Feature Scaling']",69,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'sns.set_palette', 'pd.read_csv', 'pd.read_csv', 'training_data.head', 'test_data.head', 'training_data.info', 'test_data.info', 'training_data.isnull', 'None.sum', 'test_data.isnull', 'None.sum', 'training_data.PassengerId.nunique', 'training_data.drop', 'test_data.drop', 'training_data.head', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.countplot', 'sns.barplot', 'print', 'training_data.Name.nunique', 'training_data.apply', 'None.apply', 'test_data.apply', 'None.apply', 'training_data.apply', 'test_data.apply', 'training_data.drop', 'test_data.drop', 'test_data.Name_Len.astype', 'training_data.Name_Len.astype', 'print', 'print', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.countplot', 'sns.barplot', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.countplot', 'sns.barplot', 'print', 'training_data.Age.isnull', 'None.sum', 'training_data.Age.dropna', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.distplot', 'axes.hist', 'axes.legend', 'plt.show', 'pd.concat', 'full_data.Age.mean', 'full_data.Age.std', 'training_data.Age.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'training_data.astype', 'full_data.Age.mean', 'full_data.Age.std', 'test_data.Age.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'test_data.astype', 'training_data.Age.astype', 'test_data.Age.astype', 'print', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.countplot', 'sns.barplot', 'print', 'training_data.map', 'test_data.map', 'plt.subplots', 'sns.countplot', 'sns.barplot', 'training_data.drop', 'test_data.drop', 'training_data.head', 'training_data.apply', 'test_data.apply', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.countplot', 'sns.barplot', 'print', 'training_data.drop', 'test_data.drop', 'training_data.head', 'test_data.Fare.describe', 'np.isnan', 'test_data.Fare.mean', 'plt.subplots', 'sns.distplot', 'fig1_fare.set_title', 'axes.hist', 'axes.legend', 'axes.set_title', 'plt.show', 'training_data.Fare.astype', 'test_data.Fare.astype', 'print', 'training_data.head', 'float', 'print', 'float', 'print', 'training_data.Cabin.notnull', 'None.astype', 'test_data.Cabin.notnull', 'None.astype', 'plt.subplots', 'sns.countplot', 'sns.barplot', 'training_data.drop', 'training_data.head', 'test_data.drop', 'test_data.head', 'training_data.Embarked.describe', 'training_data.fillna', 'plt.subplots', 'axes.set_title', 'axes.set_title', 'sns.countplot', 'sns.barplot', 'print', 'print', 'training_data.head', 'LabelEncoder', 'LabelEncoder', 'LabelEncoder', 'label_encoder_sex_tr.fit_transform', 'label_encoder_title_tr.fit_transform', 'label_encoder_embarked_tr.fit_transform', 'train_test_split', 'MinMaxScaler', 'scaler_x.fit_transform', 'scaler_x.transform', 'LogisticRegression', 'classifier.fit', 'classifier.score', 'accuracies.append', 'print', 'SVC', 'svm.fit', 'svm.score', 'accuracies.append', 'print', 'SVC', 'k_svm.fit', 'k_svm.score', 'accuracies.append', 'print', 'KNeighborsClassifier', 'knn.fit', 'knn.score', 'accuracies.append', 'print', 'RandomForestClassifier', 'rdmf.fit', 'rdmf.score', 'rdmf.score', 'accuracies.append', 'print', 'print', 'XGBClassifier', 'xgb.fit', 'xgb.score', 'accuracies.append', 'print', 'sns.barplot', 'test_data.replace', 'test_data.head', 'label_encoder_sex_tr.transform', 'label_encoder_title_tr.transform', 'label_encoder_embarked_tr.transform', 'scaler_x.transform', 'rdmf.predict', 'len', 'pd.DataFrame', 'titanic_submission.to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'set_palette', 'read_csv', 'read_csv', 'head', 'head', 'info', 'info', 'isnull', 'sum', 'isnull', 'sum', 'PassengerId', 'drop', 'drop', 'head', 'subplots', 'set_title', 'set_title', 'countplot', 'barplot', 'print', 'Name', 'apply', 'apply', 'apply', 'apply', 'apply', 'apply', 'drop', 'drop', 'Name_Len', 'Name_Len', 'print', 'print', 'subplots', 'set_title', 'set_title', 'countplot', 'barplot', 'subplots', 'set_title', 'set_title', 'countplot', 'barplot', 'print', 'Age', 'sum', 'Age', 'subplots', 'set_title', 'set_title', 'distplot', 'hist', 'legend', 'show', 'concat', 'Age', 'Age', 'Age', 'sum', 'random', 'isnan', 'astype', 'Age', 'Age', 'Age', 'sum', 'random', 'isnan', 'astype', 'Age', 'Age', 'print', 'subplots', 'set_title', 'set_title', 'countplot', 'barplot', 'print', 'map', 'map', 'subplots', 'countplot', 'barplot', 'drop', 'drop', 'head', 'apply', 'apply', 'subplots', 'set_title', 'set_title', 'countplot', 'barplot', 'print', 'drop', 'drop', 'head', 'Fare', 'isnan', 'Fare', 'subplots', 'distplot', 'set_title', 'hist', 'legend', 'set_title', 'show', 'Fare', 'Fare', 'print', 'head', 'float', 'print', 'float', 'print', 'Cabin', 'astype', 'Cabin', 'astype', 'subplots', 'countplot', 'barplot', 'drop', 'head', 'drop', 'head', 'Embarked', 'fillna', 'subplots', 'set_title', 'set_title', 'countplot', 'barplot', 'print', 'print', 'head', 'LabelEncoder', 'LabelEncoder', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'train_test_split', 'MinMaxScaler', 'fit_transform', 'transform', 'LogisticRegression', 'fit', 'score', 'append', 'print', 'SVC', 'fit', 'score', 'append', 'print', 'SVC', 'fit', 'score', 'append', 'print', 'KNeighborsClassifier', 'fit', 'score', 'append', 'print', 'RandomForestClassifier', 'fit', 'score', 'score', 'append', 'print', 'print', 'XGBClassifier', 'fit', 'score', 'append', 'print', 'barplot', 'replace', 'head', 'transform', 'transform', 'transform', 'transform', 'predict', 'len', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'set_palette', 'read_csv', 'head', 'info', 'isnull', 'sum', 'PassengerId', 'drop', 'subplots', 'set_title', 'countplot', 'barplot', 'print', 'Name', 'apply', 'Name_Len', 'Age', 'distplot', 'hist', 'legend', 'show', 'concat', 'random', 'isnan', 'astype', 'map', 'Fare', 'float', 'Cabin', 'Embarked', 'fillna', 'LabelEncoder', 'fit_transform', 'train_test_split', 'MinMaxScaler', 'transform', 'LogisticRegression', 'fit', 'score', 'append', 'SVC', 'KNeighborsClassifier', 'RandomForestClassifier', 'XGBClassifier', 'replace', 'predict', 'len', 'DataFrame', 'to_csv']",52,"[1 1 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0
 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings set palette read csv read csv head head info info isnull sum isnull sum passengerid drop drop head subplots set title set title countplot barplot print name apply apply apply apply apply apply drop drop name len name len print print subplots set title set title countplot barplot subplots set title set title countplot barplot print age sum age subplots set title set title distplot hist legend show concat age age age sum random isnan astype age age age sum random isnan astype age age print subplots set title set title countplot barplot print map map subplots countplot barplot drop drop head apply apply subplots set title set title countplot barplot print drop drop head fare isnan fare subplots distplot set title hist legend set title show fare fare print head float print float print cabin astype cabin astype subplots countplot barplot drop head drop head embarked fillna subplots set title set title countplot barplot print print head labelencoder labelencoder labelencoder fit transform fit transform fit transform train test split minmaxscaler fit transform transform logisticregression fit score append print svc fit score append print svc fit score append print kneighborsclassifier fit score append print randomforestclassifier fit score score append print print xgbclassifier fit score append print barplot replace head transform transform transform transform predict len dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28312215874761854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16534878798606956, 0.19069789363199674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08366230794553177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2898428451119883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07616630220692645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024520721304345395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22343272976576967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03768295601223394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015738328235208505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06856166553312439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16075073590705458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028508594532406478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1426281591992107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016351636918390918, 0.0, 0.033649097561528105, 0.0, 0.0, 0.0, 0.1384273546913306, 0.0, 0.10095729940828872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01649241277895877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14967658514671367, 0.0, 0.0, 0.05952335733146905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041421169594279175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02081263134172124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10589248767169793, 0.044687197965923034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028119083294394547, 0.0, 0.0, 0.0, 0.0, 0.09828377652470414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04821170419841524, 0.0879866369962969, 0.0, 0.0, 0.0, 0.0, 0.021124229943286714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021019437715439095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021019437715439095, 0.0, 0.0, 0.04399645279515576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04618205957225431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09349642635676061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04924759056335981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06331511592395123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014362121201968026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2545938716714384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06921997695799245, 0.020311084169732194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025021026629440026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024805717264530635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020915576986382942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.147869609603007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38385409366718065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054753952921294216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02188533416588106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2911834618423018, 0.11113668389548773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053699555570609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02282057357999581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37719452997993713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02246102967075911, 0.0, 0.0, 0.0, 0.22995170183463315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03494868625409577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
nico33_titanic-data-science-solutions.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,949,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest']",24,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score', 'to_csv']",48,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14739731056786123, 0.0, 0.0386075088739669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11408479331718284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035482800489506514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044290428976480785, 0.05138577160738971, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.06438397294899055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03757921331973189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0612572612591073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21920521835808165, 0.03733218432362304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03887529754869338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19853387909934528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066892959232493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16988786089570734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04630997037753964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022489619870565202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2969112193682155, 0.0, 0.0, 0.0, 0.0, 0.22451453910645058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05648332789475356, 0.0, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.028380818116478954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038344146661578926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1314862676876251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053884920424318535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.239980289670821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30790388882723707, 0.042840970987036014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05019161346595868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1762621307304402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05481677964674111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04354922319089523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027696891186176718, 0.0, 0.0, 0.1544300354958676, 0.0, 0.0, 0.0, 0.034119530308222235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1353037082864551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3794657982870925, 0.0, 0.02852119832929571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04183433832000622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03661327812332207, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055334378413763305, 0.0, 0.0]"
nikanth_titanic-data-science-solutions.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,955,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', '# submission.head()']",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'X_train.head', 'X_test.head', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'head', 'head', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score', 'to_csv']",48,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values head head svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14594536553543697, 0.0, 0.03822720355830088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11296099500435154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03513327527965866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0438541437546637, 0.050879593336326294, 0.0, 0.0, 0.0, 0.04207967964692365, 0.0, 0.0, 0.0, 0.0637497552055943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03720903728401055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06065384335519562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21704592571800352, 0.03696444166014157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03849235436647124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1965782105839859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06623402658652006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1682143715033541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045853791555942845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022268084676155098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29398647964011687, 0.0, 0.0, 0.0, 0.0, 0.2627216643060361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05592693587487461, 0.0, 0.0, 0.0, 0.0, 0.05025080254387299, 0.0, 0.0, 0.0, 0.0, 0.02810125136100965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037966435609366786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13019105522773997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028521972339657718, 0.0, 0.0, 0.0, 0.055559022774586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053354124155165134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028380481689721355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028380481689721355, 0.0, 0.0, 0.23761635108791945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30487086522507983, 0.04241896372808931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049697198313060034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04207967964692365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055559022774586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17452585125469797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054276804048848916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04312023925601641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02742406148924103, 0.0, 0.0, 0.15290881423320352, 0.0, 0.0, 0.0, 0.03378343406366515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1339708919253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37572785029689365, 0.0, 0.028240248751087885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028521972339657718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041422246949583796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055559022774586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3491863112886702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036252617083530225, 0.0, 0.0, 0.0, 0.05025080254387299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3491863112886702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05478930418173952, 0.0, 0.0]"
catherineb_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,403,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', '# view information about training and test dataframes', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",76,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'knn.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'KNeighborsClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'KNeighborsClassifier', 'Series', 'to_csv']",43,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score kneighborsclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.044283221368321045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0781256172299776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17137497752708372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2110997032383696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04264101435205954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18307302288315022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061752212180951005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.103163518725922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5795397210149369, 0.044863488382438046, 0.0, 0.0, 0.22319011079725898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04771712419119134, 0.11808036930859171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05359185474528739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0680535415727864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891863475572387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14272374662323228, 0.0, 0.0, 0.0, 0.0, 0.02452795964705982, 0.0, 0.0, 0.09754274559729631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06787813707445528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034106295329926525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11568617148733383, 0.07323027762652023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37895398008166026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046079601540960635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03950299687608411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03461692148549966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03444519525768304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03444519525768304, 0.0, 0.0, 0.03604916619775803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2220118022491481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07900599375216821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07060694141493552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021958461145531016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11343289265530969, 0.03328439464428582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041002721360415065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034274995505416746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10385076445649899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05027389597503298, 0.18500983520762343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11808036930859171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05107181751407641, 0.0, 0.0, 0.0, 0.0, 0.2385856209559567, 0.0728492327700975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07726502613427247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06098905312469963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
loremipsuma_titanic-eda.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'collections', 'warnings\n', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,903,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ' #   Column       Non-Null Count  Dtype  ', '    # get feature', '    # count number of categorical varible(value/sample)', '# Pclass - Survived', '# Sex - Survived', '# Sibsp - Survived', '# Parch - Survived', '        # 1st quartile', '        # 3rd quartile', '        # IQR', '        # Outlier step', '        # detect outlier and their indeces', '        # store indeces', '# find outliers', '# drop outliers', '# concat datasets', '# which columns ', '# ', '# convert to categorical']",28,"['plt.style.use', 'warnings.filterwarnings', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_df.head', 'train_df.describe', 'train_df.info', 'var.value_counts', 'plt.figure', 'plt.bar', 'plt.xticks', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'bar_plot', 'print', 'plt.figure', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'plot_hist', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'np.percentile', 'np.percentile', 'outlier_indices.extend', 'Counter', 'list', 'detect_outliers', 'train_df.drop', 'None.reset_index', 'len', 'pd.concat', 'None.reset_index', 'train_df.head', 'train_df.isnull', 'None.any', 'train_df.isnull', 'None.sum', 'train_df.isnull', 'train_df.boxplot', 'plt.show', 'train_df.fillna', 'train_df.isnull', 'train_df.isnull', 'np.mean', 'train_df.fillna', 'train_df.isnull', 'sns.heatmap', 'sns.factorplot', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'sns.FacetGrid', 'g.map', 'plt.show', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'plt.show', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'plt.show', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'plt.show', 'train_df.isnull', 'sns.factorplot', 'sns.factorplot', 'sns.factorplot', 'sns.factorplot', 'sns.heatmap', 'list', 'train_dftrain_dftrain_df.ilocitrain_dftrain_df.ilocitrain_dftrain_df.iloci.median', 'train_df.median', 'np.isnan', 'train_df.isnull', 'train_df.boxplot', 'plt.show', 'train_df.fillna', 'train_df.isnull', 'train_df.isnull', 'train_df.fillna', 'train_df.isnull', 'train_df.head', 'i.split', 'None.split', 'None.strip', 'train_df.head', 'sns.countplot', 'plt.xticks', 'plt.show', 'train_df.replace', 'train_df.head', 'sns.countplot', 'plt.xticks', 'plt.show', 'sns.factorplot', 'g.set_xticklabels', 'g.set_ylabels', 'plt.show', 'train_df.drop', 'train_df.head', 'pd.get_dummies', 'train_df.head', 'train_df.head', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'train_df.head', 'sns.countplot', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'pd.get_dummies', 'train_df.head', 'train_df.head', 'sns.countplot', 'plt.show', 'pd.get_dummies', 'train_df.head', 'train_df.head', 'a.replace', 'None.replace', 'None.strip', 'None.split', 'list', 'i.isdigit', 'tickets.append', 'tickets.append', 'train_df.head', 'train_df.head', 'pd.get_dummies', 'train_df.head', 'sns.countplot', 'plt.show', 'train_df.astype', 'pd.get_dummies', 'train_df.head', 'train_df.astype', 'pd.get_dummies', 'train_df.head', 'train_df.drop', 'test.drop', 'test.head', 'train.drop', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'LogisticRegression', 'logreg.fit', 'round', 'round', 'print', 'print', 'DecisionTreeClassifier', 'SVC', 'RandomForestClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'range', 'range', 'np.logspace', 'np.linspace', 'None.tolist', 'range', 'GridSearchCV', 'clf.fit', 'cv_result.append', 'best_estimators.append', 'print', 'pd.DataFrame', 'sns.barplot', 'g.set_xlabel', 'g.set_title', 'VotingClassifier', 'votingC.fit', 'print', 'pd.Series', 'None.astype', 'pd.concat', 'results.to_csv']","['style', 'filterwarnings', 'walk', 'print', 'read_csv', 'read_csv', 'head', 'describe', 'info', 'value_counts', 'figure', 'bar', 'xticks', 'ylabel', 'title', 'show', 'print', 'bar_plot', 'print', 'figure', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'plot_hist', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'percentile', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'drop', 'reset_index', 'len', 'concat', 'reset_index', 'head', 'isnull', 'any', 'isnull', 'sum', 'isnull', 'boxplot', 'show', 'fillna', 'isnull', 'isnull', 'mean', 'fillna', 'isnull', 'heatmap', 'factorplot', 'show', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'FacetGrid', 'map', 'show', 'FacetGrid', 'map', 'add_legend', 'show', 'FacetGrid', 'map', 'add_legend', 'show', 'FacetGrid', 'map', 'add_legend', 'show', 'isnull', 'factorplot', 'factorplot', 'factorplot', 'factorplot', 'heatmap', 'list', 'ilocitrain_dftrain_df', 'median', 'isnan', 'isnull', 'boxplot', 'show', 'fillna', 'isnull', 'isnull', 'fillna', 'isnull', 'head', 'split', 'split', 'strip', 'head', 'countplot', 'xticks', 'show', 'replace', 'head', 'countplot', 'xticks', 'show', 'factorplot', 'set_xticklabels', 'set_ylabels', 'show', 'drop', 'head', 'get_dummies', 'head', 'head', 'factorplot', 'set_ylabels', 'show', 'head', 'countplot', 'show', 'factorplot', 'set_ylabels', 'show', 'get_dummies', 'head', 'head', 'countplot', 'show', 'get_dummies', 'head', 'head', 'replace', 'replace', 'strip', 'split', 'list', 'isdigit', 'append', 'append', 'head', 'head', 'get_dummies', 'head', 'countplot', 'show', 'astype', 'get_dummies', 'head', 'astype', 'get_dummies', 'head', 'drop', 'drop', 'head', 'drop', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'LogisticRegression', 'fit', 'round', 'round', 'print', 'print', 'DecisionTreeClassifier', 'SVC', 'RandomForestClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'range', 'range', 'logspace', 'linspace', 'tolist', 'range', 'GridSearchCV', 'fit', 'append', 'append', 'print', 'DataFrame', 'barplot', 'set_xlabel', 'set_title', 'VotingClassifier', 'fit', 'print', 'Series', 'astype', 'concat', 'to_csv']","['style', 'filterwarnings', 'walk', 'print', 'read_csv', 'head', 'describe', 'info', 'value_counts', 'figure', 'bar', 'xticks', 'ylabel', 'title', 'show', 'bar_plot', 'hist', 'xlabel', 'plot_hist', 'groupby', 'mean', 'sort_values', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'drop', 'reset_index', 'len', 'concat', 'isnull', 'any', 'sum', 'boxplot', 'fillna', 'heatmap', 'factorplot', 'set_ylabels', 'FacetGrid', 'map', 'add_legend', 'ilocitrain_dftrain_df', 'median', 'isnan', 'split', 'strip', 'countplot', 'replace', 'set_xticklabels', 'get_dummies', 'isdigit', 'append', 'astype', 'train_test_split', 'LogisticRegression', 'fit', 'round', 'DecisionTreeClassifier', 'SVC', 'RandomForestClassifier', 'KNeighborsClassifier', 'range', 'logspace', 'linspace', 'tolist', 'GridSearchCV', 'DataFrame', 'barplot', 'set_xlabel', 'set_title', 'VotingClassifier', 'Series', 'to_csv']",74,"[1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1
 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",style filterwarnings walk print read csv read csv head describe info value counts figure bar xticks ylabel title show print bar plot print figure hist xlabel ylabel title show plot hist groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values percentile percentile extend counter list detect outliers drop reset index len concat reset index head isnull isnull sum isnull boxplot show fillna isnull isnull mean fillna isnull heatmap factorplot show factorplot set ylabels show factorplot set ylabels show facetgrid map show facetgrid map add legend show facetgrid map add legend show facetgrid map add legend show isnull factorplot factorplot factorplot factorplot heatmap list ilocitrain dftrain df median isnan isnull boxplot show fillna isnull isnull fillna isnull head split split strip head countplot xticks show replace head countplot xticks show factorplot set xticklabels set ylabels show drop head get dummies head head factorplot set ylabels show head countplot show factorplot set ylabels show get dummies head head countplot show get dummies head head replace replace strip split list isdigit append append head head get dummies head countplot show astype get dummies head astype get dummies head drop drop head drop train test split print print print print print logisticregression fit round round print print decisiontreeclassifier svc randomforestclassifier logisticregression kneighborsclassifier range range logspace linspace tolist range gridsearchcv fit append append print dataframe barplot set xlabel set title votingclassifier fit print series astype concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.08066443451894102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1096829055355923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0624338755211139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0856659185053594, 0.0, 0.03204418750992384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07095850732882493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04879692179024057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0478939659931217, 0.13894918333096828, 0.028366450572173664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03749506865094122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015659856871064144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027420726383898076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02234903889181421, 0.0, 0.0, 0.0, 0.054940899235816285, 0.05159630822544124, 0.0, 0.06299942651633067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07997461606472067, 0.0, 0.0, 0.0, 0.13551787427521314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05159630822544124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11589264799981479, 0.3584836394670805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05520763348037874, 0.0, 0.0, 0.0, 0.06508043037932426, 0.0, 0.033481323033737236, 0.0, 0.0, 0.0, 0.04132114661308335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09846108927855206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0331793320977917, 0.0, 0.0, 0.08665983757920202, 0.0, 0.0, 0.0, 0.0, 0.2829675645407356, 0.06012099140405191, 0.0, 0.05922657364654098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06299942651633067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06696264606747447, 0.0, 0.0, 0.020607321742959327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05706056917094181, 0.0, 0.0, 0.0, 0.0, 0.03512150244246796, 0.2445541308525745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027978881438668612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07195698068822834, 0.029182645097079088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05022696296567693, 0.09613256252977151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04182926943887861, 0.0, 0.0, 0.05965483550595563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0875541726300184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11233535167747462, 0.03126011535848755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05314874384149686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10988179847163257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0479713204588189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15999439936657464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020209813027192144, 0.0, 0.0, 0.08451315317777783, 0.0, 0.0, 0.0, 0.02489627169597053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07404610759310831, 0.0, 0.0, 0.07490899883004636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06153063478854622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03052559761600931, 0.17973656268395938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5175690202956538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10293136289192653, 0.0, 0.0, 0.0, 0.0871048552276091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10319261645088249, 0.0, 0.031010084273699074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022116511193794913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026715904691650916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02270679011375872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07037134436735976, 0.0, 0.0, 0.0, 0.0, 0.049002041890427415, 0.0, 0.0, 0.0, 0.0, 0.02234903889181421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028366450572173664, 0.10293136289192653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04509021656098247, 0.0, 0.0, 0.026546179088348196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06408837501984768, 0.0, 0.037031689280468086, 0.11109506784140426, 0.0, 0.06202016854739815, 0.28530284585470905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
aashishpotnuru_titanic-dataset.py,"['numpy', 'pandas', 'os\n', 'sklearn', 'matplotlib']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,147,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'data.set_index', 'data.drop', 'data.head', 'data.Pclass.astype', 'pd.get_dummies', 'data.drop', 'pd.concat', 'data.head', 'data.fillna', 'data.isnull', 'None.values.any', 'train_test_split', 'range', 'RandomForestClassifier', 'model.fit', 'model.predict', 'accuracy_score', 'model.predict', 'accuracy_score', 'model.predict', 'accuracy_score', 'train_accs.append', 'dev_accs.append', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.show', 'RandomForestClassifier', 'model_final.fit', 'pd.read_csv', 'test.set_index', 'test.drop', 'test.Pclass.astype', 'pd.get_dummies', 'test.drop', 'pd.concat', 'test.fillna', 'test.head', 'model_final.predict', 'pd.DataFrame', 'output.to_csv']","['walk', 'print', 'read_csv', 'set_index', 'drop', 'head', 'Pclass', 'get_dummies', 'drop', 'concat', 'head', 'fillna', 'isnull', 'values', 'train_test_split', 'range', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'predict', 'accuracy_score', 'predict', 'accuracy_score', 'append', 'append', 'plot', 'plot', 'legend', 'show', 'RandomForestClassifier', 'fit', 'read_csv', 'set_index', 'drop', 'Pclass', 'get_dummies', 'drop', 'concat', 'fillna', 'head', 'predict', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'set_index', 'drop', 'head', 'Pclass', 'get_dummies', 'concat', 'fillna', 'isnull', 'values', 'train_test_split', 'range', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'append', 'plot', 'legend', 'show', 'DataFrame', 'to_csv']",24,"[1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv set index drop head pclass get dummies drop concat head fillna isnull values train test split range randomforestclassifier fit predict accuracy score predict accuracy score predict accuracy score append append plot plot legend show randomforestclassifier fit read csv set index drop pclass get dummies drop concat fillna head predict dataframe csv,"[0.0, 0.0, 0.4134170283006472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22365071092127162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1990003126898485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1529098580836497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06386297126314439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2609176648075044, 0.0, 0.0, 0.0, 0.1842199491719075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13270330914670178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11234207398100338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13384578941571493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18220724551809786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27308254326469017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0906658317477383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09781670053375333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36122552585442136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19563340106750665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23311439941814868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054373196666373656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16483659068097065, 0.0, 0.0, 0.11488527890534889, 0.0, 0.0, 0.0, 0.10153029475110124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2571536321385473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1832473794641081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11109026542391993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08880628526943779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09260129875086674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09114234186546806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10494193408928483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10825883571120164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
g9jiggy_titanic-solution-an-approach-from-a-beginner-s.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'warnings\n', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,511,"['# Data Dictionary', '# Variable\tDefinition\tKey', '# survival\tSurvival\t0 = No, 1 = Yes', '# pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd', '# sex\tSex\t', '# Age\tAge in years\t', '# sibsp\t# of siblings / spouses aboard the Titanic\t', '# parch\t# of parents / children aboard the Titanic\t', '# ticket\tTicket number\t', '# fare\tPassenger fare\t', '# cabin\tCabin number\t', '# embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton', '# Variable Notes', '# pclass: A proxy for socio-economic status (SES)', '# 1st = Upper', '# 2nd = Middle', '# 3rd = Lower', '# age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5', '# sibsp: The dataset defines family relations in this way...', '# Sibling = brother, sister, stepbrother, stepsister', '# Spouse = husband, wife (mistresses and fiancÃ©s were ignored)', '# parch: The dataset defines family relations in this way...', '# Parent = mother, father', '# Child = daughter, son, stepdaughter, stepson', '# Some children travelled only with a nanny, therefore parch=0 for them.', '# Importing the usual libraries and filter warnings', ' #   Column       Non-Null Count  Dtype  ', '# To see the survival count', '# To see the survival count among male and female', '# Since most of the population onboard was embarked for Southampton and ', '# One value of fare is missing', ""# Since almost a thousand people are missing Cabin its best we drop this column as we couldn't see any corelation between the "", '# value of Cabin and Survived at this stage', '# Looks like we have dealt with all the missing values quickly ', '# Later we could explore multiple other pro techniqies to deal with missing values but at this stage', '# we are looking for a quick model solution', ' #   Column    Non-Null Count  Dtype  ', '# Categorical values need to be converted into numbers and one such simple approach is one hot encoding', '# Loading ', '# Logistic Regression', '# Lets try some hyperparameter tuning with Grid search']",41,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'print', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'train.info', 'train.describe', 'train.head', 'test.head', 'sns.countplot', 'ax.set_title', 'ax.annotate', 'xticks', 'sns.countplot', 'ax.set_title', 'ax.annotate', 'xticks', 'sns.countplot', 'ax.annotate', 'xticks', 'pd.concat', 'df.isnull', 'None.sum', 'df.groupby', 'None.mean', 'df.isnull', 'df.isnull', 'df.isnull', 'df.isnull', 'df.isnull', 'df.isnull', 'df.isnull', 'None.sum', 'df.fillna', 'df.isnull', 'dfdfdf.Agedf.Sex.mean', 'df.Fare.isnull', 'df.isnull', 'None.sum', 'df.drop', 'df.isnull', 'None.sum', 'df.drop', 'df_prep.head', 'df_prep.info', 'df_prep.apply', 'df_prep.apply', 'df_prep.apply', 'pd.get_dummies', 'OneHot.head', 'df_prep.drop', 'pd.concat', 'df_train.head', 'train_test_split', 'print', 'LogisticRegression', 'model.fit', 'model.predict', 'accuracy_score', 'f1_score', 'precision_score', 'recall_score', 'roc_auc_score', 'cross_val_score', 'cross_val_predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'confusion_matrix', 'confusion_matrix', 'GridSearchCV', 'grid_search.fit', 'LogisticRegression', 'model.fit', 'model.predict', 'accuracy_score', 'f1_score', 'precision_score', 'recall_score', 'roc_auc_score', 'cross_val_score', 'cross_val_predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'model.predict', 'test.copy', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'walk', 'print', 'read_csv', 'read_csv', 'print', 'isnull', 'sum', 'isnull', 'sum', 'info', 'describe', 'head', 'head', 'countplot', 'set_title', 'annotate', 'xticks', 'countplot', 'set_title', 'annotate', 'xticks', 'countplot', 'annotate', 'xticks', 'concat', 'isnull', 'sum', 'groupby', 'mean', 'isnull', 'isnull', 'isnull', 'isnull', 'isnull', 'isnull', 'isnull', 'sum', 'fillna', 'isnull', 'Agedf', 'Fare', 'isnull', 'sum', 'drop', 'isnull', 'sum', 'drop', 'head', 'info', 'apply', 'apply', 'apply', 'get_dummies', 'head', 'drop', 'concat', 'head', 'train_test_split', 'print', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'f1_score', 'precision_score', 'recall_score', 'roc_auc_score', 'cross_val_score', 'cross_val_predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'confusion_matrix', 'confusion_matrix', 'GridSearchCV', 'fit', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'f1_score', 'precision_score', 'recall_score', 'roc_auc_score', 'cross_val_score', 'cross_val_predict', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'predict', 'copy', 'to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'walk', 'print', 'read_csv', 'isnull', 'sum', 'info', 'describe', 'head', 'countplot', 'set_title', 'annotate', 'xticks', 'concat', 'groupby', 'mean', 'fillna', 'Agedf', 'Fare', 'drop', 'apply', 'get_dummies', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'f1_score', 'precision_score', 'recall_score', 'roc_auc_score', 'cross_val_score', 'cross_val_predict', 'confusion_matrix', 'GridSearchCV', 'copy', 'to_csv']",39,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings walk print read csv read csv print isnull sum isnull sum info describe head head countplot set title annotate xticks countplot set title annotate xticks countplot annotate xticks concat isnull sum groupby mean isnull isnull isnull isnull isnull isnull isnull sum fillna isnull agedf fare isnull sum drop isnull sum drop head info apply apply apply get dummies head drop concat head train test split print logisticregression fit predict accuracy score f1 score precision score recall score roc auc score cross val score cross val predict print print print print print print print confusion matrix confusion matrix gridsearchcv fit logisticregression fit predict accuracy score f1 score precision score recall score roc auc score cross val score cross val predict print print print print print print print predict copy csv,"[0.0, 0.0, 0.10541271869713821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09304711181658529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24143327628300984, 0.0, 0.11098482412412272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15668382284980917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07611139314378614, 0.0, 0.0, 0.11963109987824191, 0.0, 0.0, 0.0, 0.040383727695074215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13003626702075877, 0.0, 0.0, 0.0, 0.2191241891601249, 0.0, 0.0, 0.05848323636708989, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03485909403860886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07484463226173473, 0.0, 0.0, 0.0, 0.03522918327822961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15668382284980917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05533905264983928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025377431817626604, 0.0, 0.05222276420117429, 0.0, 0.0, 0.0, 0.06445099239127455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051191826591434106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051751731398113184, 0.0, 0.0, 0.03379209551434484, 0.0, 0.0, 0.0, 0.0, 0.11614761730624616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0642848732779108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03230081094975193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45079896976344036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03278440609714674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0652435410755067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03262177053775335, 0.0, 0.0, 0.0, 0.0, 0.11301875525286152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03504319453683144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16095551752200654, 0.0, 0.11144870491513428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3535327897948973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03883216099187445, 0.0, 0.15668382284980917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14625031713032588, 0.0, 0.0, 0.0, 0.0, 0.03246058064689985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39341287316576085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07008638907366288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03396562548278953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20697844249387098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03541709939841691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0731748487500168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03485909403860886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2191241891601249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04140561738184721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17328142994675208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ren666_kaggle-titanic.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,545,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', 'plt.ylabel(u""age"")                         # è®¾å®šçºµåæ\xa0‡åç§°', ""plt.legend((u'top', u'2',u'3'),loc='best') # sets our legend for our graph."", 'fig.set(alpha=0.2)  # è®¾å®šå›¾è¡¨é¢œè‰²alphaå‚æ•°', '#', '    # æŠŠå·²æœ‰çš„æ•°å€¼åž‹ç‰¹å¾å–å‡ºæ¥ä¸¢è¿›Random Forest Regressorä¸\xad', '    # ä¹˜å®¢åˆ†æˆå·²çŸ¥å¹´é¾„å’ŒæœªçŸ¥å¹´é¾„ä¸¤éƒ¨åˆ†', '#     unknown_age = age_df[age_df.Age.isnull()].values', '    # yå³ç›®æ\xa0‡å¹´é¾„', '    # Xå³ç‰¹å¾å±žæ€§å€¼', '    # fitåˆ°RandomForestRegressorä¹‹ä¸\xad', '    # ç”¨å¾—åˆ°çš„é¢„æµ‹ç»“æžœå¡«è¡¥åŽŸç¼ºå¤±æ•°æ®', '# def set_Cabin_type(df):', '#     df.loc[ (df.Cabin.notnull()), \'Cabin\' ] = ""Yes""', '#     df.loc[ (df.Cabin.isnull()), \'Cabin\' ] = ""No""', '#     return df', '# data_train = set_Cabin_type(data_train)', '# for dataset in combine:', ""#     dataset['isChild']=0"", ""#     dataset.loc[dataset['Age']<=14,'isChild']=1"", '# data_train.shape', '# #ç‰¹å¾å›\xa0å\xadåŒ– data_train', ""# dummies_Embarked  = pd.get_dummies(data_train['Embarked'],prefix='Embarked')"", ""# dummies_Sex = pd.get_dummies(data_train['Sex'],prefix='Sex')"", ""# dummies_Pclass = pd.get_dummies(data_train['Pclass'],prefix = 'Pclass')"", ""# dummies_isChild = pd.get_dummies(data_train['isChild'],prefix = 'isChild')"", ""# dummies_FamliySize =pd.get_dummies(data_train['FamliySize'],prefix = 'FamliySize')"", ""# dummies_isAlone =pd.get_dummies(data_train['isAlone'],prefix = 'isAlone')"", ""# dummies_AgeBand =pd.get_dummies(data_train['AgeBand'],prefix = 'AgeBand')"", '# data_train = pd.concat([data_train,dummies_Embarked,dummies_Sex,dummies_Pclass,dummies_isChild,dummies_FamliySize,dummies_isAlone,dummies_AgeBand],axis=1)', '# data_train.head()', '# #ç‰¹å¾å›\xa0å\xadåŒ– data_test', ""# dummies_Embarked  = pd.get_dummies(data_test['Embarked'],prefix='Embarked')"", ""# dummies_Sex = pd.get_dummies(data_test['Sex'],prefix='Sex')"", ""# dummies_Pclass = pd.get_dummies(data_test['Pclass'],prefix = 'Pclass')"", ""# dummies_isChild = pd.get_dummies(data_test['isChild'],prefix = 'isChild')"", ""# dummies_FamliySize =pd.get_dummies(data_test['FamliySize'],prefix = 'FamliySize')"", ""# dummies_isAlone =pd.get_dummies(data_test['isAlone'],prefix = 'isAlone')"", ""# dummies_AgeBand =pd.get_dummies(data_test['AgeBand'],prefix = 'AgeBand')"", '# data_test = pd.concat([data_test,dummies_Embarked,dummies_Sex,dummies_Pclass,dummies_isChild,dummies_FamliySize,dummies_isAlone,dummies_AgeBand],axis=1)', '# data_test.info()', '# #å½’ä¸€åŒ–', '# import sklearn.preprocessing as preprocessing', '# scaler = preprocessing.StandardScaler()', ""# age_scale_param = scaler.fit(train_df['Age'].values.reshape(-1,1))"", ""# train_df['Age_scaled']= scaler.fit_transform(train_df['Age'].values.reshape(-1,1),age_scale_param)"", ""# fare_scale_param = scaler.fit(train_df['Fare'].values.reshape(-1,1))"", ""# train_df['Fare_scaled'] = scaler.fit_transform(train_df['Fare'].values.reshape(-1,1),fare_scale_param)"", '# train_df', ""# test_df['Age_scaled'] = scaler.fit_transform(test_df['Age'].values.reshape(-1,1), age_scale_param)"", ""# test_df['Fare_scaled'] = scaler.fit_transform(test_df['Fare'].values.reshape(-1,1), fare_scale_param)"", '# test_df', ""# train_df = train_df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Embarked_.*|Sex_.*|Pclass_.*')"", '# train_np = train_df.values', ""# test = test_df.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Embarked_.*|Sex_.*|Pclass_.*')"", ""# test = test_df.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Embarked_.*|Sex_.*|Pclass_.*')"", '# predictions = clf.predict(test)', ""# result = pd.DataFrame({'PassengerId':data_test['PassengerId'].values,'Survived':predictions.astype(np.int32)})"", '# result', ""# result.to_csv('Submission.csv',index=False)"", '# #æŸ¥çœ‹æ‰“åˆ†æƒ…å†µ', '# from sklearn import cross_validation', ""# clf =linear_model.LogisticRegression(C=1.0,penalty='l1',tol=1e-6)"", ""# all_data = train_df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Embarked_.*|Sex_.*|Pclass_.*')"", '# X = all_data.values[:,1:]', '# y = all_data.values[:,0]', '# print (cross_validation.cross_val_score(clf,X,y,cv=5))', '# #åˆ†å‰²æ•°æ® è®\xadç»ƒæ•°æ®:cvæ•°æ®=7:3', '# split_train,split_cv = cross_validation.train_test_split(train_df,test_size=0.3,random_state=0)', ""# split_train_df =split_train.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Embarked_,*|Sex_.*|Pclass_.*')"", '# #ç”Ÿæˆ,æ¨¡åž‹', ""# clf = linear_model.LogisticRegression(C=1.0,penalty='l1',tol=1e-6)"", '# X =split_train_df.values[:,1:]', '# y = split_train_df.values[:,0]', '# clf.fit(X,y)', '# #å¯¹cross validationæ•°æ®è¿›è¡Œé¢„æµ‹', ""# split_cv_df = split_cv.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Embarked_.*|Sex_.*|Pclass_.*')"", '# predictions = clf.predict(split_cv_df.values[:,1:])', '# origin_data_train = pd.read_csv(""../input/train.csv"")', ""# bad_cases = origin_data_train.loc[origin_data_train['PassengerId'].isin(split_cv[predictions!=split_cv_df.values[:,0]]['PassengerId'].values)]"", '# bad_cases', '# # æ\xa0¹æ®å\xad¦ä¹\xa0æ›²çº¿åˆ¤æ–\xadæ¨¡åž‹çŠ¶æ€ è¿‡æ‹Ÿåˆ æ¬\xa0æ‹Ÿåˆ', '# import numpy as np ', '# import matplotlib.pyplot as plt', '# from sklearn.learning_curve import learning_curve', '# #ç”¨sklearnçš„learning_curveå¾—åˆ°training_score, ä½¿ç”¨matplotç”»å‡ºlearning curve', '# def plot_learning_curve(estimator,title,X,y,ylim=None,cv=None,n_jobs=1,train_sizes=np.linspace(.05,1.,20),verbose=0,plot=True):', '#     """"""', '#     ç”»å‡ºdataåœ¨æŸæ¨¡åž‹ä¸Šçš„learning curve', '#     å‚æ•°è¯´æ˜Ž:', '#     ----------------------------------', '#     estimateor:ä½\xa0ç”¨çš„åˆ†ç±»å™¨', '#     title: æ\xa0‡é¢˜', '#     X : è¾“å…¥çš„feature,numpyç±»åž‹', '#     y : è¾“å…¥çš„target ', '#     ylim  : tupleæ\xa0¼å¼çš„(ymin,ymax),è®¾å®šå›¾åƒä¸\xadåæ\xa0‡çš„æœ€é«˜ç‚¹å’Œæœ€ä½Žç‚¹', '#     cv :åšcross validationçš„æ—¶å€™,æ•°æ®åˆ†æˆçš„ä»½æ•° ,é»˜è®¤æ˜¯3ä»½', '#     n_jobs:å¹¶è¡Œçš„ä»»åŠ¡æ•°(é»˜è®¤1)', '#     """"""', '#     train_sizes,train_scores,test_scores = learning_curve(estimator,X,y,cv=cv,n_jobs=n_jobs,train_sizes=train_sizes,verbose=verbose)', '#     train_scores_mean  = np.mean(train_scores,axis=1)', '#     train_scores_std = np.std(train_scores,axis=1)', '#     test_scores_mean = np.mean(test_scores,axis=1)', '#     test_scores_std = np.std(test_scores,axis=1)', '#     if plot:', '#         plt.figure()', '#         plt.title(title)', '#         if ylim is not None:', '#             plt.ylim(*ylim)', ""#         plt.xlabel('train samples')"", ""#         plt.ylabel('score')"", '# #         plt.gca().invert_yaxis()', '#         plt.grid()', '#         plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, ', '#                          alpha=0.1, color=""b"")', '#         plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, ', '#                          alpha=0.1, color=""r"")', '#         plt.plot(train_sizes, train_scores_mean, \'o-\', color=""b"", label=u""scores on train dataset"")', '#         plt.plot(train_sizes, test_scores_mean, \'o-\', color=""r"", label=u""scores on cv dataset"")', '#         plt.legend(loc=""best"")', '#         plt.draw()', '#         plt.show()', '# #         plt.gca().invert_yaxis()', '#     midpoint = ((train_scores_mean[-1] + train_scores_std[-1]) + (test_scores_mean[-1] - test_scores_std[-1])) / 2', '#     diff = (train_scores_mean[-1] + train_scores_std[-1]) - (test_scores_mean[-1] - test_scores_std[-1])', '#     return midpoint, diff', '# plot_learning_curve(clf, u""learning curve"", X, y)']",134,"['print', 'pd.read_csv', 'pd.read_csv', 'data_train.info', 'data_train.describe', 'plt.figure', 'fig.set', 'plt.subplot2grid', 'data_train.Survived.value_counts', 'None.plot', 'plt.title', 'plt.ylabel', 'plt.subplot2grid', 'data_train.Pclass.value_counts', 'None.plot', 'plt.title', 'plt.ylabel', 'plt.subplot2grid', 'plt.scatter', 'plt.ylabel', 'plt.grid', 'plt.title', 'plt.subplot2grid', 'data_train.Agedata_train.Pclass.plot', 'data_train.Agedata_train.Pclass.plot', 'data_train.Agedata_train.Pclass.plot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.legend', 'plt.subplot2grid', 'data_train.Embarked.value_counts', 'None.plot', 'plt.title', 'plt.ylabel', 'plt.show', 'plt.figure', 'fig.set', 'data_train.Surviveddata_train.Sex.value_counts', 'data_train.Surviveddata_train.Sex.value_counts', 'pd.DataFrame', 'df.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'plt.figure', 'fig.set', 'data_train.Pclassdata_train.Survived.value_counts', 'data_train.Pclassdata_train.Survived.value_counts', 'pd.DataFrame', 'df.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'plt.figure', 'fig.set', 'plt.title', 'fig.add_subplot', 'data_train.Surviveddata_train.Sexdata_train.Pclass.value_counts', 'S1.plot', 'ax1.set_xticklabels', 'ax1.legend', 'fig.add_subplot', 'data_train.Surviveddata_train.Sexdata_train.Pclass.value_counts', 'S2.plot', 'ax2.set_xticklabels', 'ax2.legend', 'fig.add_subplot', 'data_train.Surviveddata_train.Sexdata_train.Pclass.value_counts', 'S3.plot', 'ax3.set_xticklabels', 'ax3.legend', 'fig.add_subplot', 'data_train.Surviveddata_train.Sexdata_train.Pclass.value_counts', 'S4.plot', 'ax4.set_xticklabels', 'ax4.legend', 'plt.figure', 'fig.set', 'data_train.Embarkeddata_train.Survived.value_counts', 'data_train.Embarkeddata_train.Survived.value_counts', 'pd.DataFrame', 'df.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'data_train.groupby', 'pd.DataFrame', 'print', 'data_train.groupby', 'pd.DataFrame', 'print', 'data_train.Cabin.value_counts', 'age_df.Age.notnull', 'age_df.Age.notnull', 'RandomForestRegressor', 'rfr.fit', 'df.Fare.isnull', 'age_df.Age.isnull', 'age_df.Age.isnull', 'rfr.predict', 'df.Age.isnull', 'get_rfr', 'set_missing_ages', 'set_missing_ages', 'data_train.Embarked.isnull', 'data_train.info', 'data_train.info', 'data_test.info', 'data_train.head', 'data_train.head', 'data_train.info', 'data_train.drop', 'data_test.drop', 'linear_model.LogisticRegression', 'BaggingRegressor', 'bagging_clf.fit', 'bagging_clf.predict', 'pd.DataFrame', 'result.to_csv', 'linear_model.LogisticRegression', 'clf.fit', 'pd.DataFrame']","['print', 'read_csv', 'read_csv', 'info', 'describe', 'figure', 'set', 'subplot2grid', 'Survived', 'plot', 'title', 'ylabel', 'subplot2grid', 'Pclass', 'plot', 'title', 'ylabel', 'subplot2grid', 'scatter', 'ylabel', 'grid', 'title', 'subplot2grid', 'Agedata_train', 'Agedata_train', 'Agedata_train', 'xlabel', 'ylabel', 'title', 'legend', 'subplot2grid', 'Embarked', 'plot', 'title', 'ylabel', 'show', 'figure', 'set', 'Surviveddata_train', 'Surviveddata_train', 'DataFrame', 'plot', 'title', 'xlabel', 'ylabel', 'show', 'figure', 'set', 'Pclassdata_train', 'Pclassdata_train', 'DataFrame', 'plot', 'title', 'xlabel', 'ylabel', 'show', 'figure', 'set', 'title', 'add_subplot', 'Surviveddata_train', 'plot', 'set_xticklabels', 'legend', 'add_subplot', 'Surviveddata_train', 'plot', 'set_xticklabels', 'legend', 'add_subplot', 'Surviveddata_train', 'plot', 'set_xticklabels', 'legend', 'add_subplot', 'Surviveddata_train', 'plot', 'set_xticklabels', 'legend', 'figure', 'set', 'Embarkeddata_train', 'Embarkeddata_train', 'DataFrame', 'plot', 'title', 'xlabel', 'ylabel', 'show', 'groupby', 'DataFrame', 'print', 'groupby', 'DataFrame', 'print', 'Cabin', 'Age', 'Age', 'RandomForestRegressor', 'fit', 'Fare', 'Age', 'Age', 'predict', 'Age', 'get_rfr', 'set_missing_ages', 'set_missing_ages', 'Embarked', 'info', 'info', 'info', 'head', 'head', 'info', 'drop', 'drop', 'LogisticRegression', 'BaggingRegressor', 'fit', 'predict', 'DataFrame', 'to_csv', 'LogisticRegression', 'fit', 'DataFrame']","['print', 'read_csv', 'info', 'describe', 'figure', 'set', 'subplot2grid', 'Survived', 'plot', 'title', 'ylabel', 'Pclass', 'scatter', 'grid', 'Agedata_train', 'xlabel', 'legend', 'Embarked', 'show', 'Surviveddata_train', 'DataFrame', 'Pclassdata_train', 'add_subplot', 'set_xticklabels', 'Embarkeddata_train', 'groupby', 'Cabin', 'Age', 'RandomForestRegressor', 'fit', 'Fare', 'predict', 'get_rfr', 'set_missing_ages', 'head', 'drop', 'LogisticRegression', 'BaggingRegressor', 'to_csv']",39,"[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv info describe figure set subplot2grid survived plot title ylabel subplot2grid pclass plot title ylabel subplot2grid scatter ylabel grid title subplot2grid agedata train agedata train agedata train xlabel ylabel title legend subplot2grid embarked plot title ylabel show figure set surviveddata train surviveddata train dataframe plot title xlabel ylabel show figure set pclassdata train pclassdata train dataframe plot title xlabel ylabel show figure set title add subplot surviveddata train plot set xticklabels legend add subplot surviveddata train plot set xticklabels legend add subplot surviveddata train plot set xticklabels legend add subplot surviveddata train plot set xticklabels legend figure set embarkeddata train embarkeddata train dataframe plot title xlabel ylabel show groupby dataframe print groupby dataframe print cabin age age randomforestregressor fit fare age age predict age get rfr set missing ages set missing ages embarked info info info head head info drop drop logisticregression baggingregressor fit predict dataframe csv logisticregression fit dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.11772936610191122, 0.0, 0.15418319130095057, 0.20688158088212263, 0.0, 0.13059893144197565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06896052696070754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041478786386073836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04104290841324649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11999131248830244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024463738549196888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03501677378522666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062101053537523355, 0.14824100593443018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038836353982306074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15107865688561592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04523101562393161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017962937593868786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056478428474760575, 0.0, 0.0, 0.0, 0.047429860843590174, 0.0, 0.0, 0.0, 0.0, 0.03260446114572145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11278608752691954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13127609729048845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04578721779536758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11295685694952115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04847871275264463, 0.13792105392141507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2625521945809769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03128540260593927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043783327488786085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056478428474760575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027251994350552255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07412050296721509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0581777578825928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2705223213606762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1192720376969527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1792706060516997, 0.3448026348035377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04547041339808295, 0.391796794325927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231089960283143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3180286011395595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14030502681729978, 0.0, 0.1621427335605532, 0.0, 0.0, 0.27155444052252187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
esraa966_titanic-competition.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,508,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# Make copy to avoid changing original data ', '# Apply label encoder to each column with categorical data', '# Imputation', '# Imputation removed column names; put them back', 'from sklearn.linear_model import LogisticRegression # Logistic Regression', '# Select numerical columns', '# Keep selected columns only', '# Preprocessing for numerical data', '# Preprocessing for categorical data', '# Bundle preprocessing for numerical and categorical data', '# Preprocessing of training data, fit model ', '# Preprocessing of validation data, get predictions', '# Evaluate the model', '# predictions = my_model.predict(imputed_X_valid)', '# print(accuracy_score(predictions, y_valid))', ""# test_data_sub = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')"", ""# output = pd.DataFrame({'Id': test_data_sub.index, 'Survived': prediction_rf})"", ""# output.to_csv('submission.csv', index=False)"", ""# print('done!')""]",27,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_data.head', 'test_data.head', 'print', 'print', 'train_data.pivot_table', 'sex_pivot.plot.bar', 'plt.show', 'train_data.pivot_table', 'class_pivot.plot.bar', 'plt.show', 'train_data.describe', 'survived.head', 'died.head', 'survived.plot.hist', 'died.plot.hist', 'plt.legend', 'plt.show', 'sns.scatterplot', 'sns.scatterplot', 'sns.scatterplot', 'sns.barplot', 'train_data.drop', 'train_data.drop', 'train_data.head', 'test_data.drop', 'test_data.head', 'train_data.isnull', 'None.sum', 'train_data.drop', 'test_data.drop', 'train_data.drop', 'train_data.drop', 'X.head', 'train_test_split', 'X_train.head', 'X_valid.head', 'list', 'print', 'print', 'X_train.copy', 'X_valid.copy', 'LabelEncoder', 'label_encoder.fit_transform', 'label_encoder.transform', 'label_X_train.head', 'X_train.isnull', 'None.sum', 'X_valid.isnull', 'None.sum', 'SimpleImputer', 'pd.DataFrame', 'pd.DataFrame', 'imputed_X_train.head', 'imputed_X_train.isnull', 'None.sum', 'LogisticRegression', 'model.fit', 'model.predict', 'print', 'print', 'RandomForestClassifier', 'model.fit', 'model.predict', 'print', 'print', 'SVC', 'model.fit', 'model.predict', 'print', 'print', 'LinearDiscriminantAnalysis', 'model.fit', 'model.predict', 'print', 'print', 'X_traincname.nunique', 'X_trainmy_cols.copy', 'X_validmy_cols.copy', 'SimpleImputer', 'Pipeline', 'ColumnTransformer', 'LogisticRegression', 'Pipeline', 'my_pipeline.fit', 'my_pipeline.predict', 'accuracy_score', 'print', 'print', 'XGBRegressor', 'my_model.fit', 'test_data.head']","['walk', 'print', 'read_csv', 'read_csv', 'head', 'head', 'print', 'print', 'pivot_table', 'plot', 'show', 'pivot_table', 'plot', 'show', 'describe', 'head', 'head', 'plot', 'plot', 'legend', 'show', 'scatterplot', 'scatterplot', 'scatterplot', 'barplot', 'drop', 'drop', 'head', 'drop', 'head', 'isnull', 'sum', 'drop', 'drop', 'drop', 'drop', 'head', 'train_test_split', 'head', 'head', 'list', 'print', 'print', 'copy', 'copy', 'LabelEncoder', 'fit_transform', 'transform', 'head', 'isnull', 'sum', 'isnull', 'sum', 'SimpleImputer', 'DataFrame', 'DataFrame', 'head', 'isnull', 'sum', 'LogisticRegression', 'fit', 'predict', 'print', 'print', 'RandomForestClassifier', 'fit', 'predict', 'print', 'print', 'SVC', 'fit', 'predict', 'print', 'print', 'LinearDiscriminantAnalysis', 'fit', 'predict', 'print', 'print', 'nunique', 'copy', 'copy', 'SimpleImputer', 'Pipeline', 'ColumnTransformer', 'LogisticRegression', 'Pipeline', 'fit', 'predict', 'accuracy_score', 'print', 'print', 'XGBRegressor', 'fit', 'head']","['walk', 'print', 'read_csv', 'head', 'pivot_table', 'plot', 'show', 'describe', 'legend', 'scatterplot', 'barplot', 'drop', 'isnull', 'sum', 'train_test_split', 'list', 'copy', 'LabelEncoder', 'fit_transform', 'transform', 'SimpleImputer', 'DataFrame', 'LogisticRegression', 'fit', 'predict', 'RandomForestClassifier', 'SVC', 'LinearDiscriminantAnalysis', 'nunique', 'Pipeline', 'ColumnTransformer', 'accuracy_score', 'XGBRegressor']",33,"[1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv head head print print pivot table plot show pivot table plot show describe head head plot plot legend show scatterplot scatterplot scatterplot barplot drop drop head drop head isnull sum drop drop drop drop head train test split head head list print print copy copy labelencoder fit transform transform head isnull sum isnull sum simpleimputer dataframe dataframe head isnull sum logisticregression fit predict print print randomforestclassifier fit predict print print svc fit predict print print lineardiscriminantanalysis fit predict print print nunique copy copy simpleimputer pipeline columntransformer logisticregression pipeline fit predict accuracy score print print xgbregressor fit head,"[0.0, 0.0, 0.06849240936620678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06495101377695403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11565722529850121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20991613484299879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05066634356617537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06348256319887156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04529972034754694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22694304055937284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19542756425330102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3622438088961988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18025153794326176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06607336731711264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04861702134052374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10458160392903548, 0.0, 0.0, 0.0, 0.06495101377695403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08478459485868188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09139427473863182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20916320785807097, 0.2154565343501242, 0.0, 0.19446808536209495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14482863955558323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4053698675569327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040963680041889196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05046275819659925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33408246990927326, 0.042603643867401765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16564281279275506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24183119273093157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04413864956145265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17931362095562092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054151009232292865, 0.0, 0.0, 0.20916320785807097, 0.0, 0.0, 0.0, 0.0460248535573699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04529972034754694, 0.0, 0.0, 0.0, 0.10305996098074822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05380698896356229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13724958880189608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
yergou_titanic.py,"['numpy', 'pandas', 'seaborn', 'matplotlib']","[1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,74,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Load in the train and test datasets', '    plt.subplots(figsize=(10, 8)) # è®¾ç½®ç”»é¢å¤§å°']",4,"['pd.read_csv', 'pd.read_csv', 'train.info', 'train.sample', 'train.drop', 'new_train.head', 'pd.DataFrame', 'df.corr', 'plt.subplots', 'sns.heatmap', 'plt.show', 'test']","['read_csv', 'read_csv', 'info', 'sample', 'drop', 'head', 'DataFrame', 'corr', 'subplots', 'heatmap', 'show', 'test']","['read_csv', 'info', 'sample', 'drop', 'head', 'DataFrame', 'corr', 'subplots', 'heatmap', 'show', 'test']",11,"[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv info sample drop head dataframe corr subplots heatmap show test,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3332781366208425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25998030809979195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16287159461044357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16635647891376823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15489614738212457, 0.31264659122243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2143280989450177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2589356661662788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5527777636972968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2833167376559737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3013376900371696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23616378775122393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
satyamkr1729_titanic-dataset.py,"['numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn', 'xgboost']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,668,[],0,"['pd.read_csv', 'pd.read_csv', 'train.head', 'np.delete', 'plote.subplots', 'sns.heatmap', 'train.describe', 'train.describe', 'train.describe', 'train.describe', 'train.groupby', 'None.mean', 'None.sort_values', 'train.groupby', 'None.mean', 'None.sort_values', 'train.groupby', 'None.mean', 'None.sort_values', 'train.groupby', 'None.mean', 'None.sort_values', 'train.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'sns.barplot', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'train.drop', 'test.drop', 'train.dropna', 'None.mode', 'data.fillna', 'train.describe', 'LabelEncoder', 'lb.fit_transform', 'lb.fit_transform', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datadataidataj.dropna', 'g_df.median', 'int', 'range', 'range', 'data.isnull', 'train.astype', 'test.astype', 'pd.cut', 'train.groupby', 'None.mean', 'None.sort_values', 'train.head', 'train.drop', 'test.isnull', 'test.dropna', 'None.median', 'pd.qcut', 'train.groupby', 'None.mean', 'None.sort_values', 'train.head', 'train.astype', 'test.astype', 'train.drop', 'data.str.extract', 'pd.crosstab', 'pd.crosstab', 'data.replace', 'data.replace', 'data.replace', 'data.replace', 'train.groupby', 'None.mean', 'None.sort_values', 'data.map', 'None.astype', 'train.drop', 'test.drop', 'train.groupby', 'None.mean', 'None.sort_values', 'data.astype', 'train.groupby', 'None.mean', 'None.sort_values', 'train.drop', 'test.drop', 'train.head', 'train.drop', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'coeff.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'round', 'train_test_split', 'xx_train.head', 'XGBClassifier', 'xg.fit', 'xg.predict', 'round', 'pd.DataFrame', 'xg_importance.sort_values', 'f1_score']","['read_csv', 'read_csv', 'head', 'delete', 'subplots', 'heatmap', 'describe', 'describe', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'FacetGrid', 'map', 'barplot', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'FacetGrid', 'map', 'drop', 'drop', 'dropna', 'mode', 'fillna', 'describe', 'LabelEncoder', 'fit_transform', 'fit_transform', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'isnull', 'astype', 'astype', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'isnull', 'dropna', 'median', 'qcut', 'groupby', 'mean', 'sort_values', 'head', 'astype', 'astype', 'drop', 'str', 'crosstab', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'drop', 'drop', 'groupby', 'mean', 'sort_values', 'astype', 'groupby', 'mean', 'sort_values', 'drop', 'drop', 'head', 'drop', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'round', 'train_test_split', 'head', 'XGBClassifier', 'fit', 'predict', 'round', 'DataFrame', 'sort_values', 'f1_score']","['read_csv', 'head', 'delete', 'subplots', 'heatmap', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'barplot', 'add_legend', 'drop', 'dropna', 'mode', 'fillna', 'LabelEncoder', 'fit_transform', 'zeros', 'range', 'median', 'int', 'isnull', 'astype', 'cut', 'qcut', 'str', 'crosstab', 'replace', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'SVC', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'train_test_split', 'XGBClassifier', 'f1_score']",42,"[0 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head delete subplots heatmap describe describe describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map facetgrid map barplot facetgrid map add legend facetgrid map add legend facetgrid map facetgrid map drop drop dropna mode fillna describe labelencoder fit transform fit transform facetgrid map add legend zeros range range dropna median int range range isnull astype astype cut groupby mean sort values head drop isnull dropna median qcut groupby mean sort values head astype astype drop str crosstab crosstab replace replace replace replace groupby mean sort values map astype drop drop groupby mean sort values astype groupby mean sort values drop drop head drop logisticregression fit predict round dataframe sort values svc fit predict round kneighborsclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict round train test split head xgbclassifier fit predict round dataframe sort values f1 score,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1069163860504923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16550551374103722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04247285365498845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08567090013692265, 0.033131803037123445, 0.0, 0.0, 0.0, 0.04110220522139274, 0.0, 0.0, 0.0, 0.04151260249221738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036344703651983834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08975043437210613, 0.1481122680810212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19080372356833447, 0.1083173693163141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06657314831012831, 0.0, 0.3072189910673084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02156515588395452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14605057572747362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2871574289507758, 0.0, 0.0, 0.0, 0.0, 0.09869956466671911, 0.039843576447465126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049083520027438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05893516318653051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03708450827179887, 0.0, 0.0, 0.0, 0.0, 0.043206784580593634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09537512253289197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027721227739389086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2611088207387104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.297788979708188, 0.08286721605582405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04854277554227962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11364784483307871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04211859353415761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0267870243498226, 0.0, 0.0, 0.14935687523068927, 0.0, 0.0, 0.0, 0.03299867422041248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1308588644165041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24466667902218966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02785943168436655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4092900197201188, 0.0, 0.0, 0.0, 0.028863204657439526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046091646406441804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03840237388341355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03541050026241734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03009663369300715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029622453616204244, 0.0, 0.0, 0.0, 0.0673931072955366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4092900197201188, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046091646406441804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053516596212485786, 0.0, 0.0]"
roarki_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,392,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04458423492702482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07865667322233022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172539892595686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21253464566011832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04293086506933447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431745498221466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06217197055832407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1038647689272524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5834791208246738, 0.04516844628469951, 0.0, 0.0, 0.22470723731702552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048041479577273886, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053956143394937324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045677422002361044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19047233475457281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14369390600990528, 0.0, 0.0, 0.0, 0.0, 0.02469468754518843, 0.0, 0.0, 0.09820578880126213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06833953619962328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03433813161044625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11647254395745248, 0.07372805772905346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3815299057393845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039771517035677564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034852228728417936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.03629420907111263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2235209192601581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07954303407135513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047391259657758644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022107722972670885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11420394854594243, 0.03351064408530649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041281435841698653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0345079785191372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06970445745683587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050615630922711694, 0.18626743271679844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051418976303892444, 0.0, 0.0, 0.0, 0.0, 0.2402073978863694, 0.07334442273431843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07779023229049523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06140362395662589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
omrihar_getting-to-know-kaggle-with-the-titanic-data-set.py,"['pandas', 'tensorflow', 'sklearn', 'IPython', 'matplotlib']","[1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,87,"['# Some important imports', '# Load the data', '# Prepare the data for the logistic regression', '# Handle NaNs', '# There are 177 NaN values in the age columns (out of 890 rows)', '# As a first attempt, we simply drop those rows', ""# Split this data to train and test datasets so I can estimate how well I'm doing"", ""# First attempt, feed the data to scikit-learn's LogisticRegression algorithm"", '# without tweaking any of the parameters', '# To see which factors are most important here, we plot coefficients with the data columns', '# The result of this is around 0.8, which if we compare with the leaderboard is not very good.', '# The best people get is 100% on the test data set with many above 0.88', '# To proceed now, I will plot some ""learning curves"" to see where I should spend my', '# time in improving the learning algorithm', ""# Since scikit-learn doesn't give you access to the cost function directly, we have to use a circumspect route"", '# (or program it myself)', '      4 # (or program it myself)']",17,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.head', 'train.copy', 'data.join', 'data.join', 'data.Age.isnull', 'train_test_split', 'LogisticRegression', 'None.fit', 'display', 'display', '_logistic_loss', 'display']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'copy', 'join', 'join', 'Age', 'train_test_split', 'LogisticRegression', 'fit', 'display', 'display', '_logistic_loss', 'display']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'copy', 'join', 'Age', 'train_test_split', 'LogisticRegression', 'fit', 'display', '_logistic_loss']",12,"[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv head copy join join age train test split logisticregression fit display display logistic loss display,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1362421024070535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12521531378161874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1208902233751765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6948808483349214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0666130617158994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07936365704152779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07202633920178159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10015311634956539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709327138495282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10165256975766904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32747840638512493, 0.10114829578981599, 0.0, 0.0, 0.0, 0.32747840638512493, 0.0, 0.10114829578981599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12040446736691374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10064850431652642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10531510326955765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10981559820067034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10808542567306803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
continue7777_titanic-data-science-solutions.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,944,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest']",24,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score', 'to_csv']",48,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14739731056786123, 0.0, 0.0386075088739669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11408479331718284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035482800489506514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044290428976480785, 0.05138577160738971, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.06438397294899055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03757921331973189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0612572612591073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21920521835808165, 0.03733218432362304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03887529754869338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19853387909934528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066892959232493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16988786089570734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04630997037753964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022489619870565202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2969112193682155, 0.0, 0.0, 0.0, 0.0, 0.22451453910645058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05648332789475356, 0.0, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.028380818116478954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038344146661578926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1314862676876251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053884920424318535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.239980289670821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30790388882723707, 0.042840970987036014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05019161346595868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1762621307304402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05481677964674111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04354922319089523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027696891186176718, 0.0, 0.0, 0.1544300354958676, 0.0, 0.0, 0.0, 0.034119530308222235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1353037082864551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3794657982870925, 0.0, 0.02852119832929571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04183433832000622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03661327812332207, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055334378413763305, 0.0, 0.0]"
maxwellgreene_python-titanic.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,76,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'test_data.head', 'pd.read_csv', 'train_data.head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'sum', 'len', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",12,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head sum len print sum len print get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29651471721459643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12383969942746267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3572295914637062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10892390691892337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2595466825772223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23555110859145806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615584966167075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1130107814636607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4217505198327656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1598212034362369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19688218283721298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3497991228367539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20992981393866597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kitushan_titanic-data-science-solutions-dc3035.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,949,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
eeshwarib_titanic-data-analysis-1.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,300,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# shape of our train data(no of rows,no of columns)', '# descriptive anlalysis of numerical variables', '# check data for null', '# unique values in each feature of dataset', '# grouping pclass and survived features of the dataset and plotting them using seaborn heatmap which gives us the survival rate based on passenger class', ""# emb=train_data['Embarked'].mode()"", '# librabries needed for our model building and predicting', '# since we need numerical data to process', ""# Converting 'object'-dtype to 'int' dtype"", '# Using Decision Tree Classifier to predict']",16,"['os.walk', 'print', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'print', 'print', 'print', 'print', 'print', 'train_data.describe', 'print', 'test_data.describe', 'print', 'print', 'print', 'print', 'train_data.value_counts', 'None.plot', 'plt.show', 'train_data.value_counts', 'None.plot', 'plt.show', 'train_data.Age.plot', 'plt.show', 'sns.countplot', 'plt.show', 'sns.distplot', 'plt.show', 'sns.catplot', 'plt.show', 'sns.catplot', 'plt.show', 'train_data.groupby', 'group.size', 'None.unstack', 'sns.heatmap', 'plt.show', 'train_data.fillna', 'train_data.mean', 'print', 'train_data.fillna', 'train_data.fillna', 'train_data.isnull', 'None.sum', 'test_data.mean', 'print', 'test_data.fillna', 'test_data.fillna', 'test_data.mean', 'test_data.fillna', 'print', 'test_data.isna', 'None.sum', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'train_data.head', 'test_data.head', 'print', 'print', 'print', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'print', 'RandomForestClassifier', 'RF.fit', 'RF.predict', 'round', 'print', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'print', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'print', 'print', 'print', 'print', 'print', 'describe', 'print', 'describe', 'print', 'print', 'print', 'print', 'value_counts', 'plot', 'show', 'value_counts', 'plot', 'show', 'Age', 'show', 'countplot', 'show', 'distplot', 'show', 'catplot', 'show', 'catplot', 'show', 'groupby', 'size', 'unstack', 'heatmap', 'show', 'fillna', 'mean', 'print', 'fillna', 'fillna', 'isnull', 'sum', 'mean', 'print', 'fillna', 'fillna', 'mean', 'fillna', 'print', 'isna', 'sum', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'head', 'head', 'print', 'print', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'print', 'RandomForestClassifier', 'fit', 'predict', 'round', 'print', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'print', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'describe', 'value_counts', 'plot', 'show', 'Age', 'countplot', 'distplot', 'catplot', 'groupby', 'size', 'unstack', 'heatmap', 'fillna', 'mean', 'isnull', 'sum', 'isna', 'get_dummies', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'KNeighborsClassifier', 'DataFrame', 'to_csv']",30,"[1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head print print print print print describe print describe print print print print value counts plot show value counts plot show age show countplot show distplot show catplot show catplot show groupby size unstack heatmap show fillna mean print fillna fillna isnull sum mean print fillna fillna mean fillna print isna sum get dummies get dummies get dummies get dummies get dummies get dummies head head print print print decisiontreeclassifier fit predict round print randomforestclassifier fit predict round print kneighborsclassifier fit predict round print dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06013343958878528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1924975967642422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059319705921995015, 0.12110107203610455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08003632668358152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03342726031571504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05853180948123636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09541174571309441, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07281042202206853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28927411649593593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20837934589634063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08820340669470647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21017334253958378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046245648563847996, 0.0, 0.0, 0.0, 0.0, 0.12716161717033095, 0.06416661552684882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09143049587364742, 0.0, 0.047456457155502035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059723237631950934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14387346221990738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1023987530581152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09151283864381961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5976622482092449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04313951823149544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0531431520558606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1970133472549573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4651763796665433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08618651134392985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09441904648776912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0962487983821211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12110107203610455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056665015911700756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
billlwu_titanic-exploratory.py,"['numpy', 'pandas', 'matplotlib', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,288,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# load train and test data', '# see which field, if any, contains missing values', '# create features', '# correlation matrix', '# try a few transformations to make Fare look more normalized', '# try a few transformations on Age', '# fit logistic regression model via CV, compute in-sample prediction accuracy', '# found a nice tutorial on gridsearching hyperparameters at https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74', '# Number of trees in random forest', '# Number of features to consider at every split', '# Maximum number of levels in tree', '# Minimum number of samples required to split a node', '# Minimum number of samples required at each leaf node', '# Method of selecting samples for training each tree', '# Create the random grid', '# search across 100 different combinations, and use all available cores', '# Fit the random search model', '# Create the parameter grid based on the results of random search ', '# Create a based model', '# Instantiate the grid search model']",29,"['pd.set_option', 'pd.set_option', 'pd.set_option', 'os.walk', 'print', 'pd.read_csv', 'df.set_index', 'pd.read_csv', 'df.head', 'df.hist', 'df_test.isnull', 'None.any', 'pd.DataFrame', 'df.Pclass.astype', 'df.Pclass.astype', 'df.Pclass.astype', 'df.Sex.astype', 'df.Name.str.contains', 'None.astype', 'df.Name.str.contains', 'None.astype', 'df.Sex.astype', 'df.Pclassdf.Sex.astype', 'df.Pclassdf.Sex.astype', 'df.Pclassdf.Sex.astype', 'df.Pclassdf.Sex.astype', 'df.Pclassdf.Sex.astype', 'df.Pclassdf.Sex.astype', 'df.Name.str.contains', 'None.astype', 'np.tanh', 'df.Age.fillna', 'np.tanh', 'df.Agedf.Age.astype', 'df.Age.astype', 'df.Age.isnull', 'None.astype', 'df.Embarked.astype', 'df.Embarked.astype', 'df.Embarked.astype', 'df.Embarked.isnull', 'None.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.str.astype', 'df.Cabin.isnull', 'None.Cabin.str.describe', 'df.Cabin.isnull', 'None.Cabin.str.unique', 'DF.corr', 'corr.style.background_gradient', 'pd.DataFrame', 'np.tanh', 'np.tanh', 'np.tanh', 'test.hist', 'pd.DataFrame', 'np.tanh', 'np.tanh', 'test.hist', 'LogisticRegressionCV', 'None.fit', 'pd.DataFrame', 'clf.predict', 'print', 'int', 'np.linspace', 'int', 'np.linspace', 'max_depth.append', 'RandomForestClassifier', 'RandomizedSearchCV', 'rf_random.fit', 'RandomForestClassifier', 'GridSearchCV', 'grid_search.fit', 'pd.DataFrame', 'rf_model.predict', 'print', 'pd.DataFrame', 'df_test.Pclass.astype', 'df_test.Pclass.astype', 'df_test.Pclass.astype', 'df_test.Sex.astype', 'df_test.Name.str.contains', 'None.astype', 'df_test.Name.str.contains', 'None.astype', 'df_test.Sex.astype', 'df_test.Pclassdf_test.Sex.astype', 'df_test.Pclassdf_test.Sex.astype', 'df_test.Pclassdf_test.Sex.astype', 'df_test.Pclassdf_test.Sex.astype', 'df_test.Pclassdf_test.Sex.astype', 'df_test.Pclassdf_test.Sex.astype', 'df_test.Name.str.contains', 'None.astype', 'df_test.Fare.fillna', 'np.tanh', 'df_test.Age.fillna', 'np.tanh', 'df_test.Agedf_test.Age.astype', 'df_test.Age.astype', 'df_test.Age.isnull', 'None.astype', 'df_test.Embarked.astype', 'df_test.Embarked.astype', 'df_test.Embarked.astype', 'df_test.Embarked.isnull', 'None.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'df_test.Cabin.str.astype', 'clf.predict', 'rf_model.predict', 'pd.DataFrame', 'pd.DataFrame', 'output2.to_csv', 'output2.head']","['set_option', 'set_option', 'set_option', 'walk', 'print', 'read_csv', 'set_index', 'read_csv', 'head', 'hist', 'isnull', 'any', 'DataFrame', 'Pclass', 'Pclass', 'Pclass', 'Sex', 'Name', 'astype', 'Name', 'astype', 'Sex', 'Pclassdf', 'Pclassdf', 'Pclassdf', 'Pclassdf', 'Pclassdf', 'Pclassdf', 'Name', 'astype', 'tanh', 'Age', 'tanh', 'Agedf', 'Age', 'Age', 'astype', 'Embarked', 'Embarked', 'Embarked', 'Embarked', 'astype', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'corr', 'style', 'DataFrame', 'tanh', 'tanh', 'tanh', 'hist', 'DataFrame', 'tanh', 'tanh', 'hist', 'LogisticRegressionCV', 'fit', 'DataFrame', 'predict', 'print', 'int', 'linspace', 'int', 'linspace', 'append', 'RandomForestClassifier', 'RandomizedSearchCV', 'fit', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'DataFrame', 'predict', 'print', 'DataFrame', 'Pclass', 'Pclass', 'Pclass', 'Sex', 'Name', 'astype', 'Name', 'astype', 'Sex', 'Pclassdf_test', 'Pclassdf_test', 'Pclassdf_test', 'Pclassdf_test', 'Pclassdf_test', 'Pclassdf_test', 'Name', 'astype', 'Fare', 'tanh', 'Age', 'tanh', 'Agedf_test', 'Age', 'Age', 'astype', 'Embarked', 'Embarked', 'Embarked', 'Embarked', 'astype', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'Cabin', 'predict', 'predict', 'DataFrame', 'DataFrame', 'to_csv', 'head']","['set_option', 'walk', 'print', 'read_csv', 'set_index', 'head', 'hist', 'isnull', 'any', 'DataFrame', 'Pclass', 'Sex', 'Name', 'astype', 'Pclassdf', 'tanh', 'Age', 'Agedf', 'Embarked', 'Cabin', 'corr', 'style', 'LogisticRegressionCV', 'fit', 'predict', 'int', 'linspace', 'append', 'RandomForestClassifier', 'RandomizedSearchCV', 'GridSearchCV', 'Pclassdf_test', 'Fare', 'Agedf_test', 'to_csv']",35,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0
 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set option set option set option walk print read csv set index read csv head hist isnull dataframe pclass pclass pclass sex name astype name astype sex pclassdf pclassdf pclassdf pclassdf pclassdf pclassdf name astype tanh age tanh agedf age age astype embarked embarked embarked embarked astype cabin cabin cabin cabin cabin cabin cabin cabin cabin cabin cabin cabin corr style dataframe tanh tanh tanh hist dataframe tanh tanh hist logisticregressioncv fit dataframe predict print int linspace int linspace append randomforestclassifier randomizedsearchcv fit randomforestclassifier gridsearchcv fit dataframe predict print dataframe pclass pclass pclass sex name astype name astype sex pclassdf test pclassdf test pclassdf test pclassdf test pclassdf test pclassdf test name astype fare tanh age tanh agedf test age age astype embarked embarked embarked embarked astype cabin cabin cabin cabin cabin cabin cabin cabin predict predict dataframe dataframe csv head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11973744293349732, 0.0, 0.08451841155513429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019424714006827278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14742621564876382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5368682729449837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02269995219116187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02656133083471402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08874695348315634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16075728470179057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025133336949512246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029271706524326594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023504083295022016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021100304843396072, 0.0, 0.0, 0.06293374062642929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023718012258145356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052466150122499076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015749181790089557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07116109014622564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042259205777567144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13180438984240786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09765610976980243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18824091824571695, 0.0, 0.5756139446430253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040493325694500724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02833482059226921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028633073587371004, 0.0, 0.036550582834882175, 0.0, 0.0, 0.0, 0.0, 0.01763640214193874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06366226915046759, 0.0, 0.1177065408033213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02196739830706797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.431710458482269, 0.0, 0.11259768558220078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018805188803020997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ospohngellert_titanic-kernel-79-4-accuracy.py,"['pandas', 'random\n', 'sklearn', 'numpy\n', 're\n', 'matplotlib', 'scipy', 'math\n', 'train']","[1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,691,[],0,"['pd.read_csv', 'pd.read_csv', 'train.describe', 'sum', 'len', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'print', 'print', 'pd.isnull', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'pd.isnull', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'pd.isnull', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'pd.isnull', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'train.Name.str.contains', 'pd.isnull', 'train.Name.str.contains', 'pd.isnull', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'print', 'print', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'print', 'print', 'fareUnder181.map', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'fareUnder181.map', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'math.isnan', 'vals.get', 'numpy.mean', 'frame.apply', 'frame.Fare.map', 'frame.query', 'None.copy', 'frame.copy', 'out.Fare.map', 'out.Ticket.map', 'out.Embarked.map', 'out.Cabin.map', 'out.columns.get_level_values', 'None.isin', 'cleanData', 'cleanData', 'train.corr', 'print', 'print', 'print', 'print', 'train.corr', 'print', 'print', 'train.drop', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'train.corr', 'train.drop', 'train_test_split', 'preprocessing.scale', 'numpy.transpose', 'preprocessing.scale', 'numpy.transpose', 'train_test_split', 'preprocessing.scale', 'numpy.transpose', 'preprocessing.scale', 'numpy.transpose', 'len', 'len', 'MLPClassifier', 'RandomForestClassifier', 'svm.SVC', 'neural.fit', 'forest.fit', 'machine.fit', 'neural.predict', 'forest.predict', 'machine.predict', 'list', 'sum', 'len', 'sum', 'len', 'sum', 'len', 'sum', 'len', 'pd.DataFrame', 'predictions.apply', 'predictions.describe', 'pd.DataFrame', 'predictions.apply', 'predictions.describe', 'len', 'len', 'MLPClassifier', 'neural.fit', 'neural.predict', 'str', 'sum', 'len', 'str', 'range', 'pd.DataFrame', 'predictions.apply', 'predictions.describe', 'len', 'len', 'svm.SVC', 'machine.fit', 'machine.predict', 'str', 'sum', 'len', 'str', 'range', 'pd.DataFrame', 'predictions.apply', 'predictions.describe', 'preprocessing.scale', 'numpy.transpose', 'preprocessing.scale', 'len', 'len', 'MLPClassifier', 'RandomForestClassifier', 'svm.SVC', 'neural.fit', 'forest.fit', 'machine.fit', 'neural.predict', 'forest.predict', 'machine.predict', 'list', 'pd.DataFrame', 'None.to_csv', 'pd.DataFrame', 'None.to_csv', 'pd.DataFrame', 'None.to_csv', 'pd.DataFrame', 'None.to_csv']","['read_csv', 'read_csv', 'describe', 'sum', 'len', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'print', 'print', 'isnull', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'isnull', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'isnull', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'isnull', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'Name', 'isnull', 'Name', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'print', 'print', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'print', 'print', 'map', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'map', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'isnan', 'get', 'mean', 'apply', 'Fare', 'query', 'copy', 'copy', 'Fare', 'Ticket', 'Embarked', 'Cabin', 'columns', 'isin', 'cleanData', 'cleanData', 'corr', 'print', 'print', 'print', 'print', 'corr', 'print', 'print', 'drop', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'corr', 'drop', 'train_test_split', 'scale', 'transpose', 'scale', 'transpose', 'train_test_split', 'scale', 'transpose', 'scale', 'transpose', 'len', 'len', 'MLPClassifier', 'RandomForestClassifier', 'SVC', 'fit', 'fit', 'fit', 'predict', 'predict', 'predict', 'list', 'sum', 'len', 'sum', 'len', 'sum', 'len', 'sum', 'len', 'DataFrame', 'apply', 'describe', 'DataFrame', 'apply', 'describe', 'len', 'len', 'MLPClassifier', 'fit', 'predict', 'str', 'sum', 'len', 'str', 'range', 'DataFrame', 'apply', 'describe', 'len', 'len', 'SVC', 'fit', 'predict', 'str', 'sum', 'len', 'str', 'range', 'DataFrame', 'apply', 'describe', 'scale', 'transpose', 'scale', 'len', 'len', 'MLPClassifier', 'RandomForestClassifier', 'SVC', 'fit', 'fit', 'fit', 'predict', 'predict', 'predict', 'list', 'DataFrame', 'to_csv', 'DataFrame', 'to_csv', 'DataFrame', 'to_csv', 'DataFrame', 'to_csv']","['read_csv', 'describe', 'sum', 'len', 'isnull', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'print', 'Name', 'map', 'isnan', 'get', 'mean', 'apply', 'Fare', 'query', 'copy', 'Ticket', 'Embarked', 'Cabin', 'columns', 'isin', 'cleanData', 'corr', 'drop', 'train_test_split', 'scale', 'transpose', 'MLPClassifier', 'RandomForestClassifier', 'SVC', 'fit', 'predict', 'list', 'DataFrame', 'str', 'range', 'to_csv']",41,"[1 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv describe sum len isnull hist xlabel ylabel title show print print print print isnull isnull hist xlabel ylabel title show print print isnull isnull hist xlabel ylabel title show print print isnull isnull hist xlabel ylabel title show print print isnull isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print name isnull name isnull hist xlabel ylabel title show print print hist xlabel ylabel title show print print print print hist xlabel ylabel title show print print print map hist xlabel ylabel title show print map hist xlabel ylabel title show print isnan get mean apply fare query copy copy fare ticket embarked cabin columns isin cleandata cleandata corr print print print print corr print print drop hist xlabel ylabel title show hist xlabel ylabel title show hist xlabel ylabel title show corr drop train test split scale transpose scale transpose train test split scale transpose scale transpose len len mlpclassifier randomforestclassifier svc fit fit fit predict predict predict list sum len sum len sum len sum len dataframe apply describe dataframe apply describe len len mlpclassifier fit predict str sum len str range dataframe apply describe len len svc fit predict str sum len str range dataframe apply describe scale transpose scale len len mlpclassifier randomforestclassifier svc fit fit fit predict predict predict list dataframe csv dataframe csv dataframe csv dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06707021539932302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02143071513960907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07659121799321719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027086656451449184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029285574886603202, 0.054368220318512336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0424110228548375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07085204231469128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06319801732117852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01809200725195941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016042778781482185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04013091566899164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06231831389918268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009280854918504158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33495865708651157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03107208250300186, 0.0, 0.0, 0.019863129957842448, 0.3143380281850956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24756572118166348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03624548021234156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024758335896225156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012706356699202868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08754160024665661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2806063709563096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0646565253896601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32423999787379687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035629620293530055, 0.0, 0.0, 0.022859508544111517, 0.0, 0.0, 0.031864539346270745, 0.0, 0.0, 0.0, 0.014080202889181066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18643249501801115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3081195578159795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02463127911710536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07866737052092171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08755667436016705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0453279145191067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025683862681778157, 0.0, 0.0, 0.0, 0.026514544712473664, 0.0, 0.0, 0.0, 0.2653256194011365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025279206928471413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14203046899961655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3624548021234156, 0.0, 0.0, 0.0, 0.0, 0.350757963695387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
patrikdurdevic_the-titanic-tensorflow-deep-learning-crisp-dm.py,"['numpy', 'pandas', 'tensorflow', 'matplotlib', 'math', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,383,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', 'import tensorflow as tf # Deep learning', 'import matplotlib.pyplot as plt # Plots', 'import math # Basic math', 'import seaborn as sns # Plots']",6,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'data.describe', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.kdeplot', 'sns.regplot', 'sns.lmplot', 'data.SibSp.describe', 'data.Parch.describe', 'sns.lmplot', 'data.Cabin.describe', 'data.Cabin.unique', 'filteredData.head', 'filteredData.head', 'pd.get_dummies', 'dataToEncode.join', 'dataToEncode.drop', 'oneHotEncode', 'filteredData.head', 'filteredData.apply', 'filteredData.head', 'MinMaxScaler', 'scaler.fit_transform', 'filteredData.Age.fillna', 'normalize_age', 'filteredData.head', 'train_test_split', 'X_train.to_numpy', 'X_test.to_numpy', 'y_train.to_numpy', 'y_test.to_numpy', 'tf.keras.Sequential', 'model.compile', 'model.fit', 'model.evaluate', 'print', 'plt.figure', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'oneHotEncode', 'filteredTestData.apply', 'filteredTestData.Age.fillna', 'normalize_age', 'model.fit', 'model.predict', 'np.where', 'pd.DataFrame', 'None.rename', 'predictions.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'describe', 'countplot', 'countplot', 'countplot', 'kdeplot', 'kdeplot', 'kdeplot', 'regplot', 'lmplot', 'SibSp', 'Parch', 'lmplot', 'Cabin', 'Cabin', 'head', 'head', 'get_dummies', 'join', 'drop', 'oneHotEncode', 'head', 'apply', 'head', 'MinMaxScaler', 'fit_transform', 'Age', 'normalize_age', 'head', 'train_test_split', 'to_numpy', 'to_numpy', 'to_numpy', 'to_numpy', 'keras', 'compile', 'fit', 'evaluate', 'print', 'figure', 'plot', 'plot', 'legend', 'xlabel', 'ylabel', 'title', 'show', 'oneHotEncode', 'apply', 'Age', 'normalize_age', 'fit', 'predict', 'where', 'DataFrame', 'rename', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'describe', 'countplot', 'kdeplot', 'regplot', 'lmplot', 'SibSp', 'Parch', 'Cabin', 'head', 'get_dummies', 'join', 'drop', 'oneHotEncode', 'apply', 'MinMaxScaler', 'fit_transform', 'Age', 'normalize_age', 'train_test_split', 'to_numpy', 'keras', 'compile', 'fit', 'evaluate', 'print', 'figure', 'plot', 'legend', 'xlabel', 'ylabel', 'title', 'show', 'predict', 'where', 'DataFrame', 'rename', 'to_csv']",40,"[1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv describe countplot countplot countplot kdeplot kdeplot kdeplot regplot lmplot sibsp parch lmplot cabin cabin head head get dummies join drop onehotencode head apply head minmaxscaler fit transform age normalize age head train test split numpy numpy numpy numpy keras compile fit evaluate print figure plot plot legend xlabel ylabel title show onehotencode apply age normalize age fit predict dataframe rename csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24670017956740992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10385359099549848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16591990286588987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0937744452346809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18252135005393097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08208817049123956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034284215150198256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04892888000674552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03501777782891148, 0.0, 0.0, 0.0, 0.04944834422394909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10263984786713874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060433195518918376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09046462508565498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07185381059657518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16302698010316713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04533802574818883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08395823087849649, 0.0, 0.0, 0.3298865408862371, 0.11635885205257501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052511944559602286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046016808992312086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24984606770756554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04578853066237111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1006025317804959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27585001712448143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5517000342489629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2964905129630361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12492303385378277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10502388911920457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03128629965919455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029189721931866995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05450555150600448, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14824525648151804, 0.0, 0.0, 0.0, 0.11296009578641608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04556228149998221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05963772880520965, 0.0, 0.0, 0.13060267613396706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047674790737842976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049712106824485805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05135479697257513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04892888000674552, 0.0, 0.0, 0.0, 0.05565827366746617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07015452490715327, 0.0, 0.0, 0.0, 0.0, 0.06789055671573538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
effydog_titanic-survival-prediction-end-to-end-ml-pipeline.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 're\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,899,"['# We can use the pandas library in python to read in the csv file.', '# This creates a pandas dataframe and assigns it to the titanic variable.', '# Print the first 5 rows of the dataframe.', ' # plots an axis lable', '# sets our legend for our graph.', 'titanic[""Deck""].unique() # 0 is for null values', 'titanic[""Deck""].unique() # Z is for null values', '# Create a family size variable including the passenger themselves', '# Discretize family size', '# The .apply method generates a new series', '    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.', '# Titles with very low cell counts to be combined to ""rare"" level', '# Also reassign mlle, ms, and mme accordingly', '#                \'Dr\', \'Major\', \'Rev\', \'Sir\', \'Jonkheer\']), ""Title""] = \'Rare Title\'', '# Titles with very low cell counts to be combined to ""rare"" level', '# Also reassign mlle, ms, and mme accordingly', '    # Split sets into train and test', '    # All age values are stored in a target array', '    # All the other values are stored in the feature array', '    # Create and fit a model', '    # Use the fitted model to predict the missing values', '    # Assign those predictions to the full data set', '# Import the linear regression class', '# Sklearn also has a helper that makes it easy to do cross validation', ""# The columns we'll use to predict the target"", '# Initialize our algorithm class', '# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.', '# We set random_state to ensure we get the same splits every time we run this.', ""    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds."", ""    # The target we're using to train the algorithm."", '    # Training the algorithm using the predictors and target.', '    # We can now make predictions on the test fold', '# Map predictions to outcomes (only possible outcomes are 1 and 0)', '# Initialize our algorithm', '# Compute the accuracy score for all the cross validation folds.', '# Take the mean of the scores (because we have one for each fold)', '# Initialize our algorithm with the default paramters', '# n_estimators is the number of trees we want to make', '# min_samples_split is the minimum number of rows we need to make a split', '# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)', '# Take the mean of the scores (because we have one for each fold)', '# Take the mean of the scores (because we have one for each fold)', ' #             ""FsizeD"", ""Embarked"", ""NlengthD"",""Deck"",""TicketNumber""]', '# Perform feature selection', '# Get the raw p-values for each feature, and transform from p-values into scores', '# Initialize our algorithm', '# Compute the accuracy score for all the cross validation folds.  ']",47,"['pd.read_csv', 'titanic.head', 'pd.read_csv', 'titanic_test.head', 'titanic_test.head', 'print', 'print', 'titanic.describe', 'titanic.info', 'titanic.isnull', 'None.sum', 'titanic_test.isnull', 'None.sum', 'get_ipython', 'None.run_line_magic', 'sns.set', 'titanic.hist', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'plt.subplots_adjust', 'g.fig.suptitle', 'titanic.Embarked.value_counts', 'None.plot', 'plt.title', 'sns.factorplot', 'sns.set', 'sns.factorplot', 'g.set_axis_labels', 'None.set_xticklabels', 'None.set_titles', 'None.set', 'None.despine', 'plt.subplots_adjust', 'g.fig.suptitle', 'sns.boxplot', 'sns.stripplot', 'sns.plt.title', 'titanic.Agetitanic.Pclass.plot', 'titanic.Agetitanic.Pclass.plot', 'titanic.Agetitanic.Pclass.plot', 'plt.xlabel', 'plt.title', 'plt.legend', 'titanic.corr', 'plt.figure', 'sns.heatmap', 'plt.title', 'titanic.corr', 'sns.factorplot', 'titanic.isnull', 'sns.boxplot', 'titanic.fillna', 'titanic_test.describe', 'titanic_test.isnull', 'dfdfdf.median', 'df.fillna', 'fill_missing_fare', 'titanic.unique', 'sns.factorplot', 'titanic.assign', 'None.sort', 'sns.FacetGrid', 'g.map', 'titanic.Deck.fillna', 'titanic_test.Deck.fillna', 'titanic.unique', 'print', 'print', 'print', 'sns.factorplot', 'titanic.apply', 'titanic_test.apply', 'pd.cut', 'pd.cut', 'sns.factorplot', 'print', 're.search', 'title_search.group', 'titanic.apply', 'print', 'titanic.value_counts', 'titanic_test.apply', 'print', 'titanic_test.value_counts', 'titanic.tail', 'titanic.str.extract', 'titanic.apply', 'titanic_test.str.extract', 'titanic_test.apply', 'titanic.isnull', 'titanic.TicketNumber.fillna', 'titanic_test.TicketNumber.fillna', 'LabelEncoder', 'labelEnc.fit_transform', 'labelEnc.fit_transform', 'titanic.head', 'sns.plotting_context', 'sns.set_style', 'sns.distplot', 'sns.plt.title', 'plt.ylabel', 'df.Age.notnull', 'df.Age.isnull', 'RandomForestRegressor', 'rtr.fit', 'rtr.predict', 'df.Age.isnull', 'fill_missing_age', 'fill_missing_age', 'sns.plotting_context', 'sns.set_style', 'sns.distplot', 'sns.plt.title', 'plt.ylabel', 'plt.xlim', 'preprocessing.StandardScaler', 'None.fit', 'std_scale.transform', 'preprocessing.StandardScaler', 'None.fit', 'std_scale.transform', 'titanic.corr', 'LinearRegression', 'KFold', 'alg.fit', 'alg.predict', 'predictions.append', 'np.concatenate', 'sum', 'len', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'RandomForestClassifier', 'KFold', 'ShuffleSplit', 'cross_validation.cross_val_predict', 'pd.Series', 'cross_val_score', 'print', 'RandomForestClassifier', 'rf.fit', 'KFold', 'cross_validation.cross_val_predict', 'pd.Series', 'cross_val_score', 'print', 'np.std', 'np.argsort', 'sorted_important_features.append', 'plt.figure', 'plt.title', 'plt.bar', 'plt.xticks', 'plt.xlim', 'plt.show', 'get_ipython', 'None.run_line_magic', 'SelectKBest', 'selector.fit', 'np.log10', 'np.argsort', 'sorted_important_features.append', 'plt.figure', 'plt.title', 'plt.bar', 'plt.xticks', 'plt.xlim', 'plt.show', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'AdaBoostClassifier', 'adb.fit', 'ShuffleSplit', 'cross_val_score', 'print', 'VotingClassifier', 'eclf1.fit', 'eclf1.predict', 'eclf1.predict', 'test_predictions.astype', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'head', 'read_csv', 'head', 'head', 'print', 'print', 'describe', 'info', 'isnull', 'sum', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'set', 'hist', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'subplots_adjust', 'fig', 'Embarked', 'plot', 'title', 'factorplot', 'set', 'factorplot', 'set_axis_labels', 'set_xticklabels', 'set_titles', 'set', 'despine', 'subplots_adjust', 'fig', 'boxplot', 'stripplot', 'plt', 'Agetitanic', 'Agetitanic', 'Agetitanic', 'xlabel', 'title', 'legend', 'corr', 'figure', 'heatmap', 'title', 'corr', 'factorplot', 'isnull', 'boxplot', 'fillna', 'describe', 'isnull', 'median', 'fillna', 'fill_missing_fare', 'unique', 'factorplot', 'assign', 'sort', 'FacetGrid', 'map', 'Deck', 'Deck', 'unique', 'print', 'print', 'print', 'factorplot', 'apply', 'apply', 'cut', 'cut', 'factorplot', 'print', 'search', 'group', 'apply', 'print', 'value_counts', 'apply', 'print', 'value_counts', 'tail', 'str', 'apply', 'str', 'apply', 'isnull', 'TicketNumber', 'TicketNumber', 'LabelEncoder', 'fit_transform', 'fit_transform', 'head', 'plotting_context', 'set_style', 'distplot', 'plt', 'ylabel', 'Age', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'Age', 'fill_missing_age', 'fill_missing_age', 'plotting_context', 'set_style', 'distplot', 'plt', 'ylabel', 'xlim', 'StandardScaler', 'fit', 'transform', 'StandardScaler', 'fit', 'transform', 'corr', 'LinearRegression', 'KFold', 'fit', 'predict', 'append', 'concatenate', 'sum', 'len', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'RandomForestClassifier', 'KFold', 'ShuffleSplit', 'cross_val_predict', 'Series', 'cross_val_score', 'print', 'RandomForestClassifier', 'fit', 'KFold', 'cross_val_predict', 'Series', 'cross_val_score', 'print', 'std', 'argsort', 'append', 'figure', 'title', 'bar', 'xticks', 'xlim', 'show', 'get_ipython', 'run_line_magic', 'SelectKBest', 'fit', 'log10', 'argsort', 'append', 'figure', 'title', 'bar', 'xticks', 'xlim', 'show', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'print', 'AdaBoostClassifier', 'fit', 'ShuffleSplit', 'cross_val_score', 'print', 'VotingClassifier', 'fit', 'predict', 'predict', 'astype', 'DataFrame', 'to_csv']","['read_csv', 'head', 'print', 'describe', 'info', 'isnull', 'sum', 'get_ipython', 'run_line_magic', 'set', 'hist', 'FacetGrid', 'map', 'add_legend', 'subplots_adjust', 'fig', 'Embarked', 'plot', 'title', 'factorplot', 'set_axis_labels', 'set_xticklabels', 'set_titles', 'despine', 'boxplot', 'stripplot', 'plt', 'Agetitanic', 'xlabel', 'legend', 'corr', 'figure', 'heatmap', 'fillna', 'median', 'fill_missing_fare', 'unique', 'assign', 'sort', 'Deck', 'apply', 'cut', 'search', 'group', 'value_counts', 'tail', 'str', 'TicketNumber', 'LabelEncoder', 'fit_transform', 'plotting_context', 'set_style', 'distplot', 'ylabel', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'fill_missing_age', 'xlim', 'StandardScaler', 'transform', 'LinearRegression', 'KFold', 'append', 'concatenate', 'len', 'LogisticRegression', 'ShuffleSplit', 'cross_val_score', 'RandomForestClassifier', 'cross_val_predict', 'Series', 'std', 'argsort', 'bar', 'xticks', 'show', 'SelectKBest', 'log10', 'AdaBoostClassifier', 'VotingClassifier', 'astype', 'DataFrame', 'to_csv']",85,"[1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0
 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv head read csv head head print print describe info isnull sum isnull sum get ipython run line magic set hist facetgrid map facetgrid map add legend facetgrid map add legend subplots adjust fig embarked plot title factorplot set factorplot set axis labels set xticklabels set titles set despine subplots adjust fig boxplot stripplot plt agetitanic agetitanic agetitanic xlabel title legend corr figure heatmap title corr factorplot isnull boxplot fillna describe isnull median fillna fill missing fare unique factorplot assign sort facetgrid map deck deck unique print print print factorplot apply apply cut cut factorplot print search group apply print value counts apply print value counts tail str apply str apply isnull ticketnumber ticketnumber labelencoder fit transform fit transform head plotting context set style distplot plt ylabel age age randomforestregressor fit predict age fill missing age fill missing age plotting context set style distplot plt ylabel xlim standardscaler fit transform standardscaler fit transform corr linearregression kfold fit predict append concatenate sum len logisticregression shufflesplit cross val score print randomforestclassifier kfold shufflesplit cross val predict series cross val score print randomforestclassifier fit kfold cross val predict series cross val score print std argsort append figure title bar xticks xlim show get ipython run line magic selectkbest fit log10 argsort append figure title bar xticks xlim show logisticregression shufflesplit cross val score print adaboostclassifier fit shufflesplit cross val score print votingclassifier fit predict predict astype dataframe csv,"[0.0, 0.0, 0.0, 0.04571014197107515, 0.0, 0.059175028733188584, 0.125578050860682, 0.15499607408928953, 0.0, 0.0, 0.0, 0.19693121036376268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09052068939651174, 0.1565971998490124, 0.0, 0.0, 0.0, 0.0, 0.13864819966237626, 0.0, 0.0, 0.062789025430341, 0.022900590575755622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05526937604658021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09426613883630404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07808221309221632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0584844819661189, 0.0, 0.0, 0.0, 0.12091311283450111, 0.0, 0.0, 0.10578355598386756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06242846197376357, 0.0, 0.0, 0.27053207835761484, 0.0, 0.0, 0.04125929434708917, 0.0, 0.0, 0.0, 0.06824653165394183, 0.0, 0.0, 0.0, 0.01723198989423115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12091311283450111, 0.0, 0.0, 0.0, 0.0, 0.04918543196153124, 0.0, 0.0, 0.0584844819661189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07506857843741009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031214230986881784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12752740689722467, 0.23668363651362637, 0.0, 0.0, 0.0, 0.0, 0.03904110654610816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12091311283450111, 0.09112510319070914, 0.0, 0.0, 0.1658081281397406, 0.03580701049321028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15156494015608246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03611528315983697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047908649960045735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06555271599638303, 0.0330783456335441, 0.0, 0.032586240313375814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022676143399369034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04557574954505929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12232070208505388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13328927454453293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03587049862241689, 0.05677619337398331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07918092574205482, 0.032112365364526406, 0.0, 0.0, 0.0, 0.0, 0.04625809189718036, 0.0, 0.0, 0.0584844819661189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06564373678792089, 0.0, 0.0, 0.0, 0.046028616620737164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046028616620737164, 0.0, 0.0, 0.0963439596147294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03439839817088651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17032858012194993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026393641914018273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10784296403280684, 0.188367076291023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09435103540096824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19072803285251025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044477455536949734, 0.05677619337398331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027395671991211772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045801181151511244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1156452297429509, 0.0, 0.047908649960045735, 0.0, 0.0, 0.0, 0.05526937604658021, 0.0, 0.0, 0.0, 0.0, 0.06718028063288349, 0.19778077522003334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05995043115813184, 0.0, 0.251156101721364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028316226319260528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08439845448977186, 0.0, 0.0, 0.0, 0.0, 0.03944727275227106, 0.0, 0.0, 0.07653105200842888, 0.0, 0.0, 0.0, 0.0, 0.062789025430341, 0.06824653165394183, 0.0, 0.0, 0.0, 0.0, 0.06376370344861233, 0.07301053269995042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04074939513824374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13128747357584178, 0.0, 0.0, 0.1290601722359378, 0.060456556417250555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11190022057279995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0833949407011668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27053207835761484, 0.0, 0.0, 0.06242846197376357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04961693855218132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03526118532795585, 0.16176444604921025, 0.04074939513824374, 0.08149879027648747, 0.0, 0.06824653165394183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
vloden_titanic.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,161,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', 'import matplotlib.pyplot as plt # plotting', '# Input data files are available in the ""../input/"" directory.', '# Any results you write to the current directory are saved as output.', '# Class affects survival chances ', '# Sex affects survival chances', '# Age slightly affects survival chances', ""# SibSp doesn't affect survival chances"", '# Parch slightly affects survival chances', '# Fare affects survival chances', '# Embarkation slightly affects survival chances']",15,"['plt.figure', 'datacolumn.nunique', 'plt.hist', 'plt.xticks', 'plt.title', 'plt.legend', 'plt.grid', 'plt.show', 'plt.figure', 'sns.distplot', 'sns.distplot', 'plt.legend', 'plt.grid', 'plt.show', 'np.random.seed', 'pd.read_csv', 'pd.read_csv', 'plot_hist_discrete', 'plot_hist_discrete', 'plot_hist_numeric', 'plot_hist_discrete', 'plot_hist_discrete', 'plot_hist_numeric', 'plot_hist_discrete', 'train.drop', 'train_processed.replace', 'train_processed.replace', 'train_processed.drop', 'test.drop', 'test_processed.replace', 'test_processed.replace', 'test_processed.drop', 'X_tr.copy', 'X_ts.copy', 'X_trcol.isnull', 'None.any', 'X_tr_pluscol.isnull', 'X_tscol.isnull', 'None.any', 'X_ts_pluscol.isnull', 'X_tr_plus.fillna', 'X_ts_plus.fillna', 'GBC', 'model.fit', 'model.predict', 'pd.concat', 'answer.to_csv']","['figure', 'nunique', 'hist', 'xticks', 'title', 'legend', 'grid', 'show', 'figure', 'distplot', 'distplot', 'legend', 'grid', 'show', 'random', 'read_csv', 'read_csv', 'plot_hist_discrete', 'plot_hist_discrete', 'plot_hist_numeric', 'plot_hist_discrete', 'plot_hist_discrete', 'plot_hist_numeric', 'plot_hist_discrete', 'drop', 'replace', 'replace', 'drop', 'drop', 'replace', 'replace', 'drop', 'copy', 'copy', 'isnull', 'any', 'isnull', 'isnull', 'any', 'isnull', 'fillna', 'fillna', 'GBC', 'fit', 'predict', 'concat', 'to_csv']","['figure', 'nunique', 'hist', 'xticks', 'title', 'legend', 'grid', 'show', 'distplot', 'random', 'read_csv', 'plot_hist_discrete', 'plot_hist_numeric', 'drop', 'replace', 'copy', 'isnull', 'any', 'fillna', 'GBC', 'fit', 'predict', 'concat', 'to_csv']",24,"[0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",figure nunique hist xticks title legend grid show figure distplot distplot legend grid show random read csv read csv plot hist discrete plot hist discrete plot hist numeric plot hist discrete plot hist discrete plot hist numeric plot hist discrete drop replace replace drop drop replace replace drop copy copy isnull isnull isnull isnull fillna fillna gbc fit predict concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046830065234935644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0993897246798511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0719675113303212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6498404162045858, 0.0, 0.13094016402213532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12280172929100944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10596476099316707, 0.0, 0.0, 0.0, 0.06245723476743957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026437077319360062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12996808324091713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19806646742725595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4547146345717166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1706886489949873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09207548279989226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19806646742725595, 0.0, 0.0, 0.0, 0.08654553219914386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32226418979962296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027429008488466654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06609870884852556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04778555633655407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1894974202886077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10456997391509872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045023258660449365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07107810743549928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
buraky1_titanic-eda-example.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'collections', 'warnings\n', 'os\n']","[1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,338,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '    # get feature', '    # count number of categorical variable(value/sample)', '    # visualize', '# Pclass vs Survived', '# Sex vs Survived', '# SibSp vs Survived', '# Parch vs Survived', '        # 1 st quartile', '        # 3 rd quartile', '        # IQR', '        # Outlier Step', '        # detect outlier and their indeces', '        # store indeces', '# drop outliers']",22,"['plt.style.use', 'warnings.filterwarnings', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_df.head', 'train_df.describe', 'train_df.info', 'var.value_counts', 'plt.figure', 'plt.bar', 'plt.xticks', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'bar_plot', 'print', 'plt.figure', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'plot_hist', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'np.percentile', 'np.percentile', 'outlier_indices.extend', 'Counter', 'list', 'detect_outliers', 'train_df.drop', 'None.reset_index', 'len', 'pd.concat', 'None.reset_index', 'train_df.isnull', 'None.any', 'train_df.isnull', 'None.sum', 'train_df.isnull', 'train_df.boxplot', 'plt.show', 'train_df.fillna', 'train_df.isnull', 'train_df.isnull', 'train_df.fillna', 'train_df.isnull']","['style', 'filterwarnings', 'walk', 'print', 'read_csv', 'read_csv', 'head', 'describe', 'info', 'value_counts', 'figure', 'bar', 'xticks', 'ylabel', 'title', 'show', 'print', 'bar_plot', 'print', 'figure', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'plot_hist', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'percentile', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'drop', 'reset_index', 'len', 'concat', 'reset_index', 'isnull', 'any', 'isnull', 'sum', 'isnull', 'boxplot', 'show', 'fillna', 'isnull', 'isnull', 'fillna', 'isnull']","['style', 'filterwarnings', 'walk', 'print', 'read_csv', 'head', 'describe', 'info', 'value_counts', 'figure', 'bar', 'xticks', 'ylabel', 'title', 'show', 'bar_plot', 'hist', 'xlabel', 'plot_hist', 'groupby', 'mean', 'sort_values', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'drop', 'reset_index', 'len', 'concat', 'isnull', 'any', 'sum', 'boxplot', 'fillna']",36,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",style filterwarnings walk print read csv read csv head describe info value counts figure bar xticks ylabel title show print bar plot print figure hist xlabel ylabel title show plot hist groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values percentile percentile extend counter list detect outliers drop reset index len concat reset index isnull isnull sum isnull boxplot show fillna isnull isnull fillna isnull,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23509283479877643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09736565563106386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06695665483586768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13143532960981166, 0.0, 0.07784600217383385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06859843551881165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0613324295095955, 0.0, 0.0, 0.0, 0.15077421655070355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043894840633554165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14159566111593772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15150621488546925, 0.0, 0.0, 0.0, 0.08930005733168296, 0.0, 0.09188273799133338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23782044522666929, 0.0, 0.0, 0.0, 0.0, 0.040870916170414065, 0.0, 0.0, 0.16253538556424552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18376547598266676, 0.0, 0.0, 0.05655263809328891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3660706289161433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08008588342363626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08793880941182275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2466253720008644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14585600754295078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3015484331014071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13164761333877162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10976808967694203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06832279617196987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2055726383858486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.224267965926481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2824743645333202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08510092165528794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06069430414246749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1287466406288401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07784600217383385, 0.2824743645333202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07285063422935623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08793880941182275, 0.0, 0.0, 0.10162600205807691, 0.0, 0.1702018433105759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mosleylm_titanic-data-set-exploration.py,"['numpy', 'pandas', 'csv', 'subprocess', 'matplotlib', 're', 'sklearn', 'seaborn', 'csv\n']","[1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,681,"[""training_data['Family'] = training_data['SibSp'] + training_data['Parch'] + 1 # add 1 for 'self'"", ""test_data['Family'] = test_data['SibSp'] + test_data['Parch'] + 1 # add 1 for 'self'   "", ""#                                                        'Don', 'Jonkheer', 'Lady', 'Sir', 'Dr', 'Rev',"", ""#                                                        'Major'], 'Other')"", ""#                                                        'Don', 'Jonkheer', 'Lady', 'Sir', 'Dr', 'Rev',"", ""#                                                        'Major'], 'Other')"", '# drop unused data columns', '# Normalize the data', ""# these are the features we'll use to classify"", '# intialize f1 and accuracy values', '        # add splits f1, acc', '    f1s[cls] = f1s[cls] / 10.0 # average over ten runs', '    acc[cls] = acc[cls] / 10.0 # average over ten runs']",13,"['pd.read_csv', 'pd.read_csv', 'training_data.map', 'None.astype', 'test_data.map', 'None.astype', 'print', 'training_data.Embarked.isnull', 'test_data.Embarked.isnull', 'list', 'training_data.map', 'None.astype', 'list', 'test_data.map', 'None.astype', 'print', 'training_data.Age.isnull', 'test_data.Age.isnull', 'plt.plot', 'plt.show', 'print', 'print', 'print', 'print', 'training_data.Fare.isnull', 'test_data.Fare.isnull', 'training_data.groupby', 'None.median', 'training_data.groupby', 'None.mean', 'print', 'print', 'training_data.Fare.isnull', 'training_data.Fare.isnull', 'training_data.Fare.isnull', 'test_data.Fare.isnull', 'test_data.Fare.isnull', 'test_data.Fare.isnull', 'pd.qcut', 'print', 'pd.qcut', 'print', 'pd.qcut', 'print', 'training_data.drop', 'print', 'print', 'print', 'print', 're.search', 'title.group', 'training_data.apply', 'training_data.apply', 'print', 'print', 'training_data.drop', 'test_data.drop', 'np.asarray', 'None.min', 'np.asarray', 'None.max', 'np.asarray', 'None.min', 'np.asarray', 'None.max', 'np.asarray', 'None.min', 'np.asarray', 'None.max', 'np.asarray', 'None.min', 'np.asarray', 'None.max', 'np.asarray', 'None.min', 'np.asarray', 'None.max', 'np.asarray', 'None.min', 'np.asarray', 'None.max', 'np.asarray', 'None.reshape', 'print', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LogisticRegression', 'StratifiedShuffleSplit', 'pd.DataFrame', 'splits.split', 'cls.fit', 'cls.predict', 'f1_score', 'accuracy_score', 'pd.DataFrame', 'log.append', 'print', 'StratifiedShuffleSplit', 'GradientBoostingClassifier', 'splits.split', 'cls.fit', 'cls.predict', 'cls.predict', 'np.vstack', 'np.vstack', 'pd.DataFrame', 'submit.to_csv', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.show', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.ylim', 'plt.show', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.show', 'print', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.show', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.ylim', 'plt.show', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.ylim', 'plt.show', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.ylim', 'plt.show', 'np.arange', 'plt.bar', 'plt.xticks', 'plt.ylim', 'plt.show', 'print']","['read_csv', 'read_csv', 'map', 'astype', 'map', 'astype', 'print', 'Embarked', 'Embarked', 'list', 'map', 'astype', 'list', 'map', 'astype', 'print', 'Age', 'Age', 'plot', 'show', 'print', 'print', 'print', 'print', 'Fare', 'Fare', 'groupby', 'median', 'groupby', 'mean', 'print', 'print', 'Fare', 'Fare', 'Fare', 'Fare', 'Fare', 'Fare', 'qcut', 'print', 'qcut', 'print', 'qcut', 'print', 'drop', 'print', 'print', 'print', 'print', 'search', 'group', 'apply', 'apply', 'print', 'print', 'drop', 'drop', 'asarray', 'min', 'asarray', 'max', 'asarray', 'min', 'asarray', 'max', 'asarray', 'min', 'asarray', 'max', 'asarray', 'min', 'asarray', 'max', 'asarray', 'min', 'asarray', 'max', 'asarray', 'min', 'asarray', 'max', 'asarray', 'reshape', 'print', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LogisticRegression', 'StratifiedShuffleSplit', 'DataFrame', 'split', 'fit', 'predict', 'f1_score', 'accuracy_score', 'DataFrame', 'append', 'print', 'StratifiedShuffleSplit', 'GradientBoostingClassifier', 'split', 'fit', 'predict', 'predict', 'vstack', 'vstack', 'DataFrame', 'to_csv', 'arange', 'bar', 'xticks', 'show', 'arange', 'bar', 'xticks', 'ylim', 'show', 'arange', 'bar', 'xticks', 'show', 'print', 'arange', 'bar', 'xticks', 'show', 'arange', 'bar', 'xticks', 'ylim', 'show', 'arange', 'bar', 'xticks', 'ylim', 'show', 'arange', 'bar', 'xticks', 'ylim', 'show', 'arange', 'bar', 'xticks', 'ylim', 'show', 'print']","['read_csv', 'map', 'astype', 'print', 'Embarked', 'list', 'Age', 'plot', 'show', 'Fare', 'groupby', 'median', 'mean', 'qcut', 'drop', 'search', 'group', 'apply', 'asarray', 'min', 'max', 'reshape', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LogisticRegression', 'StratifiedShuffleSplit', 'DataFrame', 'split', 'fit', 'predict', 'f1_score', 'accuracy_score', 'append', 'vstack', 'to_csv', 'arange', 'bar', 'xticks', 'ylim']",44,"[1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 0 1
 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv map astype map astype print embarked embarked list map astype list map astype print age age plot show print print print print fare fare groupby median groupby mean print print fare fare fare fare fare fare qcut print qcut print qcut print drop print print print print search group apply apply print print drop drop asarray min asarray max asarray min asarray max asarray min asarray max asarray min asarray max asarray min asarray max asarray min asarray max asarray reshape print kneighborsclassifier svc decisiontreeclassifier randomforestclassifier adaboostclassifier gradientboostingclassifier gaussiannb logisticregression stratifiedshufflesplit dataframe split fit predict f1 score accuracy score dataframe append print stratifiedshufflesplit gradientboostingclassifier split fit predict predict vstack vstack dataframe csv arange bar xticks show arange bar xticks ylim show arange bar xticks show print arange bar xticks show arange bar xticks ylim show arange bar xticks ylim show arange bar xticks ylim show arange bar xticks ylim show print,"[0.0, 0.0, 0.02796849623610627, 0.034381773091943624, 0.0, 0.0, 0.0, 0.04663332573197599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022695632878195662, 0.03926254407938237, 0.28828338938172027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6418777880740472, 0.0, 0.0689004999674135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2836164453634251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031033981409923982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03888412992729449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022695632878195662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03971611474549541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0469567829261871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041571937084975294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2349242262036428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0228005040301032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02796849623610627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06426756996317096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03603542367271503, 0.03586337997480205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023157607591586915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053044773900107596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017310659999608694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07246698468687984, 0.0, 0.0, 0.0, 0.20941225012629366, 0.0, 0.0, 0.0, 0.018595582518281414, 0.025873424794570395, 0.0, 0.0, 0.0, 0.22392207714832654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01985249155279411, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03548398397229622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23174275818112905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07890350231085261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0167272919973218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020606187981196587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04270531906997472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03479392429543404, 0.0, 0.03603542367271503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20291797714527368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036047546452217034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09445597549779323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022112264875908765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10428694234672908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24520360635302454, 0.0, 0.0, 0.0, 0.21995120794323722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
lemoinef_titanic-data-exploration-and-visualization.py,"['numpy', 'pandas', 'matplotlib', 'subprocess']","[1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,255,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '    # convert value into number or strip excess quotes if string', '    # get booleans for filtering', '    else: # catch invalid operation codes', '    # filter data and outcomes', '    # Check that the key exists', ""    # Return the function before visualizing if 'Cabin' or 'Ticket'"", '    # is selected: too many unique categories to display', '    # Merge data and outcomes into single dataframe', '    # Apply filters to data', '    # Create outcomes DataFrame', '    # Create plotting figure', ""    # 'Numerical' features"", '        # Remove NaN values from Age data', '        # Divide the range of data into bins and count survival rates', ""        # 'Fares' has larger range of values than 'Age' so create more bins"", ""        # Overlay each bin's survival rates"", '        # Add legend to plot', ""    # 'Categorical' features"", '        # Set the various categories', '        # Create DataFrame containing categories and count of each', '        # Set the width of each bar', ""        # Display each category's survival rates"", '    # Common attributes for plot formatting', '    # Report number of passengers with missing values', '# Women between the age of 40 and 50, in third class, all died. ', '# All women in second class survived, whatever there age.', '# Most women in first class survived', '# Most men die, unless they are 10 years old or less', '# We might say that men yougner than 10 years old survived.', '# Men in first class that are less than 40 years old are more likely to survive. ', '# But not always true, we see some red between 10 and 20 years old. 1 person died. ']",39,"['plt.style.use', 'print', 'condition.split', 'float', 'value.strip', 'Exception', 'datamatches.reset_index', 'print', 'print', 'pd.concat', 'filter_data', 'plt.figure', 'np.isnan', 'all_datakey.min', 'all_datakey.max', 'np.arange', 'np.arange', 'all_dataall_datakey.reset_index', 'all_dataall_datakey.reset_index', 'plt.hist', 'plt.hist', 'plt.xlim', 'plt.legend', 'np.arange', 'np.arange', 'pd.DataFrame', 'enumerate', 'len', 'len', 'np.arange', 'plt.bar', 'plt.bar', 'plt.xticks', 'plt.legend', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'sum', 'pd.isnull', 'print', 'pd.read_csv', 'data.head', 'data.drop', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats']","['style', 'print', 'split', 'float', 'strip', 'Exception', 'reset_index', 'print', 'print', 'concat', 'filter_data', 'figure', 'isnan', 'min', 'max', 'arange', 'arange', 'reset_index', 'reset_index', 'hist', 'hist', 'xlim', 'legend', 'arange', 'arange', 'DataFrame', 'enumerate', 'len', 'len', 'arange', 'bar', 'bar', 'xticks', 'legend', 'xlabel', 'ylabel', 'title', 'show', 'sum', 'isnull', 'print', 'read_csv', 'head', 'drop', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats', 'survival_stats']","['style', 'print', 'split', 'float', 'strip', 'Exception', 'reset_index', 'concat', 'filter_data', 'figure', 'isnan', 'min', 'max', 'arange', 'hist', 'xlim', 'legend', 'DataFrame', 'enumerate', 'len', 'bar', 'xticks', 'xlabel', 'ylabel', 'title', 'show', 'sum', 'isnull', 'read_csv', 'head', 'drop', 'survival_stats']",32,"[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1
 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0
 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",style print split float strip exception reset index print print concat filter data figure isnan min max arange arange reset index reset index hist hist xlim legend arange arange dataframe enumerate len len arange bar bar xticks legend xlabel ylabel title show sum isnull print read csv head drop survival stats survival stats survival stats survival stats survival stats survival stats survival stats survival stats survival stats,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24097940425163836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09483130080609391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027008848147774423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013835553259375053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04819588085032767, 0.0, 0.01733530233995394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017706217373741045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047415650403046954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07495800415183984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030557144478891227, 0.0, 0.0, 0.0, 0.0, 0.06316546992813696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05560073733729547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0164864324720685, 0.0, 0.0, 0.06556321486050515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11119045256485628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03887914611777929, 0.02461081240292189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05310376401568819, 0.06460978283552644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04668002957012474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049914411293435615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05903739113656479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013779959821496096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12438525013931372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030154928592568665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024106047281930106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6746220373665587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05711658861749839, 0.0, 0.03432784800640995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024482753029361325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6276575216533772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025966787579251117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03547258977501482, 0.054244762160966235, 0.0, 0.040993703526264885, 0.0, 0.03432784800640995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
arushiburson_titanic-machine-learning-85-accuracy.py,"['pandas', 'numpy', 'seaborn', 'collections', 'sklearn']","[1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,369,[],0,"['pd.read_csv', 'pd.read_csv', 'dfc.quantile', 'dfc.quantile', 'outliers.extend', 'list', 'detect_and_remove_outliers', 'train.info', 'pd.concat', 'Concatenated.head', 'sns.heatmap', 'sns.set_style', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.barplot', 'sns.barplot', 'sns.boxplot', 'Concatenated.groupby', 'None.mean', 'pd.isnull', 'Concatenated.apply', 'sns.heatmap', 'sns.FacetGrid', 'g.map', 'Concatenated.groupby', 'None.mean', 'pd.isnull', 'Concatenated.apply', 'sns.FacetGrid', 'g.map', 'item.split', 'None.split', 'pd.Series', 'Concatenated.head', 'Counter', 'Concatenated.replace', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'Concatenated.head', 'Concatenated.drop', 'Concatenated.head', 'Concatenated.isnull', 'Concatenated.isnull', 'Test.drop', 'Test.head', 'Train.astype', 'Train.head', 'Train.dropna', 'sns.heatmap', 'Train.drop', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'roc_auc_score', 'RandomForestClassifier', 'rfc.fit', 'rfc.predict', 'print', 'roc_auc_score', 'rfc.predict', 'pd.DataFrame', 'pd.concat', 'Test_RFC.astype', 'Test_RFC.head', 'sns.heatmap', 'pd.DataFrame', 'pd.DataFrame', 'LogisticRegression', 'logmodel_gender.fit', 'logmodel_gender.predict', 'print', 'roc_auc_score', 'pd.DataFrame', 'logmodel_gender.predict', 'pd.DataFrame', 'pd.concat', 'Test_gender.to_csv']","['read_csv', 'read_csv', 'quantile', 'quantile', 'extend', 'list', 'detect_and_remove_outliers', 'info', 'concat', 'head', 'heatmap', 'set_style', 'countplot', 'countplot', 'countplot', 'barplot', 'barplot', 'boxplot', 'groupby', 'mean', 'isnull', 'apply', 'heatmap', 'FacetGrid', 'map', 'groupby', 'mean', 'isnull', 'apply', 'FacetGrid', 'map', 'split', 'split', 'Series', 'head', 'Counter', 'replace', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'head', 'drop', 'head', 'isnull', 'isnull', 'drop', 'head', 'astype', 'head', 'dropna', 'heatmap', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'roc_auc_score', 'RandomForestClassifier', 'fit', 'predict', 'print', 'roc_auc_score', 'predict', 'DataFrame', 'concat', 'astype', 'head', 'heatmap', 'DataFrame', 'DataFrame', 'LogisticRegression', 'fit', 'predict', 'print', 'roc_auc_score', 'DataFrame', 'predict', 'DataFrame', 'concat', 'to_csv']","['read_csv', 'quantile', 'extend', 'list', 'detect_and_remove_outliers', 'info', 'concat', 'head', 'heatmap', 'set_style', 'countplot', 'barplot', 'boxplot', 'groupby', 'mean', 'isnull', 'apply', 'FacetGrid', 'map', 'split', 'Series', 'Counter', 'replace', 'get_dummies', 'drop', 'astype', 'dropna', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'roc_auc_score', 'RandomForestClassifier', 'DataFrame', 'to_csv']",36,"[1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv quantile quantile extend list detect remove outliers info concat head heatmap set style countplot countplot countplot barplot barplot boxplot groupby mean isnull apply heatmap facetgrid map groupby mean isnull apply facetgrid map split split series head counter replace get dummies get dummies get dummies get dummies concat head drop head isnull isnull drop head astype head dropna heatmap drop train test split logisticregression fit predict print roc auc score randomforestclassifier fit predict print roc auc score predict dataframe concat astype head heatmap dataframe dataframe logisticregression fit predict print roc auc score dataframe predict dataframe concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10997415390068238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09649494658229861, 0.34932825017826585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14857809816711956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08225267113130404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22625488113119738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11103408970402125, 0.19327816061614445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08692599849937141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18152369682890582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12737121697220302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11124460265558475, 0.0631524505127181, 0.0, 0.0, 0.20945023723076486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11961734630042406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13433878785373546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0957961155350765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15217696276368053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045311533489336, 0.0, 0.0, 0.0, 0.0, 0.24168885870156212, 0.27876077556871737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04777460299061434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20616637941385627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07428904908355978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09697411268461541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10148979789185739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10417223344486284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12321640668054779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16565071562389516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09273001370339923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26457062907668827, 0.0, 0.0, 0.0, 0.04685304601596408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057717810740147875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1382996838849841, 0.0, 0.0, 0.05722114106473976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.326066638162929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14618636444718183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07076845430699144, 0.05208611672243142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15145344682439416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07189165498362893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05264186663396293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051812480709339054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
nlprunner_titanic-practice-with-scikit-learn.py,['pandas'],"[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",1,63,[],0,"['pd.read_csv', 'pd.read_csv', 'df.head', 'df.drop', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'read_csv', 'head', 'drop', 'DataFrame', 'to_csv']","['read_csv', 'head', 'drop', 'DataFrame', 'to_csv']",5,"[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head drop dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7151881576686008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2986991246564687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3050902445655102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28407251581445037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47487627914000713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
aditsrivastava4_titanic-prediction-by-adit-srivastava.py,"['numpy', 'pandas', 'subprocess', 'sklearn']","[1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,142,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', ""#     if(str(x[3])=='nan'):"", '#         x[3] = np.random.randint(5,100)', '# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",18,"['print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'np.array', 'np.array', 'np.array', 'np.array', 'str', 'np.random.randint', 'print', 'str', 'np.random.randint', 'tree.DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'print', 'print', 'print', 'print', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'np.array', 'np.array', 'np.array', 'np.array', 'str', 'np.random.randint', 'print', 'str', 'np.random.randint', 'str', 'np.random.randint', 'tree.DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'print', 'print', 'print', 'print']","['print', 'read_csv', 'read_csv', 'read_csv', 'array', 'array', 'array', 'array', 'str', 'random', 'print', 'str', 'random', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'print', 'print', 'print', 'print', 'read_csv', 'read_csv', 'read_csv', 'array', 'array', 'array', 'array', 'str', 'random', 'print', 'str', 'random', 'str', 'random', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'print', 'print', 'print']","['print', 'read_csv', 'array', 'str', 'random', 'DecisionTreeClassifier', 'fit', 'predict']",8,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv read csv array array array array str random print str random decisiontreeclassifier fit predict print print print print print read csv read csv read csv array array array array str random print str random str random decisiontreeclassifier fit predict print print print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7692807247958281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1505629831960871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11010904938454384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05530891863022407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057384134421143713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32123203037118486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.345712204218275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14995799735300125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3490953880775978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kasonli_learning-ml-1-titanic-data.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,936,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sauravprasad_eda-titanic.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 're\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,298,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'sns.set_style', 'plt.figure', 'sns.scatterplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.figure', 'sns.set_style', 'plt.subplot', 'sns.scatterplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.subplot', 'sns.scatterplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'train.apply', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'train.apply', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'train.apply', 'plt.figure', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.subplot', 'sns.countplot', 'plt.xlabel', 'plt.ylabel', 'plt.title']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'set_style', 'figure', 'scatterplot', 'xlabel', 'ylabel', 'title', 'figure', 'set_style', 'subplot', 'scatterplot', 'xlabel', 'ylabel', 'title', 'subplot', 'scatterplot', 'xlabel', 'ylabel', 'title', 'apply', 'figure', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'figure', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'figure', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'apply', 'figure', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'apply', 'figure', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title', 'subplot', 'countplot', 'xlabel', 'ylabel', 'title']","['get_ipython', 'run_line_magic', 'read_csv', 'set_style', 'figure', 'scatterplot', 'xlabel', 'ylabel', 'title', 'subplot', 'apply', 'countplot']",12,"[0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv set style figure scatterplot xlabel ylabel title figure set style subplot scatterplot xlabel ylabel title subplot scatterplot xlabel ylabel title apply figure subplot countplot xlabel ylabel title subplot countplot xlabel ylabel title figure subplot countplot xlabel ylabel title subplot countplot xlabel ylabel title figure subplot countplot xlabel ylabel title apply figure subplot countplot xlabel ylabel title subplot countplot xlabel ylabel title apply figure subplot countplot xlabel ylabel title subplot countplot xlabel ylabel title,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08446623437171825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29689664042846636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029672878184225697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2293738769050918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019480054398935645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02458289130617547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024950936769897538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02482716116917636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029553647873800142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024704485810570966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19565628256073944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053340025652000245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07362235778541086, 0.0, 0.0, 0.534631550900975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3341431933642473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4564647971239435, 0.0, 0.0, 0.0, 0.0, 0.4417341467124652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
umarhabib_analyzing-titanic-data-and-ml-model.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,295,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# transform the categorical columns']",9,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'df.head', 'df.info', 'df.astype', 'df.astype', 'df.astype', 'np.where', 'df.fillna', 'df.dropna', 'df.astype', 'df.str.split', 'df.str.split', 'df.str.split', 'df.str.strip', 'df.replace', 'df.replace', 'df.replace', 'df.astype', 'df.astype', 'df.astype', 'df.value_counts', 'df.value_counts', 'df.value_counts', 'df.value_counts', 'df.dropna', 'plt.figure', 'sns.distplot', 'sns.set', 'plt.figure', 'sns.boxplot', 'sns.set', 'plt.figure', 'sns.boxplot', 'plt.figure', 'sns.countplot', 'plt.figure', 'sns.countplot', 'plt.figure', 'sns.countplot', 'sns.catplot', 'plt.figure', 'sns.countplot', 'sns.catplot', 'sns.catplot', 'sns.catplot', 'sns.catplot', 'pd.get_dummies', 'preprocessing.MinMaxScaler', 'scaler.fit', 'pd.DataFrame', 'SelectKBest', 'selector.fit', 'selector.transform', 'train_test_split', 'LogisticRegression', 'logisticRegr.fit', 'logisticRegr.predict', 'logisticRegr.predict_proba', 'accuracy_score', 'print', 'confusion_matrix', 'train_test_split', 'DecisionTreeClassifier', 'DecisionT.fit', 'DecisionT.predict', 'DecisionT.predict_proba', 'accuracy_score', 'print', 'confusion_matrix', 'train_test_split', 'svm.SVC', 'clf_svc.fit', 'clf_svc.predict', 'accuracy_score', 'print', 'confusion_matrix']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'head', 'info', 'astype', 'astype', 'astype', 'where', 'fillna', 'dropna', 'astype', 'str', 'str', 'str', 'str', 'replace', 'replace', 'replace', 'astype', 'astype', 'astype', 'value_counts', 'value_counts', 'value_counts', 'value_counts', 'dropna', 'figure', 'distplot', 'set', 'figure', 'boxplot', 'set', 'figure', 'boxplot', 'figure', 'countplot', 'figure', 'countplot', 'figure', 'countplot', 'catplot', 'figure', 'countplot', 'catplot', 'catplot', 'catplot', 'catplot', 'get_dummies', 'MinMaxScaler', 'fit', 'DataFrame', 'SelectKBest', 'fit', 'transform', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'predict_proba', 'accuracy_score', 'print', 'confusion_matrix', 'train_test_split', 'DecisionTreeClassifier', 'fit', 'predict', 'predict_proba', 'accuracy_score', 'print', 'confusion_matrix', 'train_test_split', 'SVC', 'fit', 'predict', 'accuracy_score', 'print', 'confusion_matrix']","['walk', 'print', 'read_csv', 'head', 'info', 'astype', 'where', 'fillna', 'dropna', 'str', 'replace', 'value_counts', 'figure', 'distplot', 'set', 'boxplot', 'countplot', 'catplot', 'get_dummies', 'MinMaxScaler', 'fit', 'DataFrame', 'SelectKBest', 'transform', 'train_test_split', 'LogisticRegression', 'predict', 'predict_proba', 'accuracy_score', 'confusion_matrix', 'DecisionTreeClassifier', 'SVC']",32,"[1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv head info astype astype astype fillna dropna astype str str str str replace replace replace astype astype astype value counts value counts value counts value counts dropna figure distplot set figure boxplot set figure boxplot figure countplot figure countplot figure countplot catplot figure countplot catplot catplot catplot catplot get dummies minmaxscaler fit dataframe selectkbest fit transform train test split logisticregression fit predict predict proba accuracy score print confusion matrix train test split decisiontreeclassifier fit predict predict proba accuracy score print confusion matrix train test split svc fit predict accuracy score print confusion matrix,"[0.0, 0.0, 0.1954152796073479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28082034535061007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13678420821108087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43459408903424923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22177347403028203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21427794624177082, 0.21872401928034133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07227791945329871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03018695295944065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052857965706820415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06575246561573285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10502100200711942, 0.0, 0.0, 0.04353883658911609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3724763176372155, 0.0, 0.0, 0.0, 0.03136331172462552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132755524662993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03163332733348032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028708767331752757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039724006240709646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04031640261068977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20951543543874027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08857965338141631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13773657234816536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10280518413457998, 0.0, 0.1678524850085209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07198749535895146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14273606618161577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12155219907839639, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0968207424131729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08661795582655832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1259317145557687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26813377689924955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051499305826092356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13131323178766982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12924435860505928, 0.0, 0.0, 0.0, 0.04900662540013723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21872401928034133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05117213177558242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
winnievorihilala_titanic.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn', 'statsmodels', 'GridSearchCV\n']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,792,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ' #   Column       Non-Null Count  Dtype  ', '# Visualiation des variables catÃ©gorielles et quantitatives ', '# variables quantitatives', '# Variables categorielles', ' #   Column       Non-Null Count  Dtype  ', ""# Examen d'une des variables catÃ©gorielles"", '# Analyse statistique selon la variable catÃ©gorielle', '# Voir le nombre de personnes par classe', '# Code Tutoriel Kaggle ', ""# ? : pourquoi la somme des pourcentage n'est pas Ã©gale Ã\xa0 100 ?"", '# Proportion de femmes qui ont survÃ©cu', ""# Proportion d'hommes qui ont survÃ©cu"", ""# Examen d'une des variables quantitatives"", '# Analyse statistique selon la variable quantitative', '# Proportion de personnes par classe sociale', '# Proportion de personnes (survivantes et non-survivantes) par classe sociale', ""# Examen d'une des variables quantitatives"", '# Analyse statistique selon la variable quantitative', ""# Examen d'une des variables catÃ©gorielles"", '# Analyse statistique selon la variable catÃ©gorielle', '# Code tutoriel Kaggle: Random Forest', '# from sklearn.ensemble import RandomForestClassifier', 'model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1) # cf RandomForestClassifier dans sklearn', ""# n_estimators : nombre d'arbres dans la foret"", '# max_depth : profondeur maximale des arbres', '# random_state : ContrÃ´le Ã\xa0 la fois le caractÃ¨re alÃ©atoire du bootstrap des Ã©chantillons utilisÃ©s ', ""# lors de la construction d'arbres (si bootstrap=True) et l'Ã©chantillonnage des entitÃ©s Ã\xa0 prendre en compte "", '# lors de la recherche de la meilleure rÃ©partition sur chaque nÅ“ud (si )', '# DÃ©coupage du jeu de donnÃ©es en apprentissage et validation', ""# LDA sur donnÃ©es d'apprentissage et validation et calculs d'erreur de classification"", '# LDA', '# QDA', '# Recherche de la valeur optimale du paramÃ¨tre de rÃ©gularisaton C avec GridSearchCV', '# the grid', '# the classifier', ""clf_reg = linear_model.LogisticRegression(tol=1e-5, multi_class='multinomial', solver='lbfgs') # solveur par defaut"", '# Perf a K-fold validation using the accuracy as the performance measure', 'K = 10 # feel free to adapt the value of $K$', '# we will do it on a grid search using n_jobs processors', '# Calcul des erreurs de classification ', '# Get the best parameters', '# Recherche de la valeur optimale du paramÃ¨tre de rÃ©gularisation C avec GridSearchCV', '# the grid', '# the classifier', '# Perf a K-fold validation using the accuracy as the performance measure', 'K = 5 # feel free to adapt the value of $K$', '# we will dot it on a grid search using n_jobs processors', '# Calcul des erreurs de classification ', '# Get the best parameters', '# Recherche des valeurs optimales des paramÃ¨tres C et gamma avec GridSearchCV', '# the grid', '# the classifier', '# Perf a K-fold validation using the accuracy as the performance measure', 'K = 3 # feel free to adapt the value of $K$', '# we will do it on a grid search using n_jobs processors', '# Calcul des erreurs de classification', '# Get the best parameters', '# Kppv et GridSearchCV', '# the grid', '# the classifier', '# Perf a K-fold validation using the accuracy as the performance measure', 'K = 5 # feel free to adapt the value of $K$', '# we will dot it on a grid search using n_jobs processors', '# Calcul des erreurs de classification', '# Get the best parameters', '# PrÃ©diction sur les donnÃ©es de validation et matrice de confusion', '# matrices de confusion', '# accuracy: (tp + tn) / (p + n)', '# precision tp / (tp + fp)', '# recall: tp / (tp + fn)', '# f1: 2 tp / (2 tp + fp + fn)']",80,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'train_data.info', 'train_data.head', 'test_data.head', 'gender_submission_data.head', 'train_data.head', 'train_data.Survived.value_counts', 'list', 'print', 'list', 'print', 'train_data.info', 'print', 'plt.figure', 'sb.countplot', 'print', 'print', 'print', 'print', 'print', 'train_data.Sex.value_counts', 'round', 'print', 'round', 'print', 'print', 'plt.figure', 'sb.countplot', 'print', 'print', 'print', 'print', 'print', 'train_data.Survived.value_counts', 'train_data.Pclass.value_counts', 'round', 'print', 'round', 'print', 'round', 'print', 'round', 'print', 'round', 'print', 'round', 'print', 'print', 'plt.figure', 'sb.countplot', 'print', 'print', 'print', 'print', 'print', 'print', 'plt.figure', 'sb.countplot', 'print', 'print', 'print', 'print', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print', 'print', 'output.head', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'print', 'LinearDiscriminantAnalysis', 'clf_lda.fit', 'clf_lda.predict', 'sum', 'print', 'clf_lda.predict', 'sum', 'print', 'print', 'QuadraticDiscriminantAnalysis', 'clf_qda.fit', 'clf_qda.predict', 'sum', 'print', 'clf_qda.predict', 'sum', 'print', 'np.logspace', 'linear_model.LogisticRegression', 'GridSearchCV', 'clf_reg.fit', 'print', 'print', 'clf_reg.predict', 'sum', 'print', 'clf_reg.predict', 'sum', 'print', 'np.logspace', 'SVC', 'GridSearchCV', 'clf_svm_lin.fit', 'print', 'print', 'clf_reg.predict', 'sum', 'print', 'clf_svm_lin.predict', 'sum', 'print', 'np.logspace', 'np.logspace', 'SVC', 'GridSearchCV', 'clf_svm_rbf.fit', 'print', 'print', 'clf_reg.predict', 'sum', 'print', 'clf_svm_rbf.predict', 'sum', 'print', 'range', 'KNeighborsClassifier', 'GridSearchCV', 'clf_knn.fit', 'print', 'print', 'clf_knn.predict', 'sum', 'print', 'clf_knn.predict', 'sum', 'print', 'clf_lda.predict', 'clf_qda.predict', 'clf_reg.predict', 'clf_svm_lin.predict', 'clf_svm_rbf.predict', 'clf_knn.predict', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'plt.subplots', 'ax1.matshow', 'ax2.matshow', 'ax3.matshow', 'ax4.matshow', 'ax5.matshow', 'ax6.matshow', 'range', 'range', 'ax1.text', 'ax1.set', 'ax1.set_title', 'range', 'range', 'ax2.text', 'ax2.set', 'ax2.set_title', 'range', 'range', 'ax3.text', 'ax3.set', 'ax3.set_title', 'range', 'range', 'ax4.text', 'ax4.set', 'ax4.set_title', 'range', 'range', 'ax5.text', 'ax5.set', 'ax5.set_title', 'range', 'range', 'ax6.text', 'ax6.set', 'ax6.set_title', 'plt.show', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'clf_svm_rbf.fit', 'clf_svm_rbf.predict', 'pd.DataFrame', 'output_2.to_csv', 'print', 'clf_knn.fit', 'clf_knn.predict', 'pd.DataFrame', 'output_3.to_csv', 'print', 'clf_reg.fit', 'clf_reg.predict', 'pd.DataFrame', 'output_4.to_csv', 'print', 'plt.plot', 'plt.plot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.legend', 'plt.show', 'clf_lda.predict_proba', 'clf_qda.predict_proba', 'clf_reg.predict_proba', 'clf_svm_lin.predict_proba', 'clf_svm_rbf.predict_proba', 'clf_knn.predict_proba', 'enumerate', 'print', 'roc_auc_score', 'roc_curve', 'plt.figure', 'plt.subplot', 'plot_roc_curve', 'contingency_matrix', 'contingency_matrix', 'contingency_matrix', 'mcnemar', 'mcnemar', 'mcnemar', 'pd.DataFrame']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'print', 'print', 'print', 'info', 'head', 'head', 'head', 'head', 'Survived', 'list', 'print', 'list', 'print', 'info', 'print', 'figure', 'countplot', 'print', 'print', 'print', 'print', 'print', 'Sex', 'round', 'print', 'round', 'print', 'print', 'figure', 'countplot', 'print', 'print', 'print', 'print', 'print', 'Survived', 'Pclass', 'round', 'print', 'round', 'print', 'round', 'print', 'round', 'print', 'round', 'print', 'round', 'print', 'print', 'figure', 'countplot', 'print', 'print', 'print', 'print', 'print', 'print', 'figure', 'countplot', 'print', 'print', 'print', 'print', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print', 'print', 'head', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'print', 'LinearDiscriminantAnalysis', 'fit', 'predict', 'sum', 'print', 'predict', 'sum', 'print', 'print', 'QuadraticDiscriminantAnalysis', 'fit', 'predict', 'sum', 'print', 'predict', 'sum', 'print', 'logspace', 'LogisticRegression', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'sum', 'print', 'predict', 'sum', 'print', 'logspace', 'SVC', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'sum', 'print', 'predict', 'sum', 'print', 'logspace', 'logspace', 'SVC', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'sum', 'print', 'predict', 'sum', 'print', 'range', 'KNeighborsClassifier', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'sum', 'print', 'predict', 'sum', 'print', 'predict', 'predict', 'predict', 'predict', 'predict', 'predict', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'confusion_matrix', 'subplots', 'matshow', 'matshow', 'matshow', 'matshow', 'matshow', 'matshow', 'range', 'range', 'text', 'set', 'set_title', 'range', 'range', 'text', 'set', 'set_title', 'range', 'range', 'text', 'set', 'set_title', 'range', 'range', 'text', 'set', 'set_title', 'range', 'range', 'text', 'set', 'set_title', 'range', 'range', 'text', 'set', 'set_title', 'show', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'fit', 'predict', 'DataFrame', 'to_csv', 'print', 'fit', 'predict', 'DataFrame', 'to_csv', 'print', 'fit', 'predict', 'DataFrame', 'to_csv', 'print', 'plot', 'plot', 'xlabel', 'ylabel', 'title', 'legend', 'show', 'predict_proba', 'predict_proba', 'predict_proba', 'predict_proba', 'predict_proba', 'predict_proba', 'enumerate', 'print', 'roc_auc_score', 'roc_curve', 'figure', 'subplot', 'plot_roc_curve', 'contingency_matrix', 'contingency_matrix', 'contingency_matrix', 'mcnemar', 'mcnemar', 'mcnemar', 'DataFrame']","['walk', 'print', 'read_csv', 'info', 'head', 'Survived', 'list', 'figure', 'countplot', 'Sex', 'round', 'Pclass', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'train_test_split', 'LinearDiscriminantAnalysis', 'sum', 'QuadraticDiscriminantAnalysis', 'logspace', 'LogisticRegression', 'GridSearchCV', 'SVC', 'range', 'KNeighborsClassifier', 'confusion_matrix', 'subplots', 'matshow', 'text', 'set', 'set_title', 'show', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'plot', 'xlabel', 'ylabel', 'title', 'legend', 'predict_proba', 'enumerate', 'roc_auc_score', 'roc_curve', 'subplot', 'plot_roc_curve', 'contingency_matrix', 'mcnemar']",52,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0
 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0
 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv print print print info head head head head survived list print list print info print figure countplot print print print print print sex round print round print print figure countplot print print print print print survived pclass round print round print round print round print round print round print print figure countplot print print print print print print figure countplot print print print print print get dummies get dummies randomforestclassifier fit predict dataframe csv print print head train test split print print print print print print lineardiscriminantanalysis fit predict sum print predict sum print print quadraticdiscriminantanalysis fit predict sum print predict sum print logspace logisticregression gridsearchcv fit print print predict sum print predict sum print logspace svc gridsearchcv fit print print predict sum print predict sum print logspace logspace svc gridsearchcv fit print print predict sum print predict sum print range kneighborsclassifier gridsearchcv fit print print predict sum print predict sum print predict predict predict predict predict predict confusion matrix confusion matrix confusion matrix confusion matrix confusion matrix confusion matrix subplots matshow matshow matshow matshow matshow matshow range range text set set title range range text set set title range range text set set title range range text set set title range range text set set title range range text set set title show accuracy score precision score recall score f1 score accuracy score precision score recall score f1 score accuracy score precision score recall score f1 score accuracy score precision score recall score f1 score accuracy score precision score recall score f1 score accuracy score precision score recall score f1 score dataframe fit predict dataframe csv print fit predict dataframe csv print fit predict dataframe csv print plot plot xlabel ylabel title legend show predict proba predict proba predict proba predict proba predict proba predict proba enumerate print roc auc score roc curve figure subplot plot roc curve contingency matrix contingency matrix contingency matrix mcnemar mcnemar mcnemar dataframe,"[0.0, 0.0, 0.12237882315292967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030316996033076606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1388856429901309, 0.0, 0.0, 0.12261536213446952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06709578427384298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05280805675556669, 0.0, 0.0, 0.06063399206615321, 0.0, 0.0, 0.0, 0.0, 0.05671373986474524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027266197371719713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025853975217171907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18190197619845963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0833083221836421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08313815024061161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019810371938475378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08010818255336458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04494716543264445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02487715978210992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01688805349759425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014477745081315194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031143532864231542, 0.0, 0.0, 0.0, 0.03868374467655536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012624074010920881, 0.0, 0.0, 0.14403064048477612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19681356907878056, 0.18686119718538927, 0.0, 0.0, 0.0, 0.12261536213446952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026732301599049213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04343323524394559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18686119718538927, 0.0, 0.24152108809647277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.571388020829265, 0.0, 0.1576764336436144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031143532864231542, 0.0, 0.0, 0.0, 0.0, 0.012198643620823723, 0.0, 0.0, 0.22105261210661514, 0.0, 0.0, 0.0, 0.02254108527607738, 0.0, 0.18190197619845963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08489460246051851, 0.0, 0.0, 0.14855957044998294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31717528061167694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1627334902255218, 0.0, 0.025073454631377185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0328847024086275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01314412316847489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024713506386145438, 0.0, 0.017488201267883367, 0.16019432015094476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05014690926275437, 0.0, 0.0, 0.0, 0.03225144140649387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013705819049285382, 0.18686119718538927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0991110052874587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013489880403265084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016023274325082354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01934187233827768, 0.0, 0.0, 0.0, 0.0, 0.018717687600453857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
dreamwave_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,404,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'X_train.head', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'head', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy head logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04454350775575292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07858482128167796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17238227944456924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2123404977751276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042891648231871825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18414908316716058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06211517719857741, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10376988968933029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5829461195490817, 0.045127185443262316, 0.0, 0.0, 0.22450196991353136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04799759425390563, 0.1187744180205931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053906855096129164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045635696217625844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19029834052964545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14356264332634971, 0.0, 0.0, 0.0, 0.0, 0.049344258480400034, 0.0, 0.0, 0.09811607897475177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0682771088416121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034306764133365066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11636614766616268, 0.07366070802035957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3811813826831555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0397351862252755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03482039162970013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034647656035399224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034647656035399224, 0.0, 0.0, 0.03626105474040724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22331673554417733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.079470372450551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04734796830259619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022087527829221337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11409962458972854, 0.03348003250829216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04124372573832632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03447645588891385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06964078325940026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05056939414253596, 0.1860972796201478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1187744180205931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05137200567721282, 0.0, 0.0, 0.0, 0.0, 0.23998797126952812, 0.07327742347165467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0777191718333861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06134753247241202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
wonne2_titanic-wonne.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'os\n', 'sklearn\n', 'sklearn', 'xgboost', 'lightgbm', 'catboost', 'keras\n', 'keras']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",12,375,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', 'import matplotlib.pyplot as plt # import matplotlib to draw graph', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Scewnessë¥¼ ë” ì¤„ì´ê¸° ìœ„í•´ logë¥¼ ë‘ë²ˆì·¨í•´ì¤Œ.', '# histogram', '# í•„ìš”ì—†ëŠ” feature ì\xa0œê±°', '# íŒŒë¼ë¯¸í„° ì¡°í•©', '# Grid Searchë¥¼ ì´ìš©í•œ Hyper Parameter ì„\xa0ì\xa0•ê³¼ì\xa0•.', '# grid search', '    953         # Prepare validation data.', ""    750             check_batch_axis=False,  # Don't enforce the batch size."", '    399             # Python 3 and encoding', '    402             # Python 3 and no explicit encoding']",19,"['print', 'pd.read_csv', 'pd.read_csv', 'df_train.describe', 'df_train.info', 'df_train.Name.str.extract', 'df_train.unique', 'df_train.replace', 'df_train.unique', 'np.where', 'df_test.Name.str.extract', 'df_test.replace', 'df_test.unique', 'np.where', 'df_train.groupby', 'None.mean', 'df_train.isnull', 'None.sum', 'df_train.fillna', 'df_test.fillna', 'df_train.isnull', 'None.sum', 'df_test.isnull', 'None.sum', 'df_train.map', 'df_train.Initial.unique', 'df_test.map', 'df_train.map', 'df_train.Sex.unique', 'df_test.map', 'df_train.map', 'df_train.Embarked.unique', 'df_test.map', 'df_test.Embarked.unique', 'df_train.map', 'df_test.map', 'df_train.map', 'df_test.map', 'plt.subplots', 'sns.distplot', 'g.legend', 'df_train.drop', 'df_test.drop', 'df_fillage.drop', 'df_fillagetest.drop', 'df_fillage.Age.isnull', 'df_fillage.Age.isnull', 'df_fillage.Age.isnull', 'df_fillage.Age.isnull', 'df_fillage.Age.isnull', 'df_fillagetest.Age.isnull', 'df_fillagetest.Age.isnull', 'df_fillagetest.Age.isnull', 'df_fillagetest.Age.isnull', 'df_fillagetest.Age.isnull', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'df_fillage.drop', 'df_fillage.info', 'df_fillagetest.drop', 'df_fillage.drop', 'df_fillage.info', 'df_fillagetest.drop', 'df_fillage.drop', 'df_fillage.info', 'df_fillagetest.drop', 'df_fillage.drop', 'df_fillage.drop', 'train_test_split', 'RandomForestClassifier', 'model.fit', 'model.predict', 'print', 'predictiony_vld.sum', 'xgb.XGBClassifier', 'model_xgb.fit', 'model_xgb.predict', 'metrics.accuracy_score', 'print', 'lgbm.LGBMClassifier', 'model_lgbm.fit', 'model_lgbm.predict', 'metrics.accuracy_score', 'print', 'cboost.CatBoostClassifier', 'model_cboost.fit', 'model_cboost.predict', 'metrics.accuracy_score', 'print', 'Sequential', 'model_mlp.add', 'model_mlp.add', 'model_mlp.add', 'model_mlp.add', 'Adam', 'model_mlp.compile', 'model_mlp.fit', 'model_mlp.predict_classes', 'metrics.accuracy_score', 'print', 'pd.read_csv', 'model_lgbm.predict', 'submission.to_csv']","['print', 'read_csv', 'read_csv', 'describe', 'info', 'Name', 'unique', 'replace', 'unique', 'where', 'Name', 'replace', 'unique', 'where', 'groupby', 'mean', 'isnull', 'sum', 'fillna', 'fillna', 'isnull', 'sum', 'isnull', 'sum', 'map', 'Initial', 'map', 'map', 'Sex', 'map', 'map', 'Embarked', 'map', 'Embarked', 'map', 'map', 'map', 'map', 'subplots', 'distplot', 'legend', 'drop', 'drop', 'drop', 'drop', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'drop', 'info', 'drop', 'drop', 'info', 'drop', 'drop', 'info', 'drop', 'drop', 'drop', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'print', 'sum', 'XGBClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'LGBMClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'CatBoostClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'Sequential', 'add', 'add', 'add', 'add', 'Adam', 'compile', 'fit', 'predict_classes', 'accuracy_score', 'print', 'read_csv', 'predict', 'to_csv']","['print', 'read_csv', 'describe', 'info', 'Name', 'unique', 'replace', 'where', 'groupby', 'mean', 'isnull', 'sum', 'fillna', 'map', 'Initial', 'Sex', 'Embarked', 'subplots', 'distplot', 'legend', 'drop', 'Age', 'get_dummies', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'XGBClassifier', 'accuracy_score', 'LGBMClassifier', 'CatBoostClassifier', 'Sequential', 'add', 'Adam', 'compile', 'predict_classes', 'to_csv']",37,"[1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0
 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv describe info name unique replace unique name replace unique groupby mean isnull sum fillna fillna isnull sum isnull sum map initial map map sex map map embarked map embarked map map map map subplots distplot legend drop drop drop drop age age age age age age age age age age get dummies get dummies get dummies get dummies get dummies get dummies drop info drop drop info drop drop info drop drop drop train test split randomforestclassifier fit predict print sum xgbclassifier fit predict accuracy score print lgbmclassifier fit predict accuracy score print catboostclassifier fit predict accuracy score print sequential add add add add adam compile fit predict classes accuracy score print read csv predict csv,"[0.0, 0.0, 0.23682099893676486, 0.0, 0.11863936830554128, 0.18844094503137102, 0.0, 0.4935799323263683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11863936830554128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08585559860458747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07504685957511316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08759258293616878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039157350148479264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05976335865711762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3362930165610089, 0.0, 0.0, 0.0, 0.23743843661732283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09940069842833114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05701312733207338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12066339961325945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17251190834399088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03795878673268189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14442287509857657, 0.0, 0.11863936830554128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11685788342446815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04202484503660002, 0.0, 0.0, 0.0904009661145861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38350523832702127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03936415092372106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10866442480296878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15022889431801012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14016165858674262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03540925088420304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06543046657911485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08648990459025344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1473073818308727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08214176293359067, 0.0, 0.0, 0.0, 0.07278122659969682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03815371359245964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050763357423676006, 0.15499977015931318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0397841596471579, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039157350148479264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19917634735024445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06092765847963558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
gihanr_machine-learning-and-titanic.py,"['numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,453,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', ""# survived_female_ages_age_NaN = data[(data['Survived'] == 1) & (data['Sex'] == 'female') & (~survived_female_ages['Age'].notna())]"", '# len(survived_female_ages_age_NaN)', ""# survived_female_ages = data[(data['Survived'] == 1) & (data['Sex'] == 'female')]"", '# replace NaN with survived females means', '# Analysis of based on Pclass', '# survived females with pclass', '# Analysis of based on Pclass', '# check ages of survived and not survived females', '# check ages of survived and not survived females', '# Analysis on Cabins', ""# data_replaced_ages.loc[data_replaced_ages['Embarked'].isnull()] = 'S'"", '# Change categorical values to numberical values using sklearn', '# pd.DataFrame({""PassengerId"": passengerId, ""Survived"" : results }, ignore_index=True)']",15,"['pd.read_csv', 'data.count', 'data.describe', 'female_ages.notna', 'print', 'female_ages.notna', 'print', 'sns.set_style', 'sns.boxplot', 'sns.swarmplot', 'drawBoxplot', 'female_ages_survived_age.mean', 'female_ages.notna', 'print', 'female_ages.notna', 'print', 'drawBoxplot', 'female_ages_not_survived_age.mean', 'data.copy', 'data_replaced_ages.isnull', 'female_ages_survived_age.mean', 'data_replaced_ages.isnull', 'female_ages_not_survived_age.mean', 'drawBoxplot', 'drawBoxplot', 'data_replaced_ages.notna', 'data_replaced_ages.isnull', 'survive_males.median', 'data_replaced_ages.notna', 'data_replaced_ages.isnull', 'not_survived_males.median', 'data_replaced_ages.head', 'data_replaced_ages_females.groupby', 'None.size', 'None.plot.bar', 'pd.crosstab', 'None.plot.bar', 'plt.subplots', 'sns.swarmplot', 'None.set_title', 'plt.subplots', 'sns.swarmplot', 'None.set_title', 'plt.subplots', 'sns.swarmplot', 'None.set_title', 'plt.subplots', 'sns.swarmplot', 'None.set_title', 'data_replaced_ages.notna', 'pd.crosstab', 'None.plot.bar', 'data_replaced_ages.isnull', 'pd.crosstab', 'None.plot.bar', 'data_replaced_ages.notna', 'data_replaced_ages.isnull', 'data_replaced_ages.head', 'pd.crosstab', 'None.plot.bar', 'None.set_title', 'pd.crosstab', 'None.plot.bar', 'None.set_title', 'data_replaced_ages.isnull', 'data_replaced_ages.drop', 'pd.read_csv', 'test_dataset.count', 'test_dataset.isnull', 'not_survived_males.median', 'survive_males.median', 'test_dataset.isnull', 'female_ages_survived_age.mean', 'female_ages_not_survived_age.mean', 'test_dataset.notna', 'test_dataset.isnull', 'test_dataset.isnull', 'test_dataset.mean', 'test_dataset.drop', 'final_test_data_set.head', 'final_data_set.head', 'LabelEncoder', 'le.fit_transform', 'le.fit_transform', 'X_train.head', 'X_train.drop', 'le.fit_transform', 'le.fit_transform', 'X_test.drop', 'X_test.head', 'X_train.head', 'linear_model.LogisticRegression', 'model.fit', 'model.predict', 'pd.DataFrame', 'results.count', 'passengerId.count', 'pd.concat', 'submit.to_csv']","['read_csv', 'count', 'describe', 'notna', 'print', 'notna', 'print', 'set_style', 'boxplot', 'swarmplot', 'drawBoxplot', 'mean', 'notna', 'print', 'notna', 'print', 'drawBoxplot', 'mean', 'copy', 'isnull', 'mean', 'isnull', 'mean', 'drawBoxplot', 'drawBoxplot', 'notna', 'isnull', 'median', 'notna', 'isnull', 'median', 'head', 'groupby', 'size', 'plot', 'crosstab', 'plot', 'subplots', 'swarmplot', 'set_title', 'subplots', 'swarmplot', 'set_title', 'subplots', 'swarmplot', 'set_title', 'subplots', 'swarmplot', 'set_title', 'notna', 'crosstab', 'plot', 'isnull', 'crosstab', 'plot', 'notna', 'isnull', 'head', 'crosstab', 'plot', 'set_title', 'crosstab', 'plot', 'set_title', 'isnull', 'drop', 'read_csv', 'count', 'isnull', 'median', 'median', 'isnull', 'mean', 'mean', 'notna', 'isnull', 'isnull', 'mean', 'drop', 'head', 'head', 'LabelEncoder', 'fit_transform', 'fit_transform', 'head', 'drop', 'fit_transform', 'fit_transform', 'drop', 'head', 'head', 'LogisticRegression', 'fit', 'predict', 'DataFrame', 'count', 'count', 'concat', 'to_csv']","['read_csv', 'count', 'describe', 'notna', 'print', 'set_style', 'boxplot', 'swarmplot', 'drawBoxplot', 'mean', 'copy', 'isnull', 'median', 'head', 'groupby', 'size', 'plot', 'crosstab', 'subplots', 'set_title', 'drop', 'LabelEncoder', 'fit_transform', 'LogisticRegression', 'fit', 'predict', 'DataFrame', 'concat', 'to_csv']",29,"[1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv count describe notna print notna print set style boxplot swarmplot drawboxplot mean notna print notna print drawboxplot mean copy isnull mean isnull mean drawboxplot drawboxplot notna isnull median notna isnull median head groupby size plot crosstab plot subplots swarmplot set title subplots swarmplot set title subplots swarmplot set title subplots swarmplot set title notna crosstab plot isnull crosstab plot notna isnull head crosstab plot set title crosstab plot set title isnull drop read csv count isnull median median isnull mean mean notna isnull isnull mean drop head head labelencoder fit transform fit transform head drop fit transform fit transform drop head head logisticregression fit predict dataframe count count concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0428060666903858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029436981794994137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031237768956038452, 0.0, 0.0, 0.0, 0.17300560743003648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1949584260887604, 0.04523816719523327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01889377053771147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026964334095579332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32678733895412376, 0.07719212543049132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08309061282091593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02613898548910438, 0.0, 0.0, 0.0, 0.0, 0.12578010247699875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29505695169639345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039329698671197996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025233711426781862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18974718131075355, 0.15086254016969672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6195972150889493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1736336025167689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017241642083543045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06434493609658844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030037595397014866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18974718131075355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04871437722978837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037413970092215254, 0.0, 0.0, 0.0, 0.0, 0.1398256137552726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3442206750494162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16980743104541798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12269140729531015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
maxsantos_titanic-notebook.py,"['the', 'numpy', 'pandas', 'IPython', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,373,"['# Impute missing values for age in training set', ""# Create Child column in training set ('Feature Engineering')"", '# Create Family Size column for training set', '# Simplify Cabin column, by slicing off numbers', ""# NaN Cabin values labelled as 'N'"", '# Visualise new features', '# Child plot', '# Famliy_Size plot', '# Cabin plot', '# Convert sex to integer values in training set', '# Convert embarked to integer values, and impute missing values', '# Create feature and target arrays', '# Split into training and test set', '# Create random forest classifier', '# Choose some parameter combinations to try (these values were borrowed from another user)', '# Type of scoring used to compare parameter combinations', '# Run the grid search with 10-fold cross-validation', '# Set the classifier to the best combination of parameters', '# Fit the best algorithm to the data, and print feature importances & prediction score', '# Print confusion matrix, showing actual numbers of correct and incorrect predictions', '# Accuracy on test set (diagonal divided by total in confusion matrix)', '# Print classification report, showing precision and recall calculated from confusion matrix', '# high precision = a low rate of incorrect survival predictions', '# high recall = predicted a large number of survivals correctly', '# Fit logreg to Kaggle test data', '# Create submission file', '# Fit knn to kaggle test data', '# Create submission file']",28,"['pd.read_csv', 'pd.read_csv', 'display', 'print', 'train.value_counts', 'print', 'sns.factorplot', 'sex_plot.set_ylabels', 'plt.show', 'sns.factorplot', 'embarked_plot1.set_ylabels', 'plt.show', 'sns.factorplot', 'embarked_plot2.set_ylabels', 'plt.show', 'sns.pointplot', 'plt.show', 'train.fillna', 'float', 'train.fillna', 'train.apply', 'sns.factorplot', 'child_plot.set_ylabels', 'plt.show', 'sns.factorplot', 'family_plot.set_ylabels', 'plt.show', 'sns.factorplot', 'cabin_plot.set_ylabels', 'plt.show', 'train.fillna', 'display', 'train.drop', 'train_test_split', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'grid.fit', 'print', 'print', 'forest.fit', 'print', 'print', 'forest.predict', 'print', 'test.fillna', 'float', 'display', 'test.drop', 'forest.predict', 'pd.DataFrame', 'forestsubmission.to_csv', 'display', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'print', 'print', 'print', 'print', 'logreg.predict', 'pd.DataFrame', 'logregsubmission.to_csv', 'display', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'print', 'print', 'knn.predict', 'pd.DataFrame', 'knnsubmission.to_csv', 'display']","['read_csv', 'read_csv', 'display', 'print', 'value_counts', 'print', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'pointplot', 'show', 'fillna', 'float', 'fillna', 'apply', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'fillna', 'display', 'drop', 'train_test_split', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'fit', 'print', 'print', 'fit', 'print', 'print', 'predict', 'print', 'fillna', 'float', 'display', 'drop', 'predict', 'DataFrame', 'to_csv', 'display', 'LogisticRegression', 'fit', 'predict', 'print', 'print', 'print', 'print', 'predict', 'DataFrame', 'to_csv', 'display', 'KNeighborsClassifier', 'fit', 'predict', 'print', 'print', 'predict', 'DataFrame', 'to_csv', 'display']","['read_csv', 'display', 'print', 'value_counts', 'factorplot', 'set_ylabels', 'show', 'pointplot', 'fillna', 'float', 'apply', 'drop', 'train_test_split', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'fit', 'predict', 'DataFrame', 'to_csv', 'LogisticRegression', 'KNeighborsClassifier']",22,"[1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv display print value counts print factorplot set ylabels show factorplot set ylabels show factorplot set ylabels show pointplot show fillna float fillna apply factorplot set ylabels show factorplot set ylabels show factorplot set ylabels show fillna display drop train test split randomforestclassifier make scorer gridsearchcv fit print print fit print print predict print fillna float display drop predict dataframe csv display logisticregression fit predict print print print print predict dataframe csv display kneighborsclassifier fit predict print print predict dataframe csv display,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038540862274478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046093673908438326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10154516060992906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07633880744766754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46694784990146654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051981461190719745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34950783716271466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10575155069517489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08952563887212184, 0.0, 0.1632312260189637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05391429958162016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04546389877279686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03398494817739427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08384071176517736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09693530489043285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1393270223611619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2816457581542281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03283965785764226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0404548544475162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08927545894995735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2190453425437984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3098482448509108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03538495927158471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03689708644893543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03631576351878246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046093673908438326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5563187248337653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
jatinmittal0001_titanic-challenge-ensemble.py,"['numpy', 'pandas', 'matplotlib', 'sklearn', 'seaborn', 'os\n', 'xgboost']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,382,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# missing value treatment', '# cabin column treatment', ""# now treating 'age' variable"", '# now checking #missing values', '# filling embark missing values with values which occured most', '#', ""# also ticket number won't provide aby valueable information so we can drop that"", '# ONE HOT ENCODING OF CATEGORICAL DATA', '# scaling data', '# fit only to training data i.e. find mean and dev for training data', '# apply those transformtions to x_train and x_test data set', '# it is almost 60%, therefore right now we are not upsampling or downsampling it', '# applying model: XGBOOST', ""# since the size of data is small, we'll now train on final_train_data, and directly predict test_data"", '# trainging data may give more accuracy', '# apply those transformtions to x_train and x_test data set', '    # apply those transformtions to x_train and x_test data set', '\'\\nfrom sklearn.model_selection import KFold\\nkf = KFold(n_splits=5)\\nfor train_index, test_index in kf.split(final_train_data):\\n    #print(""TRAIN:"", train_index, ""TEST:"", test_index)\\n    x_train, x_test = final_train_data.iloc[train_index], final_train_data.iloc[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    scale = StandardScaler()\\n    scale.fit(x_train)\\n\\n    # apply those transformtions to x_train and x_test data set\\n    x_train = scale.transform(x_train)\\n    x_test = scale.transform(x_test)\\n    model = VotingClassifier(estimators=[(\\\'xgb\\\', xgb_model),(\\\'svc\\\',svc)], voting=\\\'soft\\\')\\n    model = model.fit(x_train,y_train)\\n    y_pred = model.predict(x_test)\\n    print(find_accuracy(y_pred, y_test))\\n\'']",28,"['print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train_data.drop', 'test_data.drop', 'train_data.append', 'train_data.head', 'total_data.isnull', 'None.sum', 'None.sort_values', 'total_data.isnull', 'None.sum', 'total_data.isnull', 'None.count', 'None.sort_values', 'pd.concat', 'print', 'total_data.unique', 'total_data.fillna', 'total_data.apply', 'total_data.map', 'total_data.head', 'pd.crosstab', 'total_data.replace', 'total_data.replace', 'total_data.replace', 'total_data.replace', 'total_data.unique', 'print', 'total_data.groupby', 'None.transform', 'total_data.isnull', 'None.sum', 'None.sort_values', 'total_data.isnull', 'None.sum', 'total_data.isnull', 'None.count', 'None.sort_values', 'pd.concat', 'print', 'total_data.fillna', 'total_data.groupby', 'None.transform', 'total_data.drop', 'pd.cut', 'pd.cut', 'LabelEncoder', 'label.fit_transform', 'label.fit_transform', 'total_data.head', 'total_data.drop', 'total_data.copy', 'pd.get_dummies', 'total_data_onehot.head', 'total_data_onehot.drop', 'total_data_onehot.head', 'train_test_split', 'StandardScaler', 'scale.fit', 'scale.transform', 'scale.transform', 'accuracy_score', 'yy.count', 'AdaBoostClassifier', 'ada.fit', 'ada.predict', 'print', 'SVC', 'svc.fit', 'svc.predict', 'print', 'XGBClassifier', 'xgb_model.fit', 'xgb_model.predict', 'print', 'MLPClassifier', 'mlp.fit', 'mlp.predict', 'print', 'Lasso', 'lasso.fit', 'lasso.predict', 'print', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'print', 'ElasticNet', 'elastic_net_model.fit', 'elastic_net_model.predict', 'print', 'VotingClassifier', 'model.fit', 'model.predict', 'print', 'scale.transform', 'model.fit', 'model.predict', 'pd.DataFrame', 'solution.to_csv']","['print', 'read_csv', 'read_csv', 'read_csv', 'drop', 'drop', 'append', 'head', 'isnull', 'sum', 'sort_values', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'concat', 'print', 'unique', 'fillna', 'apply', 'map', 'head', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'unique', 'print', 'groupby', 'transform', 'isnull', 'sum', 'sort_values', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'concat', 'print', 'fillna', 'groupby', 'transform', 'drop', 'cut', 'cut', 'LabelEncoder', 'fit_transform', 'fit_transform', 'head', 'drop', 'copy', 'get_dummies', 'head', 'drop', 'head', 'train_test_split', 'StandardScaler', 'fit', 'transform', 'transform', 'accuracy_score', 'count', 'AdaBoostClassifier', 'fit', 'predict', 'print', 'SVC', 'fit', 'predict', 'print', 'XGBClassifier', 'fit', 'predict', 'print', 'MLPClassifier', 'fit', 'predict', 'print', 'Lasso', 'fit', 'predict', 'print', 'RandomForestClassifier', 'fit', 'predict', 'print', 'ElasticNet', 'fit', 'predict', 'print', 'VotingClassifier', 'fit', 'predict', 'print', 'transform', 'fit', 'predict', 'DataFrame', 'to_csv']","['print', 'read_csv', 'drop', 'append', 'head', 'isnull', 'sum', 'sort_values', 'count', 'concat', 'unique', 'fillna', 'apply', 'map', 'crosstab', 'replace', 'groupby', 'transform', 'cut', 'LabelEncoder', 'fit_transform', 'copy', 'get_dummies', 'train_test_split', 'StandardScaler', 'fit', 'accuracy_score', 'AdaBoostClassifier', 'predict', 'SVC', 'XGBClassifier', 'MLPClassifier', 'Lasso', 'RandomForestClassifier', 'ElasticNet', 'VotingClassifier', 'DataFrame', 'to_csv']",38,"[1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0
 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv read csv drop drop append head isnull sum sort values isnull sum isnull count sort values concat print unique fillna apply map head crosstab replace replace replace replace unique print groupby transform isnull sum sort values isnull sum isnull count sort values concat print fillna groupby transform drop cut cut labelencoder fit transform fit transform head drop copy get dummies head drop head train test split standardscaler fit transform transform accuracy score count adaboostclassifier fit predict print svc fit predict print xgbclassifier fit predict print mlpclassifier fit predict print lasso fit predict print randomforestclassifier fit predict print elasticnet fit predict print votingclassifier fit predict print transform fit predict dataframe csv,"[0.0, 0.0, 0.07095155023702471, 0.08722099608708307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05757514893630732, 0.04980136123810284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10245862930006923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05436323281913746, 0.0, 0.0, 0.0, 0.2258118400430122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06785740891054971, 0.10497092025603347, 0.0, 0.0, 0.0, 0.13022340805924743, 0.0, 0.0, 0.0, 0.032880915663934404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1679222631299133, 0.0, 0.0, 0.0, 0.04742435634083534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13227955065076769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06832451152951378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3470471404965109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034456368273383706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09097959305608788, 0.0, 0.0, 0.0, 0.0, 0.15635406440643432, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28008489191779584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06844565527640065, 0.0, 0.0, 0.13227955065076769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04595925412946574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10833648565881258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2700513803280534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3359393636601413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04243443367345614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07841184789123584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20729894183646821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04413327850647449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21612441865142512, 0.0, 0.0, 0.0, 0.045723396807515096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08052170646796948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1857516694644515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05609523869116882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047677322779925535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04692615449950769, 0.0, 0.0, 0.0, 0.3736607345712235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1591285759117039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21612441865142512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09467568064109992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07301568426533725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
astrocyte_cungbuk-univ-2020-comphy2-titanic-tutorial.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,81,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",8,"['os.walk', 'print', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'sum', 'len', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",12,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head sum len print sum len print get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29651471721459643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12383969942746267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3572295914637062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10892390691892337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2595466825772223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23555110859145806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615584966167075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1130107814636607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4217505198327656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1598212034362369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19688218283721298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3497991228367539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20992981393866597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
iamaniket_titanicsurvivorprediction.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'math\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,254,"['import numpy as np # linear algebra', 'import pandas as pd # data processing']",2,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'titanic_data.head', 'print', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'titanic_data.plot.hist', 'titanic_data.plot.hist', 'titanic_data.info', 'sns.countplot', 'sns.countplot', 'titanic_data.isnull', 'titanic_data.isnull', 'None.sum', 'sns.boxplot', 'titanic_data.head', 'titanic_data.drop', 'titanic_data.head', 'titanic_data.dropna', 'titanic_data.head', 'titanic_data.isnull', 'None.sum', 'pd.get_dummies', 'sex.head', 'pd.get_dummies', 'embark.head', 'titanic_data.drop', 'pd.concat', 'titanic_data.head', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'X_test.head', 'classification_report', 'confusion_matrix', 'accuracy_score']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'print', 'countplot', 'countplot', 'countplot', 'plot', 'plot', 'info', 'countplot', 'countplot', 'isnull', 'isnull', 'sum', 'boxplot', 'head', 'drop', 'head', 'dropna', 'head', 'isnull', 'sum', 'get_dummies', 'head', 'get_dummies', 'head', 'drop', 'concat', 'head', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'head', 'classification_report', 'confusion_matrix', 'accuracy_score']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'countplot', 'plot', 'info', 'isnull', 'sum', 'boxplot', 'drop', 'dropna', 'get_dummies', 'concat', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'classification_report', 'confusion_matrix', 'accuracy_score']",23,"[1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic read csv head print countplot countplot countplot plot plot info countplot countplot isnull isnull sum boxplot head drop head dropna head isnull sum get dummies head get dummies head drop concat head train test split logisticregression fit predict head classification report confusion matrix accuracy score,"[0.0, 0.0, 0.1309849971416506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13752772422058093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21296662297361185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.094575405478623, 0.0, 0.0, 0.1486526433363818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5386067347009622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0484471996868294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12400178478193907, 0.10559186320043445, 0.0, 0.0, 0.1751020001394525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0533908568054469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19083165701342192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46183710683576046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07987986693286107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08027345622461621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2585350048357903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08147527911244472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08107109983416466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08107109983416466, 0.0, 0.0, 0.0, 0.0, 0.1404361970426143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18595054430852015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05539410604403979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10336400083764344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04825253118780323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2000020326116993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08067051330810475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08147527911244472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0844108265447544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1714598328900325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08801800619137505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08663126023959898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10290057483465276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
vivekkr970_titanic-survival-prediction.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn', 'IPython']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,489,"['# below is distribution of embarked according to fare and sex', '# we replace missing age by mean age of pessenger who belong to some group of class/sex/family', '# we replace the missing value of fare for test dataset using interpolation', '# in case of Pclass and FamilySize their order has some meaning so we will not create dummies for them', '# in case of Pclass and FamilySize their order has some meaning so we will not create dummies for them', '# environment settings: ', '# create a list of features column', '# create x and y for training and test data', '# create a NumPy array with the same shape as y_test', '# fill the array with the mean value of y_test', '# compute null RMSE', '# compute RMSE', '# compute error between predicted data and true responce and display it in confusion matrix', '# compute RMSE', '# compute error between predicted data and true responce and display it in confusion matrix', '# compute RMSE', '# compute error between predicted data and true responce and display it in confusion matrix', '# compute RMSE', '# compute error between predicted data and true responce and display it in confusion matrix']",19,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train_data.head', 'train_data.describe', 'print', 'print', 'train_data.drop', 'None.hist', 'plt.show', 'test_data.drop', 'None.hist', 'plt.show', 'sns.catplot', 'display', 'train_data.fillna', 'train_data.groupby', 'None.transform', 'train_data.groupby', 'None.transform', 'train_data.groupby', 'None.transform', 'train_data.tail', 'test_data.groupby', 'None.transform', 'test_data.groupby', 'None.transform', 'test_data.groupby', 'None.transform', 'test_data.head', 'display', 'test_data.interpolate', 'test_data.fillna', 'train_data.fillna', 'print', 'print', 'plt.figure', 'sns.heatmap', 'pd.Series', 'print', 'pd.Series', 'print', 'train_data.replace', 'train_data.replace', 'train_data.replace', 'train_data.map', 'test_data.replace', 'test_data.replace', 'test_data.replace', 'test_data.map', 'train_data.groupby', 'None.transform', 'test_data.groupby', 'None.transform', 'train_data.map', 'train_data.map', 'test_data.map', 'test_data.map', 'train_data.map', 'test_data.map', 'train_data.head', 'train_data.between', 'np.where', 'test_data.between', 'np.where', 'train_data.apply', 'test_data.apply', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'train_data.drop', 'train_data.drop', 'train_data.drop', 'train_data.drop', 'train_data.head', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'test_data.drop', 'test_data.drop', 'test_data.drop', 'test_data.drop', 'test_data.head', 'pd.set_option', 'pd.set_option', 'pd.set_option', 'pd.set_option', 'pd.set_option', 'print', 'print', 'np.zeros_like', 'y_null.fill', 'np.sqrt', 'LogisticRegression', 'lg.fit', 'lg.predict', 'print', 'print', 'print', 'print', 'sns.heatmap', 'DecisionTreeClassifier', 'dt.fit', 'dt.predict', 'print', 'print', 'print', 'print', 'sns.heatmap', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'print', 'print', 'print', 'print', 'sns.heatmap', 'SVC', 'svm.fit', 'svm.predict', 'print', 'print', 'print', 'print', 'sns.heatmap', 'test_survived_data.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'read_csv', 'head', 'describe', 'print', 'print', 'drop', 'hist', 'show', 'drop', 'hist', 'show', 'catplot', 'display', 'fillna', 'groupby', 'transform', 'groupby', 'transform', 'groupby', 'transform', 'tail', 'groupby', 'transform', 'groupby', 'transform', 'groupby', 'transform', 'head', 'display', 'interpolate', 'fillna', 'fillna', 'print', 'print', 'figure', 'heatmap', 'Series', 'print', 'Series', 'print', 'replace', 'replace', 'replace', 'map', 'replace', 'replace', 'replace', 'map', 'groupby', 'transform', 'groupby', 'transform', 'map', 'map', 'map', 'map', 'map', 'map', 'head', 'between', 'where', 'between', 'where', 'apply', 'apply', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'drop', 'drop', 'drop', 'drop', 'head', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'drop', 'drop', 'drop', 'drop', 'head', 'set_option', 'set_option', 'set_option', 'set_option', 'set_option', 'print', 'print', 'zeros_like', 'fill', 'sqrt', 'LogisticRegression', 'fit', 'predict', 'print', 'print', 'print', 'print', 'heatmap', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'print', 'print', 'print', 'heatmap', 'RandomForestClassifier', 'fit', 'predict', 'print', 'print', 'print', 'print', 'heatmap', 'SVC', 'fit', 'predict', 'print', 'print', 'print', 'print', 'heatmap', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'describe', 'print', 'drop', 'hist', 'show', 'catplot', 'display', 'fillna', 'groupby', 'transform', 'tail', 'interpolate', 'figure', 'heatmap', 'Series', 'replace', 'map', 'between', 'where', 'apply', 'get_dummies', 'concat', 'set_option', 'zeros_like', 'fill', 'sqrt', 'LogisticRegression', 'fit', 'predict', 'DecisionTreeClassifier', 'RandomForestClassifier', 'SVC', 'to_csv']",37,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv read csv head describe print print drop hist show drop hist show catplot display fillna groupby transform groupby transform groupby transform tail groupby transform groupby transform groupby transform head display interpolate fillna fillna print print figure heatmap series print series print replace replace replace map replace replace replace map groupby transform groupby transform map map map map map map head apply apply get dummies get dummies get dummies get dummies concat drop drop drop drop head get dummies get dummies get dummies get dummies concat drop drop drop drop head set option set option set option set option set option print print zeros like fill sqrt logisticregression fit predict print print print print heatmap decisiontreeclassifier fit predict print print print print heatmap randomforestclassifier fit predict print print print print heatmap svc fit predict print print print print heatmap csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.069823804680498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06636983476688192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07182586120362956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07358703508170036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04036150673230523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032896316131953554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14099353925236005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2354347554122582, 0.0, 0.0, 0.0, 0.2659645368654962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040631003701299115, 0.0, 0.0, 0.07393078780994082, 0.07184558658625344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08109601541846276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21739237659947672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2551151686431883, 0.0, 0.0, 0.0, 0.0, 0.10960780370963172, 0.2212353682151571, 0.0, 0.08717762314166713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09273101455705407, 0.0, 0.0, 0.0, 0.030482079859695376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09966961887552361, 0.03093844567433641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030784967480950883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030784967480950883, 0.0, 0.0, 0.2577479734543444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3381901127381051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0841387748132395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4710024772324891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029747516281502955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05496851306551896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2179820058942861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030632853556219537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08986334617376779, 0.1653502532912011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0801923763592144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08780799644687994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0393240555328573, 0.0, 0.0, 0.0, 0.054508212338238236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2993654734253195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05943123044841236, 0.0, 0.0]"
kobezorro_titanic-my-try.py,"['pandas', 'sklearn', 'numpy', 'seaborn', 'matplotlib', 'math\n', 'SelectKBest\n', 'chi2\n', 'xgboost', 'mlxtend']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",10,343,"['# ml', '# visualization', '# Load the data', '# feature processing methods', '    # cut into categories', '    # bins = (0, 8, 15, 31, 1000)', ""    # group_names = ['1_quartile', '2_quartile', '3_quartile', '4_quartile']"", ""    # df['Fare'] = pd.cut(df.Fare, bins, labels=group_names)"", ""    # fare_map = {'1_quartile': 1, '2_quartile': 2, '3_quartile': 3, '4_quartile': 4}"", ""    # df['Fare'] = df['Fare'].map(fare_map)"", '            # Convert random age float to nearest .5 age', '    # cut into categories', '    # bins = (0, 5, 12, 18, 25, 35, 60, 100)', ""    # group_names = ['Baby', 'Child', 'Teenager', 'Student', 'Young', 'Adult', 'Senior']"", ""    # df['Age'] = pd.cut(df.Age, bins, labels=group_names)"", ""    # age_map = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young': 5, 'Adult': 6, 'Senior': 7}"", ""    # df['Age'] = df['Age'].map(age_map)"", '# train & predict', '# train and test data', '# feature selection', '# xgboost', '# semi-supervised with xgboost', 'semi_train_df = semi_train_df.sample(frac=1).reset_index(drop=True)  # shuffle', '# random forest', '# adaboost', '# stacking']",26,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'pd.concat', 'df.Name.str.extract', 'print', 'df.replace', 'df.replace', 'df.Title.value_counts', 'df.replace', 'df.map', 'None.astype', 'dfdfc.dropna', 'df.Fare.isnull', 'guess_df.mean', 'df.map', 'None.astype', 'dfdf.Titletdf.Pclassc.Age.dropna', 'guess_df.median', 'math.isnan', 'int', 'df.Age.isnull', 'df.Cabin.isnull', 'df.apply', 'df.map', 'None.astype', 'df.Embarked.isnull', 'df.map', 'None.astype', 'df.drop', 'KFold', 'clf.fit', 'clf.predict', 'clf.predict_proba', 'roc_auc_score', 'accuracy_score', 'aucs.append', 'accs.append', 'print', 'sum', 'len', 'sum', 'len', 'print', 'list', 'print', 'clf.set_params', 'run_kfold', 'print', 'run_kfold', 'clf.set_params', 'clf.fit', 'clf.predict', 'clf.predict_proba', 'clf.predict', 'clf.predict_proba', 'accuracy_score', 'roc_auc_score', 'print', 'process_name', 'process_fare', 'process_sex', 'process_age', 'process_cabin', 'process_embarked', 'process_parch_sibsp', 'tt_df.drop', 'print', 'p_train_df.drop', 'p_train_df.astype', 'p_test_df.drop', 'xgb.XGBClassifier', 'grid_search', 'train_and_predict', 'p_test_df.assign', 'p_test_df.drop', 'p_test_df.Survived.notnull', 'pd.concat', 'semi_train_df.sample', 'None.reset_index', 'semi_train_df.drop', 'semi_train_df.astype', 'grid_search', 'train_and_predict', 'RandomForestClassifier', 'grid_search', 'random_forest.set_params', 'random_forest.fit', 'random_forest.predict', 'random_forest.predict_proba', 'random_forest.predict', 'accuracy_score', 'roc_auc_score', 'print', 'AdaBoostClassifier', 'grid_search', 'ada.set_params', 'ada.fit', 'ada.predict', 'ada.predict', 'accuracy_score', 'roc_auc_score', 'print', 'LogisticRegression', 'StackingClassifier', 'grid_search', 'sclf.fit', 'sclf.predict', 'sclf.predict', 'accuracy_score', 'roc_auc_score', 'print', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'concat', 'Name', 'print', 'replace', 'replace', 'Title', 'replace', 'map', 'astype', 'dropna', 'Fare', 'mean', 'map', 'astype', 'Titletdf', 'median', 'isnan', 'int', 'Age', 'Cabin', 'apply', 'map', 'astype', 'Embarked', 'map', 'astype', 'drop', 'KFold', 'fit', 'predict', 'predict_proba', 'roc_auc_score', 'accuracy_score', 'append', 'append', 'print', 'sum', 'len', 'sum', 'len', 'print', 'list', 'print', 'set_params', 'run_kfold', 'print', 'run_kfold', 'set_params', 'fit', 'predict', 'predict_proba', 'predict', 'predict_proba', 'accuracy_score', 'roc_auc_score', 'print', 'process_name', 'process_fare', 'process_sex', 'process_age', 'process_cabin', 'process_embarked', 'process_parch_sibsp', 'drop', 'print', 'drop', 'astype', 'drop', 'XGBClassifier', 'grid_search', 'train_and_predict', 'assign', 'drop', 'Survived', 'concat', 'sample', 'reset_index', 'drop', 'astype', 'grid_search', 'train_and_predict', 'RandomForestClassifier', 'grid_search', 'set_params', 'fit', 'predict', 'predict_proba', 'predict', 'accuracy_score', 'roc_auc_score', 'print', 'AdaBoostClassifier', 'grid_search', 'set_params', 'fit', 'predict', 'predict', 'accuracy_score', 'roc_auc_score', 'print', 'LogisticRegression', 'StackingClassifier', 'grid_search', 'fit', 'predict', 'predict', 'accuracy_score', 'roc_auc_score', 'print', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'concat', 'Name', 'print', 'replace', 'Title', 'map', 'astype', 'dropna', 'Fare', 'mean', 'Titletdf', 'median', 'isnan', 'int', 'Age', 'Cabin', 'apply', 'Embarked', 'drop', 'KFold', 'fit', 'predict', 'predict_proba', 'roc_auc_score', 'accuracy_score', 'append', 'sum', 'len', 'list', 'set_params', 'run_kfold', 'process_name', 'process_fare', 'process_sex', 'process_age', 'process_cabin', 'process_embarked', 'process_parch_sibsp', 'XGBClassifier', 'grid_search', 'train_and_predict', 'assign', 'Survived', 'sample', 'reset_index', 'RandomForestClassifier', 'AdaBoostClassifier', 'LogisticRegression', 'StackingClassifier', 'DataFrame', 'to_csv']",54,"[1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0
 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv concat name print replace replace title replace map astype dropna fare mean map astype titletdf median isnan int age cabin apply map astype embarked map astype drop kfold fit predict predict proba roc auc score accuracy score append append print sum len sum len print list print set params run kfold print run kfold set params fit predict predict proba predict predict proba accuracy score roc auc score print process name process fare process sex process age process cabin process embarked process parch sibsp drop print drop astype drop xgbclassifier grid search train predict assign drop survived concat sample reset index drop astype grid search train predict randomforestclassifier grid search set params fit predict predict proba predict accuracy score roc auc score print adaboostclassifier grid search set params fit predict predict accuracy score roc auc score print logisticregression stackingclassifier grid search fit predict predict accuracy score roc auc score print dataframe csv,"[0.0, 0.0, 0.19336921958029182, 0.047541895527389945, 0.0, 0.0, 0.0, 0.06448290767656326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06276543122646606, 0.02714542620838433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06530518520736263, 0.14290974882865756, 0.287420995490811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08673684629631215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05584753291741923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042912688011872445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01792253158607521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10983606767078656, 0.031176419630740082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06493017280432861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0812112204710843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0788193192998094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018781269811123814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2952569974008018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03831900090508083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04238235548891139, 0.0, 0.0, 0.0, 0.0, 0.02370105878061807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04019616795084892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1386306078272006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06679842387117314, 0.0, 0.0, 0.0, 0.0, 0.0240559017915956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03667421532172026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023936566244293158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023936566244293158, 0.0, 0.0, 0.1002047743714502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025713311497662403, 0.035776853486578275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07098139139562375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24331257893411845, 0.06530518520736263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24532996806115562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15259317181995147, 0.0, 0.19931401943140503, 0.0, 0.0, 0.47792005871728643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023129905676073526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028493505369836813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08474494454771007, 0.0, 0.0, 0.042866256973699446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2682817598900337, 0.0, 0.0, 0.0, 0.0, 0.07145487441432878, 0.0, 0.06082814473352961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24055901791595602, 0.0, 0.24914252428925632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10285324599064961, 0.0, 0.047541895527389945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06827429410246949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07210214122262497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05062420093723879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047541895527389945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026846406336127983, 0.0, 0.0774971887247786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051156451652772314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03979894966732252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
reubensinha_competition-kernel-titanic-survival-prediction.py,"['numpy', 'pandas', 'matplotlib', 'scipy', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,149,[],0,"['pd.read_csv', 'pr', 'plt.style.use', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.hist', 'plt.hist', 'plt.legend', 'plt.show', 'pd.read_csv', 'pr', 'plt.style.use', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.hist', 'plt.hist', 'plt.legend', 'plt.show', 'pd.read_csv', 'pr', 'plt.style.use', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.hist', 'plt.hist', 'plt.legend', 'plt.show', 'pd.read_csv', 'pr', 'plt.style.use', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.boxplot', 'plt.xticks', 'plt.show', 'pd.read_csv', 'plt.style.use', 'plt.xlabel', 'plt.xticks', 'plt.title', 'plt.hist', 'plt.hist', 'plt.legend', 'plt.show', 'pd.read_csv', 'plt.style.use', 'data.describe', 'pd.read_csv', 'data.Age.fillna', 'pd.get_dummies', 'pd.read_csv', 'test_data.fillna', 'test_data.fillna', 'pd.get_dummies', 'DecisionTreeClassifier', 'GridSearchCV', 'model.fit', 'model.predict', 'pd.DataFrame', 'result_data.to_csv', 'print']","['read_csv', 'pr', 'style', 'xlabel', 'ylabel', 'title', 'hist', 'hist', 'legend', 'show', 'read_csv', 'pr', 'style', 'xlabel', 'ylabel', 'title', 'hist', 'hist', 'legend', 'show', 'read_csv', 'pr', 'style', 'xlabel', 'ylabel', 'title', 'hist', 'hist', 'legend', 'show', 'read_csv', 'pr', 'style', 'xlabel', 'ylabel', 'title', 'boxplot', 'xticks', 'show', 'read_csv', 'style', 'xlabel', 'xticks', 'title', 'hist', 'hist', 'legend', 'show', 'read_csv', 'style', 'describe', 'read_csv', 'Age', 'get_dummies', 'read_csv', 'fillna', 'fillna', 'get_dummies', 'DecisionTreeClassifier', 'GridSearchCV', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['read_csv', 'pr', 'style', 'xlabel', 'ylabel', 'title', 'hist', 'legend', 'show', 'boxplot', 'xticks', 'describe', 'Age', 'get_dummies', 'fillna', 'DecisionTreeClassifier', 'GridSearchCV', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']",22,"[1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv pr style xlabel ylabel title hist hist legend show read csv pr style xlabel ylabel title hist hist legend show read csv pr style xlabel ylabel title hist hist legend show read csv pr style xlabel ylabel title boxplot xticks show read csv style xlabel xticks title hist hist legend show read csv style describe read csv age get dummies read csv fillna fillna get dummies decisiontreeclassifier gridsearchcv fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05285021088994479, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06656074118206325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21102751346054735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029378624759194637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05144256666519248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04192784344948101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08474595924419108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061046967383653145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025840135299673175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0615725379678939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06224598062980163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444473017246152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17999288685286025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5081337569981852, 0.0, 0.0, 0.026809668932610244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025013082075953413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18682628585459707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2555220308213379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3490582208237386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22003322859108604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3005819811504291, 0.0, 0.0, 0.1389463661804251, 0.0, 0.23270548054915907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mzr2017_titanic-best-working-classifier.py,"['numpy', 'pandas', 're', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,269,"['6. Age¶we have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std).', '    # Mapping Sex', '    # Mapping titles', '    # Mapping Embarked', '    # Mapping Fare', '    # Mapping Age', '# Feature Selection']",7,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'print', 'dataset.fillna', 'print', 'dataset.fillna', 'pd.qcut', 'print', 'dataset.mean', 'dataset.std', 'dataset.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'dataset.astype', 'pd.cut', 'print', 're.search', 'title_search.group', 'dataset.apply', 'print', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'print', 'dataset.map', 'None.astype', 'dataset.map', 'dataset.fillna', 'dataset.map', 'None.astype', 'dataset.astype', 'train.drop', 'train.drop', 'test.drop', 'print', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LogisticRegression', 'pd.DataFrame', 'StratifiedShuffleSplit', 'sss.split', 'clf.fit', 'clf.predict', 'accuracy_score', 'pd.DataFrame', 'log.append', 'plt.xlabel', 'plt.title', 'sns.set_color_codes', 'sns.barplot', 'SVC', 'candidate_classifier.fit', 'candidate_classifier.predict']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'print', 'fillna', 'print', 'fillna', 'qcut', 'print', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'cut', 'print', 'search', 'group', 'apply', 'print', 'replace', 'replace', 'replace', 'replace', 'print', 'map', 'astype', 'map', 'fillna', 'map', 'astype', 'astype', 'drop', 'drop', 'drop', 'print', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LogisticRegression', 'DataFrame', 'StratifiedShuffleSplit', 'split', 'fit', 'predict', 'accuracy_score', 'DataFrame', 'append', 'xlabel', 'title', 'set_color_codes', 'barplot', 'SVC', 'fit', 'predict']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'fillna', 'qcut', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'cut', 'search', 'group', 'apply', 'replace', 'map', 'drop', 'KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'LogisticRegression', 'DataFrame', 'StratifiedShuffleSplit', 'split', 'fit', 'predict', 'accuracy_score', 'append', 'xlabel', 'title', 'set_color_codes', 'barplot']",41,"[1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1
 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print print print print print fillna print fillna qcut print mean std isnull sum random isnan astype cut print search group apply print replace replace replace replace print map astype map fillna map astype astype drop drop drop print kneighborsclassifier svc decisiontreeclassifier randomforestclassifier adaboostclassifier gradientboostingclassifier gaussiannb lineardiscriminantanalysis quadraticdiscriminantanalysis logisticregression dataframe stratifiedshufflesplit split fit predict accuracy score dataframe append xlabel title set color codes barplot svc fit predict,"[0.0, 0.0, 0.10879908149466096, 0.13374710248927174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0882873355164512, 0.07636679313966478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26802696318367136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1031736320341249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2180187459507557, 0.0, 0.1837196267022616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08048266506759176, 0.0, 0.0, 0.0, 0.09984409881545585, 0.0, 0.0, 0.0, 0.10084102210560773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0882873355164512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1544980026229696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15715606085735742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08869529041350774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10879908149466096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05283635392408485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1250022976362263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.140179899690173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06667693626160323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11308175525943989, 0.07158166119318474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09008444409413155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06767519735385334, 0.0, 0.1661261817770339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.067339476964529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.067339476964529, 0.0, 0.0, 0.21142559755613005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0723379004994677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09202317806354277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4722105376864683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10231307522652568, 0.1661261817770339, 0.0, 0.0, 0.0, 0.11087920397661757, 0.06507014141332935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08015927300968934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3178779658975449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06700674079591784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06767519735385334, 0.0, 0.140179899690173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0723379004994677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07011352900472106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11542205305463325, 0.0, 0.0, 0.0, 0.0, 0.1837196267022616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07120919471216214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1720359999305031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07552557633378547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1031736320341249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
tetsuyazama_titanic-example-for-nst.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'warnings\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,459,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã‚‚åŒã˜ã“ã¨ã‚’è¡Œã†ï¼ˆãƒ¯ãƒ³ãƒ©ã‚¤ãƒŠãƒ¼ï¼‰', 'from sklearn.svm import SVC # ã‚«ãƒ¼ãƒãƒ«ã‚’é™å®šã—ãªã„SVMãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª', '# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å€™è£œ', '# GridSearchCVãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–', '# ã™ã¹ã¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›ã§äº¤å·®æ¤œè¨¼ã‚’è¡Œã„æœ€ã‚‚å„ªã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŽ¢ã—å‡ºã™ï¼ˆ=Grid Searchï¼‰', '# æœ€ã‚‚ã‚¹ã‚³ã‚¢ãŒé«˜ã‹ã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›', '# æœ€ã‚‚é«˜ã‹ã£ãŸã‚¹ã‚³ã‚¢']",15,"['print', 'pd.read_csv', 'pd.read_csv', 'print', 'train_data.head', 'print', 'test_data.head', 'train_data.isnull', 'None.any', 'test_data.isnull', 'None.any', 'pd.concat', 'None.mean', 'train_data.fillna', 'train_data.isnull', 'None.any', 'test_data.fillna', 'test_data.isnull', 'None.any', 'pd.concat', 'None.mean', 'test_data.fillna', 'test_data.isnull', 'None.any', 'pd.concat', 'None.value_counts', 'pd.concat', 'None.value_counts', 'pd.concat', 'None.value_counts', 'train_data.fillna', 'train_data.isnull', 'None.any', 'test_data.fillna', 'test_data.isnull', 'None.any', 'pd.concat', 'None.value_counts', 'pd.concat', 'None.value_counts', 'pd.concat', 'None.value_counts', 'train_data.fillna', 'train_data.isnull', 'None.any', 'train_data.isnull', 'None.any', 'test_data.isnull', 'None.any', 'train_X.head', 'train_y.head', 'test_X.head', 'pd.concat', 'None.value_counts', 'pd.get_dummies', 'None.head', 'pd.get_dummies', 'None.head', 'train_X.join', 'train_X.head', 'train_X.drop', 'train_X.head', 'test_X.join', 'None.drop', 'test_X.head', 'warnings.filterwarnings', 'get_ipython', 'None.run_line_magic', 'sns.heatmap', 'plt.gcf', 'fig.set_size_inches', 'plt.show', 'sns.factorplot', 'g.despine', 'g.set_ylabels', 'sns.factorplot', 'g.despine', 'g.set_ylabels', 'GridSearchCV', 'modelsvm.fit', 'print', 'print', 'modelsvm.best_estimator_.predict', 'pd.DataFrame', 'print', 'submission.to_csv']","['print', 'read_csv', 'read_csv', 'print', 'head', 'print', 'head', 'isnull', 'any', 'isnull', 'any', 'concat', 'mean', 'fillna', 'isnull', 'any', 'fillna', 'isnull', 'any', 'concat', 'mean', 'fillna', 'isnull', 'any', 'concat', 'value_counts', 'concat', 'value_counts', 'concat', 'value_counts', 'fillna', 'isnull', 'any', 'fillna', 'isnull', 'any', 'concat', 'value_counts', 'concat', 'value_counts', 'concat', 'value_counts', 'fillna', 'isnull', 'any', 'isnull', 'any', 'isnull', 'any', 'head', 'head', 'head', 'concat', 'value_counts', 'get_dummies', 'head', 'get_dummies', 'head', 'join', 'head', 'drop', 'head', 'join', 'drop', 'head', 'filterwarnings', 'get_ipython', 'run_line_magic', 'heatmap', 'gcf', 'set_size_inches', 'show', 'factorplot', 'despine', 'set_ylabels', 'factorplot', 'despine', 'set_ylabels', 'GridSearchCV', 'fit', 'print', 'print', 'best_estimator_', 'DataFrame', 'print', 'to_csv']","['print', 'read_csv', 'head', 'isnull', 'any', 'concat', 'mean', 'fillna', 'value_counts', 'get_dummies', 'join', 'drop', 'filterwarnings', 'get_ipython', 'run_line_magic', 'heatmap', 'gcf', 'set_size_inches', 'show', 'factorplot', 'despine', 'set_ylabels', 'GridSearchCV', 'fit', 'best_estimator_', 'DataFrame', 'to_csv']",27,"[1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv print head print head isnull isnull concat mean fillna isnull fillna isnull concat mean fillna isnull concat value counts concat value counts concat value counts fillna isnull fillna isnull concat value counts concat value counts concat value counts fillna isnull isnull isnull head head head concat value counts get dummies head get dummies head join head drop head join drop head filterwarnings get ipython run line magic heatmap gcf set size inches show factorplot despine set ylabels factorplot despine set ylabels gridsearchcv fit print print best estimator dataframe print csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11769233759675077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41021971941105534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37094936307197646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07004638806888212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029254951409888236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1985795823527126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059761810756291604, 0.0, 0.0, 0.0, 0.08438920950842842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12649867456826264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13394019549728714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18236994541116458, 0.0, 0.06254811180941493, 0.0, 0.0, 0.0, 0.025731357706942563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1065976651166566, 0.0, 0.0919700098897829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06198394763920224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.278224037535909, 0.0561574954586519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10263780510850543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03868724234965769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41533058200314477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1432842463536103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03926645265789068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03907166122337493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08394368561591857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14944671646303906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04650995374669094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03887860129118112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12591552842387785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05088927515910806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07542892171659908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37094936307197646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2131953302333132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
vincentlino_titanic-data-science-solutions-d3a853.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn', 'xgboost']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,1041,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", '# fill age na with median group by title', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '        # age_mean = guess_df.mean()', '        # age_std = guess_df.std()', '        # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '        # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Gridsearch and tuning an randomforrest algorithm', '# Choose the type of classifier. ', '# Choose some parameter combinations to try', '# Type of scoring used to compare parameter combinations', '# Run the grid search', '# Set the clf to the best combination of parameters', '# Fit the best algorithm to the data. ', '# Random Forest', '# Xgboost', ""# submission.to_csv('../output/submission.csv', index=False)""]",33,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'train_df.drop', 'pd.concat', 'all_sample.dropna', 'None.groupby', 'None.median', 'train_df.combine_first', 'train_df.astype', 'test_df.combine_first', 'test_df.astype', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'dataset.astype', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'train_df.info', 'test_df.info', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'print', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'grid_obj.fit', 'clf.fit', 'KFold', 'clf.fit', 'clf.predict', 'accuracy_score', 'outcomes.append', 'print', 'np.mean', 'print', 'run_kfold', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'xgb.XGBClassifier', 'None.fit', 'gbm.predict', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'drop', 'concat', 'dropna', 'groupby', 'median', 'combine_first', 'astype', 'combine_first', 'astype', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'astype', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'info', 'info', 'LogisticRegression', 'fit', 'predict', 'round', 'print', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'fit', 'fit', 'KFold', 'fit', 'predict', 'accuracy_score', 'append', 'print', 'mean', 'print', 'run_kfold', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'XGBClassifier', 'fit', 'predict', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'concat', 'dropna', 'median', 'combine_first', 'astype', 'replace', 'fillna', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'KFold', 'accuracy_score', 'append', 'run_kfold', 'score', 'XGBClassifier']",51,"[1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0
 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab drop concat dropna groupby median combine first astype combine first astype replace replace replace replace groupby mean map fillna astype head drop drop map astype head facetgrid map add legend groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy info info logisticregression fit predict round print dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier make scorer gridsearchcv fit fit kfold fit predict accuracy score append print mean print run kfold randomforestclassifier fit predict score round xgbclassifier fit predict round dataframe sort values dataframe,"[0.0, 0.0, 0.04379539911750594, 0.0, 0.0, 0.13939382799297353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03553871083143179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1618352057612452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1755201948920871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031621695003413414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033556130495787484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418855161922386, 0.032397060620853714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060888006817627204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03553871083143179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05793107151260653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2073026596296058, 0.035305095189055336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03676441936966923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18775374725179084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06326075840374419, 0.0, 0.0, 0.0, 0.0, 0.1755201948920871, 0.23206902425923867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04379539911750594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021268462713379163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043002168231979436, 0.0, 0.0, 0.28078932568272574, 0.0, 0.0, 0.0, 0.0, 0.15441722993109713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10683271306238795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026839776544002502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1046595870303219, 0.036262109286048956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12434673408134245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027241611213541666, 0.0, 0.0, 0.0, 0.05306495917623282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05095903921248536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02710647212743581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02710647212743581, 0.06687154280019884, 0.0, 0.22694967154558288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29118510746362186, 0.04051476188956301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047466274026367244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04019070838723184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05306495917623282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20373384276719006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10368059937821748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04118455691838711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05238597191593307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032266884115200366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12795689261243526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3987347757331222, 0.0, 0.05394506858708172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05448322242708333, 0.07120630954207928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03956278806928454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05306495917623282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3001600961512523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03462522466196251, 0.0, 0.0, 0.0, 0.04799502677328051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3001600961512523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045069501984884866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
nitinkaushik1978_titanic-basic-solution-with-logistic-regression.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'os\n', 're\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,271,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['get_ipython', 'None.run_line_magic', 'print', 'pd.read_csv', 'train.head', 'pd.read_csv', 'test.head', 'train.info', 'test.info', 'pd.concat', 'all.info', 'all.fillna', 'all.fillna', 'all.info', 'sns.catplot', 'all.fillna', 'all.info', 're.search', 'title_search.group', 'all.apply', 'all.value_counts', 'all.replace', 'all.replace', 'all.replace', 'all.replace', 'all.value_counts', 'all.fillna', 'all.value_counts', 'all.head', 'all.drop', 'all_1.head', 'pd.get_dummies', 'all_dummies.head', 'all_dummies.notna', 'all_train.info', 'all_dummies.isna', 'all_test.info', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'confusion_matrix', 'all_test.head', 'all_test.drop', 'TestForPred.info', 'logmodel.predict', 'None.astype', 'pd.DataFrame', 'logSub.head', 'logSub.to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'read_csv', 'head', 'info', 'info', 'concat', 'info', 'fillna', 'fillna', 'info', 'catplot', 'fillna', 'info', 'search', 'group', 'apply', 'value_counts', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'fillna', 'value_counts', 'head', 'drop', 'head', 'get_dummies', 'head', 'notna', 'info', 'isna', 'info', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix', 'head', 'drop', 'info', 'predict', 'astype', 'DataFrame', 'head', 'to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'info', 'concat', 'fillna', 'catplot', 'search', 'group', 'apply', 'value_counts', 'replace', 'drop', 'get_dummies', 'notna', 'isna', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'confusion_matrix', 'astype', 'DataFrame', 'to_csv']",26,"[1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic print read csv head read csv head info info concat info fillna fillna info catplot fillna info search group apply value counts replace replace replace replace value counts fillna value counts head drop head get dummies head notna info isna info train test split logisticregression fit predict print confusion matrix head drop info predict astype dataframe head csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07816776532012103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06858697313402044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14860209042266223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08040906805596972, 0.0, 0.0, 0.12638614081793892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2804586565155509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12357105392331454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051609587272940724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10542770502682515, 0.0, 0.0, 0.0, 0.07443683997279889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21448306833688435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04539350391054987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10816480682527321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14348578814275514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3435766917476484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5433180539063547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06824939075848886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14116293443231637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06927119402636349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06892755628112136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06892755628112136, 0.0, 0.0, 0.0, 0.0, 0.11940042623527075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18805232057470764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09419337765993686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08788123017638046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08204968394303865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3253745406498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06858697313402044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14348578814275514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07176702930268668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07483389380331829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07365486687714871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2804586565155509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
greeshmagirish_titanic-regression.py,"['pandas', 'numpy', 'sklearn', 'random']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,163,[],0,"['random.seed', 'pd.read_csv', 'data.head', 'data.describe', 'data.value_counts', 'Pipeline', 'Pipeline', 'ColumnTransformer', 'Pipeline', 'data.drop', 'x.head', 'y.head', 'x.tail', 'y.tail', 'model_pipeline.fit', 'model_pipeline.score', 'Pipeline', 'model_pipeline.fit', 'model_pipeline.score', 'data.tail', 'df.drop', 'model_pipeline.predict', 'df.tail', 'df.to_csv']","['seed', 'read_csv', 'head', 'describe', 'value_counts', 'Pipeline', 'Pipeline', 'ColumnTransformer', 'Pipeline', 'drop', 'head', 'head', 'tail', 'tail', 'fit', 'score', 'Pipeline', 'fit', 'score', 'tail', 'drop', 'predict', 'tail', 'to_csv']","['seed', 'read_csv', 'head', 'describe', 'value_counts', 'Pipeline', 'ColumnTransformer', 'drop', 'tail', 'fit', 'score', 'predict', 'to_csv']",13,"[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",seed read csv head describe value counts pipeline pipeline columntransformer pipeline drop head head tail tail fit score pipeline fit score tail drop predict tail csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20175291945587218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1002971807097078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08838256932282289, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07902101063780757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11310866686297776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0974013179980587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15797488183509584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7297302476210813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0505279298820249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04401371710104296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1486359284086674, 0.0, 0.0, 0.21092564266105301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5237418086268869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1002971807097078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
brightller_solutions-of-titanic-data-science.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,945,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
souravdas4_prediction-of-survival-in-titanic-disaster.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,220,"['# data analysis and wrangling', '# visualization', '# machine learning', '#', '#', '#', '#', '#', '#', '# Logistic Regression', ""#          intercept_scaling=1, max_iter=1000000, multi_class='ovr', n_jobs=1,"", ""#          penalty='l2', random_state=None, solver='saga', tol=0.0000001,"", '#          verbose=0, warm_start=False)']",13,"['pd.read_csv', 'pd.read_csv', 'print', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'print', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'dataset.mean', 'dataset.std', 'dataset.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'dataset.astype', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'train_df.drop', 'test_df.drop', 'None.copy', 'GridSearchCV', 'clf.fit', 'clf.predict', 'clf.score', 'print', 'pd.DataFrame', 'print', 'print', 'submission.to_csv', 'clf.predict', 'confusion_matrix']","['read_csv', 'read_csv', 'print', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'print', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'drop', 'drop', 'head', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'drop', 'drop', 'copy', 'GridSearchCV', 'fit', 'predict', 'score', 'print', 'DataFrame', 'print', 'print', 'to_csv', 'predict', 'confusion_matrix']","['read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'std', 'isnull', 'sum', 'random', 'isnan', 'Embarked', 'mode', 'copy', 'GridSearchCV', 'fit', 'predict', 'score', 'DataFrame', 'to_csv', 'confusion_matrix']",33,"[1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv print print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop print name crosstab replace replace replace replace groupby mean map fillna drop drop map astype head facetgrid map add legend mean std isnull sum random isnan astype drop drop head embarked mode fillna groupby mean sort values map astype head fillna drop drop copy gridsearchcv fit predict score print dataframe print print csv predict confusion matrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.23105804084167722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1341283402601151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08238670078386862, 0.0, 0.0, 0.0, 0.05562236063260379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0694290805437156, 0.08055164418535991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03364248323999154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09602605854426127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27489852074483656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06094039337714277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3112190376382303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10486050286003049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02959043610325209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07128003360468892, 0.0, 0.0, 0.27926041955649544, 0.0, 0.0, 0.0, 0.0, 0.12798035298190033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08854250483472159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07545244934309277, 0.04776200769683695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20611610410286077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3761898731960199, 0.0, 0.0778329579972062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3378661953336012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07867969795003725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06661978133250675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061401365457229615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2291467899313239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07398282333037802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05348531663897949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2121002726226048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04515546640048428, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27641269963965287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07701398506947457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04751348389008421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07955615407116189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27641269963965287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
srksiva20_titanic-competetion.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,153,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Reading data ']",9,"['print', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.DataFrame', 'KFold', 'pd.crosstab', 'Sex.plot', 'pd.crosstab', 'Pclass.plot', 'dataframe.Name.apply', 'dataframe.Title.map', 'dataframe.groupby', 'grouped.Age.apply', 'grouped.Age.median', 'dataframe.fillna', 'CalculateAge', 'CalclateFamilySize', 'CalculateAge', 'CalclateFamilySize', 'pd.get_dummies', 'pd.get_dummies', 'train_test_split', 'RandomForestClassifier', 'model.fit', 'model.predict', 'accuracy_score', 'print', 'model.predict', 'submission.replace', 'submission.replace', 'print']","['print', 'print', 'read_csv', 'read_csv', 'DataFrame', 'KFold', 'crosstab', 'plot', 'crosstab', 'plot', 'Name', 'Title', 'groupby', 'Age', 'Age', 'fillna', 'CalculateAge', 'CalclateFamilySize', 'CalculateAge', 'CalclateFamilySize', 'get_dummies', 'get_dummies', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'predict', 'replace', 'replace', 'print']","['print', 'read_csv', 'DataFrame', 'KFold', 'crosstab', 'plot', 'Name', 'Title', 'groupby', 'Age', 'fillna', 'CalculateAge', 'CalclateFamilySize', 'get_dummies', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'replace']",20,"[1 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print print read csv read csv dataframe kfold crosstab plot crosstab plot name title groupby age age fillna calculateage calclatefamilysize calculateage calclatefamilysize get dummies get dummies train test split randomforestclassifier fit predict accuracy score print predict replace replace print,"[0.0, 0.0, 0.13296367034223894, 0.0, 0.0, 0.0, 0.0, 0.22169723024236263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5328826726620328, 0.0, 0.5328826726620328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2543304584190067, 0.09835809640394105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061619051539890196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17774710944667088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06402029129001405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05419738472713813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12914292011909367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.085248176950108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15887425515540168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12201976026027085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18875953286970773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11246179052059821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20985085670183407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07952240692794237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09796287804007694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.194239788084685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08270605328359586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08568594540545106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08934761548877995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09230002400843658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08793992120619744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
anthonyivan_titanic.py,"['numpy', 'pandas', 'sklearn', 'subprocess']","[1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,115,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'pd.read_csv', 'titanic_train.fillna', 'titanic_test.fillna', 'titanic_train.fillna', 'titanic_test.fillna', 'titanic_train.values.tolist', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'pd.DataFrame', 'submission.to_csv']","['print', 'read_csv', 'read_csv', 'fillna', 'fillna', 'fillna', 'fillna', 'values', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'to_csv']","['print', 'read_csv', 'fillna', 'values', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'to_csv']",10,"[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv fillna fillna fillna fillna values randomforestclassifier fit predict score dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4045430522291203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1689578529664173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7021679621694921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.148607833633469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15418366716354293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14385141163911028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21804839252627733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26861168957375814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22677786887187398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27763762817752496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mrhippo_titanic-prediction-and-analysis-with-dsh.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'DataScienceHelper', 'warnings\n', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,345,"['!pip install datasciencehelper # pip install Data Science Helper', ' #   Column    Non-Null Count  Dtype  ', ' #   Column  Non-Null Count  Dtype  ', ' #   Column    Non-Null Count  Dtype  ', '# converting features to categorical', ""test_ID = test['PassengerId'] # save PassengerId (for submission)"", ' #   Column    Non-Null Count  Dtype  ', ' #   Column  Non-Null Count  Dtype  ', ' #   Column  Non-Null Count  Dtype  ', ' #   Column    Non-Null Count  Dtype  ', 'all_data[""Sex""] = [1 if each == ""male"" else 0 for each in all_data[""Sex""]] # male -> 1, female -> 0']",11,"['get_ipython', 'None.system', 'warnings.filterwarnings', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train.head', 'train.drop', 'train.describe', 'train.info', 'dsh.fill_nan_numeric', 'dsh.fill_nan_categorical', 'train.info', 'plt.figure', 'sns.kdeplot', 'sns.kdeplot', 'plt.title', 'plt.ylabel', 'plt.xlabel', 'plt.grid', 'plt.show', 'dsh.find_numericlike_categorical_features', 'train.apply', 'train.apply', 'train.apply', 'plt.figure', 'sns.distplot', 'plt.title', 'plt.show', 'plt.figure', 'sns.distplot', 'plt.title', 'plt.show', 'plt.figure', 'sns.jointplot', 'plt.show', 'pd.read_csv', 'test.head', 'test.drop', 'test.info', 'dsh.fill_nan_numeric', 'test.info', 'pd.concat', 'None.reset_index', 'all_data.drop', 'all_data.head', 'all_data.apply', 'all_data.apply', 'all_data.apply', 'all_data.apply', 'plt.figure', 'sns.countplot', 'plt.title', 'plt.show', 'show_countplot', 'dsh.categorical_features_as_binary', 'dsh.numeric_features_as_5_classes', 'all_data.head', 'pd.get_dummies', 'all_data.head', 'train_test_split', 'np.arange', 'RidgeClassifier', 'ridge.fit', 'score_list_ridge.append', 'train_list.append', 'dsh.show_sklearn_model_results', 'pd.Series', 'None.astype', 'pd.concat', 'results.to_csv']","['get_ipython', 'system', 'filterwarnings', 'walk', 'print', 'read_csv', 'read_csv', 'head', 'drop', 'describe', 'info', 'fill_nan_numeric', 'fill_nan_categorical', 'info', 'figure', 'kdeplot', 'kdeplot', 'title', 'ylabel', 'xlabel', 'grid', 'show', 'find_numericlike_categorical_features', 'apply', 'apply', 'apply', 'figure', 'distplot', 'title', 'show', 'figure', 'distplot', 'title', 'show', 'figure', 'jointplot', 'show', 'read_csv', 'head', 'drop', 'info', 'fill_nan_numeric', 'info', 'concat', 'reset_index', 'drop', 'head', 'apply', 'apply', 'apply', 'apply', 'figure', 'countplot', 'title', 'show', 'show_countplot', 'categorical_features_as_binary', 'numeric_features_as_5_classes', 'head', 'get_dummies', 'head', 'train_test_split', 'arange', 'RidgeClassifier', 'fit', 'append', 'append', 'show_sklearn_model_results', 'Series', 'astype', 'concat', 'to_csv']","['get_ipython', 'system', 'filterwarnings', 'walk', 'print', 'read_csv', 'head', 'drop', 'describe', 'info', 'fill_nan_numeric', 'fill_nan_categorical', 'figure', 'kdeplot', 'title', 'ylabel', 'xlabel', 'grid', 'show', 'find_numericlike_categorical_features', 'apply', 'distplot', 'jointplot', 'concat', 'reset_index', 'countplot', 'show_countplot', 'categorical_features_as_binary', 'numeric_features_as_5_classes', 'get_dummies', 'train_test_split', 'arange', 'RidgeClassifier', 'fit', 'append', 'show_sklearn_model_results', 'Series', 'astype', 'to_csv']",39,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython system filterwarnings walk print read csv read csv head drop describe info fill nan numeric fill nan categorical info figure kdeplot kdeplot title ylabel xlabel grid show find numericlike categorical features apply apply apply figure distplot title show figure distplot title show figure jointplot show read csv head drop info fill nan numeric info concat reset index drop head apply apply apply apply figure countplot title show show countplot categorical features binary numeric features 5 classes head get dummies head train test split arange ridgeclassifier fit append append show sklearn model results series astype concat csv,"[0.11572122451788272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09372330375382086, 0.28374079225441284, 0.07440548093329935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035566217308705246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11572122451788272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32299551286725625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08374382925448058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08339328176739587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09498491275067666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08543808940344985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038194206297420694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11658674761807608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08200532468494884, 0.0, 0.0, 0.0, 0.0385997034899431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28167976928267285, 0.0, 0.23587275414271808, 0.0, 0.0, 0.25751160859628086, 0.0, 0.0, 0.057219129880772046, 0.09751574378267505, 0.0, 0.0, 0.02353909424361764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05608955824868731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0881773954614938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12725993542561015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057219129880772046, 0.0, 0.0, 0.14087054064346285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035391161790446934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11572122451788272, 0.0, 0.17167440573085394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07568777569234993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34716367355364813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2645321863844814, 0.11572122451788272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022785689373563667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06382108925101146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06400923477510184, 0.0, 0.0, 0.09389325642755762, 0.0, 0.0, 0.0, 0.0, 0.11572122451788272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0521678349723105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32587522987389944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11572122451788272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037215255946518686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09751574378267505, 0.0, 0.0, 0.0, 0.0, 0.038805598314779775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1603515722953214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038194206297420694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04536706233394275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054763084636965824, 0.0, 0.0, 0.0, 0.0, 0.05299581614151095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
dbabs8_titanic-data-science-solutions-db.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,949,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
yangsudlor_titanic.py,"['numpy', 'pandas', 'matplotlib', 'torch\n', 'sklearn', 'torch', 'random\n']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,303,"['        # linear layer (7 -> hidden_1)', '        # linear layer (n_hidden -> hidden_2)', '        # linear layer (n_hidden -> 10)', '        # dropout layer (p=0.5)', '        # dropout prevents overfitting of data', '        # flatten image input', '        # add hidden layer, with relu activation function', '        # add dropout layer', '        # add hidden layer, with relu activation function', '        # add dropout layer', '        # add output layer', '    # initialize tracker for minimum validation loss', '        # initialize variables to monitor training and validation loss', '        # train the model #', '            # move to GPU', '        # validate the model #', '            # move to GPU', '        # calculate average losses', '        # print training/validation statistics ', '    # return trained model']",20,"['pd.read_csv', 'pd.read_csv', 'pd.DataFrame', 'x_trainfeature_name.min', 'x_trainfeature_name.max', 'x_trainfeature_name.min', 'x_testfeature_name.min', 'x_testfeature_name.max', 'x_testfeature_name.min', 'KFold', 'kf.split', 'kf_data.append', 'kf_data.append', 'data_scikit.append', 'data_scikit.append', 'torch.cuda.is_available', 'super', 'None.__init__', 'nn.Linear', 'nn.Linear', 'nn.Linear', 'nn.Linear', 'nn.Dropout', 'x.view', 'F.relu', 'self.dropout', 'F.relu', 'self.dropout', 'F.relu', 'self.dropout', 'self.fc4', 'range', 'model.train', 'data.cuda', 'target.cuda', 'optimizer.zero_grad', 'model', 'criterion', 'loss.backward', 'optimizer.step', 'loss.item', 'data.size', 'model.eval', 'data.cuda', 'target.cuda', 'model', 'criterion', 'loss.item', 'data.size', 'len', 'len', 'print', 'print', 'torch.save', 'range', 'Net', 'model.cuda', 'nn.CrossEntropyLoss', 'torch.optim.SGD', 'torch.utils.data.DataLoader', 'torch.utils.data.DataLoader', 'print', 'print', 'train', 'random.seed', 'range', 'list', 'random.shuffle', 'zip', 'GaussianNB', 'print', 'range', 'model_scikit.fit', 'model_scikit.predict', 'zip', 'score', 'f1_score', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'DecisionTreeClassifier', 'print', 'range', 'model_scikit.fit', 'model_scikit.predict', 'zip', 'score', 'f1_score', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'range', 'torch.utils.data.DataLoader', 'model.load_state_dict', 'model.eval', 'enumerate', 'data.cuda', '_.cuda', 'model', 'Survived.append', 'result.append', 'zip', 'score', 'f1_score', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print']","['read_csv', 'read_csv', 'DataFrame', 'min', 'max', 'min', 'min', 'max', 'min', 'KFold', 'split', 'append', 'append', 'append', 'append', 'cuda', 'super', '__init__', 'Linear', 'Linear', 'Linear', 'Linear', 'Dropout', 'view', 'relu', 'dropout', 'relu', 'dropout', 'relu', 'dropout', 'fc4', 'range', 'train', 'cuda', 'cuda', 'zero_grad', 'model', 'criterion', 'backward', 'step', 'item', 'size', 'eval', 'cuda', 'cuda', 'model', 'criterion', 'item', 'size', 'len', 'len', 'print', 'print', 'save', 'range', 'Net', 'cuda', 'CrossEntropyLoss', 'optim', 'utils', 'utils', 'print', 'print', 'train', 'seed', 'range', 'list', 'shuffle', 'zip', 'GaussianNB', 'print', 'range', 'fit', 'predict', 'zip', 'score', 'f1_score', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'DecisionTreeClassifier', 'print', 'range', 'fit', 'predict', 'zip', 'score', 'f1_score', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'range', 'utils', 'load_state_dict', 'eval', 'enumerate', 'cuda', 'cuda', 'model', 'append', 'append', 'zip', 'score', 'f1_score', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print']","['read_csv', 'DataFrame', 'min', 'max', 'KFold', 'split', 'append', 'cuda', 'super', '__init__', 'Linear', 'Dropout', 'view', 'relu', 'dropout', 'fc4', 'range', 'train', 'zero_grad', 'model', 'criterion', 'backward', 'step', 'item', 'size', 'eval', 'len', 'print', 'save', 'Net', 'CrossEntropyLoss', 'optim', 'utils', 'seed', 'list', 'shuffle', 'zip', 'GaussianNB', 'fit', 'predict', 'score', 'f1_score', 'DecisionTreeClassifier', 'load_state_dict', 'enumerate']",45,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv dataframe min max min min max min kfold split append append append append cuda super init linear linear linear linear dropout view relu dropout relu dropout relu dropout fc4 range train cuda cuda zero grad model criterion backward step item size eval cuda cuda model criterion item size len len print print save range net cuda crossentropyloss optim utils utils print print train seed range list shuffle zip gaussiannb print range fit predict zip score f1 score print print print print print print print print print decisiontreeclassifier print range fit predict zip score f1 score print print print print print print print print print range utils load state dict eval enumerate cuda cuda model append append zip score f1 score print print print print print print print print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1614076223313938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1328612127727972, 0.0, 0.0664306063863986, 0.0, 0.024523176760411082, 0.5314448510911888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015363197824770641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026901270388565632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050618871987265404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2657224255455944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04202153517987686, 0.0, 0.0, 0.10780020667880834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14782640247592896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027025574796755783, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033151227094967484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05597961842084305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12361194107794152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039611395343133717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057259622915829735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2657224255455944, 0.0, 0.0, 0.0, 0.0, 0.03143714504560161, 0.0, 0.0, 0.05597961842084305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08273920058481947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17694412476224622, 0.0, 0.0, 0.0, 0.0, 0.13034734612154586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02803958665896312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4316495660558222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16582428584829256, 0.0, 0.0, 0.0, 0.024424638763536923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19929181915919575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06180597053897076, 0.0, 0.0, 0.0, 0.0, 0.1237243442878383, 0.0, 0.0, 0.058524739186831994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07922279068626743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0213636869956403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.06180597053897076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06180597053897076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0438513210580963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19929181915919575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664306063863986, 0.0, 0.17694412476224622, 0.0]"
alissecian_titanic-crash-course-decision-tree-visualization.py,"['numpy', 'pandas', 'sklearn', 'graphviz\n', 'IPython', 'os\n', 'subprocess']","[1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,91,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Loading data', '# Cleaning and preparing data', '# Training the tree', '# https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c', '# Parameters that we will pass to the library that draws the tree, to make it understandable', '# Create DOT data               ', '# Convert to png using system command hdddrequires Graphviz)', '# Display in jupyter notebook', '# Training a tree with modified parameters']",17,"['print', 'pd.read_csv', 'pd.read_csv', 'train_df.drop', 'test_df.drop', 'X_train.drop', 'pd.get_dummies', 'pd.get_dummies', 'X_train.fillna', 'X_test.fillna', 'X_test.fillna', 'tree.DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'list', 'tree.export_graphviz', 'call', 'Image', 'tree.DecisionTreeClassifier', 'decision_tree_mod.fit', 'decision_tree_mod.predict']","['print', 'read_csv', 'read_csv', 'drop', 'drop', 'drop', 'get_dummies', 'get_dummies', 'fillna', 'fillna', 'fillna', 'DecisionTreeClassifier', 'fit', 'predict', 'list', 'export_graphviz', 'call', 'Image', 'DecisionTreeClassifier', 'fit', 'predict']","['print', 'read_csv', 'drop', 'get_dummies', 'fillna', 'DecisionTreeClassifier', 'fit', 'predict', 'list', 'export_graphviz', 'call', 'Image']",12,"[1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv drop drop drop get dummies get dummies fillna fillna fillna decisiontreeclassifier fit predict list export graphviz call image decisiontreeclassifier fit predict,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38570678895094646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14238550989760762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3123862082463025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27332937922916234, 0.0, 0.0, 0.0, 0.25731092545194917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33980405198538743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27803186984279943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15691483551690963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18695034982485065, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32502667132394936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38570678895094646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18252912217593134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16280235153708913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07594626758337507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14181338243360525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
yosher_exploratory-analysis-on-titanic.py,"['numpy', 'pandas', 'IPython', 'sklearn']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,187,"['# Premise', '# NaN detection', '# a. Looking further into the sex and embarked columns', '# b. Further investigation into the Fare column of x_test:', '# Further investigation into Age column with decimal points', '# Cleansing Process', '  # This is added back by InteractiveShellApp.init_path()', '#  KNN method']",8,"['np.arange', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'np.unique', 'print', 'np.unique', 'print', 'print', 'print', 'print', 'print', 'print', 'x_train.Embarked.isnull', 'x_test.Age.isnull', 'x_train.Age.isnull', 'x_test.Fare.isnull', 'x_trainkey.astype', 'x_testkey.astype', 'print', 'KNeighborsClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['arange', 'read_csv', 'read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'unique', 'print', 'unique', 'print', 'print', 'print', 'print', 'print', 'print', 'Embarked', 'Age', 'Age', 'Fare', 'astype', 'astype', 'print', 'KNeighborsClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['arange', 'read_csv', 'print', 'unique', 'Embarked', 'Age', 'Fare', 'astype', 'KNeighborsClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",13,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",arange read csv read csv read csv print print print print unique print unique print print print print print print embarked age age fare astype astype print kneighborsclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2520509316127501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19476976958433007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18620198037326388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2236496126105669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07005563095553573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12689960126484884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15871929876221266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06161782579112938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12516577953134653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06392975464909138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7753934841189687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16706321486159995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33903717592566496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
simo2712_titanic-disaster-ml-first-project.py,"['the', 'pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,698,"['Sibsp:      # of siblings / spouses aboard the Titanic', 'Parch:      # of parents / children aboard the Titanic', ""  X = X[np.logical_and(X>clip[0], X<clip[1])] # won't work for two columns."", ""  X = X[np.logical_and(X>clip[0], X<clip[1])] # won't work for two columns.""]",4,"['sns.set_context', 'pd.read_csv', 'pd.read_csv', 'data_train.head', 'data_train.info', 'data_train.value_counts', 'data_train.fillna', 'sns.set_style', 'sns.color_palette', 'plt.subplots', 'sns.factorplot', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'sns.factorplot', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'plt.close', 'plt.close', 'plt.show', 'data_train.str.replace', 'data_train.str.extract', 'data_train.rename', 'data_test.str.replace', 'data_test.str.extract', 'data_test.rename', 'data_train.value_counts', 'sns.set_style', 'sns.color_palette', 'plt.subplots', 'sns.factorplot', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'sns.factorplot', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'plt.close', 'plt.close', 'plt.show', 'data_traindata_train.Sexdata_train.Survived.count', 'None.astype', 'data_traindata_train.Sex.count', 'data_traindata_train.Sexdata_train.Survived.count', 'None.astype', 'data_traindata_train.Sex.count', 'print', 'print', 'sns.set_style', 'sns.distplot', 'sns.distplot', 'sns.plt.title', 'sns.plt.ylabel', 'sns.plt.xlabel', 'sns.plt.xlim', 'plt.show', 'sns.set_style', 'sns.set_context', 'sns.color_palette', 'plt.subplots', 'sns.factorplot', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'data_train.groupby', 'None.agg', 'df_SibSp.groupby', 'None.apply', 'None.unstack', 'pd.DataFrame', 'perc_df.columns.droplevel', 'perc_df.reset_index', 'sns.barplot', 'sns.barplot', 'plt.Rectangle', 'plt.Rectangle', 'axs.legend', 'l.draw_frame', 'sns.despine', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'plt.close', 'plt.close', 'plt.show', 'sns.set_style', 'sns.set_context', 'sns.color_palette', 'plt.subplots', 'sns.factorplot', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'data_train.groupby', 'None.agg', 'df_SibSp.groupby', 'None.apply', 'None.unstack', 'pd.DataFrame', 'perc_df.columns.droplevel', 'perc_df.reset_index', 'sns.barplot', 'sns.barplot', 'plt.Rectangle', 'plt.Rectangle', 'axs.legend', 'l.draw_frame', 'sns.despine', 'axs.set_title', 'axs.set_ylabel', 'axs.set_xlabel', 'plt.close', 'plt.close', 'plt.show', 'sns.set_style', 'sns.distplot', 'sns.distplot', 'sns.plt.title', 'sns.plt.ylabel', 'sns.plt.xlabel', 'sns.plt.xlim', 'plt.show', 'data_train.corr', 'print', 'data_train.str.extract', 'data_train.str.strip', 'data_test.str.extract', 'data_test.str.strip', 'sns.set_style', 'sns.set_context', 'sns.factorplot', 'sns.plt.title', 'sns.plt.ylabel', 'sns.plt.xlabel', 'plt.show', 'sns.set_style', 'sns.set_context', 'sns.factorplot', 'sns.plt.title', 'sns.plt.ylabel', 'sns.plt.xlabel', 'plt.show', 'data_train.append', 'print', 'total_df.value_counts', 'total_df.astype', 'total_df.fillna', 'None.astype', 'total_df.fillna', 'pd.get_dummies', 'cabin.head', 'total_df.fillna', 'pd.get_dummies', 'embarked.head', 'total_df.fillna', 'total_df.Title.map', 'pd.get_dummies', 'title.head', 'pd.get_dummies', 'pclass.head', 'total_df.str.replace', 'total_df.str.replace', 'total_df.str.extract', 'total_df.fillna', 'pd.get_dummies', 'ticket.head', 'pd.concat', 'final_df.head', 'list', 'SelectKBest', 'selector.fit_transform', 'zip', 'sorted', 'range', 'range', 'list', 'train_test_split', 'tree.DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'accuracy_score', 'print', 'print', 'print', 'range', 'train_test_split', 'model.fit', 'model.predict', 'accuracy_score', 'precision_score', 'recall_score', 'print', 'print', 'print', 'DecisionTreeClassifier', 'validate_clf', 'LogisticRegression', 'validate_clf', 'RandomForestClassifier', 'validate_clf', 'SVC', 'validate_clf', 'KNeighborsClassifier', 'validate_clf', 'GaussianNB', 'validate_clf', 'DecisionTreeClassifier', 'validate_clf', 'LogisticRegression', 'validate_clf', 'RandomForestClassifier', 'validate_clf', 'DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'pd.DataFrame', 'test.head', 'test.to_csv']","['set_context', 'read_csv', 'read_csv', 'head', 'info', 'value_counts', 'fillna', 'set_style', 'color_palette', 'subplots', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'close', 'close', 'show', 'str', 'str', 'rename', 'str', 'str', 'rename', 'value_counts', 'set_style', 'color_palette', 'subplots', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'close', 'close', 'show', 'Sexdata_train', 'astype', 'Sex', 'Sexdata_train', 'astype', 'Sex', 'print', 'print', 'set_style', 'distplot', 'distplot', 'plt', 'plt', 'plt', 'plt', 'show', 'set_style', 'set_context', 'color_palette', 'subplots', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'groupby', 'agg', 'groupby', 'apply', 'unstack', 'DataFrame', 'columns', 'reset_index', 'barplot', 'barplot', 'Rectangle', 'Rectangle', 'legend', 'draw_frame', 'despine', 'set_title', 'set_ylabel', 'set_xlabel', 'close', 'close', 'show', 'set_style', 'set_context', 'color_palette', 'subplots', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'groupby', 'agg', 'groupby', 'apply', 'unstack', 'DataFrame', 'columns', 'reset_index', 'barplot', 'barplot', 'Rectangle', 'Rectangle', 'legend', 'draw_frame', 'despine', 'set_title', 'set_ylabel', 'set_xlabel', 'close', 'close', 'show', 'set_style', 'distplot', 'distplot', 'plt', 'plt', 'plt', 'plt', 'show', 'corr', 'print', 'str', 'str', 'str', 'str', 'set_style', 'set_context', 'factorplot', 'plt', 'plt', 'plt', 'show', 'set_style', 'set_context', 'factorplot', 'plt', 'plt', 'plt', 'show', 'append', 'print', 'value_counts', 'astype', 'fillna', 'astype', 'fillna', 'get_dummies', 'head', 'fillna', 'get_dummies', 'head', 'fillna', 'Title', 'get_dummies', 'head', 'get_dummies', 'head', 'str', 'str', 'str', 'fillna', 'get_dummies', 'head', 'concat', 'head', 'list', 'SelectKBest', 'fit_transform', 'zip', 'sorted', 'range', 'range', 'list', 'train_test_split', 'DecisionTreeClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'print', 'print', 'range', 'train_test_split', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'print', 'print', 'print', 'DecisionTreeClassifier', 'validate_clf', 'LogisticRegression', 'validate_clf', 'RandomForestClassifier', 'validate_clf', 'SVC', 'validate_clf', 'KNeighborsClassifier', 'validate_clf', 'GaussianNB', 'validate_clf', 'DecisionTreeClassifier', 'validate_clf', 'LogisticRegression', 'validate_clf', 'RandomForestClassifier', 'validate_clf', 'DecisionTreeClassifier', 'fit', 'predict', 'DataFrame', 'head', 'to_csv']","['set_context', 'read_csv', 'head', 'info', 'value_counts', 'fillna', 'set_style', 'color_palette', 'subplots', 'factorplot', 'set_title', 'set_ylabel', 'set_xlabel', 'close', 'show', 'str', 'rename', 'Sexdata_train', 'astype', 'Sex', 'print', 'distplot', 'plt', 'groupby', 'agg', 'apply', 'unstack', 'DataFrame', 'columns', 'reset_index', 'barplot', 'Rectangle', 'legend', 'draw_frame', 'despine', 'corr', 'append', 'get_dummies', 'Title', 'concat', 'list', 'SelectKBest', 'fit_transform', 'zip', 'sorted', 'range', 'train_test_split', 'DecisionTreeClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'validate_clf', 'LogisticRegression', 'RandomForestClassifier', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'to_csv']",60,"[1 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set context read csv read csv head info value counts fillna set style color palette subplots factorplot set title set ylabel set xlabel factorplot set title set ylabel set xlabel close close show str str rename str str rename value counts set style color palette subplots factorplot set title set ylabel set xlabel factorplot set title set ylabel set xlabel close close show sexdata train astype sex sexdata train astype sex print print set style distplot distplot plt plt plt plt show set style set context color palette subplots factorplot set title set ylabel set xlabel groupby agg groupby apply unstack dataframe columns reset index barplot barplot rectangle rectangle legend draw frame despine set title set ylabel set xlabel close close show set style set context color palette subplots factorplot set title set ylabel set xlabel groupby agg groupby apply unstack dataframe columns reset index barplot barplot rectangle rectangle legend draw frame despine set title set ylabel set xlabel close close show set style distplot distplot plt plt plt plt show corr print str str str str set style set context factorplot plt plt plt show set style set context factorplot plt plt plt show append print value counts astype fillna astype fillna get dummies head fillna get dummies head fillna title get dummies head get dummies head str str str fillna get dummies head concat head list selectkbest fit transform zip sorted range range list train test split decisiontreeclassifier fit predict accuracy score print print print range train test split fit predict accuracy score precision score recall score print print print decisiontreeclassifier validate clf logisticregression validate clf randomforestclassifier validate clf svc validate clf kneighborsclassifier validate clf gaussiannb validate clf decisiontreeclassifier validate clf logisticregression validate clf randomforestclassifier validate clf decisiontreeclassifier fit predict dataframe head csv,"[0.0, 0.0, 0.03749942486386031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05437922453615099, 0.0, 0.0, 0.0, 0.015214854110657417, 0.02632109372702151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04618998997656041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07112103906107144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31460668221303045, 0.2648039607736614, 0.0, 0.0, 0.0, 0.12664409005835223, 0.0, 0.0, 0.0, 0.05314955520609689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013537898954486535, 0.0, 0.0, 0.0, 0.0, 0.15242443888578744, 0.0, 0.0, 0.01778025976526786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047218815546721055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02080477341869951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02606740985099456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06085941644262967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0589809600512939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07570583985832866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06620099019341535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0626619884054371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912857155387353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05416646735487313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030570316706238183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06332204502917611, 0.0, 0.018749712431930157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0455273348092047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04808467753775778, 0.0, 0.0, 0.0, 0.0, 0.06610919672121461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037155357466331904, 0.0, 0.0, 0.011434321233540308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015524555889179465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026617699037510583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03556051953053572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023209678079193385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10875844907230198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4432543152042328, 0.0, 0.0, 0.0, 0.0, 0.028629084850195108, 0.0, 0.023787996673231112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07397966690123105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022427513590081646, 0.0, 0.0, 0.04689355336650051, 0.0, 0.0, 0.0, 0.013814117702436757, 0.0, 0.027869280457607296, 0.0, 0.15028762137288096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057258169700390216, 0.0, 0.0, 0.0, 0.0, 0.04156452578308907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046650779463469585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027869280457607296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46125066595679576, 0.0, 0.046098177959357035, 0.07514381068644048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12091870753831926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030484887777157486, 0.0, 0.0, 0.02416580155579393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21224700323875523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13765176066541565, 0.0, 0.0, 0.0, 0.0, 0.06430499714443703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014823771866101548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02519849358221445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11714019422354979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049602969883691735, 0.0, 0.0, 0.0, 0.014106268486653386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050038139558268774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29790445587036907, 0.047218815546721055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14224207812214287, 0.0, 0.0, 0.0, 0.0, 0.13765176066541565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025019069779134387, 0.0]"
keilorgilbert_titanic-initial-exploration-of-data.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'scipy', 'our']","[1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,501,[' #   Column       Non-Null Count  Dtype  '],1,"['pd.read_csv', 'titanic.head', 'titanic.info', 'titanic.describe', 'sns.set', 'plt.subplots', 'enumerate', 'sns.countplot', 'ax.text', 'sns.distplot', 'ax.set_xlim', 'ax.set_yticklabels', 'ax.axis', 'ax.set_xticklabels', 'ax.set_title', 'ax.set_xlabel', 'ax.set_ylabel', 'fig.suptitle', 'fig.tight_layout', 'titanic.sort_values', 'None.head', 'sns.boxplot', 'print', 'titanic.quantile', 'stats.iqr', 'print', 'plt.figure', 'fig.add_gridspec', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'str', 'enumerate', 'sns.barplot', 'ax.set_ylabel', 'ax.yaxis.set_major_formatter', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_title', 'ax.text', 'ax.set_xticklabels', 'sns.lmplot', 'plt.gca', 'h.yaxis.set_major_formatter', 'h.set', 'h.set_title', 'fig.suptitle', 'fig.tight_layout', 'np.math.isnan', 'titanic.apply', 'plt.subplots', 'enumerate', 'sns.countplot', 'ax.text', 'ax.set_title', 'ax.set_ylabel', 'sns.barplot', 'ax.set_ylabel', 'ax.yaxis.set_major_formatter', 'ax.set_title', 'ax.text', 'fig.tight_layout', 'plt.figure', 'fig.add_gridspec', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'enumerate', 'sns.barplot', 'ax.set_ylabel', 'ax.yaxis.set_major_formatter', 'ax.set_title', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.text', 'sns.lmplot', 'plt.gca', 'h.yaxis.set_major_formatter', 'h.set', 'h.set_title', 'fig.suptitle', 'fig.tight_layout', 'sns.catplot', 'plt.subplots', 'sns.countplot', 'ax1.text', 'ax1.set', 'ax1.set_title', 'sns.countplot', 'ax2.text', 'ax2.set', 'ax2.set_title', 'sns.countplot', 'ax3.text', 'ax3.set', 'ax3.set_title', 'plt.tight_layout', 'np.where', 'plt.figure', 'fig.add_gridspec', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'enumerate', 'sns.barplot', 'ax.set_ylabel', 'ax.yaxis.set_major_formatter', 'ax.set_title', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.text', 'sns.lmplot', 'plt.gca', 'h.yaxis.set_major_formatter', 'h.set', 'h.set_title', 'fig.suptitle', 'fig.tight_layout', 'sns.lmplot', 'plt.gca', 'h.yaxis.set_major_formatter', 'h.set', 'h.set_title', 'sns.lmplot', 'plt.gca', 'h.yaxis.set_major_formatter', 'h.set', 'h.set_title']","['read_csv', 'head', 'info', 'describe', 'set', 'subplots', 'enumerate', 'countplot', 'text', 'distplot', 'set_xlim', 'set_yticklabels', 'axis', 'set_xticklabels', 'set_title', 'set_xlabel', 'set_ylabel', 'suptitle', 'tight_layout', 'sort_values', 'head', 'boxplot', 'print', 'quantile', 'iqr', 'print', 'figure', 'add_gridspec', 'add_subplot', 'add_subplot', 'add_subplot', 'add_subplot', 'add_subplot', 'add_subplot', 'str', 'enumerate', 'barplot', 'set_ylabel', 'yaxis', 'set_xlabel', 'set_ylabel', 'set_title', 'text', 'set_xticklabels', 'lmplot', 'gca', 'yaxis', 'set', 'set_title', 'suptitle', 'tight_layout', 'math', 'apply', 'subplots', 'enumerate', 'countplot', 'text', 'set_title', 'set_ylabel', 'barplot', 'set_ylabel', 'yaxis', 'set_title', 'text', 'tight_layout', 'figure', 'add_gridspec', 'add_subplot', 'add_subplot', 'add_subplot', 'add_subplot', 'enumerate', 'barplot', 'set_ylabel', 'yaxis', 'set_title', 'set_xlabel', 'set_ylabel', 'text', 'lmplot', 'gca', 'yaxis', 'set', 'set_title', 'suptitle', 'tight_layout', 'catplot', 'subplots', 'countplot', 'text', 'set', 'set_title', 'countplot', 'text', 'set', 'set_title', 'countplot', 'text', 'set', 'set_title', 'tight_layout', 'where', 'figure', 'add_gridspec', 'add_subplot', 'add_subplot', 'add_subplot', 'add_subplot', 'enumerate', 'barplot', 'set_ylabel', 'yaxis', 'set_title', 'set_xlabel', 'set_ylabel', 'text', 'lmplot', 'gca', 'yaxis', 'set', 'set_title', 'suptitle', 'tight_layout', 'lmplot', 'gca', 'yaxis', 'set', 'set_title', 'lmplot', 'gca', 'yaxis', 'set', 'set_title']","['read_csv', 'head', 'info', 'describe', 'set', 'subplots', 'enumerate', 'countplot', 'text', 'distplot', 'set_xlim', 'set_yticklabels', 'axis', 'set_xticklabels', 'set_title', 'set_xlabel', 'set_ylabel', 'suptitle', 'tight_layout', 'sort_values', 'boxplot', 'print', 'quantile', 'iqr', 'figure', 'add_gridspec', 'add_subplot', 'str', 'barplot', 'yaxis', 'lmplot', 'gca', 'math', 'apply', 'catplot', 'where']",36,"[1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv head info describe set subplots enumerate countplot text distplot set xlim set yticklabels axis set xticklabels set title set xlabel set ylabel suptitle tight layout sort values head boxplot print quantile iqr print figure add gridspec add subplot add subplot add subplot add subplot add subplot add subplot str enumerate barplot set ylabel yaxis set xlabel set ylabel set title text set xticklabels lmplot gca yaxis set set title suptitle tight layout math apply subplots enumerate countplot text set title set ylabel barplot set ylabel yaxis set title text tight layout figure add gridspec add subplot add subplot add subplot add subplot enumerate barplot set ylabel yaxis set title set xlabel set ylabel text lmplot gca yaxis set set title suptitle tight layout catplot subplots countplot text set set title countplot text set set title countplot text set set title tight layout figure add gridspec add subplot add subplot add subplot add subplot enumerate barplot set ylabel yaxis set title set xlabel set ylabel text lmplot gca yaxis set set title suptitle tight layout lmplot gca yaxis set set title lmplot gca yaxis set set title,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.2807265105659688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014566619161244472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030846833261120494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07871960801469723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021789544049537972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02769210618836179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08533548590043595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00767585152474264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013725637297903045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020948562186196545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13152907065580247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05085855975028924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15843907562230955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12475825859815759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018293075160191994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012655963654376653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04158608619938586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16615263713017073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1752184244350471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04158608619938586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016376730307671762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03504368488700942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007645008741161165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5519250470935083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015803795416800746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02135667859369852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35203579336919655, 0.0, 0.05338150534031352, 0.0, 0.0, 0.0, 0.0, 0.12675126049784766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2851903361201572, 0.0, 0.0, 0.0, 0.0, 0.17275653854436132, 0.0, 0.2016862522334813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015803795416800746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07871960801469723, 0.030094549349547445, 0.04548594130179962, 0.0, 0.3742747757944728, 0.1714032778951795, 0.0, 0.0, 0.03663695066192389, 0.0, 0.0, 0.0, 0.0, 0.0]"
builderdavid_titanic-model-baseline2.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'warnings\n', 'tqdm', 're\n', 'sklearn', 'seaborn', 'lightgbm', 'randint']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]",11,716,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '#tr_data.info() # have some missing value at Age and Embarked and many at Cabin', '#tst_data.info() # Also have one missing value at Fare', ""tst_data[tst_data['Fare'].isna()] # this is person we don't know his Fare Value. I guess he didn't survive"", ""title_list = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev','Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess','Don', 'Jonkheer'] # We have all the titles for Passengers"", '    return None # for cases no title in name', '# overwrite Fare because only one missing record', 'Prev_Family_Name=set() # A set store the family names in previous Companion group', ""overall_data['Companion_Group_Num'] = 0 # Initial all Companion group as 0 which means they all travel independently"", '    # step 1 check the group', '        Current_Family_Name |= Prev_Family_Name # put these family together for next iteration', '        Group_Num -=1 # use the previous group_num', ""overall_data[idx].groupby(['Survived']).size()#.unstack() #"", ""# columns to code Let's try sklearn ordinal encode for Sex and onehot encode for other"", 'enc2 = OneHotEncoder(sparse=True) # exercise a little with sparse matrix', ""        if featurename == 'ImputedEmbarked': featurename='Embarked' # shorten the column name for convenience"", ""#                        categorical_feature=['Pclass','Male?','EmbarkedCode','CabinCode','Missing_Age','Ticket_Type'],"", '#                        free_raw_data=False', '#                       )', ""#    'num_leaves':sp_randint(10,30), "", ""#    'early_stopping_round':50,"", ""#    'first_metric_only':True,    "", '#    print(k,v[-1])    ', ""tst_data['Survived'] = pd.Series(np.nan,index = tst_data.index) # use the value in test data,did not modify value in overall_data"", ""    elif survived_count>dead_count: tst_data.loc[na_index,'Survived']=1 # similar to the above""]",26,"['pd.read_csv', 'pd.read_csv', 'tr_data.groupby', 'None.size', 'df.unstack', 'df.plot.bar', 'tst_data.groupby', 'None.size', 'plt.figure', 'df.plot.bar', 'tr_data.groupby', 'None.size', 'df.unstack', 'df.plot.bar', 'tst_data.groupby', 'None.size', 'plt.figure', 'df.plot.bar', 'tr_data.groupby', 'None.size', 'df.unstack', 'df.plot.bar', 'tst_data.groupby', 'None.size', 'plt.figure', 'df.plot.bar', 'tr_data.groupby', 'None.size', 'df.unstack', 'df.plot.bar', 'tst_data.groupby', 'None.size', 'plt.figure', 'df.plot.bar', 'tst_data.isna', 'pd.concat', 'overall_data.info', 're.compile', 'p.sub', 's.replace', 'None.upper', 'overall_data.apply', 'overall_data.apply', 'overall_data.groupby', 'None.size', 'df.unstack', 'df.div', 'df.plot.barh', 'pd.isna', 'overall_data.apply', 'overall_data.groupby', 'None.size', 'df.unstack', 'df.div', 'df.plot.bar', 'overall_data.groupby', 'None.size', 'df.unstack', 'df.div', 'df.plot.bar', 's.isdigit', 'len', 'len', 'len', 's.startswith', 's.startswith', 's.startswith', 's.startswith', 's.startswith', 'overall_data.apply', 'overall_data.groupby', 'None.size', 'df.unstack', 'df.plot.bar', 'overall_data.Age.isna', 'None.astype', 's.fillna', 's.fillna', 's.fillna', 'overall_data.groupby', 'None.transform', 'pd.cut', 'overall_data.transform', 'overall_data.groupby', 'None.transform', 'overall_data.groupby', 'None.Fare.transform', 'overall_data.Name.apply', 'set', 'pd.DataFrame', 'overall_data.groupby', 'set', 'Prev_Family_Name.isdisjoint', 'prev_df.Companion_Group_Num.all', 'len', 'overall_data.iterrows', 'overall_dataidx.groupby', 'None.Companion_Group_Num.transform', 'overall_dataidx.groupby', 'None.Companion_Group_Num.transform', 's.dropna', 'len', 's.sum', 's.sum', 'len', 'len', 'print', 'print', 'overall_dataoverall_data.Companion_Group_Numoverall_data.WC_group.groupby', 'None.agg', 's.dropna', 'print', 'print', 'print', 'overall_dataoverall_data.Companion_Group_Numoverall_data.WC_group.groupby', 'None.agg', 's.dropna', 'print', 'print', 'print', 'len', 'len', 'print', 'df.Survived.dropna', 'len', 's.sum', 's.sum', 'overall_data.locidx.groupby', 'None.filter', 'None.sort_values', 'pd.Series', 'df.WC_group.sum', 'df.WC_group.sum', 'overall_dataidx.groupby', 'None.apply', 'idx.reset_index', 'overall_data.locidx.sort_values', 'dfidx.groupby', 'None.size', 'None.unstack', 'overall_dataidx.groupby', 'None.size', 'None.unstack', 'sns.relplot', 'sns.relplot', 'sns.relplot', 'sns.relplot', 'overall_dataidx.groupby', 'None.size', 'sns.relplot', 'overall_dataidx.groupby', 'None.size', 'print', 'print', 'OrdinalEncoder', 'OneHotEncoder', 'enc.fit_transform', 'enc2.fit_transform', 'enumerate', 'SparseColumns.append', 'pd.DataFrame.sparse.from_spmatrix', 'None.sparse.to_dense', 'pd.DataFrame', 'pd.concat', 'tr_dataidx.groupby', 'None.size', 'df.unstack', 'print', 'print', 'tr_dataidx2.groupby', 'None.size', 'df.unstack', 'print', 'print', 'overall_dataidx.groupby', 'None.size', 'df.Companion_Group_Num.all', 'df.Survived.isna', 'None.all', 'df.WC_group.all', 'overall_data.groupby', 'None.filter', 'None.loc.sort_values', 'RepeatedStratifiedKFold', 'train_data.get_label', 'tmp.sum', 'len', 'warnings.filterwarnings', 'pd.DataFrame', 'cv_splitter.split', 'lgb.Dataset', 'lgb.Dataset', 'lgb.train', 'model.eval_valid', 'binary_logloss.append', 'auc.append', 'acc2.append', 'pd.DataFrame', 'tmpdf.agg', 'result.append', 'lgb.Dataset', 'lgb.train', 'lgb.plot_importance', 'lgb.create_tree_digraph', 'pd.Series', 'print', 'overall_dataidx.groupby', 'df.Survived.sum', 'df.Survived.sum', 'df.Survived.isna', 'df.Survived.isna', 'print', 'tst_data.Survived.isna', 'print', 'print', 'pd.DataFrame', 'print', 'resultDF.to_csv']","['read_csv', 'read_csv', 'groupby', 'size', 'unstack', 'plot', 'groupby', 'size', 'figure', 'plot', 'groupby', 'size', 'unstack', 'plot', 'groupby', 'size', 'figure', 'plot', 'groupby', 'size', 'unstack', 'plot', 'groupby', 'size', 'figure', 'plot', 'groupby', 'size', 'unstack', 'plot', 'groupby', 'size', 'figure', 'plot', 'isna', 'concat', 'info', 'compile', 'sub', 'replace', 'upper', 'apply', 'apply', 'groupby', 'size', 'unstack', 'div', 'plot', 'isna', 'apply', 'groupby', 'size', 'unstack', 'div', 'plot', 'groupby', 'size', 'unstack', 'div', 'plot', 'isdigit', 'len', 'len', 'len', 'startswith', 'startswith', 'startswith', 'startswith', 'startswith', 'apply', 'groupby', 'size', 'unstack', 'plot', 'Age', 'astype', 'fillna', 'fillna', 'fillna', 'groupby', 'transform', 'cut', 'transform', 'groupby', 'transform', 'groupby', 'Fare', 'Name', 'set', 'DataFrame', 'groupby', 'set', 'isdisjoint', 'Companion_Group_Num', 'len', 'iterrows', 'groupby', 'Companion_Group_Num', 'groupby', 'Companion_Group_Num', 'dropna', 'len', 'sum', 'sum', 'len', 'len', 'print', 'print', 'Companion_Group_Numoverall_data', 'agg', 'dropna', 'print', 'print', 'print', 'Companion_Group_Numoverall_data', 'agg', 'dropna', 'print', 'print', 'print', 'len', 'len', 'print', 'Survived', 'len', 'sum', 'sum', 'locidx', 'filter', 'sort_values', 'Series', 'WC_group', 'WC_group', 'groupby', 'apply', 'reset_index', 'locidx', 'groupby', 'size', 'unstack', 'groupby', 'size', 'unstack', 'relplot', 'relplot', 'relplot', 'relplot', 'groupby', 'size', 'relplot', 'groupby', 'size', 'print', 'print', 'OrdinalEncoder', 'OneHotEncoder', 'fit_transform', 'fit_transform', 'enumerate', 'append', 'DataFrame', 'sparse', 'DataFrame', 'concat', 'groupby', 'size', 'unstack', 'print', 'print', 'groupby', 'size', 'unstack', 'print', 'print', 'groupby', 'size', 'Companion_Group_Num', 'Survived', 'all', 'WC_group', 'groupby', 'filter', 'loc', 'RepeatedStratifiedKFold', 'get_label', 'sum', 'len', 'filterwarnings', 'DataFrame', 'split', 'Dataset', 'Dataset', 'train', 'eval_valid', 'append', 'append', 'append', 'DataFrame', 'agg', 'append', 'Dataset', 'train', 'plot_importance', 'create_tree_digraph', 'Series', 'print', 'groupby', 'Survived', 'Survived', 'Survived', 'Survived', 'print', 'Survived', 'print', 'print', 'DataFrame', 'print', 'to_csv']","['read_csv', 'groupby', 'size', 'unstack', 'plot', 'figure', 'isna', 'concat', 'info', 'compile', 'sub', 'replace', 'upper', 'apply', 'div', 'isdigit', 'len', 'startswith', 'Age', 'astype', 'fillna', 'transform', 'cut', 'Fare', 'Name', 'set', 'DataFrame', 'isdisjoint', 'Companion_Group_Num', 'iterrows', 'dropna', 'sum', 'print', 'Companion_Group_Numoverall_data', 'agg', 'Survived', 'locidx', 'filter', 'sort_values', 'Series', 'WC_group', 'reset_index', 'relplot', 'OrdinalEncoder', 'OneHotEncoder', 'fit_transform', 'enumerate', 'append', 'sparse', 'all', 'loc', 'RepeatedStratifiedKFold', 'get_label', 'filterwarnings', 'split', 'Dataset', 'train', 'eval_valid', 'plot_importance', 'create_tree_digraph', 'to_csv']",61,"[1 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1
 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0
 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv groupby size unstack plot groupby size figure plot groupby size unstack plot groupby size figure plot groupby size unstack plot groupby size figure plot groupby size unstack plot groupby size figure plot isna concat info compile sub replace upper apply apply groupby size unstack div plot isna apply groupby size unstack div plot groupby size unstack div plot isdigit len len len startswith startswith startswith startswith startswith apply groupby size unstack plot age astype fillna fillna fillna groupby transform cut transform groupby transform groupby fare name set dataframe groupby set isdisjoint companion group num len iterrows groupby companion group num groupby companion group num dropna len sum sum len len print print companion group numoverall data agg dropna print print print companion group numoverall data agg dropna print print print len len print survived len sum sum locidx filter sort values series wc group wc group groupby apply reset index locidx groupby size unstack groupby size unstack relplot relplot relplot relplot groupby size relplot groupby size print print ordinalencoder onehotencoder fit transform fit transform enumerate append dataframe sparse dataframe concat groupby size unstack print print groupby size unstack print print groupby size companion group num survived wc group groupby filter loc repeatedstratifiedkfold get label sum len filterwarnings dataframe split dataset dataset train eval valid append append append dataframe agg append dataset train plot importance create tree digraph series print groupby survived survived survived survived print survived print print dataframe print csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017671961877890992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09221830748219376, 0.0, 0.0, 0.0, 0.08600638121399719, 0.07439381293409413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013055116589688779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25486332688172647, 0.0, 0.0, 0.0, 0.0, 0.026869513013140542, 0.0, 0.0, 0.030610762084154683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03334070046051815, 0.0, 0.0, 0.0, 0.0, 0.02352100468010587, 0.0, 0.0, 0.0, 0.019452913771737926, 0.0, 0.054623308408922856, 0.0, 0.058941441635926954, 0.0, 0.0, 0.10339480853483547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042477221146954416, 0.0, 0.0, 0.0, 0.0, 0.12743166344086324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051264608162558116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026869513013140542, 0.0, 0.0, 0.03446493617827849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022256465223630433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06926452209266518, 0.0, 0.0, 0.0, 0.030619168652268176, 0.07158924961645784, 0.02100314478962559, 0.0, 0.0, 0.0, 0.01728075927213568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010294259241079382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24580488784015284, 0.3805376448240002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03334070046051815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02100314478962559, 0.0, 0.0, 0.012927164253863194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03579462480822892, 0.042477221146954416, 0.0, 0.0, 0.053739026026281084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03579462480822892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039520125159109486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2013719863073084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024664949573419692, 0.0, 0.0, 0.0, 0.0, 0.08495444229390883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019452913771737926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12946737274116968, 0.0, 0.0, 0.08495444229390883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03236684318529242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042477221146954416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19560355557486594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16727662026374515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015617662379274252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19760062579554744, 0.0, 0.0, 0.0, 0.042477221146954416, 0.015483270253081702, 0.0, 0.0, 0.023495555221757627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038297981586501786, 0.028187603624839793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48123989434500225, 0.0, 0.0, 0.0, 0.016142449896874005, 0.0, 0.0, 0.039520125159109486, 0.013660421097916218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19760062579554744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039520125159109486, 0.0, 0.0, 0.0, 0.0, 0.06936946404068066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1824083363931961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028039519183919906, 0.0, 0.0, 0.0, 0.07973977904397296, 0.0, 0.0, 0.03742203216612342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3394261377562459, 0.0, 0.03742203216612342, 0.0, 0.0, 0.0, 0.0, 0.042477221146954416, 0.0, 0.0, 0.016142449896874005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12743166344086324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
lystahi_titanic-data-lightgbm.py,"['pandas', 'numpy', 'lightgbm', 'sklearn']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,166,"[""sample_submission.to_csv('submission.csv', index=False)  # scoreã¯0.77511""]",1,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
currypurin_titanic-lightgbm-ex-ver2.py,"['pandas', 'numpy', 'lightgbm', 'sklearn', 'warnings\n', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,231,"['# Sexã®å¤‰æ›', '# Embarkedã®å¤‰æ› ä»Šå›žã¯onehot encodingã—ãªã„', '# ä¸è¦ãªåˆ—ã®å‰Šé™¤', '# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’trainã¨validã«åˆ†å‰²', '# lab.Datasetã‚’ä½¿ã£ã¦ã€trainã¨validã‚’ä½œã£ã¦ãŠã', '# lgb.trainã§å\xad¦ç¿’', '# valid_xã«ã¤ã„ã¦æŽ¨è«–', ""print('score', round(accuracy_score(valid_y, (oof > 0.5).astype(int))*100,2))  # validã®score"", ""sample_submission.to_csv('train_test_split.csv', index=False)  # score:75.119"", '# importanceã¯training dataã®åˆ—é\xa0†ã«è¡¨ç¤ºã•ã‚Œã‚‹', '# è¦‹ã‚„ã™ãã™ã‚‹', '# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’trainã¨validã«åˆ†å‰²', '# LightGBMã®åˆ†é¡žå™¨ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–', ""gbm = lgb.LGBMClassifier(objective='binary')  # , importance_type='gain'"", '# trainã¨validã‚’æŒ‡å®šã—å\xad¦ç¿’', '# valid_xã«ã¤ã„ã¦æŽ¨è«–', ""print('score', round(accuracy_score(valid_y, oof)*100,2));  # validã®score"", '# æŒ‡å®šã—ã¦ã„ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€åˆæœŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã‚‹', '# GridSearchCVã‚’import', '# è©¦è¡Œã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¾…åˆ—ã™ã‚‹', '                           gbm,  # åˆ†é¡žå™¨ã‚’æ¸¡ã™', '                           param_grid=params,  # è©¦è¡Œã—ã¦ã»ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã™', '                           cv=3,  # 3åˆ†å‰²äº¤å·®æ¤œè¨¼ã§ã‚¹ã‚³ã‚¢ã‚’ç¢ºèª', 'grid_search.fit(X_train, y_train)  # ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã™', 'print(grid_search.best_score_)  # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º', 'print(grid_search.best_params_)  # ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¡¨ç¤º', '# ã‚¹ã‚³ã‚¢ã¨ãƒ¢ãƒ‡ãƒ«ã‚’æ\xa0¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ', '                             reg_lambda=10)  # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®š']",28,"['warnings.filterwarnings', 'os.listdir', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train.map', 'test.map', 'train.map', 'test.map', 'train.drop', 'test.drop', 'train.drop', 'X_train.head', 'train_test_split', 'lgb.Dataset', 'lgb.Dataset', 'lgb.train', 'gbm.predict', 'oof.astype', 'print', 'gbm.predict', 'print', 'gbm.predict', 'None.astype', 'sample_submission.to_csv', 'gbm.feature_importance', 'pd.DataFrame', 'None.sort_values', 'pd.DataFrame', 'None.sort_values', 'train_test_split', 'lgb.LGBMClassifier', 'gbm.fit', 'gbm.predict', 'print', 'gbm.get_params', 'lgb.LGBMClassifier', 'GridSearchCV', 'grid_search.fit', 'print', 'print', 'KFold', 'np.zeros', 'enumerate', 'print', 'lgb.LGBMClassifier', 'gbm.fit', 'gbm.predict', 'score_list.append', 'gbm.predict_proba', 'print', 'print', 'np.mean', 'None.astype', 'sample_submission.to_csv']","['filterwarnings', 'listdir', 'read_csv', 'read_csv', 'read_csv', 'map', 'map', 'map', 'map', 'drop', 'drop', 'drop', 'head', 'train_test_split', 'Dataset', 'Dataset', 'train', 'predict', 'astype', 'print', 'predict', 'print', 'predict', 'astype', 'to_csv', 'feature_importance', 'DataFrame', 'sort_values', 'DataFrame', 'sort_values', 'train_test_split', 'LGBMClassifier', 'fit', 'predict', 'print', 'get_params', 'LGBMClassifier', 'GridSearchCV', 'fit', 'print', 'print', 'KFold', 'zeros', 'enumerate', 'print', 'LGBMClassifier', 'fit', 'predict', 'append', 'predict_proba', 'print', 'print', 'mean', 'astype', 'to_csv']","['filterwarnings', 'listdir', 'read_csv', 'map', 'drop', 'head', 'train_test_split', 'Dataset', 'train', 'predict', 'astype', 'print', 'to_csv', 'feature_importance', 'DataFrame', 'sort_values', 'LGBMClassifier', 'fit', 'get_params', 'GridSearchCV', 'KFold', 'zeros', 'enumerate', 'append', 'predict_proba', 'mean']",26,"[1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0
 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",filterwarnings listdir read csv read csv read csv map map map map drop drop drop head train test split dataset dataset train predict astype print predict print predict astype csv feature importance dataframe sort values dataframe sort values train test split lgbmclassifier fit predict print get params lgbmclassifier gridsearchcv fit print print kfold zeros enumerate print lgbmclassifier fit predict append predict proba print print mean astype csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08100653172308435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18444266016840802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1846137252534198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09252495172044259, 0.0, 0.0, 0.3246136980130756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14175699467449307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12653747475242938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1623068490065378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09891079537761348, 0.0, 0.0, 0.0, 0.1220712656216335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048479091086466794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09801865131146936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043997108865092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15701244904170378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11927993388829279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.457278693555609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20003936415994877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25865324511632204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06637240094871302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15701244904170378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25330287009310776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151044993326639, 0.0, 0.12861966469783012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11032315089091368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15204033249646948, 0.0, 0.0, 0.0, 0.12866293400552342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13416116611409246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1980711345086725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15204033249646948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11927993388829279, 0.0, 0.0]"
leapleap_titanic-analysis-heavy-on-the-data-cleaning.py,"['pandas', 'os', 'matplotlib', 'numpy', 'random', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,817,"['# make pandas window less tiny', '# for my own sanity temporarily:', ""pd.options.mode.chained_assignment = None # None|'warn'|'raise'"", '# and the test data', ""# have a look at counts, in this case we're just using 'HasCabin'"", ""# on y axis as it's a nice column full of 1's."", '# do the same thing to test before i forget...']",7,"['pd.set_option', 'pd.set_option', 'pd.read_csv', 'pd.read_csv', 'sea.color_palette', 'plt.subplots', 'dflabelmetric.groupby', 'None.mean', 'sea.barplot', 'axis1.set_title', 'plt.show', 'datax_valy_valhue_val.groupby', 'None.count', 'sea.factorplot', 'g.fig.suptitle', 'plt.show', 'datax_valy_valhue_val.groupby', 'None.sum', 'sea.factorplot', 'g.fig.suptitle', 'plt.show', 'sea.color_palette', 'sea.FacetGrid', 'g.map', 'g.set', 'g.add_legend', 'plt.show', 'train.describe', 'test.describe', 'traintrain.describe', 'train.head', 'train.drop', 'test.drop', 'train.isnull', 'None.sum', 'train.isnull', 'males.str.contains', 't_males.str.contains', 'pd.concat', 'print', 'allmasters.describe', 'df.median', 'df.std', 'int', 'int', 'np.isnan', 'float', 'get_age_range', 'masters.isnull', 'null_masters.apply', 't_masters.isnull', 'null_t_masters.apply', 'malesmales.dropna', 't_malest_males.dropna', 'pd.concat', 'allmen.describe', 'get_age_range', 'males.isnull', 'null_men.apply', 't_males.isnull', 'null_t_men.apply', 'males.isnull', 'None.sum', 't_males.isnull', 'None.sum', 'women.str.contains', 't_women.str.contains', 'pd.concat', 'all_unmarried_women.describe', 'bar_graph_by', 'get_age_range', 'get_age_range', 'unmarried_women.isnull', 'wp_unmarried.apply', 'np_unmarried.apply', 't_unmarried_women.isnull', 'twp_unmarried.apply', 'tnp_unmarried.apply', 'women.str.contains', 't_women.str.contains', 'pd.concat', 'all_married_women.describe', 'get_age_range', 'women.isnull', 'mw_train.apply', 't_women.isnull', 'mw_test.apply', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'train.isnull', 'None.sum', 'train.value_counts', 'train.value_counts', 'train.fillna', 'test.fillna', 'train.notnull', 'test.notnull', 'bar_graph_by', 'bar_graph_by', 'withcabins.apply', 'withcabins_t.apply', 'pd.concat', 'multi_bar_count_by', 'test_train_withcabinstest_train_withcabinscls.value_counts', 'np.random.choice', 'train.isnull', 'null_cab.apply', 'test.isnull', 'null_cabx.apply', 'multi_bar_count_by', 'bar_graph_by', 'dict', 'train.apply', 'test.apply', 'train.drop', 'test.drop', 'train.describe', 'facet_by', 'pd.concat', 'None.median', 'train.fillna', 'test.fillna', 'sea.xkcd_palette', 'sea.palplot', 'plt.show', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'facet_by', 'facet_by', 'facet_by', 'facet_by', 'facet_by', 'train.groupby', 'None.mean', 'train.astype', 'test.astype', 'dict', 'train.apply', 'test.apply', 'trainnf_vals.astype', 'testnf_vals.astype', 'RandomForestClassifier', 'pd.DataFrame', 'rf.fit', 'test_features', 'print', 'train_test_split', 'RandomForestClassifier', 'GridSearchCV', 'rfc_gs.fit', 'print', 'RandomForestClassifier', 'best_rfc.fit', 'best_rfc.predict', 'best_rfc.score', 'AdaBoostClassifier', 'GridSearchCV', 'ada_gs.fit', 'print', 'AdaBoostClassifier', 'ada2.fit', 'ada2.predict', 'ada2.score', 'mdl.fit', 'mdl.predict', 'pd.DataFrame', 'results.to_csv', 'RandomForestClassifier', 'make_submission']","['set_option', 'set_option', 'read_csv', 'read_csv', 'color_palette', 'subplots', 'groupby', 'mean', 'barplot', 'set_title', 'show', 'groupby', 'count', 'factorplot', 'fig', 'show', 'groupby', 'sum', 'factorplot', 'fig', 'show', 'color_palette', 'FacetGrid', 'map', 'set', 'add_legend', 'show', 'describe', 'describe', 'describe', 'head', 'drop', 'drop', 'isnull', 'sum', 'isnull', 'str', 'str', 'concat', 'print', 'describe', 'median', 'std', 'int', 'int', 'isnan', 'float', 'get_age_range', 'isnull', 'apply', 'isnull', 'apply', 'dropna', 'dropna', 'concat', 'describe', 'get_age_range', 'isnull', 'apply', 'isnull', 'apply', 'isnull', 'sum', 'isnull', 'sum', 'str', 'str', 'concat', 'describe', 'bar_graph_by', 'get_age_range', 'get_age_range', 'isnull', 'apply', 'apply', 'isnull', 'apply', 'apply', 'str', 'str', 'concat', 'describe', 'get_age_range', 'isnull', 'apply', 'isnull', 'apply', 'isnull', 'sum', 'isnull', 'sum', 'isnull', 'sum', 'value_counts', 'value_counts', 'fillna', 'fillna', 'notnull', 'notnull', 'bar_graph_by', 'bar_graph_by', 'apply', 'apply', 'concat', 'multi_bar_count_by', 'value_counts', 'random', 'isnull', 'apply', 'isnull', 'apply', 'multi_bar_count_by', 'bar_graph_by', 'dict', 'apply', 'apply', 'drop', 'drop', 'describe', 'facet_by', 'concat', 'median', 'fillna', 'fillna', 'xkcd_palette', 'palplot', 'show', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'bar_graph_by', 'facet_by', 'facet_by', 'facet_by', 'facet_by', 'facet_by', 'groupby', 'mean', 'astype', 'astype', 'dict', 'apply', 'apply', 'astype', 'astype', 'RandomForestClassifier', 'DataFrame', 'fit', 'test_features', 'print', 'train_test_split', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print', 'RandomForestClassifier', 'fit', 'predict', 'score', 'AdaBoostClassifier', 'GridSearchCV', 'fit', 'print', 'AdaBoostClassifier', 'fit', 'predict', 'score', 'fit', 'predict', 'DataFrame', 'to_csv', 'RandomForestClassifier', 'make_submission']","['set_option', 'read_csv', 'color_palette', 'subplots', 'groupby', 'mean', 'barplot', 'set_title', 'show', 'count', 'factorplot', 'fig', 'sum', 'FacetGrid', 'map', 'set', 'add_legend', 'describe', 'head', 'drop', 'isnull', 'str', 'concat', 'print', 'median', 'std', 'int', 'isnan', 'float', 'get_age_range', 'apply', 'dropna', 'bar_graph_by', 'value_counts', 'fillna', 'notnull', 'multi_bar_count_by', 'random', 'dict', 'facet_by', 'xkcd_palette', 'palplot', 'astype', 'RandomForestClassifier', 'DataFrame', 'fit', 'test_features', 'train_test_split', 'GridSearchCV', 'predict', 'score', 'AdaBoostClassifier', 'to_csv', 'make_submission']",54,"[1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set option set option read csv read csv color palette subplots groupby mean barplot set title show groupby count factorplot fig show groupby sum factorplot fig show color palette facetgrid map set add legend show describe describe describe head drop drop isnull sum isnull str str concat print describe median std int int isnan float get age range isnull apply isnull apply dropna dropna concat describe get age range isnull apply isnull apply isnull sum isnull sum str str concat describe bar graph get age range get age range isnull apply apply isnull apply apply str str concat describe get age range isnull apply isnull apply isnull sum isnull sum isnull sum value counts value counts fillna fillna notnull notnull bar graph bar graph apply apply concat multi bar count value counts random isnull apply isnull apply multi bar count bar graph dict apply apply drop drop describe facet concat median fillna fillna xkcd palette palplot show bar graph bar graph bar graph bar graph bar graph bar graph bar graph bar graph facet facet facet facet facet groupby mean astype astype dict apply apply astype astype randomforestclassifier dataframe fit test features print train test split randomforestclassifier gridsearchcv fit print randomforestclassifier fit predict score adaboostclassifier gridsearchcv fit print adaboostclassifier fit predict score fit predict dataframe csv randomforestclassifier make submission,"[0.0, 0.0, 0.0, 0.05974014008888392, 0.0, 0.019334464704361468, 0.0, 0.10128482192398883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3069933143861195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05985912229192041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4311986867485295, 0.0, 0.023042021533483257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08206111408769352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1052652424696563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07733247476576337, 0.0, 0.0, 0.0, 0.0611924110770566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026961587931878698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022521074008980756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12856422968773518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07420273925251926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046005892954524896, 0.03917562931703522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2921439832944195, 0.020833738489680266, 0.051554983177175585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039506365479497894, 0.07901273095899579, 0.0, 0.0, 0.0, 0.0, 0.04679740055023513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059425613444061914, 0.0, 0.036116714204664335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059000365736219765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.584287966588839, 0.0, 0.0, 0.047716540444481106, 0.0, 0.0, 0.06231451001744811, 0.0, 0.0, 0.0, 0.0, 0.01070913441733791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05325677123550415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025254827113872266, 0.271770649958272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017247374405411443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03710136962625963, 0.0, 0.015739399933782167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03231080321848905, 0.04495643717016514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09738132776480651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07223342840932867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06608513725029183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10570772974732486, 0.04869066388240326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030827644748685254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03834907026741977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024762925907267395, 0.05812910023897669, 0.0, 0.0, 0.10128482192398883, 0.0, 0.0, 0.0, 0.01790216800923239, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030228137247207736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0646216064369781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09793907329258805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01565862724093048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025777491588587793, 0.0, 0.0, 0.15003155440951033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045301012607569704, 0.0, 0.0, 0.020833738489680266, 0.11132327474696828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03265555393442127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01686731310996421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016070528710966897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0611924110770566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04869066388240326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
atul0204_titanic-using-neural-network.py,"['numpy', 'pandas', 'tensorflow', 'keras', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,168,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'pd.read_csv', 'dataset.Embarked.dropna', 'None.mode', 'dataset.fillna', 'test_data.fillna', 'LabelEncoder', 'le_x.fit_transform', 'le_x.fit_transform', 'pd.get_dummies', 'pd.concat', 'pd.get_dummies', 'pd.concat', 'train_test_split', 'tf.logging.set_verbosity', 'tf.keras.layers.Dense', 'tf.keras.Sequential', 'model.compile', 'model.fit', 'print', 'model.predict_classes', 'confusion_matrix', 'accuracy_score', 'print', 'model.fit', 'model.predict_classes', 'print', 'flat_list.append', 'pd.DataFrame', 'submission.to_csv']","['print', 'read_csv', 'read_csv', 'Embarked', 'mode', 'fillna', 'fillna', 'LabelEncoder', 'fit_transform', 'fit_transform', 'get_dummies', 'concat', 'get_dummies', 'concat', 'train_test_split', 'logging', 'keras', 'keras', 'compile', 'fit', 'print', 'predict_classes', 'confusion_matrix', 'accuracy_score', 'print', 'fit', 'predict_classes', 'print', 'append', 'DataFrame', 'to_csv']","['print', 'read_csv', 'Embarked', 'mode', 'fillna', 'LabelEncoder', 'fit_transform', 'get_dummies', 'concat', 'train_test_split', 'logging', 'keras', 'compile', 'fit', 'predict_classes', 'confusion_matrix', 'accuracy_score', 'append', 'DataFrame', 'to_csv']",20,"[1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv embarked mode fillna fillna labelencoder fit transform fit transform get dummies concat get dummies concat train test split logging keras keras compile fit print predict classes confusion matrix accuracy score print fit predict classes print append dataframe csv,"[0.0, 0.0, 0.1437593598475591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11665659913787534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41694092838516056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18222520029093683, 0.0, 0.0, 0.2075978172405043, 0.0, 0.0, 0.163150050097535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.159516094943002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0666220733903306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19217889069274588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12068001434511952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13843655292332852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2343912833853277, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13962839230730542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45222373894806484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1386820098223506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28807444807506305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154132291688635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15580908738999918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12159287548950533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22688923030830296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1059167560553731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0894211873436138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0926430251790921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09660199642136758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0950800075321902, 0.0, 0.0, 0.0, 0.21631351785701258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
gomesbruna_titanic-survival-prediction-1.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 're\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,577,"[' # plots an axis lable', '# sets our legend for our graph.', 'titanic[""Deck""].unique() # 0 is for null values', 'titanic[""Deck""].unique() # Z is for null values', '# Create a family size variable including the passenger themselves', '# Discretize family size', '# The .apply method generates a new series', '    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.', '# Titles with very low cell counts to be combined to ""rare"" level', '# Also reassign mlle, ms, and mme accordingly', '#                \'Dr\', \'Major\', \'Rev\', \'Sir\', \'Jonkheer\']), ""Title""] = \'Rare Title\'', '# Titles with very low cell counts to be combined to ""rare"" level', '# Also reassign mlle, ms, and mme accordingly', '    # Split sets into train and test', '    # All age values are stored in a target array', '    # All the other values are stored in the feature array', '    # Create and fit a model', '    # Use the fitted model to predict the missing values', '    # Assign those predictions to the full data set', '# Import the linear regression class', '# Sklearn also has a helper that makes it easy to do cross validation', ""# The columns we'll use to predict the target"", '# Initialize our algorithm class', '# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.', '# We set random_state to ensure we get the same splits every time we run this.', ""    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds."", ""    # The target we're using to train the algorithm."", '    # Training the algorithm using the predictors and target.', '    # We can now make predictions on the test fold', '# Map predictions to outcomes (only possible outcomes are 1 and 0)', '# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.', '# We set random_state to ensure we get the same splits every time we run this.', ""    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds."", ""    # The target we're using to train the algorithm."", '    # Training the algorithm using the predictors and target.', '    # We can now make predictions on the test fold', '# Map predictions to outcomes (only possible outcomes are 1 and 0)']",37,"['pd.read_csv', 'pd.read_csv', 'titanic.describe', 'get_ipython', 'None.run_line_magic', 'sns.set', 'titanic.hist', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'sns.FacetGrid', 'g.map', 'None.add_legend', 'plt.subplots_adjust', 'g.fig.suptitle', 'titanic.Embarked.value_counts', 'None.plot', 'plt.title', 'sns.factorplot', 'sns.set', 'sns.factorplot', 'g.set_axis_labels', 'None.set_xticklabels', 'None.set_titles', 'None.set', 'None.despine', 'plt.subplots_adjust', 'g.fig.suptitle', 'sns.boxplot', 'sns.stripplot', 'sns.plt.title', 'titanic.Agetitanic.Pclass.plot', 'titanic.Agetitanic.Pclass.plot', 'titanic.Agetitanic.Pclass.plot', 'plt.xlabel', 'plt.title', 'plt.legend', 'titanic.corr', 'plt.figure', 'sns.heatmap', 'plt.title', 'titanic.corr', 'sns.factorplot', 'sns.boxplot', 'titanic.fillna', 'dfdfdf.median', 'df.fillna', 'fill_missing_fare', 'titanic.unique', 'sns.factorplot', 'titanic.assign', 'None.sort', 'sns.FacetGrid', 'g.map', 'titanic.Deck.fillna', 'titanic_test.Deck.fillna', 'titanic.unique', 'print', 'print', 'print', 'sns.factorplot', 'titanic.apply', 'titanic_test.apply', 'pd.cut', 'pd.cut', 'sns.factorplot', 'print', 're.search', 'title_search.group', 'titanic.apply', 'print', 'titanic.value_counts', 'titanic_test.apply', 'print', 'titanic_test.value_counts', 'titanic.str.extract', 'titanic.apply', 'titanic_test.str.extract', 'titanic_test.apply', 'titanic.TicketNumber.fillna', 'titanic_test.TicketNumber.fillna', 'LabelEncoder', 'labelEnc.fit_transform', 'labelEnc.fit_transform', 'titanic.head', 'sns.plotting_context', 'sns.set_style', 'sns.distplot', 'sns.plt.title', 'plt.ylabel', 'df.Age.notnull', 'df.Age.isnull', 'RandomForestRegressor', 'rtr.fit', 'rtr.predict', 'df.Age.isnull', 'fill_missing_age', 'fill_missing_age', 'sns.plotting_context', 'sns.set_style', 'sns.distplot', 'sns.plt.title', 'plt.ylabel', 'plt.xlim', 'preprocessing.StandardScaler', 'None.fit', 'std_scale.transform', 'preprocessing.StandardScaler', 'None.fit', 'std_scale.transform', 'titanic.corr', 'LinearRegression', 'KFold', 'alg.fit', 'alg.predict', 'predictions.append', 'np.concatenate', 'sum', 'len', 'accuracy_score', 'metrics.confusion_matrix', 'classification_report', 'KFold', 'alg.fit', 'alg.predict', 'predictionsF.append', 'np.concatenate', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'read_csv', 'describe', 'get_ipython', 'run_line_magic', 'set', 'hist', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'subplots_adjust', 'fig', 'Embarked', 'plot', 'title', 'factorplot', 'set', 'factorplot', 'set_axis_labels', 'set_xticklabels', 'set_titles', 'set', 'despine', 'subplots_adjust', 'fig', 'boxplot', 'stripplot', 'plt', 'Agetitanic', 'Agetitanic', 'Agetitanic', 'xlabel', 'title', 'legend', 'corr', 'figure', 'heatmap', 'title', 'corr', 'factorplot', 'boxplot', 'fillna', 'median', 'fillna', 'fill_missing_fare', 'unique', 'factorplot', 'assign', 'sort', 'FacetGrid', 'map', 'Deck', 'Deck', 'unique', 'print', 'print', 'print', 'factorplot', 'apply', 'apply', 'cut', 'cut', 'factorplot', 'print', 'search', 'group', 'apply', 'print', 'value_counts', 'apply', 'print', 'value_counts', 'str', 'apply', 'str', 'apply', 'TicketNumber', 'TicketNumber', 'LabelEncoder', 'fit_transform', 'fit_transform', 'head', 'plotting_context', 'set_style', 'distplot', 'plt', 'ylabel', 'Age', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'Age', 'fill_missing_age', 'fill_missing_age', 'plotting_context', 'set_style', 'distplot', 'plt', 'ylabel', 'xlim', 'StandardScaler', 'fit', 'transform', 'StandardScaler', 'fit', 'transform', 'corr', 'LinearRegression', 'KFold', 'fit', 'predict', 'append', 'concatenate', 'sum', 'len', 'accuracy_score', 'confusion_matrix', 'classification_report', 'KFold', 'fit', 'predict', 'append', 'concatenate', 'DataFrame', 'to_csv']","['read_csv', 'describe', 'get_ipython', 'run_line_magic', 'set', 'hist', 'FacetGrid', 'map', 'add_legend', 'subplots_adjust', 'fig', 'Embarked', 'plot', 'title', 'factorplot', 'set_axis_labels', 'set_xticklabels', 'set_titles', 'despine', 'boxplot', 'stripplot', 'plt', 'Agetitanic', 'xlabel', 'legend', 'corr', 'figure', 'heatmap', 'fillna', 'median', 'fill_missing_fare', 'unique', 'assign', 'sort', 'Deck', 'print', 'apply', 'cut', 'search', 'group', 'value_counts', 'str', 'TicketNumber', 'LabelEncoder', 'fit_transform', 'head', 'plotting_context', 'set_style', 'distplot', 'ylabel', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'fill_missing_age', 'xlim', 'StandardScaler', 'transform', 'LinearRegression', 'KFold', 'append', 'concatenate', 'sum', 'len', 'accuracy_score', 'confusion_matrix', 'classification_report', 'DataFrame', 'to_csv']",69,"[1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0
 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0
 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv describe get ipython run line magic set hist facetgrid map facetgrid map add legend facetgrid map add legend subplots adjust fig embarked plot title factorplot set factorplot set axis labels set xticklabels set titles set despine subplots adjust fig boxplot stripplot plt agetitanic agetitanic agetitanic xlabel title legend corr figure heatmap title corr factorplot boxplot fillna median fillna fill missing fare unique factorplot assign sort facetgrid map deck deck unique print print print factorplot apply apply cut cut factorplot print search group apply print value counts apply print value counts str apply str apply ticketnumber ticketnumber labelencoder fit transform fit transform head plotting context set style distplot plt ylabel age age randomforestregressor fit predict age fill missing age fill missing age plotting context set style distplot plt ylabel xlim standardscaler fit transform standardscaler fit transform corr linearregression kfold fit predict append concatenate sum len accuracy score confusion matrix classification report kfold fit predict append concatenate dataframe csv,"[0.0, 0.0, 0.047968790296455344, 0.0, 0.0, 0.07633853599181332, 0.16200151923261064, 0.19995213578694665, 0.0, 0.0, 0.0, 0.254050409642368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07785059625580139, 0.20201766239593455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08100075961630532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07130006259229038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10072968213224572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07799176623653988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15089539716705275, 0.0, 0.05443896347537694, 0.0, 0.15598353247307975, 0.0, 0.0, 0.1364657013049724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08053561600764947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05322640637342991, 0.0, 0.0, 0.0, 0.08804119616859439, 0.0, 0.0, 0.0, 0.022230067461100254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15598353247307975, 0.0, 0.0, 0.0, 0.0, 0.03172574604904562, 0.0, 0.0, 0.07544769858352637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09684195343169211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040267808003824734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16451627907543956, 0.30533288604108716, 0.0, 0.0, 0.0, 0.0, 0.05036484106612286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15598353247307975, 0.039185205418583086, 0.0, 0.0, 0.21390018777687114, 0.046192706920682905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1368680695358756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0232951964905889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061804384004345014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02114151220785287, 0.04267260249389121, 0.0, 0.042037763770536946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029397417048046662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11463290400210947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046274609556646876, 0.07324392694256718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10214707249030591, 0.041426443073060544, 0.0, 0.0, 0.0, 0.0, 0.029837543713983693, 0.0, 0.0, 0.07544769858352637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02968952683063772, 0.0, 0.0, 0.12428818348030445, 0.0, 0.0514299700956115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04437553158898906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21973178082770153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034049024163435304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1391224333561663, 0.24300227884891595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06085860933247038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11356062576437458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07324392694256718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03534168951147617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07324392694256718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029542825670325647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029837543713983693, 0.0, 0.061804384004345014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2551463877727753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03652924735823318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10887792695075388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09872861227628138, 0.0, 0.0, 0.0, 0.0, 0.08100075961630532, 0.08804119616859439, 0.0, 0.0, 0.0, 0.0, 0.08225813953771978, 0.031395659608530656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16936693976157868, 0.0, 0.0, 0.09989617053941956, 0.07799176623653988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14435648276918456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10758334754606753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08053561600764947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04548856710165747, 0.06956121667808315, 0.052568612707082046, 0.0, 0.0, 0.08804119616859439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
elshera_titanic-dataset-predicting-survivals.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,399,"['# Load the neccessary Libraries', '# Explore the dataset to see values, datatypes, nan values', '# data dimensions', '# show some initial rows ', '# For the Cathegorical variables we should see the set of their values over all samples.', '# Let see if the 209 cabines in the dataset host each one person or more', '# Are the Ticket unique', '# It makes sense to extract those columns which contain booleant values like 0-1 or Trus - False. ', '# Embarked have 2 missing values. With low error we can fill them based on the most likely value.', '# The most recurrent value is ""S"" therefore we can fill the missing values in Embarked with S and replace labels with ', '# numbers', '# Could replace SibSp and Parch with one column, called Family, indicating the overall family number. ', '# I do not see much difference if one is a brother or a sister from beeing a mother or a father.', '# Consider now replacing the Sex type from a label to a number.', '# Consider the distribution of the age', '# generate random numbers age_mean', '# fill in the randome values to the missing age values', '# convert from float to int', '# There are some columns which can be dropped already', '# finally look at the dataset', '# To better consider correlation between the various fields, we might use a correlation matrix.', '# collect all the survival', '# create groups based on them', '# Prepare the data. One of the first things to do is to split between the target to be predicted Y, and the variable ', '# before creating the feature matriy we need to drop the target ""Survived""', '# create features matrix', '# show the second row', '# load and prepare the test data.', '# We already know the data to be dropped', '# Filling missing data from the Age', '# Consider now replacing the Sex type from a label to a number.', '# Could replace SibSp and Parch with one column, called Family', '# We can drop now SibSp and Parch', '# create features matrix', '# Linear Regression', '# Random Forests', '# Support Vector Machine', '# If 3 or more out of 5 predictors vote for 1 than we have Survived = 1 otherwise we have Survived = 0']",38,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'df.info', 'df.head', 'print', 'print', 'print', 'print', 'print', 'print', 'df.columns.tolist', 'dfcol.unique', 'dfcol.unique', 'print', 'print', 'print', 'print', 'df.fillna', 'df.map', 'df.map', 'df.mean', 'df.std', 'np.random.randint', 'np.isnan', 'df.astype', 'df.drop', 'df.info', 'df.head', 'df.drop', 'df.info', 'df.head', 'df.describe', 'df.corr', 'plt.figure', 'sns.heatmap', 'plt.title', 'plt.show', 'df.drop', 'df.head', 'Survive.groupby', 'Survive.groupby', 'Survive.groupby', 'Survive.groupby', 'Survive.groupby', 'print', 'print', 'print', 'print', 'by_age.count', 'df.groupby', 'None.count', 'df.groupby', 'None.count', 'age_distribution.hist', 'np.shape', 'df.drop', 'df.info', 'df.head', 'df.as_matrix', 'print', 'pd.read_csv', 'df_test.info', 'df_test.drop', 'df_test.head', 'df_test.mean', 'df_test.std', 'np.random.randint', 'np.isnan', 'df_test.astype', 'df_test.map', 'df_test.map', 'df_test.drop', 'df_test.info', 'df_test.head', 'df_test.as_matrix', 'print', 'LogisticRegression', 'logistic.fit', 'logistic.predict', 'logistic.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'SVC', 'None.fit', 'svc.predict', 'svc.score', 'tree.DecisionTreeClassifier', 'None.fit', 'clf.predict', 'clf.score', 'KNeighborsClassifier', 'knb.fit', 'knb.predict', 'knb.score', 'GaussianNB', 'gaus.fit', 'gaus.predict', 'gaus.score', 'type', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'info', 'head', 'print', 'print', 'print', 'print', 'print', 'print', 'columns', 'unique', 'unique', 'print', 'print', 'print', 'print', 'fillna', 'map', 'map', 'mean', 'std', 'random', 'isnan', 'astype', 'drop', 'info', 'head', 'drop', 'info', 'head', 'describe', 'corr', 'figure', 'heatmap', 'title', 'show', 'drop', 'head', 'groupby', 'groupby', 'groupby', 'groupby', 'groupby', 'print', 'print', 'print', 'print', 'count', 'groupby', 'count', 'groupby', 'count', 'hist', 'shape', 'drop', 'info', 'head', 'as_matrix', 'print', 'read_csv', 'info', 'drop', 'head', 'mean', 'std', 'random', 'isnan', 'astype', 'map', 'map', 'drop', 'info', 'head', 'as_matrix', 'print', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'SVC', 'fit', 'predict', 'score', 'DecisionTreeClassifier', 'fit', 'predict', 'score', 'KNeighborsClassifier', 'fit', 'predict', 'score', 'GaussianNB', 'fit', 'predict', 'score', 'type', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'info', 'head', 'print', 'columns', 'unique', 'fillna', 'map', 'mean', 'std', 'random', 'isnan', 'astype', 'drop', 'describe', 'corr', 'figure', 'heatmap', 'title', 'show', 'groupby', 'count', 'hist', 'shape', 'as_matrix', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'GaussianNB', 'type', 'DataFrame', 'to_csv']",39,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv info head print print print print print print columns unique unique print print print print fillna map map mean std random isnan astype drop info head drop info head describe corr figure heatmap title show drop head groupby groupby groupby groupby groupby print print print print count groupby count groupby count hist shape drop info head matrix print read csv info drop head mean std random isnan astype map map drop info head matrix print logisticregression fit predict score randomforestclassifier fit predict score svc fit predict score decisiontreeclassifier fit predict score kneighborsclassifier fit predict score gaussiannb fit predict score type dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09186777593257765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10570973128739945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07072670597969628, 0.0, 0.0, 0.2373694164590779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08275768250770513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034563837583988496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06052197928573004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04932794448729955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2118202992476012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06092608932263211, 0.0, 0.0, 0.0, 0.03591075965840194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18240491111484047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07458301598986805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03621992553089456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3347264925635898, 0.0, 0.0, 0.0, 0.0, 0.23009928191067164, 0.06634837723573683, 0.0, 0.06536131489035979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2729021577767101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045707803182130746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15503767577469904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06175391779057156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04639212258981809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04616198241932105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04616198241932105, 0.0, 0.0, 0.1932462236086073, 0.0, 0.1599290813169777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09917691795752961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18924882636868093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47084469797186107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1520179275325541, 0.04460632691767231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054950099380308086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045933887966288826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27835273553890855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12594190748439155, 0.06012413477370499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15824627763938526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058966323784081294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05177364725843888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11730787612273201, 0.1672731474086144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
naimur978_titanic-who-s-gonna-survive-public-score-81.py,"['datetime', 'numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn', 'xgboost', 'lightgbm', 'catboost', 'IPython', 'warnings\n', 'sys\n', 're\n', 'statistics']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",15,1056,"['# machine learning models', '# preprocessing functions and evaluation models', ""# Let's be rebels and ignore warnings for now"", '# console ascii color code, not necessarry to use', ' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ', '# loop through all columns to see if there are any outliers', '# Create dummy classifer', '# train the model', '# Get accuracy score', '# create scaler', '# apply normalization to training set and transform training set', '# transform validation set', '# function to train a given model, generate predictions, and return accuracy score', '# create model apply fit_evaluate_model', '# create model apply fit_evaluate_model', '# create model apply fit_evaluate_model', '# create model apply fit_evaluate_model', '# create model apply fit_evaluate_model', '# create model apply fit_evaluate_model', '# create dataframe of accuracy and model and sort values', '# The number of trees in the forest algorithm, default value is 10.', '# The minimum number of samples required to split an internal node, default value is 2.', '# The minimum number of samples required to be at a leaf node, default value is 1.', '# The number of features to consider when looking for the best split, default value is auto.', '# Define the grid of hyperparameters to search', '# create model', '# create Randomized search object', '# Fit on the all training data using random search object', '# Create a range of trees to evaluate', '# 100, 200, 300, 400, 500, 600, 700', '# 50, 100, 150, 200, 250, 300, 350', '# define all parameters except n_estimators', '# Grid Search Object using the trees range, the model and 5-fold cross validation', '# fit the dataset to grid search object', '# Get the results into a dataframe', '# Plot the training and testing error vs number of trees', '# set title, labels and legend', '# Feature Importance', '# Plot the feature importance scores']",41,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
bhavinmoriya_titanic-starts-off.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,78,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'print', 'sum', 'len', 'print', 'sum', 'len', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'print', 'sum', 'len', 'print', 'sum', 'len', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'sum', 'len', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",12,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head print sum len print sum len print get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2827087709022059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11807363068828185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34059671533777763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10385232860002956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24746199552060358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22458367335051466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4400679888801011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10774891521882464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5026418764696403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15237980904290085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18771520161061298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33351221487019117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20015532527977833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
vardos_leaning-titanic.py,['sample'],"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",1,14,"['{""cells"":[{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""c9c0744f-9e2d-223c-acce-38c9ef8235d2""},""source"":[""# Test 1""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""5767a33c-8f18-4034-e52d-bf7a8f7d8ab8""},""outputs"":[],""source"":[""# data analysis and wrangling\\n"",""import pandas as pd\\n"",""import numpy as np\\n"",""import random as rnd\\n"",""\\n"",""# visualization\\n"",""import seaborn as sns\\n"",""import matplotlib.pyplot as plt\\n"",""%matplotlib inline\\n"",""\\n"",""# machine learning\\n"",""from sklearn.linear_model import LogisticRegression\\n"",""from sklearn.svm import SVC, LinearSVC\\n"",""from sklearn.ensemble import RandomForestClassifier\\n"",""from sklearn.neighbors import KNeighborsClassifier\\n"",""from sklearn.naive_bayes import GaussianNB\\n"",""from sklearn.linear_model import Perceptron\\n"",""from sklearn.linear_model import SGDClassifier\\n"",""from sklearn.tree import DecisionTreeClassifier""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""6b5dc743-15b1-aac6-405e-081def6ecca1""},""source"":[""## Acquire data\\n"",""\\n"",""The Python Pandas packages helps us work with our datasets. We start by acquiring the training and testing datasets into Pandas DataFrames. We also combine these datasets to run certain operations on both datasets together.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""e7319668-86fe-8adc-438d-0eef3fd0a982""},""outputs"":[],""source"":[""train_df = pd.read_csv(\'../input/train.csv\')\\n"",""test_df = pd.read_csv(\'../input/test.csv\')\\n"",""combine = [train_df, test_df]""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""3d6188f3-dc82-8ae6-dabd-83e28fcbf10d""},""source"":[""## Analyze by describing data\\n"",""\\n"",""Pandas also helps describe the datasets answering following questions early in our project.\\n"",""\\n"",""**Which features are available in the dataset?**\\n"",""\\n"",""Noting the feature names for directly manipulating or analyzing these. These feature names are described on the [Kaggle data page here](https://www.kaggle.com/c/titanic/data).""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""ce473d29-8d19-76b8-24a4-48c217286e42""},""outputs"":[],""source"":[""print(train_df.columns.values)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""cd19a6f6-347f-be19-607b-dca950590b37""},""source"":[""**Which features are categorical?**\\n"",""\\n"",""These values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, ratio, or interval based? Among other things this helps us select the appropriate plots for visualization.\\n"",""\\n"",""- Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\\n"",""\\n"",""**Which features are numerical?**\\n"",""\\n"",""Which features are numerical? These values change from sample to sample. Within numerical features are the values discrete, continuous, or timeseries based? Among other things this helps us select the appropriate plots for visualization.\\n"",""\\n"",""- Continous: Age, Fare. Discrete: SibSp, Parch.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""8d7ac195-ac1a-30a4-3f3f-80b8cf2c1c0f""},""outputs"":[],""source"":[""# preview the data\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""97f4e6f8-2fea-46c4-e4e8-b69062ee3d46""},""source"":[""**Which features are mixed data types?**\\n"",""\\n"",""Numerical, alphanumeric data within same feature. These are candidates for correcting goal.\\n"",""\\n"",""- Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric.\\n"",""\\n"",""**Which features may contain errors or typos?**\\n"",""\\n"",""This is harder to review for a large dataset, however reviewing a few samples from a smaller dataset may just tell us outright, which features may require correcting.\\n"",""\\n"",""- Name feature may contain errors or typos as there are several ways used to describe a name including titles, round brackets, and quotes used for alternative or short names.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""f6e761c2-e2ff-d300-164c-af257083bb46""},""outputs"":[],""source"":[""train_df.tail()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""8bfe9610-689a-29b2-26ee-f67cd4719079""},""source"":[""**Which features contain blank, null or empty values?**\\n"",""\\n"",""These will require correcting.\\n"",""\\n"",""- Cabin > Age > Embarked features contain a number of null values in that order for the training dataset.\\n"",""- Cabin > Age are incomplete in case of test dataset.\\n"",""\\n"",""**What are the data types for various features?**\\n"",""\\n"",""Helping us during converting goal.\\n"",""\\n"",""- Seven features are integer or floats. Six in case of test dataset.\\n"",""- Five features are strings (object).""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""9b805f69-665a-2b2e-f31d-50d87d52865d""},""outputs"":[],""source"":[""train_df.info()\\n"",""print(\'_\'*40)\\n"",""test_df.info()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""859102e1-10df-d451-2649-2d4571e5f082""},""source"":[""**What is the distribution of numerical feature values across the samples?**\\n"",""\\n"",""This helps us determine, among other early insights, how representative is the training dataset of the actual problem domain.\\n"",""\\n"",""- Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\\n"",""- Survived is a categorical feature with 0 or 1 values.\\n"",""- Around 38% samples survived representative of the actual survival rate at 32%.\\n"",""- Most passengers (> 75%) did not travel with parents or children.\\n"",""- Nearly 30% of the passengers had siblings and/or spouse aboard.\\n"",""- Fares varied significantly with few passengers (<1%) paying as high as $512.\\n"",""- Few elderly passengers (<1%) within age range 65-80.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""58e387fe-86e4-e068-8307-70e37fe3f37b""},""outputs"":[],""source"":[""train_df.describe()\\n"",""# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.\\n"",""# Review Parch distribution using `percentiles=[.75, .8]`\\n"",""# SibSp distribution `[.68, .69]`\\n"",""# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""5462bc60-258c-76bf-0a73-9adc00a2f493""},""source"":[""**What is the distribution of categorical features?**\\n"",""\\n"",""- Names are unique across the dataset (count=unique=891)\\n"",""- Sex variable as two possible values with 65% male (top=male, freq=577/count=891).\\n"",""- Cabin values have several dupicates across samples. Alternatively several passengers shared a cabin.\\n"",""- Embarked takes three possible values. S port used by most passengers (top=S)\\n"",""- Ticket feature has high ratio (22%) of duplicate values (unique=681).""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""8066b378-1964-92e8-1352-dcac934c6af3""},""outputs"":[],""source"":[""train_df.describe(include=[\'O\'])""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""2cb22b88-937d-6f14-8b06-ea3361357889""},""source"":[""### Assumtions based on data analysis\\n"",""\\n"",""We arrive at following assumptions based on data analysis done so far. We may validate these assumptions further before taking appropriate actions.\\n"",""\\n"",""**Correlating.**\\n"",""\\n"",""We want to know how well does each feature correlate with Survival. We want to do this early in our project and match these quick correlations with modelled correlations later in the project.\\n"",""\\n"",""**Completing.**\\n"",""\\n"",""1. We may want to complete Age feature as it is definitely correlated to survival.\\n"",""2. We may want to complete the Embarked feature as it may also correlate with survival or another important feature.\\n"",""\\n"",""**Correcting.**\\n"",""\\n"",""1. Ticket feature may be dropped from our analysis as it contains high ratio of duplicates (22%) and there may not be a correlation between Ticket and survival.\\n"",""2. Cabin feature may be dropped as it is highly incomplete or contains many null values both in training and test dataset.\\n"",""3. PassengerId may be dropped from training dataset as it does not contribute to survival.\\n"",""4. Name feature is relatively non-standard, may not contribute directly to survival, so maybe dropped.\\n"",""\\n"",""**Creating.**\\n"",""\\n"",""1. We may want to create a new feature called Family based on Parch and SibSp to get total count of family members on board.\\n"",""2. We may want to engineer the Name feature to extract Title as a new feature.\\n"",""3. We may want to create new feature for Age bands. This turns a continous numerical feature into an ordinal categorical feature.\\n"",""4. We may also want to create a Fare range feature if it helps our analysis.\\n"",""\\n"",""**Classifying.**\\n"",""\\n"",""We may also add to our assumptions based on the problem description noted earlier.\\n"",""\\n"",""1. Women (Sex=female) were more likely to have survived.\\n"",""2. Children (Age<?) were more likely to have survived. \\n"",""3. The upper-class passengers (Pclass=1) were more likely to have survived.""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""6db63a30-1d86-266e-2799-dded03c45816""},""source"":[""## Analyze by pivoting features\\n"",""\\n"",""To confirm some of our observations and assumptions, we can quickly analyze our feature correlations by pivoting features against each other. We can only do so at this stage for features which do not have any empty values. It also makes sense doing so only for features which are categorical (Sex), ordinal (Pclass) or discrete (SibSp, Parch) type.\\n"",""\\n"",""- **Pclass** We observe significant correlation (>0.5) among Pclass=1 and Survived (classifying #3). We decide to include this feature in our model.\\n"",""- **Sex** We confirm the observation during problem definition that Sex=female had very high survival rate at 74% (classifying #1).\\n"",""- **SibSp and Parch** These features have zero correlation for certain values. It may be best to derive a feature or a set of features from these individual features (creating #1).""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""0964832a-a4be-2d6f-a89e-63526389cee9""},""outputs"":[],""source"":[""train_df[[\'Pclass\', \'Survived\']].groupby([\'Pclass\'], as_index=False).mean().sort_values(by=\'Survived\', ascending=False)""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""68908ba6-bfe9-5b31-cfde-6987fc0fbe9a""},""outputs"":[],""source"":[""train_df[[\\""Sex\\"", \\""Survived\\""]].groupby([\'Sex\'], as_index=False).mean().sort_values(by=\'Survived\', ascending=False)""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""01c06927-c5a6-342a-5aa8-2e486ec3fd7c""},""outputs"":[],""source"":[""train_df[[\\""SibSp\\"", \\""Survived\\""]].groupby([\'SibSp\'], as_index=False).mean().sort_values(by=\'Survived\', ascending=False)""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""e686f98b-a8c9-68f8-36a4-d4598638bbd5""},""outputs"":[],""source"":[""train_df[[\\""Parch\\"", \\""Survived\\""]].groupby([\'Parch\'], as_index=False).mean().sort_values(by=\'Survived\', ascending=False)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""0d43550e-9eff-3859-3568-8856570eff76""},""source"":[""## Analyze by visualizing data\\n"",""\\n"",""Now we can continue confirming some of our assumptions using visualizations for analyzing the data.\\n"",""\\n"",""### Correlating numerical features\\n"",""\\n"",""Let us start by understanding correlations between numerical features and our solution goal (Survived).\\n"",""\\n"",""A histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have better survival rate?)\\n"",""\\n"",""Note that x-axis in historgram visualizations represents the count of samples or passengers.\\n"",""\\n"",""**Observations.**\\n"",""\\n"",""- Infants (Age <=4) had high survival rate.\\n"",""- Oldest passengers (Age = 80) survived.\\n"",""- Large number of 15-25 year olds did not survive.\\n"",""- Most passengers are in 15-35 age range.\\n"",""\\n"",""**Decisions.**\\n"",""\\n"",""This simple analysis confirms our assumptions as decisions for subsequent workflow stages.\\n"",""\\n"",""- We should consider Age (our assumption classifying #2) in our model training.\\n"",""- Complete the Age feature for null values (completing #1).\\n"",""- We should band age groups (creating #3).""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""50294eac-263a-af78-cb7e-3778eb9ad41f""},""outputs"":[],""source"":[""g = sns.FacetGrid(train_df, col=\'Survived\')\\n"",""g.map(plt.hist, \'Age\', bins=20)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""87096158-4017-9213-7225-a19aea67a800""},""source"":[""### Correlating numerical and ordinal features\\n"",""\\n"",""We can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\\n"",""\\n"",""**Observations.**\\n"",""\\n"",""- Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\\n"",""- Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\\n"",""- Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\\n"",""- Pclass varies in terms of Age distribution of passengers.\\n"",""\\n"",""**Decisions.**\\n"",""\\n"",""- Consider Pclass for model training.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""916fdc6b-0190-9267-1ea9-907a3d87330d""},""outputs"":[],""source"":[""# grid = sns.FacetGrid(train_df, col=\'Pclass\', hue=\'Survived\')\\n"",""grid = sns.FacetGrid(train_df, col=\'Survived\', row=\'Pclass\', size=2.2, aspect=1.6)\\n"",""grid.map(plt.hist, \'Age\', alpha=.5, bins=20)\\n"",""grid.add_legend();""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""36f5a7c0-c55c-f76f-fdf8-945a32a68cb0""},""source"":[""### Correlating categorical features\\n"",""\\n"",""Now we can correlate categorical features with our solution goal.\\n"",""\\n"",""**Observations.**\\n"",""\\n"",""- Female passengers had much better survival rate than males. Confirms classifying (#1).\\n"",""- Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\\n"",""- Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\\n"",""- Ports of embarkation have varying survival rates for Pclass=3 and among male passengers. Correlating (#1).\\n"",""\\n"",""**Decisions.**\\n"",""\\n"",""- Add Sex feature to model training.\\n"",""- Complete and add Embarked feature to model training.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""db57aabd-0e26-9ff9-9ebd-56d401cdf6e8""},""outputs"":[],""source"":[""# grid = sns.FacetGrid(train_df, col=\'Embarked\')\\n"",""grid = sns.FacetGrid(train_df, row=\'Embarked\', size=2.2, aspect=1.6)\\n"",""grid.map(sns.pointplot, \'Pclass\', \'Survived\', \'Sex\', palette=\'deep\')\\n"",""grid.add_legend()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""6b3f73f4-4600-c1ce-34e0-bd7d9eeb074a""},""source"":[""### Correlating categorical and numerical features\\n"",""\\n"",""We may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\\n"",""\\n"",""**Observations.**\\n"",""\\n"",""- Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\\n"",""- Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\\n"",""\\n"",""**Decisions.**\\n"",""\\n"",""- Consider banding Fare feature.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""a21f66ac-c30d-f429-cc64-1da5460d16a9""},""outputs"":[],""source"":[""# grid = sns.FacetGrid(train_df, col=\'Embarked\', hue=\'Survived\', palette={0: \'k\', 1: \'w\'})\\n"",""grid = sns.FacetGrid(train_df, row=\'Embarked\', col=\'Survived\', size=2.2, aspect=1.6)\\n"",""grid.map(sns.barplot, \'Sex\', \'Fare\', alpha=.5, ci=None)\\n"",""grid.add_legend()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""cfac6291-33cc-506e-e548-6cad9408623d""},""source"":[""## Wrangle data\\n"",""\\n"",""We have collected several assumptions and decisions regarding our datasets and solution requirements. So far we did not have to change a single feature or value to arrive at these. Let us now execute our decisions and assumptions for correcting, creating, and completing goals.\\n"",""\\n"",""### Correcting by dropping features\\n"",""\\n"",""This is a good starting goal to execute. By dropping features we are dealing with fewer data points. Speeds up our notebook and eases the analysis.\\n"",""\\n"",""Based on our assumptions and decisions we want to drop the Cabin (correcting #2) and Ticket (correcting #1) features.\\n"",""\\n"",""Note that where applicable we perform operations on both training and testing datasets together to stay consistent.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""da057efe-88f0-bf49-917b-bb2fec418ed9""},""outputs"":[],""source"":[""print(\\""Before\\"", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\\n"",""\\n"",""train_df = train_df.drop([\'Ticket\', \'Cabin\'], axis=1)\\n"",""test_df = test_df.drop([\'Ticket\', \'Cabin\'], axis=1)\\n"",""combine = [train_df, test_df]\\n"",""\\n"",""\\""After\\"", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""6b3a1216-64b6-7fe2-50bc-e89cc964a41c""},""source"":[""### Creating new feature extracting from existing\\n"",""\\n"",""We want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\\n"",""\\n"",""In the following code we extract Title feature using regular expressions. The RegEx pattern `(\\\\w+\\\\.)` matches the first word which ends with a dot character within Name feature. The `expand=False` flag returns a DataFrame.\\n"",""\\n"",""**Observations.**\\n"",""\\n"",""When we plot Title, Age, and Survived, we note the following observations.\\n"",""\\n"",""- Most titles band Age groups accurately. For example: Master title has Age mean of 5 years.\\n"",""- Survival among Title Age bands varies slightly.\\n"",""- Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).\\n"",""\\n"",""**Decision.**\\n"",""\\n"",""- We decide to retain the new Title feature for model training.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""df7f0cd4-992c-4a79-fb19-bf6f0c024d4b""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'Title\'] = dataset.Name.str.extract(\' ([A-Za-z]+)\\\\.\', expand=False)\\n"",""\\n"",""pd.crosstab(train_df[\'Title\'], train_df[\'Sex\'])""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""908c08a6-3395-19a5-0cd7-13341054012a""},""source"":[""We can replace many titles with a more common name or classify them as `Rare`.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""553f56d7-002a-ee63-21a4-c0efad10cfe9""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'Title\'] = dataset[\'Title\'].replace([\'Lady\', \'Countess\',\'Capt\', \'Col\',\\\\\\n"","" \\t\'Don\', \'Dr\', \'Major\', \'Rev\', \'Sir\', \'Jonkheer\', \'Dona\'], \'Rare\')\\n"",""\\n"",""    dataset[\'Title\'] = dataset[\'Title\'].replace(\'Mlle\', \'Miss\')\\n"",""    dataset[\'Title\'] = dataset[\'Title\'].replace(\'Ms\', \'Miss\')\\n"",""    dataset[\'Title\'] = dataset[\'Title\'].replace(\'Mme\', \'Mrs\')\\n"",""    \\n"",""train_df[[\'Title\', \'Survived\']].groupby([\'Title\'], as_index=False).mean()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""6d46be9a-812a-f334-73b9-56ed912c9eca""},""source"":[""We can convert the categorical titles to ordinal.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""67444ebc-4d11-bac1-74a6-059133b6e2e8""},""outputs"":[],""source"":[""title_mapping = {\\""Mr\\"": 1, \\""Miss\\"": 2, \\""Mrs\\"": 3, \\""Master\\"": 4, \\""Rare\\"": 5}\\n"",""for dataset in combine:\\n"",""    dataset[\'Title\'] = dataset[\'Title\'].map(title_mapping)\\n"",""    dataset[\'Title\'] = dataset[\'Title\'].fillna(0)\\n"",""\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""f27bb974-a3d7-07a1-f7e4-876f6da87e62""},""source"":[""Now we can safely drop the Name feature from training and testing datasets. We also do not need the PassengerId feature in the training dataset.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""9d61dded-5ff0-5018-7580-aecb4ea17506""},""outputs"":[],""source"":[""train_df = train_df.drop([\'Name\', \'PassengerId\'], axis=1)\\n"",""test_df = test_df.drop([\'Name\'], axis=1)\\n"",""combine = [train_df, test_df]\\n"",""train_df.shape, test_df.shape""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""2c8e84bb-196d-bd4a-4df9-f5213561b5d3""},""source"":[""### Converting a categorical feature\\n"",""\\n"",""Now we can convert features which contain strings to numerical values. This is required by most model algorithms. Doing so will also help us in achieving the feature completing goal.\\n"",""\\n"",""Let us start by converting Sex feature to a new feature called Gender where female=1 and male=0.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""c20c1df2-157c-e5a0-3e24-15a828095c96""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'Sex\'] = dataset[\'Sex\'].map( {\'female\': 1, \'male\': 0} ).astype(int)\\n"",""\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""d72cb29e-5034-1597-b459-83a9640d3d3a""},""source"":[""### Completing a numerical continuous feature\\n"",""\\n"",""Now we should start estimating and completing features with missing or null values. We will first do this for the Age feature.\\n"",""\\n"",""We can consider three methods to complete a numerical continuous feature.\\n"",""\\n"",""1. A simple way is to generate random numbers between mean and [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation).\\n"",""\\n"",""2. More accurate way of guessing missing values is to use other correlated features. In our case we note correlation among Age, Gender, and Pclass. Guess Age values using [median](https://en.wikipedia.org/wiki/Median) values for Age across sets of Pclass and Gender feature combinations. So, median Age for Pclass=1 and Gender=0, Pclass=1 and Gender=1, and so on...\\n"",""\\n"",""3. Combine methods 1 and 2. So instead of guessing age values based on median, use random numbers between mean and standard deviation, based on sets of Pclass and Gender combinations.\\n"",""\\n"",""Method 1 and 3 will introduce random noise into our models. The results from multiple executions might vary. We will prefer method 2.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""c311c43d-6554-3b52-8ef8-533ca08b2f68""},""outputs"":[],""source"":[""# grid = sns.FacetGrid(train_df, col=\'Pclass\', hue=\'Gender\')\\n"",""grid = sns.FacetGrid(train_df, row=\'Pclass\', col=\'Sex\', size=2.2, aspect=1.6)\\n"",""grid.map(plt.hist, \'Age\', alpha=.5, bins=20)\\n"",""grid.add_legend()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""a4f166f9-f5f9-1819-66c3-d89dd5b0d8ff""},""source"":[""Let us start by preparing an empty array to contain guessed Age values based on Pclass x Gender combinations.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""9299523c-dcf1-fb00-e52f-e2fb860a3920""},""outputs"":[],""source"":[""guess_ages = np.zeros((2,3))\\n"",""guess_ages""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""ec9fed37-16b1-5518-4fa8-0a7f579dbc82""},""source"":[""Now we iterate over Sex (0 or 1) and Pclass (1, 2, 3) to calculate guessed values of Age for the six combinations.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""a4015dfa-a0ab-65bc-0cbe-efecf1eb2569""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    for i in range(0, 2):\\n"",""        for j in range(0, 3):\\n"",""            guess_df = dataset[(dataset[\'Sex\'] == i) & \\\\\\n"",""                                  (dataset[\'Pclass\'] == j+1)][\'Age\'].dropna()\\n"",""\\n"",""            # age_mean = guess_df.mean()\\n"",""            # age_std = guess_df.std()\\n"",""            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\\n"",""\\n"",""            age_guess = guess_df.median()\\n"",""\\n"",""            # Convert random age float to nearest .5 age\\n"",""            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\\n"",""            \\n"",""    for i in range(0, 2):\\n"",""        for j in range(0, 3):\\n"",""            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\\\\n"",""                    \'Age\'] = guess_ages[i,j]\\n"",""\\n"",""    dataset[\'Age\'] = dataset[\'Age\'].astype(int)\\n"",""\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""dbe0a8bf-40bc-c581-e10e-76f07b3b71d4""},""source"":[""Let us create Age bands and determine correlations with Survived.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""725d1c84-6323-9d70-5812-baf9994d3aa1""},""outputs"":[],""source"":[""train_df[\'AgeBand\'] = pd.cut(train_df[\'Age\'], 5)\\n"",""train_df[[\'AgeBand\', \'Survived\']].groupby([\'AgeBand\'], as_index=False).mean().sort_values(by=\'AgeBand\', ascending=True)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""ba4be3a0-e524-9c57-fbec-c8ecc5cde5c6""},""source"":[""Let us replace Age with ordinals based on these bands.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""797b986d-2c45-a9ee-e5b5-088de817c8b2""},""outputs"":[],""source"":[""for dataset in combine:    \\n"",""    dataset.loc[ dataset[\'Age\'] <= 16, \'Age\'] = 0\\n"",""    dataset.loc[(dataset[\'Age\'] > 16) & (dataset[\'Age\'] <= 32), \'Age\'] = 1\\n"",""    dataset.loc[(dataset[\'Age\'] > 32) & (dataset[\'Age\'] <= 48), \'Age\'] = 2\\n"",""    dataset.loc[(dataset[\'Age\'] > 48) & (dataset[\'Age\'] <= 64), \'Age\'] = 3\\n"",""    dataset.loc[ dataset[\'Age\'] > 64, \'Age\']\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""004568b6-dd9a-ff89-43d5-13d4e9370b1d""},""source"":[""We can not remove the AgeBand feature.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""875e55d4-51b0-5061-b72c-8a23946133a3""},""outputs"":[],""source"":[""train_df = train_df.drop([\'AgeBand\'], axis=1)\\n"",""combine = [train_df, test_df]\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""1c237b76-d7ac-098f-0156-480a838a64a9""},""source"":[""### Create new feature combining existing features\\n"",""\\n"",""We can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""7e6c04ed-cfaa-3139-4378-574fd095d6ba""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'FamilySize\'] = dataset[\'SibSp\'] + dataset[\'Parch\'] + 1\\n"",""\\n"",""train_df[[\'FamilySize\', \'Survived\']].groupby([\'FamilySize\'], as_index=False).mean().sort_values(by=\'Survived\', ascending=False)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""842188e6-acf8-2476-ccec-9e3451e4fa86""},""source"":[""We can create another feature called IsAlone.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""5c778c69-a9ae-1b6b-44fe-a0898d07be7a""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'IsAlone\'] = 0\\n"",""    dataset.loc[dataset[\'FamilySize\'] == 1, \'IsAlone\'] = 1\\n"",""\\n"",""train_df[[\'IsAlone\', \'Survived\']].groupby([\'IsAlone\'], as_index=False).mean()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""e6b87c09-e7b2-f098-5b04-4360080d26bc""},""source"":[""Let us drop Parch, SibSp, and FamilySize features in favor of IsAlone.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""74ee56a6-7357-f3bc-b605-6c41f8aa6566""},""outputs"":[],""source"":[""train_df = train_df.drop([\'Parch\', \'SibSp\', \'FamilySize\'], axis=1)\\n"",""test_df = test_df.drop([\'Parch\', \'SibSp\', \'FamilySize\'], axis=1)\\n"",""combine = [train_df, test_df]\\n"",""\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""f890b730-b1fe-919e-fb07-352fbd7edd44""},""source"":[""We can also create an artificial feature combining Pclass and Age.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""305402aa-1ea1-c245-c367-056eef8fe453""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'Age*Class\'] = dataset.Age * dataset.Pclass\\n"",""\\n"",""train_df.loc[:, [\'Age*Class\', \'Age\', \'Pclass\']].head(10)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""13292c1b-020d-d9aa-525c-941331bb996a""},""source"":[""### Completing a categorical feature\\n"",""\\n"",""Embarked feature takes S, Q, C values based on port of embarkation. Our training dataset has two missing values. We simply fill these with the most common occurance.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""bf351113-9b7f-ef56-7211-e8dd00665b18""},""outputs"":[],""source"":[""freq_port = train_df.Embarked.dropna().mode()[0]\\n"",""freq_port""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""51c21fcc-f066-cd80-18c8-3d140be6cbae""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'Embarked\'] = dataset[\'Embarked\'].fillna(freq_port)\\n"",""    \\n"",""train_df[[\'Embarked\', \'Survived\']].groupby([\'Embarked\'], as_index=False).mean().sort_values(by=\'Survived\', ascending=False)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""f6acf7b2-0db3-e583-de50-7e14b495de34""},""source"":[""### Converting categorical feature to numeric\\n"",""\\n"",""We can now convert the EmbarkedFill feature by creating a new numeric Port feature.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""89a91d76-2cc0-9bbb-c5c5-3c9ecae33c66""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset[\'Embarked\'] = dataset[\'Embarked\'].map( {\'S\': 0, \'C\': 1, \'Q\': 2} ).astype(int)\\n"",""\\n"",""train_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""e3dfc817-e1c1-a274-a111-62c1c814cecf""},""source"":[""### Quick completing and converting a numeric feature\\n"",""\\n"",""We can now complete the Fare feature for single missing value in test dataset using mode to get the value that occurs most frequently for this feature. We do this in a single line of code.\\n"",""\\n"",""Note that we are not creating an intermediate new feature or doing any further analysis for correlation to guess missing feature as we are replacing only a single value. The completion goal achieves desired requirement for model algorithm to operate on non-null values.\\n"",""\\n"",""We may also want round off the fare to two decimals as it represents currency.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""3600cb86-cf5f-d87b-1b33-638dc8db1564""},""outputs"":[],""source"":[""test_df[\'Fare\'].fillna(test_df[\'Fare\'].dropna().median(), inplace=True)\\n"",""test_df.head()""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""4b816bc7-d1fb-c02b-ed1d-ee34b819497d""},""source"":[""We can not create FareBand.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""0e9018b1-ced5-9999-8ce1-258a0952cbf2""},""outputs"":[],""source"":[""train_df[\'FareBand\'] = pd.qcut(train_df[\'Fare\'], 4)\\n"",""train_df[[\'FareBand\', \'Survived\']].groupby([\'FareBand\'], as_index=False).mean().sort_values(by=\'FareBand\', ascending=True)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""d65901a5-3684-6869-e904-5f1a7cce8a6d""},""source"":[""Convert the Fare feature to ordinal values based on the FareBand.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""385f217a-4e00-76dc-1570-1de4eec0c29c""},""outputs"":[],""source"":[""for dataset in combine:\\n"",""    dataset.loc[ dataset[\'Fare\'] <= 7.91, \'Fare\'] = 0\\n"",""    dataset.loc[(dataset[\'Fare\'] > 7.91) & (dataset[\'Fare\'] <= 14.454), \'Fare\'] = 1\\n"",""    dataset.loc[(dataset[\'Fare\'] > 14.454) & (dataset[\'Fare\'] <= 31), \'Fare\']   = 2\\n"",""    dataset.loc[ dataset[\'Fare\'] > 31, \'Fare\'] = 3\\n"",""    dataset[\'Fare\'] = dataset[\'Fare\'].astype(int)\\n"",""\\n"",""train_df = train_df.drop([\'FareBand\'], axis=1)\\n"",""combine = [train_df, test_df]\\n"",""    \\n"",""train_df.head(10)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""27272bb9-3c64-4f9a-4a3b-54f02e1c8289""},""source"":[""And the test dataset.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""d2334d33-4fe5-964d-beac-6aa620066e15""},""outputs"":[],""source"":[""test_df.head(10)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""69783c08-c8cc-a6ca-2a9a-5e75581c6d31""},""source"":[""## Model, predict and solve\\n"",""\\n"",""Now we are ready to train a model and predict the required solution. There are 60+ predictive modelling algorithms to choose from. We must understand the type of problem and solution requirement to narrow down to a select few models which we can evaluate. Our problem is a classification and regression problem. We want to identify relationship between output (Survived or not) with other variables or features (Gender, Age, Port...). We are also perfoming a category of machine learning which is called supervised learning as we are training our model with a given dataset. With these two criteria - Supervised Learning plus Classification and Regression, we can narrow down our choice of models to a few. These include:\\n"",""\\n"",""- Logistic Regression\\n"",""- KNN or k-Nearest Neighbors\\n"",""- Support Vector Machines\\n"",""- Naive Bayes classifier\\n"",""- Decision Tree\\n"",""- Random Forrest\\n"",""- Perceptron\\n"",""- Artificial neural network\\n"",""- RVM or Relevance Vector Machine""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""0acf54f9-6cf5-24b5-72d9-29b30052823a""},""outputs"":[],""source"":[""X_train = train_df.drop(\\""Survived\\"", axis=1)\\n"",""Y_train = train_df[\\""Survived\\""]\\n"",""X_test  = test_df.drop(\\""PassengerId\\"", axis=1).copy()\\n"",""X_train.shape, Y_train.shape, X_test.shape""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""579bc004-926a-bcfe-e9bb-c8df83356876""},""source"":[""Logistic Regression is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. Reference [Wikipedia](https://en.wikipedia.org/wiki/Logistic_regression).\\n"",""\\n"",""Note the confidence score generated by the model based on our training dataset.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""0edd9322-db0b-9c37-172d-a3a4f8dec229""},""outputs"":[],""source"":[""# Logistic Regression\\n"",""\\n"",""logreg = LogisticRegression()\\n"",""logreg.fit(X_train, Y_train)\\n"",""Y_pred = logreg.predict(X_test)\\n"",""acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\\n"",""acc_log""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""3af439ae-1f04-9236-cdc2-ec8170a0d4ee""},""source"":[""We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\\n"",""\\n"",""Positive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability).\\n"",""\\n"",""- Sex is highest positivie coefficient, implying as the Sex value increases (male: 0 to female: 1), the probability of Survived=1 increases the most.\\n"",""- Inversely as Pclass increases, probability of Survived=1 decreases the most.\\n"",""- This way Age*Class is a good artificial feature to model as it has second highest negative correlation with Survived.\\n"",""- So is Title as second highest positive correlation.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""e545d5aa-4767-7a41-5799-a4c5e529ce72""},""outputs"":[],""source"":[""coeff_df = pd.DataFrame(train_df.columns.delete(0))\\n"",""coeff_df.columns = [\'Feature\']\\n"",""coeff_df[\\""Correlation\\""] = pd.Series(logreg.coef_[0])\\n"",""\\n"",""coeff_df.sort_values(by=\'Correlation\', ascending=False)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""ac041064-1693-8584-156b-66674117e4d0""},""source"":[""Next we model using Support Vector Machines which are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training samples, each marked as belonging to one or the other of **two categories**, an SVM training algorithm builds a model that assigns new test samples to one category or the other, making it a non-probabilistic binary linear classifier. Reference [Wikipedia](https://en.wikipedia.org/wiki/Support_vector_machine).\\n"",""\\n"",""Note that the model generates a confidence score which is higher than Logistics Regression model.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""7a63bf04-a410-9c81-5310-bdef7963298f""},""outputs"":[],""source"":[""# Support Vector Machines\\n"",""\\n"",""svc = SVC()\\n"",""svc.fit(X_train, Y_train)\\n"",""Y_pred = svc.predict(X_test)\\n"",""acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\\n"",""acc_svc""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""172a6286-d495-5ac4-1a9c-5b77b74ca6d2""},""source"":[""In pattern recognition, the k-Nearest Neighbors algorithm (or k-NN for short) is a non-parametric method used for classification and regression. A sample is classified by a majority vote of its neighbors, with the sample being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor. Reference [Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\\n"",""\\n"",""KNN confidence score is better than Logistics Regression but worse than SVM.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""ca14ae53-f05e-eb73-201c-064d7c3ed610""},""outputs"":[],""source"":[""knn = KNeighborsClassifier(n_neighbors = 3)\\n"",""knn.fit(X_train, Y_train)\\n"",""Y_pred = knn.predict(X_test)\\n"",""acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\\n"",""acc_knn""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""810f723d-2313-8dfd-e3e2-26673b9caa90""},""source"":[""In machine learning, naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes\' theorem with strong (naive) independence assumptions between the features. Naive Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features) in a learning problem. Reference [Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier).\\n"",""\\n"",""The model generated confidence score is the lowest among the models evaluated so far.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""50378071-7043-ed8d-a782-70c947520dae""},""outputs"":[],""source"":[""# Gaussian Naive Bayes\\n"",""\\n"",""gaussian = GaussianNB()\\n"",""gaussian.fit(X_train, Y_train)\\n"",""Y_pred = gaussian.predict(X_test)\\n"",""acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\\n"",""acc_gaussian""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""1e286e19-b714-385a-fcfa-8cf5ec19956a""},""source"":[""The perceptron is an algorithm for supervised learning of binary classifiers (functions that can decide whether an input, represented by a vector of numbers, belongs to some specific class or not). It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. The algorithm allows for online learning, in that it processes elements in the training set one at a time. Reference [Wikipedia](https://en.wikipedia.org/wiki/Perceptron).""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""ccc22a86-b7cb-c2dd-74bd-53b218d6ed0d""},""outputs"":[],""source"":[""# Perceptron\\n"",""\\n"",""perceptron = Perceptron()\\n"",""perceptron.fit(X_train, Y_train)\\n"",""Y_pred = perceptron.predict(X_test)\\n"",""acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\\n"",""acc_perceptron""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""a4d56857-9432-55bb-14c0-52ebeb64d198""},""outputs"":[],""source"":[""# Linear SVC\\n"",""\\n"",""linear_svc = LinearSVC()\\n"",""linear_svc.fit(X_train, Y_train)\\n"",""Y_pred = linear_svc.predict(X_test)\\n"",""acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\\n"",""acc_linear_svc""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""dc98ed72-3aeb-861f-804d-b6e3d178bf4b""},""outputs"":[],""source"":[""# Stochastic Gradient Descent\\n"",""\\n"",""sgd = SGDClassifier()\\n"",""sgd.fit(X_train, Y_train)\\n"",""Y_pred = sgd.predict(X_test)\\n"",""acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\\n"",""acc_sgd""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""bae7f8d7-9da0-f4fd-bdb1-d97e719a18d7""},""source"":[""This model uses a decision tree as a predictive model which maps features (tree branches) to conclusions about the target value (tree leaves). Tree models where the target variable can take a finite set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning).\\n"",""\\n"",""The model confidence score is the highest among models evaluated so far.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""dd85f2b7-ace2-0306-b4ec-79c68cd3fea0""},""outputs"":[],""source"":[""# Decision Tree\\n"",""\\n"",""decision_tree = DecisionTreeClassifier()\\n"",""decision_tree.fit(X_train, Y_train)\\n"",""Y_pred = decision_tree.predict(X_test)\\n"",""acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\\n"",""acc_decision_tree""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""85693668-0cd5-4319-7768-eddb62d2b7d0""},""source"":[""The next model Random Forests is one of the most popular. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees (n_estimators=100) at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Reference [Wikipedia](https://en.wikipedia.org/wiki/Random_forest).\\n"",""\\n"",""The model confidence score is the highest among models evaluated so far. We decide to use this model\'s output (Y_pred) for creating our competition submission of results.""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""f0694a8e-b618-8ed9-6f0d-8c6fba2c4567""},""outputs"":[],""source"":[""# Random Forest\\n"",""\\n"",""random_forest = RandomForestClassifier(n_estimators=100)\\n"",""random_forest.fit(X_train, Y_train)\\n"",""Y_pred = random_forest.predict(X_test)\\n"",""random_forest.score(X_train, Y_train)\\n"",""acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\\n"",""acc_random_forest""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""f6c9eef8-83dd-581c-2d8e-ce932fe3a44d""},""source"":[""### Model evaluation\\n"",""\\n"",""We can now rank our evaluation of all the models to choose the best one for our problem. While both Decision Tree and Random Forest score the same, we choose to use Random Forest as they correct for decision trees\' habit of overfitting to their training set. ""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""1f3cebe0-31af-70b2-1ce4-0fd406bcdfc6""},""outputs"":[],""source"":[""models = pd.DataFrame({\\n"",""    \'Model\': [\'Support Vector Machines\', \'KNN\', \'Logistic Regression\', \\n"",""              \'Random Forest\', \'Naive Bayes\', \'Perceptron\', \\n"",""              \'Stochastic Gradient Decent\', \'Linear SVC\', \\n"",""              \'Decision Tree\'],\\n"",""    \'Score\': [acc_svc, acc_knn, acc_log, \\n"",""              acc_random_forest, acc_gaussian, acc_perceptron, \\n"",""              acc_sgd, acc_linear_svc, acc_decision_tree]})\\n"",""models.sort_values(by=\'Score\', ascending=False)""]},{""cell_type"":""code"",""execution_count"":null,""metadata"":{""_cell_guid"":""28854d36-051f-3ef0-5535-fa5ba6a9bef7""},""outputs"":[],""source"":[""submission = pd.DataFrame({\\n"",""        \\""PassengerId\\"": test_df[\\""PassengerId\\""],\\n"",""        \\""Survived\\"": Y_pred\\n"",""    })\\n"",""# submission.to_csv(\'../output/submission.csv\', index=False)""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""fcfc8d9f-e955-cf70-5843-1fb764c54699""},""source"":[""Our submission to the competition site Kaggle results in scoring 3,883 of 6,082 competition entries. This result is indicative while the competition is running. This result only accounts for part of the submission dataset. Not bad for our first attempt. Any suggestions to improve our score are most welcome.""]},{""cell_type"":""markdown"",""metadata"":{""_cell_guid"":""aeec9210-f9d8-cd7c-c4cf-a87376d5f693""},""source"":[""## References\\n"",""\\n"",""This notebook has been created based on great work done solving the Titanic competition and other sources.\\n"",""\\n"",""- [A journey through Titanic](https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic)\\n"",""- [Getting Started with Pandas: Kaggle\'s Titanic Competition](https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests)\\n"",""- [Titanic Best Working Classifier](https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier)""]}],""metadata"":{""_change_revision"":0,""_is_fork"":false,""kernelspec"":{""display_name"":""Python 3"",""language"":""python"",""name"":""python3""},""language_info"":{""codemirror_mode"":{""name"":""ipython"",""version"":3},""file_extension"":"".py"",""mimetype"":""text/x-python"",""name"":""python"",""nbconvert_exporter"":""python"",""pygments_lexer"":""ipython3"",""version"":""3.6.0""}},""nbformat"":4,""nbformat_minor"":0}']",1,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
tkayyang_titanic-practice.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'missingno', 'warnings\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,727,[],0,"['plt.style.use', 'sns.set', 'warnings.filterwarnings', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'df_train.head', 'df_train.describe', 'df_test.describe', '.format', 'print', '.format', 'print', 'msno.matrix', 'msno.bar', 'msno.bar', 'plt.subplots', 'df_train.value_counts', 'None.plot.pie', 'ax.set_title', 'ax.set_ylabel', 'sns.countplot', 'ax.set_title', 'plt.show', 'df_train.groupby', 'None.count', 'df_train.groupby', 'None.sum', 'pd.crosstab', 'None.style.background_gradient', 'df_train.groupby', 'None.mean', 'None.sort_values', 'None.plot.bar', 'plt.subplots', 'df_train.value_counts', 'None.plot.bar', 'ax.set_title', 'ax.set_ylabel', 'sns.countplot', 'ax.set_title', 'plt.show', 'plt.subplots', 'df_train.groupby', 'None.mean', 'None.plot.bar', 'ax.set_title', 'sns.countplot', 'ax.set_title', 'plt.show', 'df_train.groupby', 'None.mean', 'None.sort_values', 'pd.crosstab', 'None.style.background_gradient', 'sns.factorplot', 'sns.factorplot', 'sns.factorplot', 'print', 'print', 'print', 'plt.subplots', 'sns.kdeplot', 'sns.kdeplot', 'plt.legend', 'plt.show', 'plt.figure', 'df_traindf_train.plot', 'df_traindf_train.plot', 'df_traindf_train.plot', 'plt.xlabel', 'plt.title', 'plt.legend', 'range', 'cummulate_survival_ratio.append', 'plt.figure', 'plt.plot', 'plt.title', 'plt.ylabel', 'plt.xlabel', 'plt.show', 'plt.subplots', 'sns.violinplot', 'ax.set_title', 'ax.set_yticks', 'sns.violinplot', 'ax.set_title', 'ax.set_yticks', 'plt.show', 'plt.subplots', 'df_train.groupby', 'None.mean', 'None.sort_values', 'None.plot.bar', 'df_train.groupby', 'None.mean', 'None.sort_values', 'plt.subplots', 'sns.countplot', 'ax.set_title', 'sns.countplot', 'ax.set_title', 'sns.countplot', 'ax.set_title', 'sns.countplot', 'ax.set_title', 'plt.subplots_adjust', 'plt.show', 'print', 'print', 'plt.subplots', 'sns.countplot', 'ax.set_title', 'sns.countplot', 'ax.set_title', 'df_train.groupby', 'None.mean', 'None.sort_values', 'None.plot.bar', 'ax.set_title', 'plt.subplots_adjust', 'plt.show', 'df_train.head', 'df_train.groupby', 'None.mean', 'None.sort_values', 'plt.subplots', 'sns.distplot', 'g.legend', 'df_test.Fare.isnull', 'df_test.mean', 'df_train.map', 'df_test.map', 'plt.subplots', 'sns.distplot', 'g.legend', 'df_train.Name.str.extract', 'df_test.Name.str.extract', 'pd.crosstab', 'None.T.style.background_gradient', 'df_train.replace', 'df_test.replace', 'df_train.groupby', 'None.mean', 'df_train.groupby', 'None.mean', 'None.plot.bar', 'df_train.groupby', 'None.mean', 'df_train.Age.isnull', 'df_train.Age.isnull', 'df_train.Age.isnull', 'df_train.Age.isnull', 'df_train.Age.isnull', 'df_test.Age.isnull', 'df_test.Age.isnull', 'df_test.Age.isnull', 'df_test.Age.isnull', 'df_test.Age.isnull', 'print', 'df_train.fillna', 'df_train.apply', 'print', 'df_train.drop', 'df_test.drop', 'df_train.map', 'df_test.map', 'df_train.unique', 'df_train.value_counts', 'df_train.map', 'df_test.map', 'df_train.isnull', 'None.any', 'df_train.map', 'df_test.map', 'plt.figure', 'plt.title', 'sns.heatmap', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'df_train.head', 'df_train.drop', 'df_test.drop', 'df_train.head', 'df_train.drop', 'df_train.drop', 'train_test_split', 'RandomForestClassifier', 'model.fit', 'model.predict', 'print', 'Series', 'plt.figure', 'Series_feat_imp.sort_values', 'None.plot.barh', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'pd.read_csv', 'submission.head', 'model.predict', 'submission.to_csv']","['style', 'set', 'filterwarnings', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'describe', 'describe', 'format', 'print', 'format', 'print', 'matrix', 'bar', 'bar', 'subplots', 'value_counts', 'plot', 'set_title', 'set_ylabel', 'countplot', 'set_title', 'show', 'groupby', 'count', 'groupby', 'sum', 'crosstab', 'style', 'groupby', 'mean', 'sort_values', 'plot', 'subplots', 'value_counts', 'plot', 'set_title', 'set_ylabel', 'countplot', 'set_title', 'show', 'subplots', 'groupby', 'mean', 'plot', 'set_title', 'countplot', 'set_title', 'show', 'groupby', 'mean', 'sort_values', 'crosstab', 'style', 'factorplot', 'factorplot', 'factorplot', 'print', 'print', 'print', 'subplots', 'kdeplot', 'kdeplot', 'legend', 'show', 'figure', 'plot', 'plot', 'plot', 'xlabel', 'title', 'legend', 'range', 'append', 'figure', 'plot', 'title', 'ylabel', 'xlabel', 'show', 'subplots', 'violinplot', 'set_title', 'set_yticks', 'violinplot', 'set_title', 'set_yticks', 'show', 'subplots', 'groupby', 'mean', 'sort_values', 'plot', 'groupby', 'mean', 'sort_values', 'subplots', 'countplot', 'set_title', 'countplot', 'set_title', 'countplot', 'set_title', 'countplot', 'set_title', 'subplots_adjust', 'show', 'print', 'print', 'subplots', 'countplot', 'set_title', 'countplot', 'set_title', 'groupby', 'mean', 'sort_values', 'plot', 'set_title', 'subplots_adjust', 'show', 'head', 'groupby', 'mean', 'sort_values', 'subplots', 'distplot', 'legend', 'Fare', 'mean', 'map', 'map', 'subplots', 'distplot', 'legend', 'Name', 'Name', 'crosstab', 'T', 'replace', 'replace', 'groupby', 'mean', 'groupby', 'mean', 'plot', 'groupby', 'mean', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'Age', 'print', 'fillna', 'apply', 'print', 'drop', 'drop', 'map', 'map', 'unique', 'value_counts', 'map', 'map', 'isnull', 'any', 'map', 'map', 'figure', 'title', 'heatmap', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'head', 'drop', 'drop', 'head', 'drop', 'drop', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'print', 'Series', 'figure', 'sort_values', 'plot', 'xlabel', 'ylabel', 'show', 'read_csv', 'head', 'predict', 'to_csv']","['style', 'set', 'filterwarnings', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'describe', 'format', 'print', 'matrix', 'bar', 'subplots', 'value_counts', 'plot', 'set_title', 'set_ylabel', 'countplot', 'show', 'groupby', 'count', 'sum', 'crosstab', 'mean', 'sort_values', 'factorplot', 'kdeplot', 'legend', 'figure', 'xlabel', 'title', 'range', 'append', 'ylabel', 'violinplot', 'set_yticks', 'subplots_adjust', 'distplot', 'Fare', 'map', 'Name', 'T', 'replace', 'Age', 'fillna', 'apply', 'drop', 'unique', 'isnull', 'any', 'heatmap', 'get_dummies', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'Series', 'to_csv']",58,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0
 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",style set filterwarnings get ipython run line magic read csv read csv head describe describe format print format print matrix bar bar subplots value counts plot set title set ylabel countplot set title show groupby count groupby sum crosstab style groupby mean sort values plot subplots value counts plot set title set ylabel countplot set title show subplots groupby mean plot set title countplot set title show groupby mean sort values crosstab style factorplot factorplot factorplot print print print subplots kdeplot kdeplot legend show figure plot plot plot xlabel title legend range append figure plot title ylabel xlabel show subplots violinplot set title set yticks violinplot set title set yticks show subplots groupby mean sort values plot groupby mean sort values subplots countplot set title countplot set title countplot set title countplot set title subplots adjust show print print subplots countplot set title countplot set title groupby mean sort values plot set title subplots adjust show head groupby mean sort values subplots distplot legend fare mean map map subplots distplot legend name name crosstab replace replace groupby mean groupby mean plot groupby mean age age age age age age age age age age print fillna apply print drop drop map map unique value counts map map isnull map map figure title heatmap get dummies get dummies get dummies get dummies head drop drop head drop drop train test split randomforestclassifier fit predict print series figure sort values plot xlabel ylabel show read csv head predict csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10239737127302445, 0.2527701367492939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024603770527563462, 0.021281773238972755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07686538173461718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03216562931211452, 0.0, 0.0, 0.22441465601053473, 0.07635701886100257, 0.0, 0.0, 0.0, 0.0, 0.08699316362744355, 0.04485755541689885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040106204095941206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06121153373945505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08611050228815958, 0.0, 0.0, 0.0, 0.08106400086732612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09649688793634356, 0.0, 0.0, 0.0, 0.0, 0.03183443806072968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09907220738825466, 0.0, 0.0, 0.0, 0.014598664824468604, 0.0, 0.03004175663869451, 0.0, 0.0, 0.0, 0.012358729366132656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08793603620669202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07362174426586233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23327158382718638, 0.0, 0.0, 0.0, 0.0, 0.06681527695157909, 0.026972353972058195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018581419743444114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019948260480131257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09013420387211991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08608636722082377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018859613514913637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0187660555048996, 0.0, 0.0, 0.15711930763326618, 0.0, 0.03250768120809561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22174908816942157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055648780913296496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2582591016624713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025644869029608774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1196316924832362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018133640778312303, 0.0, 0.0, 0.02527701367492939, 0.0, 0.0, 0.0, 0.03350798300656401, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04429285629111833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018673329132642007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027389675548568176, 0.4031801603080392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21997832677299617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16162498013898477, 0.0, 0.0, 0.0, 0.01953912379866057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08347317136994475, 0.0, 0.0, 0.0, 0.0, 0.3119606764567898, 0.019844462129272863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020374101165479278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3788521976312137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020053102047970603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034000458864993005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07635701886100257, 0.16162498013898477, 0.0, 0.0, 0.0, 0.09859354259628829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08625677801511647, 0.0, 0.0, 0.0, 0.0, 0.11129756182659299, 0.0, 0.0, 0.0, 0.08594755167694279, 0.0, 0.0, 0.0, 0.0]"
dannydwkim_titanic-thx-to-ahmed.py,"['numpy', 'pandas', 'os\n', 'os', 'warnings\n', 'matplotlib', 'seaborn', 'pylab', 'collections', 'sklearn', 'xgboost', 'lightgbm']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",12,841,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Outlier detection ', '    # iterate over features(columns)', '        # 1st quartile (25%)', '        # 3rd quartile (75%)', '        # Interquartile range (IQR)', '        # outlier step', '        # Determine a list of indices of outliers for feature col', '        # append the found outlier indices for col to the list of outlier indices ', '    # select observations containing more than 2 outliers', '# detect outliers from Age, SibSp , Parch and Fare', '    # reading train data', '    # reading test data', '    # extracting and then removing the targets from the training data ', '    # merging train data and test data for future feature engineering', ""    # we'll also remove the PassengerID since this is not an informative feature"", '    # we extract the title from each name', '    # a map of more aggregated title', '    # we map each title', '    # a function that fills the missing values of the Age variable', '    # we clean the Name variable', '    # encoding in dummy variable', '    # removing the title variable', ""    # there's one missing fare value - replacing it with the mean."", '    # two missing embarked values - filling them with the most frequent one in the train  set(S)', '    # dummy encoding ', '    # replacing missing cabins with U (for Uknown)', '    # mapping each Cabin value with the cabin letter', '    # dummy encoding ...', '    # mapping string values to numerical one ', '    # encoding into 3 categories:', '    # adding dummy variable', '    # removing ""Pclass""', ""    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)"", '    # Extracting dummy variables from tickets:', '    # introducing a new feature : the size of families (including the passenger)', '    # introducing other features based on the family size', '                         subsample=.632, # Standard RF bagging fraction', '                         reg_alpha=10, # Hard L1 regularization', '# turn run_gs to True if you want to run the gridsearch again.']",47,"['print', 'warnings.filterwarnings', 'get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'warnings.filterwarnings', 'plot.rcParams.update', 'pd.read_csv', 'np.percentile', 'np.percentile', 'outlier_indices.extend', 'Counter', 'list', 'detect_outliers', 'data.describe', 'data.info', 'data.fillna', 'data.groupby', 'None.agg', 'None.plot', 'data.groupby', 'None.agg', 'None.plot', 'plt.figure', 'sns.violinplot', 'plt.figure', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.legend', 'plt.figure', 'plt.subplot', 'ax.scatter', 'ax.scatter', 'plt.subplot', 'ax.set_ylabel', 'data.groupby', 'None.mean', 'None.plot', 'plt.figure', 'sns.violinplot', 'print', 'pd.read_csv', 'pd.read_csv', 'train.drop', 'train.append', 'combined.reset_index', 'combined.drop', 'get_combined_data', 'print', 'combined.head', 'data.info', 'set', 'titles.add', 'print', 'combined.map', 'combined.Title.map', 'status', 'get_titles', 'combined.isnull', 'print', 'combined.iloc.groupby', 'grouped_train.median', 'grouped_median_train.reset_index', 'grouped_median_train.head', 'combined.apply', 'status', 'process_age', 'combined.drop', 'pd.get_dummies', 'pd.concat', 'combined.drop', 'status', 'process_names', 'combined.Fare.fillna', 'status', 'process_fares', 'combined.Embarked.fillna', 'pd.get_dummies', 'pd.concat', 'combined.drop', 'status', 'process_embarked', 'combined.head', 'set', 'set', 'train_cabin.add', 'train_cabin.add', 'test_cabin.add', 'test_cabin.add', 'combined.Cabin.fillna', 'combined.map', 'pd.get_dummies', 'pd.concat', 'combined.drop', 'status', 'process_cabin', 'combined.map', 'status', 'process_sex', 'pd.get_dummies', 'pd.concat', 'combined.drop', 'status', 'process_pclass', 'ticket.replace', 'ticket.replace', 'ticket.split', 'map', 'list', 'len', 'set', 'tickets.add', 'print', 'ticket.replace', 'ticket.replace', 'ticket.split', 'list', 'list', 'len', 'combined.map', 'pd.get_dummies', 'pd.concat', 'combined.drop', 'status', 'process_ticket', 'combined.map', 'combined.map', 'combined.map', 'status', 'process_family', 'print', 'cross_val_score', 'np.mean', 'pd.read_csv', 'pd.read_csv', 'recover_train_test_target', 'RandomForestClassifier', 'clf.fit', 'pd.DataFrame', 'features.sort_values', 'features.set_index', 'features.plot', 'print', 'SelectFromModel', 'model.transform', 'print', 'model.transform', 'print', 'StandardScaler', 'std.fit_transform', 'LogisticRegression', 'RandomForestClassifier', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'GaussianNB', 'SVC', 'XGBClassifier', 'LGBMClassifier', 'DecisionTreeClassifier', 'print', 'compute_score', 'print', 'print', 'XGBClassifier', 'StratifiedKFold', 'GridSearchCV', 'grid_search.fit', 'print', 'print', 'XGBClassifier', 'model.fit']","['print', 'filterwarnings', 'get_ipython', 'run_line_magic', 'filterwarnings', 'filterwarnings', 'rcParams', 'read_csv', 'percentile', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'describe', 'info', 'fillna', 'groupby', 'agg', 'plot', 'groupby', 'agg', 'plot', 'figure', 'violinplot', 'figure', 'hist', 'xlabel', 'ylabel', 'legend', 'figure', 'subplot', 'scatter', 'scatter', 'subplot', 'set_ylabel', 'groupby', 'mean', 'plot', 'figure', 'violinplot', 'print', 'read_csv', 'read_csv', 'drop', 'append', 'reset_index', 'drop', 'get_combined_data', 'print', 'head', 'info', 'set', 'add', 'print', 'map', 'Title', 'status', 'get_titles', 'isnull', 'print', 'iloc', 'median', 'reset_index', 'head', 'apply', 'status', 'process_age', 'drop', 'get_dummies', 'concat', 'drop', 'status', 'process_names', 'Fare', 'status', 'process_fares', 'Embarked', 'get_dummies', 'concat', 'drop', 'status', 'process_embarked', 'head', 'set', 'set', 'add', 'add', 'add', 'add', 'Cabin', 'map', 'get_dummies', 'concat', 'drop', 'status', 'process_cabin', 'map', 'status', 'process_sex', 'get_dummies', 'concat', 'drop', 'status', 'process_pclass', 'replace', 'replace', 'split', 'map', 'list', 'len', 'set', 'add', 'print', 'replace', 'replace', 'split', 'list', 'list', 'len', 'map', 'get_dummies', 'concat', 'drop', 'status', 'process_ticket', 'map', 'map', 'map', 'status', 'process_family', 'print', 'cross_val_score', 'mean', 'read_csv', 'read_csv', 'recover_train_test_target', 'RandomForestClassifier', 'fit', 'DataFrame', 'sort_values', 'set_index', 'plot', 'print', 'SelectFromModel', 'transform', 'print', 'transform', 'print', 'StandardScaler', 'fit_transform', 'LogisticRegression', 'RandomForestClassifier', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'GaussianNB', 'SVC', 'XGBClassifier', 'LGBMClassifier', 'DecisionTreeClassifier', 'print', 'compute_score', 'print', 'print', 'XGBClassifier', 'StratifiedKFold', 'GridSearchCV', 'fit', 'print', 'print', 'XGBClassifier', 'fit']","['print', 'filterwarnings', 'get_ipython', 'run_line_magic', 'rcParams', 'read_csv', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'describe', 'info', 'fillna', 'groupby', 'agg', 'plot', 'figure', 'violinplot', 'hist', 'xlabel', 'ylabel', 'legend', 'subplot', 'scatter', 'set_ylabel', 'mean', 'drop', 'append', 'reset_index', 'get_combined_data', 'head', 'set', 'add', 'map', 'Title', 'status', 'get_titles', 'isnull', 'iloc', 'median', 'apply', 'process_age', 'get_dummies', 'concat', 'process_names', 'Fare', 'process_fares', 'Embarked', 'process_embarked', 'Cabin', 'process_cabin', 'process_sex', 'process_pclass', 'replace', 'split', 'len', 'process_ticket', 'process_family', 'cross_val_score', 'recover_train_test_target', 'RandomForestClassifier', 'fit', 'DataFrame', 'sort_values', 'set_index', 'SelectFromModel', 'transform', 'StandardScaler', 'fit_transform', 'LogisticRegression', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'GaussianNB', 'SVC', 'XGBClassifier', 'LGBMClassifier', 'DecisionTreeClassifier', 'compute_score', 'StratifiedKFold', 'GridSearchCV']",81,"[1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1
 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0
 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print filterwarnings get ipython run line magic filterwarnings filterwarnings rcparams read csv percentile percentile extend counter list detect outliers describe info fillna groupby agg plot groupby agg plot figure violinplot figure hist xlabel ylabel legend figure subplot scatter scatter subplot set ylabel groupby mean plot figure violinplot print read csv read csv drop append reset index drop get combined data print head info set add print map title status get titles isnull print iloc median reset index head apply status process age drop get dummies concat drop status process names fare status process fares embarked get dummies concat drop status process embarked head set set add add add add cabin map get dummies concat drop status process cabin map status process sex get dummies concat drop status process pclass replace replace split map list len set add print replace replace split list list len map get dummies concat drop status process ticket map map map status process family print cross val score mean read csv read csv recover train test target randomforestclassifier fit dataframe sort values set index plot print selectfrommodel transform print transform print standardscaler fit transform logisticregression randomforestclassifier gradientboostingclassifier kneighborsclassifier gaussiannb svc xgbclassifier lgbmclassifier decisiontreeclassifier print compute score print print xgbclassifier stratifiedkfold gridsearchcv fit print print xgbclassifier fit,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14728306956318468, 0.0, 0.02571839062390406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08947153956420817, 0.0, 0.0, 0.0, 0.02503339157807149, 0.02165338692173565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06918832214338425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06181802414603819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06181802414603819, 0.11137127020976165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04372416646251567, 0.0, 0.0, 0.0, 0.0, 0.032063713817909, 0.0, 0.0, 0.057051049793783185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03974724460525817, 0.0, 0.014296460408142307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02503339157807149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020403261173302312, 0.0, 0.0, 0.0, 0.05015757150143152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1168188385515394, 0.0, 0.0, 0.0, 0.10309938441769935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05179355607955165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047104171118851505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054461097632444846, 0.0, 0.03239031809166483, 0.05751449801502486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10080216604506327, 0.0, 0.0, 0.0, 0.014853580781796216, 0.0, 0.09169900078368733, 0.0, 0.0, 0.0, 0.05029812992008072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03084938507270785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11985167563179906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03544371847424483, 0.0, 0.0, 0.0, 0.0, 0.03029063494067878, 0.0, 0.0, 0.05933621937581516, 0.0, 0.0, 0.0, 0.0, 0.04078918691228295, 0.0, 0.0, 0.027035060799701912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05751449801502486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09169900078368733, 0.0, 0.0, 0.03762636681059885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018905880949955763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02029658890457663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02554295189575715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02189739310239326, 0.05328382419716312, 0.0, 0.047104171118851505, 0.0, 0.0, 0.019188932428101168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11701727846394641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01909374074610581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01909374074610581, 0.0, 0.0, 0.15986286118433166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04102203285546696, 0.028538511255640196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05015757150143152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04852144680047917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040432243651090743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10031514300286304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08758957240957305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1825809787807873, 0.0, 0.0, 0.0, 0.0, 0.49014987869200366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03690056610071397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06181802414603819, 0.056821809666324545, 0.0, 0.0, 0.06181802414603819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09013256032481928, 0.0, 0.0, 0.06838718545162299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018999395223587713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09704289360095834, 0.0, 0.038377864856202336, 0.0, 0.0, 0.0, 0.0, 0.06181802414603819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12306609856640088, 0.0, 0.03792326010815578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023492458559114505, 0.0, 0.0, 0.0, 0.039760616089010874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03501044193176331, 0.0, 0.0, 0.0, 0.618180241460382, 0.0, 0.0, 0.0, 0.0, 0.052092696295697426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07475768653702147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02438993388232266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06181802414603819, 0.020729865447058148, 0.0, 0.0, 0.0, 0.04280064498783817, 0.0, 0.0, 0.0, 0.02141486449289072, 0.05015757150143152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020403261173302312, 0.0, 0.0, 0.0, 0.0696282212429073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032063713817909, 0.0, 0.0, 0.0, 0.023492458559114505, 0.0, 0.0, 0.0, 0.10031514300286304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.095240581187748, 0.0, 0.0, 0.0, 0.029254319615986603, 0.0, 0.0, 0.0, 0.0, 0.056620497329228664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ayumka_titanic-my-first-shakyo.py,"['sys,', 'warnings\n', 'sys\n', 'pandas', 'matplotlib\n', 'numpy', 'scipy', 'IPython\n', 'IPython', 'sklearn\n', 'random\n', 'time\n', 'os\n', 'sklearn', 'xgboost', 'matplotlib', 'seaborn', 'file\n', 'itertools\n', 'graphviz\n']","[1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",20,929,"['# matplotlibã¨ã¯', '# import data from file', '# 3.24 Da-Double Check Cleaned Data', '# 3.25 Split Training and Testing Data']",4,"['print', 'print', 'print', 'print', 'print', 'print', 'print', 'warnings.filterwarnings', 'print', 'print', 'get_ipython', 'None.run_line_magic', 'mpl.style.use', 'sns.set_style', 'pd.read_csv', 'pd.read_csv', 'data_raw.copy', 'print', 'data_raw.sample', 'print', 'print', 'print', 'print', 'data_raw.describe', 'dataset.fillna', 'dataset.fillna', 'dataset.fillna', 'data1.drop', 'print', 'print', 'print', 'dataset.str.split', 'None.str.split', 'pd.qcut', 'pd.cut', 'data1.value_counts', 'data1.apply', 'print', 'print', 'data1.info', 'data_val.info', 'data1.sample', 'LabelEncoder', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'print', 'print', 'pd.get_dummies', 'data1_dummy.columns.tolist', 'print', 'data1_dummy.head', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'data_raw.describe', 'model_selection.train_test_split', 'model_selection.train_test_split', 'model_selection.train_test_split', 'print', 'print', 'print', 'train1_x_bin.head', 'print', 'print', 'print', 'print', 'plt.figure', 'plt.subplot', 'plt.boxplot', 'plt.title', 'plt.ylabel', 'plt.subplot', 'plt.boxplot', 'plt.title', 'plt.ylabel', 'plt.subplot', 'plt.boxplot', 'plt.title', 'plt.ylabel', 'plt.subplot', 'plt.hist', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.legend', 'plt.subplot', 'plt.hist', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.legend', 'plt.subplot', 'plt.hist', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.legend', 'plt.subplots', 'sns.barplot', 'sns.barplot', 'sns.barplot', 'sns.pointplot', 'sns.pointplot', 'sns.pointplot', 'plt.subplots', 'sns.boxplot', 'axis1.set_title', 'sns.violinplot', 'axis2.set_title', 'sns.boxplot', 'axis3.set_title', 'plt.subplots', 'sns.barplot', 'axis1.set_title', 'sns.barplot', 'axis1.set_title', 'sns.barplot', 'axis1.set_title', 'plt.subplots', 'sns.pointplot', 'sns.pointplot', 'sns.FacetGrid', 'e.map', 'e.add_legend', 'sns.FacetGrid', 'a.map', 'a.set', 'a.add_legend', 'sns.FacetGrid', 'h.map', 'h.add_legend', 'sns.pairplot', 'pp.set', 'plt.subplots', 'sns.diverging_palette', 'sns.heatmap', 'plt.title', 'correlation_heatmap', 'ensemble.AdaBoostClassifier', 'ensemble.BaggingClassifier', 'ensemble.ExtraTreesClassifier', 'ensemble.GradientBoostingClassifier', 'ensemble.RandomForestClassifier', 'gaussian_process.GaussianProcessClassifier', 'linear_model.LogisticRegressionCV', 'linear_model.PassiveAggressiveClassifier', 'linear_model.RidgeClassifierCV', 'linear_model.SGDClassifier', 'linear_model.Perceptron', 'naive_bayes.BernoulliNB', 'naive_bayes.GaussianNB', 'neighbors.KNeighborsClassifier', 'svm.SVC', 'svm.NuSVC', 'svm.LinearSVC', 'tree.DecisionTreeClassifier', 'tree.ExtraTreeClassifier', 'discriminant_analysis.LinearDiscriminantAnalysis', 'discriminant_analysis.QuadraticDiscriminantAnalysis', 'XGBClassifier', 'model_selection.ShuffleSplit', 'pd.DataFrame', 'str', 'model_selection.cross_validate', 'cv_results.mean', 'cv_results.mean', 'cv_results.mean', 'cv_results.std', 'alg.fit', 'alg.predict', 'MLA_compare.sort_values', 'sns.barplot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'data1.iterrows', 'random.random', 'data1.set_value', 'data1.set_value', 'print', 'print', 'data1data1.Sex.groupby', 'None.mean', 'print', 'data1data1.Sex.groupby', 'None.mean', 'print', 'pd.DataFrame', 'df.iterrows', 'mytree', 'print', 'print', 'cm.astype', 'cm.sum', 'print', 'print', 'print', 'plt.imshow', 'plt.title', 'plt.colorbar', 'np.arange', 'plt.xticks', 'plt.yticks', 'cm.max', 'itertools.product', 'plt.text', 'plt.tight_layout', 'plt.ylabel', 'plt.xlabel', 'metrics.confusion_matrix', 'np.set_printoptions', 'plt.figure', 'plot_confusion_matrix', 'plt.figure', 'plot_confusion_matrix', 'tree.DecisionTreeClassifier', 'model_selection.cross_validate', 'dtree.fit', 'print', 'print', 'print', 'print', 'print', 'model_selection.GridSearchCV', 'tune_model.fit', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'feature_selection.RFECV', 'dtree_rfe.fit', 'dtree_rfe.get_support', 'model_selection.cross_validate', 'print', 'print', 'print', 'print', 'print', 'print', 'model_selection.GridSearchCV', 'rfe_tune_model.fit', 'print', 'print', 'print', 'print', 'print', 'tree.export_graphviz', 'graphviz.Source', 'correlation_heatmap', 'ensemble.AdaBoostClassifier', 'ensemble.BaggingClassifier', 'ensemble.ExtraTreesClassifier', 'ensemble.GradientBoostingClassifier', 'ensemble.RandomForestClassifier', 'gaussian_process.GaussianProcessClassifier', 'linear_model.LogisticRegressionCV', 'naive_bayes.BernoulliNB', 'naive_bayes.GaussianNB', 'neighbors.KNeighborsClassifier', 'svm.SVC', 'XGBClassifier', 'ensemble.VotingClassifier', 'model_selection.cross_validate', 'vote_hard.fit', 'print', 'print', 'print', 'print', 'ensemble.VotingClassifier', 'model_selection.cross_validate', 'vote_soft.fit', 'print', 'print', 'print', 'print', 'warnings.filterwarnings', 'time.perf_counter', 'zip', 'time.perf_counter', 'model_selection.GridSearchCV', 'best_search.fit', 'time.perf_counter', 'print', 'clf.set_params', 'time.perf_counter', 'print', 'print', 'ensemble.VotingClassifier', 'model_selection.cross_validate', 'grid_hard.fit', 'print', 'print', 'print', 'print', 'ensemble.VotingClassifier', 'model_selection.cross_validate', 'grid_soft.fit', 'print', 'print', 'print', 'print', 'print', 'print', 'mytree', 'None.astype', 'grid_hard.predict', 'submit.to_csv', 'print', 'submit.sample']","['print', 'print', 'print', 'print', 'print', 'print', 'print', 'filterwarnings', 'print', 'print', 'get_ipython', 'run_line_magic', 'style', 'set_style', 'read_csv', 'read_csv', 'copy', 'print', 'sample', 'print', 'print', 'print', 'print', 'describe', 'fillna', 'fillna', 'fillna', 'drop', 'print', 'print', 'print', 'str', 'str', 'qcut', 'cut', 'value_counts', 'apply', 'print', 'print', 'info', 'info', 'sample', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'print', 'print', 'get_dummies', 'columns', 'print', 'head', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'describe', 'train_test_split', 'train_test_split', 'train_test_split', 'print', 'print', 'print', 'head', 'print', 'print', 'print', 'print', 'figure', 'subplot', 'boxplot', 'title', 'ylabel', 'subplot', 'boxplot', 'title', 'ylabel', 'subplot', 'boxplot', 'title', 'ylabel', 'subplot', 'hist', 'title', 'xlabel', 'ylabel', 'legend', 'subplot', 'hist', 'title', 'xlabel', 'ylabel', 'legend', 'subplot', 'hist', 'title', 'xlabel', 'ylabel', 'legend', 'subplots', 'barplot', 'barplot', 'barplot', 'pointplot', 'pointplot', 'pointplot', 'subplots', 'boxplot', 'set_title', 'violinplot', 'set_title', 'boxplot', 'set_title', 'subplots', 'barplot', 'set_title', 'barplot', 'set_title', 'barplot', 'set_title', 'subplots', 'pointplot', 'pointplot', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'set', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'pairplot', 'set', 'subplots', 'diverging_palette', 'heatmap', 'title', 'correlation_heatmap', 'AdaBoostClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 'GaussianProcessClassifier', 'LogisticRegressionCV', 'PassiveAggressiveClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'KNeighborsClassifier', 'SVC', 'NuSVC', 'LinearSVC', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'XGBClassifier', 'ShuffleSplit', 'DataFrame', 'str', 'cross_validate', 'mean', 'mean', 'mean', 'std', 'fit', 'predict', 'sort_values', 'barplot', 'title', 'xlabel', 'ylabel', 'iterrows', 'random', 'set_value', 'set_value', 'print', 'print', 'Sex', 'mean', 'print', 'Sex', 'mean', 'print', 'DataFrame', 'iterrows', 'mytree', 'print', 'print', 'astype', 'sum', 'print', 'print', 'print', 'imshow', 'title', 'colorbar', 'arange', 'xticks', 'yticks', 'max', 'product', 'text', 'tight_layout', 'ylabel', 'xlabel', 'confusion_matrix', 'set_printoptions', 'figure', 'plot_confusion_matrix', 'figure', 'plot_confusion_matrix', 'DecisionTreeClassifier', 'cross_validate', 'fit', 'print', 'print', 'print', 'print', 'print', 'GridSearchCV', 'fit', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'RFECV', 'fit', 'get_support', 'cross_validate', 'print', 'print', 'print', 'print', 'print', 'print', 'GridSearchCV', 'fit', 'print', 'print', 'print', 'print', 'print', 'export_graphviz', 'Source', 'correlation_heatmap', 'AdaBoostClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 'GaussianProcessClassifier', 'LogisticRegressionCV', 'BernoulliNB', 'GaussianNB', 'KNeighborsClassifier', 'SVC', 'XGBClassifier', 'VotingClassifier', 'cross_validate', 'fit', 'print', 'print', 'print', 'print', 'VotingClassifier', 'cross_validate', 'fit', 'print', 'print', 'print', 'print', 'filterwarnings', 'perf_counter', 'zip', 'perf_counter', 'GridSearchCV', 'fit', 'perf_counter', 'print', 'set_params', 'perf_counter', 'print', 'print', 'VotingClassifier', 'cross_validate', 'fit', 'print', 'print', 'print', 'print', 'VotingClassifier', 'cross_validate', 'fit', 'print', 'print', 'print', 'print', 'print', 'print', 'mytree', 'astype', 'predict', 'to_csv', 'print', 'sample']","['print', 'filterwarnings', 'get_ipython', 'run_line_magic', 'style', 'set_style', 'read_csv', 'copy', 'sample', 'describe', 'fillna', 'drop', 'str', 'qcut', 'cut', 'value_counts', 'apply', 'info', 'LabelEncoder', 'fit_transform', 'get_dummies', 'columns', 'head', 'train_test_split', 'figure', 'subplot', 'boxplot', 'title', 'ylabel', 'hist', 'xlabel', 'legend', 'subplots', 'barplot', 'pointplot', 'set_title', 'violinplot', 'FacetGrid', 'map', 'add_legend', 'set', 'pairplot', 'diverging_palette', 'heatmap', 'correlation_heatmap', 'AdaBoostClassifier', 'BaggingClassifier', 'ExtraTreesClassifier', 'GradientBoostingClassifier', 'RandomForestClassifier', 'GaussianProcessClassifier', 'LogisticRegressionCV', 'PassiveAggressiveClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'KNeighborsClassifier', 'SVC', 'NuSVC', 'LinearSVC', 'DecisionTreeClassifier', 'ExtraTreeClassifier', 'LinearDiscriminantAnalysis', 'QuadraticDiscriminantAnalysis', 'XGBClassifier', 'ShuffleSplit', 'DataFrame', 'cross_validate', 'mean', 'std', 'fit', 'predict', 'sort_values', 'iterrows', 'random', 'set_value', 'Sex', 'mytree', 'astype', 'sum', 'imshow', 'colorbar', 'arange', 'xticks', 'yticks', 'max', 'product', 'text', 'tight_layout', 'confusion_matrix', 'set_printoptions', 'plot_confusion_matrix', 'GridSearchCV', 'RFECV', 'get_support', 'export_graphviz', 'Source', 'VotingClassifier', 'perf_counter', 'zip', 'set_params', 'to_csv']",104,"[1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0
 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0
 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print print print print print print print filterwarnings print print get ipython run line magic style set style read csv read csv copy print sample print print print print describe fillna fillna fillna drop print print print str str qcut cut value counts apply print print info info sample labelencoder fit transform fit transform fit transform fit transform fit transform print print get dummies columns print head print print print print print print print print describe train test split train test split train test split print print print head print print print print figure subplot boxplot title ylabel subplot boxplot title ylabel subplot boxplot title ylabel subplot hist title xlabel ylabel legend subplot hist title xlabel ylabel legend subplot hist title xlabel ylabel legend subplots barplot barplot barplot pointplot pointplot pointplot subplots boxplot set title violinplot set title boxplot set title subplots barplot set title barplot set title barplot set title subplots pointplot pointplot facetgrid map add legend facetgrid map set add legend facetgrid map add legend pairplot set subplots diverging palette heatmap title correlation heatmap adaboostclassifier baggingclassifier extratreesclassifier gradientboostingclassifier randomforestclassifier gaussianprocessclassifier logisticregressioncv passiveaggressiveclassifier ridgeclassifiercv sgdclassifier perceptron bernoullinb gaussiannb kneighborsclassifier svc nusvc linearsvc decisiontreeclassifier extratreeclassifier lineardiscriminantanalysis quadraticdiscriminantanalysis xgbclassifier shufflesplit dataframe str cross validate mean mean mean std fit predict sort values barplot title xlabel ylabel iterrows random set value set value print print sex mean print sex mean print dataframe iterrows mytree print print astype sum print print print imshow title colorbar arange xticks yticks max product text tight layout ylabel xlabel confusion matrix set printoptions figure plot confusion matrix figure plot confusion matrix decisiontreeclassifier cross validate fit print print print print print gridsearchcv fit print print print print print print print print print print print rfecv fit get support cross validate print print print print print print gridsearchcv fit print print print print print export graphviz source correlation heatmap adaboostclassifier baggingclassifier extratreesclassifier gradientboostingclassifier randomforestclassifier gaussianprocessclassifier logisticregressioncv bernoullinb gaussiannb kneighborsclassifier svc xgbclassifier votingclassifier cross validate fit print print print print votingclassifier cross validate fit print print print print filterwarnings perf counter zip perf counter gridsearchcv fit perf counter print set params perf counter print print votingclassifier cross validate fit print print print print votingclassifier cross validate fit print print print print print print mytree astype predict csv print sample,"[0.0, 0.0, 0.0, 0.04761611104287074, 0.0, 0.04623183090703764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013593900856349001, 0.02495314494817249, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02385547313531677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06838087403317467, 0.0, 0.0, 0.0, 0.1285601302659648, 0.0, 0.07221469663335786, 0.0, 0.0, 0.0, 0.0, 0.10167249456982536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028786967548355684, 0.0, 0.0, 0.02744983895897126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06593820333200867, 0.0, 0.0, 0.0, 0.014839120433691283, 0.0, 0.07221469663335786, 0.0, 0.0, 0.0, 0.10979935583588504, 0.0, 0.01625788309440926, 0.0, 0.0, 0.14090620733453613, 0.0, 0.0, 0.021489838539821945, 0.0, 0.0, 0.0, 0.017773049313548502, 0.0, 0.0, 0.0, 0.017950509644283158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0314317057595153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025618154844649545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03419043701658733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009167293984788879, 0.0, 0.0, 0.0, 0.01294506781031997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03419043701658733, 0.0, 0.0, 0.03610734831667893, 0.059143581964759814, 0.0, 0.0, 0.04981683691501763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047462366612944944, 0.0, 0.0, 0.0, 0.027975037610419747, 0.0, 0.03837881897445589, 0.0, 0.0, 0.0, 0.11841354089282098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03873421591490305, 0.06838087403317467, 0.0, 0.0, 0.0, 0.0, 0.02821588261044513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044502820428113335, 0.0, 0.0, 0.03270356509783587, 0.0, 0.057048981262988845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01707151449026732, 0.05168641282490356, 0.0, 0.05091747597983486, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03610734831667893, 0.0, 0.0, 0.0, 0.0, 0.02362166721800316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011869028718904702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06540713019567174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03207150520188294, 0.0, 0.0, 0.0, 0.0, 0.018683092765812846, 0.0, 0.0, 0.0, 0.0, 0.025842904373420718, 0.0, 0.08248252116558244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01204672718912828, 0.0, 0.029571790982379907, 0.0, 0.023466273029421024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06838087403317467, 0.0, 0.0, 0.0, 0.0, 0.011986966270798453, 0.0, 0.0, 0.03763544982720472, 0.0, 0.062293614885915595, 0.0, 0.024168321514148265, 0.0, 0.0, 0.0, 0.0643836284802334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0776181661015895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03610734831667893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02687005624826409, 0.02808491906362845, 0.0, 0.030461550407628137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03419043701658733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023466273029421024, 0.155236332203179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02749417372186081, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17095218508293664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016380862776234704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7259490462572942, 0.03419043701658733, 0.0, 0.0, 0.0, 0.0, 0.03610734831667893, 0.0, 0.0, 0.0, 0.01821254689055642, 0.029571790982379907, 0.0, 0.0, 0.0, 0.019737386420461828, 0.02316601273183412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014268992649957861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03880908305079475, 0.0, 0.0, 0.0, 0.03610734831667893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011927736567658385, 0.0, 0.0913846512228844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16739743404860685, 0.0, 0.04761611104287074, 0.0, 0.0, 0.0, 0.023466273029421024, 0.0, 0.0, 0.0, 0.0, 0.03270356509783587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014748461923244104, 0.0, 0.03610734831667893, 0.0, 0.03744230926009179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0205460499433488, 0.0, 0.0, 0.059791617027251026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035546098627097004, 0.0, 0.0, 0.14079763817652613, 0.0, 0.08302806152502938, 0.012675807025276285, 0.0, 0.0, 0.03610734831667893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03062378594975251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039042354436925476, 0.029571790982379907, 0.0, 0.0, 0.0, 0.0, 0.02687005624826409, 0.0, 0.20166236290472933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038427232266974316, 0.0, 0.0, 0.0, 0.07285381726510262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2393330591161113, 0.04877364928322778, 0.014748461923244104, 0.0, 0.0, 0.0, 0.03148870228247151, 0.0, 0.10337161749368287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03986107801816735, 0.0, 0.0, 0.0, 0.09182866447568913, 0.0, 0.0, 0.021224258339213296, 0.0, 0.14218439450838802, 0.0, 0.0, 0.0, 0.02744983895897126, 0.0, 0.0, 0.025842904373420718, 0.0]"
moosecat_titanic-visualisations-plotly-and-d3.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'plotly', 'colorlover', 'sklearn', 'DecisionTreeClassifier\n', 'IPython', 'string', 'json\n', 'warnings\n', 'graph']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0]",14,1409,"['# data analysis and wrangling', '# visualization', '# plotly', '# machine learning', 'df = train_df # as we alter train_df later', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', '# import graph objects as ""go""', ""#                            filename='distplot with pandas')"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", '# colours', ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# rules defined in the tree object clf', '    if clf.tree_.children_left[node_index] == -1:  # indicates leaf', '        #                          for count, label in count_labels))', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",33,"['get_ipython', 'None.run_line_magic', 'init_notebook_mode', 'warnings.filterwarnings', 'get_ipython', 'None.run_cell_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'go.Histogram', 'go_hist_trace', 'go_hist_trace', 'go.Layout', 'dict', 'iplot', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go.Layout', 'dict', 'iplot', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'tree.DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'clf.tree_.valuenode_index.tolist', 'np.float64', 'None.item', '.format', 'np.float64', 'None.item', 'clf.tree_.valuenode_index.tolist', 'rules', 'rules', 'isinstance', 'int', 'isinstance', 'float', 'isinstance', 'obj.tolist', 'super', 'None.default', 'rules', 'open', 'json.dump', 'json.dumps', 'display', 'IPython.display.Javascript', 'IPython.display.display_javascript', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'init_notebook_mode', 'filterwarnings', 'get_ipython', 'run_cell_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'Histogram', 'go_hist_trace', 'go_hist_trace', 'Layout', 'dict', 'iplot', 'FacetGrid', 'map', 'add_legend', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'go_hist_trace', 'Layout', 'dict', 'iplot', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'tree_', 'float64', 'item', 'format', 'float64', 'item', 'tree_', 'rules', 'rules', 'isinstance', 'int', 'isinstance', 'float', 'isinstance', 'tolist', 'super', 'default', 'rules', 'open', 'dump', 'dumps', 'display', 'display', 'display', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'init_notebook_mode', 'filterwarnings', 'run_cell_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'Histogram', 'go_hist_trace', 'Layout', 'dict', 'iplot', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'tree_', 'float64', 'item', 'format', 'rules', 'isinstance', 'float', 'tolist', 'super', 'default', 'open', 'dump', 'dumps', 'display', 'RandomForestClassifier', 'score']",69,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic init notebook mode filterwarnings get ipython run cell magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map histogram go hist trace go hist trace layout dict iplot facetgrid map add legend go hist trace go hist trace go hist trace go hist trace go hist trace go hist trace layout dict iplot facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round tree float64 item format float64 item tree rules rules isinstance int isinstance float isinstance tolist super default rules open dump dumps display display display randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.09323831064762185, 0.0, 0.0244217407485495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07216599379253906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05461477665326333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022445161054448416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028016554438585292, 0.021669877682025194, 0.0, 0.0, 0.0, 0.02688292450039894, 0.0, 0.0, 0.0, 0.04072701766008327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023771277453432653, 0.0, 0.0, 0.0, 0.05870133094093834, 0.0, 0.0, 0.03874917074602668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08945861909187211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1245591460300969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13866144616960877, 0.023615015672336162, 0.0, 0.0, 0.0, 0.0, 0.051715320243437196, 0.05870133094093834, 0.0, 0.0, 0.0, 0.024591134366016943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12558549014379586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04231411339209204, 0.0, 0.029025263889812043, 0.0, 0.0, 0.0, 0.1074650350703734, 0.0, 0.04354221166808717, 0.11740266188187667, 0.0, 0.0, 0.042480316431226794, 0.0, 0.0, 0.02929404469802233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028452271696955883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39573061702982343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18781550626374882, 0.0, 0.0, 0.0, 0.0, 0.14201993415936334, 0.0, 0.0, 0.20537622454740312, 0.05870133094093834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03572934982580893, 0.04946632712872793, 0.0, 0.0, 0.0, 0.06420621745252061, 0.0, 0.0, 0.0, 0.10343064048687439, 0.03590539780927178, 0.0, 0.0, 0.0, 0.0, 0.176103992822815, 0.0, 0.0, 0.0, 0.0, 0.10922955330652666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024255147154155735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07817823884752288, 0.0, 0.08317354926846439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018221479712846177, 0.0, 0.0, 0.0, 0.035494305733725647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034085689422616014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018131087331258032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036262174662516064, 0.0, 0.0, 0.15180301941352412, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1947690790658455, 0.027099678725114873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06349886887644207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02688292450039894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051715320243437196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04762876595576219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035494305733725647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11149717207960982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467515051471705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027547693948363365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017520070986649317, 0.0, 0.0, 0.097686962994198, 0.0, 0.0, 0.0, 0.021582804691435246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08558832679093949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24003660476932895, 0.176103992822815, 0.03608299689626953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018221479712846177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026462918604085686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035494305733725647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22308034000521193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05461477665326333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023160261108823934, 0.0, 0.0, 0.0, 0.03210310872626031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042480316431226794, 0.0, 0.0, 0.0, 0.4696106475275067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10343064048687439, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22308034000521193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03500256513608643, 0.0, 0.0]"
brudi16_eda-titanic.py,"['numpy', 'pandas', 'seaborn', 'matplotlib']","[1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,480,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '    439     # Create the parser.']",3,"['get_ipython', 'None.run_line_magic', 'pd.set_option', 'sns.catplot', 'g.set_axis_labels', 'int', 'datavalor.map', 'sns.catplot', 'g.set_axis_labels', 'pd.cut', 'datadato1dato2.groupby', 'None.count', 'group_bydato2.tolist', 'sum', 'group_bydato1.tolist', 'pd.DataFrame', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'train_df.astype', 'train_df.astype', 'train_df.astype', 'train_df.astype', 'train_df.astype', 'train_df.astype', 'train_df.info', 'train_df.describe', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'sns.catplot', 'train_df.describe', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'sns.catplot', 'pd.cut', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'train_df.hist', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'sns.catplot', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'sns.catplot', 'train_df.describe', 'pd.cut', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'train_df.hist', 'train_df.describe', 'train_df.groupby', 'None.mean', 'plot_hue_survived', 'percentaje_of_', 'sns.catplot', 'percentaje_of_', 'sns.catplot']","['get_ipython', 'run_line_magic', 'set_option', 'catplot', 'set_axis_labels', 'int', 'map', 'catplot', 'set_axis_labels', 'cut', 'groupby', 'count', 'tolist', 'sum', 'tolist', 'DataFrame', 'read_csv', 'read_csv', 'print', 'print', 'astype', 'astype', 'astype', 'astype', 'astype', 'astype', 'info', 'describe', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'catplot', 'describe', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'catplot', 'cut', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'hist', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'catplot', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'catplot', 'describe', 'cut', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'hist', 'describe', 'groupby', 'mean', 'plot_hue_survived', 'percentaje_of_', 'catplot', 'percentaje_of_', 'catplot']","['get_ipython', 'run_line_magic', 'set_option', 'catplot', 'set_axis_labels', 'int', 'map', 'cut', 'groupby', 'count', 'tolist', 'sum', 'DataFrame', 'read_csv', 'print', 'astype', 'info', 'describe', 'mean', 'plot_hue_survived', 'percentaje_of_', 'hist']",22,"[1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic set option catplot set axis labels int map catplot set axis labels cut groupby count tolist sum tolist dataframe read csv read csv print print astype astype astype astype astype astype info describe groupby mean plot hue survived percentaje catplot describe groupby mean plot hue survived percentaje catplot cut groupby mean plot hue survived percentaje hist groupby mean plot hue survived percentaje catplot groupby mean plot hue survived percentaje catplot describe cut groupby mean plot hue survived percentaje hist describe groupby mean plot hue survived percentaje catplot percentaje catplot,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13185985089621036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10607894820471138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38092072183462666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03785573044626584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026396429397714204, 0.0, 0.0, 0.0, 0.09823957878186013, 0.0, 0.0, 0.0, 0.01653674687691142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09440198646491618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01732908676444104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18302489099878186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06254302736248739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5005353017353379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021761250200445437, 0.0, 0.0, 0.0, 0.0, 0.039105317315324926, 0.0, 0.0, 0.0, 0.0, 0.02186847365214821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10897099455408292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02219587991311056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02208577148731811, 0.0, 0.0, 0.02311421494335843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16607596147525872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04852491433571222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5720403448403862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17730133589891117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028158908750280837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026290364375923064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02197664181603506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07117541206082516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023354948287423998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30706142267149733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10349192458982455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
runzedong_titanic-1st-version.py,"['numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn', 'xgboost']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,260,"[""  X = X[np.logical_and(X > clip[0], X < clip[1])] # won't work for two columns."", ""  X = X[np.logical_and(X > clip[0], X < clip[1])] # won't work for two columns."", ""X_train = Data_train.drop(['Survived'], axis = 1) # Input columns""]",3,"['pd.read_csv', 'pd.read_csv', 'Data_train_sur.head', 'sns.kdeplot', 'sns.kdeplot', 'plt.title', 'sns.kdeplot', 'sns.kdeplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'Data_train.drop', 'X_train.info', 'X_train.apply', 'X_traincol.isnull', 'None.any', 'X_train.fillna', 'X_train.fillna', 'X_train.head', 'X_testcol.isnull', 'None.any', 'X_test.fillna', 'X_test.fillna', 'X_test.apply', 'X_test.info', 'X_train.copy', 'X_test.copy', 'LabelEncoder', 'label_encoder.fit_transform', 'label_encoder.transform', 'label_X_train.head', 'train_test_split', 'X_train_real.info', 'XGBClassifier', 'range', 'range', 'GridSearchCV', 'grid_search.fit', 'grid_search.predict', 'grid_search.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['read_csv', 'read_csv', 'head', 'kdeplot', 'kdeplot', 'title', 'kdeplot', 'kdeplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'drop', 'info', 'apply', 'isnull', 'any', 'fillna', 'fillna', 'head', 'isnull', 'any', 'fillna', 'fillna', 'apply', 'info', 'copy', 'copy', 'LabelEncoder', 'fit_transform', 'transform', 'head', 'train_test_split', 'info', 'XGBClassifier', 'range', 'range', 'GridSearchCV', 'fit', 'predict', 'predict', 'DataFrame', 'to_csv', 'print']","['read_csv', 'head', 'kdeplot', 'title', 'countplot', 'drop', 'info', 'apply', 'isnull', 'any', 'fillna', 'copy', 'LabelEncoder', 'fit_transform', 'transform', 'train_test_split', 'XGBClassifier', 'range', 'GridSearchCV', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']",24,"[1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head kdeplot kdeplot title kdeplot kdeplot title countplot title countplot title countplot title countplot title countplot title drop info apply isnull fillna fillna head isnull fillna fillna apply info copy copy labelencoder fit transform transform head train test split info xgbclassifier range range gridsearchcv fit predict predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13780399956498723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15042703101914456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4036479272139148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1089233227491931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04549194615570522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04646531520427928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18905890768880035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08002539624261804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09638609099065369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12979293068176218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17959305353733318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.129169221364138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.583638104386814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0946970606369483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0830279855188172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03873203025377765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1636740295251957, 0.0, 0.0, 0.0, 0.07232376775828962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06325998724861942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06596331510109242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4770010787573873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06492404638619698, 0.0, 0.0, 0.0, 0.1477066444547286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1010198624354016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
penguinwang96825_xgboost-newbie-for-titanic-dataset.py,"['numpy', 'pandas', 'os\n', 'xgboost', 'sklearn', 'matplotlib']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,190,[],0,"['print', 'df.memory_usage', 'None.sum', 'print', 'dfcol.min', 'dfcol.max', 'str', 'np.iinfo', 'np.iinfo', 'np.iinfo', 'dfcol.astype', 'np.iinfo', 'np.iinfo', 'np.iinfo', 'dfcol.astype', 'np.iinfo', 'np.iinfo', 'np.iinfo', 'dfcol.astype', 'np.iinfo', 'np.iinfo', 'np.iinfo', 'dfcol.astype', 'np.finfo', 'np.finfo', 'np.finfo', 'dfcol.astype', 'np.finfo', 'np.finfo', 'np.finfo', 'dfcol.astype', 'dfcol.astype', 'dfcol.astype', 'df.memory_usage', 'None.sum', 'print', 'print', 'pd.read_csv', 'reduce_mem_usage', 'print', 'print', 'import_data', 'print', 'print', 'import_data', 'train.head', 'test.head', 'df.fillna', 'None.astype', 'df.fillna', 'None.astype', 'df.cat.add_categories', 'None.fillna', 'df.apply', 'None.astype', 'df.map', 'None.astype', 'df.drop', 'preprocess_dataframe', 'preprocess_dataframe', 'cleaned_train.head', 'df.drop', 'train_test_split', 'xgb.DMatrix', 'xgb.train', 'bst.predict', 'print', 'bst.predict', 'xgboost_training', 'xgb.plot_tree', 'plt.gcf', 'fig.set_size_inches', 'plt.show', 'xgboost_predict', 'None.round', 'None.astype', 'pd.DataFrame', 'submit_data.to_csv']","['print', 'memory_usage', 'sum', 'print', 'min', 'max', 'str', 'iinfo', 'iinfo', 'iinfo', 'astype', 'iinfo', 'iinfo', 'iinfo', 'astype', 'iinfo', 'iinfo', 'iinfo', 'astype', 'iinfo', 'iinfo', 'iinfo', 'astype', 'finfo', 'finfo', 'finfo', 'astype', 'finfo', 'finfo', 'finfo', 'astype', 'astype', 'astype', 'memory_usage', 'sum', 'print', 'print', 'read_csv', 'reduce_mem_usage', 'print', 'print', 'import_data', 'print', 'print', 'import_data', 'head', 'head', 'fillna', 'astype', 'fillna', 'astype', 'cat', 'fillna', 'apply', 'astype', 'map', 'astype', 'drop', 'preprocess_dataframe', 'preprocess_dataframe', 'head', 'drop', 'train_test_split', 'DMatrix', 'train', 'predict', 'print', 'predict', 'xgboost_training', 'plot_tree', 'gcf', 'set_size_inches', 'show', 'xgboost_predict', 'round', 'astype', 'DataFrame', 'to_csv']","['print', 'memory_usage', 'sum', 'min', 'max', 'str', 'iinfo', 'astype', 'finfo', 'read_csv', 'reduce_mem_usage', 'import_data', 'head', 'fillna', 'cat', 'apply', 'map', 'drop', 'preprocess_dataframe', 'train_test_split', 'DMatrix', 'train', 'predict', 'xgboost_training', 'plot_tree', 'gcf', 'set_size_inches', 'show', 'xgboost_predict', 'round', 'DataFrame', 'to_csv']",32,"[1 1 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print memory usage sum print min max str iinfo iinfo iinfo astype iinfo iinfo iinfo astype iinfo iinfo iinfo astype iinfo iinfo iinfo astype finfo finfo finfo astype finfo finfo finfo astype astype astype memory usage sum print print read csv reduce mem usage print print import data print print import data head head fillna astype fillna astype cat fillna apply astype map astype drop preprocess dataframe preprocess dataframe head drop train test split dmatrix train predict print predict xgboost training plot tree gcf set size inches show xgboost predict round astype dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0227532884209174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25953830556861096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06495812124403208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023979601812241916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08353247680919385, 0.0, 0.04506798242331703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06043599398330274, 0.0, 0.0, 0.03068818675072547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046824241699438704, 0.0, 0.0, 0.0, 0.3897487274641924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054738787411103614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04286110702332063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7794974549283848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12991624248806416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05270536637015768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02099790324642559, 0.0, 0.0, 0.0, 0.04045261149628327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06495812124403208, 0.12991624248806416, 0.0, 0.04325550576367489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023009689095096274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04112710169837608, 0.0, 0.0, 0.10541073274031536, 0.0, 0.0, 0.11511319735951014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011941623992674882, 0.0, 0.0, 0.0, 0.0, 0.06495812124403208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029513483530722515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021552890283317697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02613206594526338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03873337850294554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02089014455190175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03335946813575787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042433190628913285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021782855917577462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042879323025207486, 0.06495812124403208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05722749363088703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1948743637320962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12991624248806416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
umang5916_titanic-data-analysis-logistic-regression.py,"['pandas', 'numpy', 'sklearn']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,115,[],0,"['pd.read_csv', 'pd.read_csv', 'print', 'print', 'train.drop', 'test.drop', 'print', 'print', 'pd.concat', 'pd.get_dummies', 'print', 'print', 'train_ohe.sparse.to_coo', 'None.tocsr', 'test_ohe.sparse.to_coo', 'None.tocsr', 'KFold', 'kf.split', 'np.zeros', 'print', 'params.copy', 'model_fn', 'eval_fn', 'cv_scores.append', 'print', 'print', 'print', 'print', 'range', 'print', 'LogisticRegression', 'model.fit', 'print', 'model.predict_proba', 'print', 'model.predict_proba', 'run_cv_model', 'pd.read_csv', 'submission.to_csv']","['read_csv', 'read_csv', 'print', 'print', 'drop', 'drop', 'print', 'print', 'concat', 'get_dummies', 'print', 'print', 'sparse', 'tocsr', 'sparse', 'tocsr', 'KFold', 'split', 'zeros', 'print', 'copy', 'model_fn', 'eval_fn', 'append', 'print', 'print', 'print', 'print', 'range', 'print', 'LogisticRegression', 'fit', 'print', 'predict_proba', 'print', 'predict_proba', 'run_cv_model', 'read_csv', 'to_csv']","['read_csv', 'print', 'drop', 'concat', 'get_dummies', 'sparse', 'tocsr', 'KFold', 'split', 'zeros', 'copy', 'model_fn', 'eval_fn', 'append', 'range', 'LogisticRegression', 'fit', 'predict_proba', 'run_cv_model', 'to_csv']",20,"[1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv print print drop drop print print concat get dummies print print sparse tocsr sparse tocsr kfold split zeros print copy model fn eval fn append print print print print range print logisticregression fit print predict proba print predict proba run cv model read csv csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0778905122307101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06930555340349485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07354527307405252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14200985840464708, 0.0, 0.0, 0.0, 0.0, 0.17895432574971776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09086942079540826, 0.0, 0.0, 0.0, 0.0641580174058392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15606350918575526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03912521293313012, 0.0, 0.0, 0.0, 0.0, 0.38468919010104496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04661428105714209, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11469167919895995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059409498807877256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25160699130988057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08118641744637971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5302213054925768, 0.0, 0.2473442907172701, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0800218625270153, 0.0, 0.0, 0.0, 0.10607943027574916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05911594605244296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3579086514994355, 0.06185687512862877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38468919010104496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11469167919895995, 0.0, 0.0]"
shari1_titanic.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,490,[],0,"['pd.read_csv', 'pd.read_csv', 'train.info', 'test.info', 'train.describe', 'train.head', 'train.isnull', 'None.sum', 'train.isnull', 'None.count', 'train.isnull', 'None.sum', 'train.isnull', 'None.count', 'round', 'pd.concat', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'sns.barplot', 'print', 'print', 'print', 'sns.barplot', 'print', 'print', 'sns.barplot', 'print', 'print', 'print', 'print', 'print', 'sns.barplot', 'print', 'print', 'print', 'print', 'train.fillna', 'test.fillna', 'pd.cut', 'pd.cut', 'sns.barplot', 'train.notnull', 'None.astype', 'test.notnull', 'None.astype', 'print', 'print', 'sns.barplot', 'train.drop', 'test.drop', 'train.drop', 'test.drop', 'train.drop', 'test.drop', 'print', 'print', 'print', 'train.fillna', 'test.fillna', 'train.isnull', 'None.sum', 'test.isnull', 'None.sum', 'train.info', 'train.drop', 'test.drop', 'train.info', 'test.info', 'LabelEncoder', 'le.fit_transform', 'le.fit_transform', 'le.fit_transform', 'le.fit_transform', 'le.fit_transform', 'le.fit_transform', 'train.info', 'test.info', 'train.head', 'test.head', 'train.drop', 'test.drop', 'trainn.info', 'testn.info', 'trainn.drop', 'testn.drop', 'LogisticRegression', 'LR.fit', 'LR.predict', 'accuracy_score', 'print', 'DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'accuracy_score', 'print', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'accuracy_score', 'print', 'SVC', 'sv.fit', 'sv.predict', 'accuracy_score', 'print', 'KNeighborsClassifier', 'knc.fit', 'knc.predict', 'accuracy_score', 'print', 'GaussianNB', 'nb.fit', 'nb.predict', 'accuracy_score', 'print', 'pd.DataFrame', 'accu_score.sort_values', 'print', 'pd.DataFrame']","['read_csv', 'read_csv', 'info', 'info', 'describe', 'head', 'isnull', 'sum', 'isnull', 'count', 'isnull', 'sum', 'isnull', 'count', 'round', 'concat', 'subplots', 'distplot', 'distplot', 'legend', 'set_title', 'distplot', 'distplot', 'legend', 'set_title', 'barplot', 'print', 'print', 'print', 'barplot', 'print', 'print', 'barplot', 'print', 'print', 'print', 'print', 'print', 'barplot', 'print', 'print', 'print', 'print', 'fillna', 'fillna', 'cut', 'cut', 'barplot', 'notnull', 'astype', 'notnull', 'astype', 'print', 'print', 'barplot', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'print', 'print', 'print', 'fillna', 'fillna', 'isnull', 'sum', 'isnull', 'sum', 'info', 'drop', 'drop', 'info', 'info', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'info', 'info', 'head', 'head', 'drop', 'drop', 'info', 'info', 'drop', 'drop', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'SVC', 'fit', 'predict', 'accuracy_score', 'print', 'KNeighborsClassifier', 'fit', 'predict', 'accuracy_score', 'print', 'GaussianNB', 'fit', 'predict', 'accuracy_score', 'print', 'DataFrame', 'sort_values', 'print', 'DataFrame']","['read_csv', 'info', 'describe', 'head', 'isnull', 'sum', 'count', 'round', 'concat', 'subplots', 'distplot', 'legend', 'set_title', 'barplot', 'print', 'fillna', 'cut', 'notnull', 'astype', 'drop', 'LabelEncoder', 'fit_transform', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'DecisionTreeClassifier', 'RandomForestClassifier', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'DataFrame', 'sort_values']",33,"[1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv info info describe head isnull sum isnull count isnull sum isnull count round concat subplots distplot distplot legend set title distplot distplot legend set title barplot print print print barplot print print barplot print print print print print barplot print print print print fillna fillna cut cut barplot notnull astype notnull astype print print barplot drop drop drop drop drop drop print print print fillna fillna isnull sum isnull sum info drop drop info info labelencoder fit transform fit transform fit transform fit transform fit transform fit transform info info head head drop drop info info drop drop logisticregression fit predict accuracy score print decisiontreeclassifier fit predict accuracy score print randomforestclassifier fit predict accuracy score print svc fit predict accuracy score print kneighborsclassifier fit predict accuracy score print gaussiannb fit predict accuracy score print dataframe sort values print dataframe,"[0.0, 0.0, 0.3081679352412856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06326440957236491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29223413211315286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037084536482495455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10897572320927462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03799385125907949, 0.0, 0.0, 0.0, 0.09426779881867482, 0.0, 0.0, 0.0, 0.04760452193619997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04167824078458867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033969509457785325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.207381957097096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2917385564482587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09891925581179811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25122495646894016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05136132254021427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06791015704907082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28189961671825225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2027514610233865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0425266107526987, 0.0, 0.0, 0.0, 0.0, 0.049547323002578414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07291419697807047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03178928120118575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15268533933450898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13032551556777053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5268989176238545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030717984701289665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037841185964807816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04676186502943133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19168659835245874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06829782362854617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039112732343724026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044037871397675996, 0.13446431227895092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040606944284692574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07130746754154328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23184886964390014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039112732343724026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mukultiwari_titanic-2.py,"['numpy', 'pandas', 'sklearn', 'xgboost', 'statistics']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,275,"['# Imports', '# Importing Dataset', '# Saving the passengerId of test data for later use.', '# Since passengerId does not have significant contribution to survival directly therefore we will Drop it.', '# Preprocessing and Feature Egineering', '    # Title Feature', '    # Name Leangth', '    # Dropping the name feature ', '    # Categorizing the name length by simply dividing it with 10.', '    # Taking care of null values in Age ', '    # We will create a new feature of family size = SibSp + Parch + 1', '    # wheather or not the passenger was alone ?', '    # Replacing Null values of Fare with Mean', '    # Categorizing the fare value by dividing it with 20 simply', '    # Making a new feature hasCabin which is 1 if cabin is available else 0', '    # Since ""S"" is the most frequent class constituting 72% of the total therefore we will replace null values with ""S""', '# Cleaning Data for Classification', '# Resolving the categorical data for training set', '# Splitting the dataset into training and test set', '# For Submission Use whole Data for training', '# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)', '# Feature Scaling', '# Non_scaled_x_train = X_train', '# Non_scaled_x_test = X_test', '# scaler_x = MinMaxScaler((-1,1))', '# X_train = scaler_x.fit_transform(X_train)', '# X_test = scaler_x.transform(X_test)', '# For Submission consider whole data', '# Feature Scaling', '# Hyper Parameter tuned', '# XGBoost', '# Hyper Parameter tuned', '# Logistic Regression', '# Hyper Parameter tuned', '# Logistic Regression', '# Hyper Parameter tuned', '# KNN', '# Hyper Parameter tuned', '# Random Forest', '# Ensemble of Models Hard Voting', '#     yTest = np.array([])', '#     for i in range(0,len(df)):', '#         yTest = np.append(yTest, mode([xgb_pred[i], lr_pred[i], K_svm_pred[i], knn_pred[i], rf_pred[i]]))', '#     return yTest.astype(int)', '# from sklearn.metrics import classification_report', '# # classification report for precision, recall f1-score and accuracy', '# matrix = classification_report(yTest,y_test,labels=[1,0])', ""# print('Classification report : \\n',matrix)"", '# Making Submission', '# Preparing test data ', '# Taking care of categorical data', '# Feature Scaling', '# y_pred = rf.predict(titanic_test)']",53,"['pd.read_csv', 'pd.read_csv', 'training_data.drop', 'test_data.drop', 'training_data.head', 'test_data.head', 'df.apply', 'None.apply', 'df.apply', 'df.drop', 'df.Name_Len.astype', 'pd.concat', 'full_data.Age.mean', 'full_data.Age.std', 'df.Age.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'df.astype', 'df.Age.astype', 'df.map', 'df.drop', 'df.drop', 'np.isnan', 'df.Fare.mean', 'df.Fare.astype', 'df.Cabin.notnull', 'None.astype', 'df.drop', 'df.fillna', 'preprocess_data', 'preprocess_data', 'LabelEncoder', 'LabelEncoder', 'LabelEncoder', 'label_encoder_sex_tr.fit_transform', 'label_encoder_title_tr.fit_transform', 'label_encoder_embarked_tr.fit_transform', 'MinMaxScaler', 'scaler_x.fit_transform', 'XGBClassifier', 'xgb.fit', 'LogisticRegression', 'lr.fit', 'SVC', 'k_svm.fit', 'KNeighborsClassifier', 'knn.fit', 'RandomForestClassifier', 'rf.fit', 'xgb.predict', 'lr.predict', 'k_svm.predict', 'knn.predict', 'rf.predict', 'np.array', 'range', 'np.append', 'yTest.astype', 'test.replace', 'test.head', 'label_encoder_sex_tr.transform', 'label_encoder_title_tr.transform', 'label_encoder_embarked_tr.transform', 'scaler_x.transform', 'predict_surival', 'print', 'pd.DataFrame', 'titanic_submission.to_csv', 'len']","['read_csv', 'read_csv', 'drop', 'drop', 'head', 'head', 'apply', 'apply', 'apply', 'drop', 'Name_Len', 'concat', 'Age', 'Age', 'Age', 'sum', 'random', 'isnan', 'astype', 'Age', 'map', 'drop', 'drop', 'isnan', 'Fare', 'Fare', 'Cabin', 'astype', 'drop', 'fillna', 'preprocess_data', 'preprocess_data', 'LabelEncoder', 'LabelEncoder', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'MinMaxScaler', 'fit_transform', 'XGBClassifier', 'fit', 'LogisticRegression', 'fit', 'SVC', 'fit', 'KNeighborsClassifier', 'fit', 'RandomForestClassifier', 'fit', 'predict', 'predict', 'predict', 'predict', 'predict', 'array', 'range', 'append', 'astype', 'replace', 'head', 'transform', 'transform', 'transform', 'transform', 'predict_surival', 'print', 'DataFrame', 'to_csv', 'len']","['read_csv', 'drop', 'head', 'apply', 'Name_Len', 'concat', 'Age', 'sum', 'random', 'isnan', 'astype', 'map', 'Fare', 'Cabin', 'fillna', 'preprocess_data', 'LabelEncoder', 'fit_transform', 'MinMaxScaler', 'XGBClassifier', 'fit', 'LogisticRegression', 'SVC', 'KNeighborsClassifier', 'RandomForestClassifier', 'predict', 'array', 'range', 'append', 'replace', 'transform', 'predict_surival', 'print', 'DataFrame', 'to_csv', 'len']",36,"[1 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv drop drop head head apply apply apply drop name len concat age age age sum random isnan astype age map drop drop isnan fare fare cabin astype drop fillna preprocess data preprocess data labelencoder labelencoder labelencoder fit transform fit transform fit transform minmaxscaler fit transform xgbclassifier fit logisticregression fit svc fit kneighborsclassifier fit randomforestclassifier fit predict predict predict predict predict array range append astype replace head transform transform transform transform predict surival print dataframe csv len,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27987882683744997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06810609156197646, 0.17673125286113248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11895639770903954, 0.0, 0.0, 0.1550698250396075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09411721516481515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06059955481960294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09312818861586172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2162734899088357, 0.0, 0.03889509092415679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23836386161686263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1762428365163943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04041079809714541, 0.0, 0.0, 0.0, 0.0, 0.0, 0.307893571666548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11097146345203794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17446571091169338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06949240637850533, 0.0, 0.0, 0.0, 0.0, 0.24289469422463278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14496449664947136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05194661903719172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05436555923327661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11413254186103583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07702114120978736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21296391903859885, 0.0, 0.0, 0.2729183655797741, 0.0, 0.0, 0.033115440549446415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0855337764377706, 0.05019602169578649, 0.0, 0.0, 0.06996970670936249, 0.0, 0.0, 0.0, 0.06183598989825777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06130388272652916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05493177369949546, 0.0, 0.0, 0.0, 0.0, 0.1681827250430799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06635549422057123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5051499310673716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08637082091679192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ozankaans_beginner-titanic-disaster-prediction.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,144,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Matplotlib and seaborn for plotting graphs for EDA', '# Load DataSet', '# Data Info', '# Count the nulls present in columns', '# Drop columns not used or convert string into categorical data', '# Almost all female survived whoose Fare>30', '# Pair Plot applicable for low no. of dimensions', '# Facetgrid + Distance plot', '# Check for balanced data', '# Count Not Null', '# Classification Report', '# Confusion Matrix', '# Accuracy=TP+TN/Total=0.8022', '# Error_rate=FP+FN/Total=0.1977']",22,"['print', 'pd.read_csv', 'print', 'print', 'print', 'print', 'print', 'print', 'pd.get_dummies', 'pd.get_dummies', 'titanic.drop', 'pd.concat', 'train.fillna', 'print', 'sns.scatterplot', 'plt.show', 'sns.pairplot', 'plt.show', 'enumerate', 'sns.FacetGrid', 'fg.map', 'None.add_legend', 'plt.show', 'sns.countplot', 'plt.show', 'train.isnull', 'None.count', 'train_test_split', 'print', 'print', 'LogisticRegression', 'titanic_model.fit', 'titanic_model.predict', 'print', 'print']","['print', 'read_csv', 'print', 'print', 'print', 'print', 'print', 'print', 'get_dummies', 'get_dummies', 'drop', 'concat', 'fillna', 'print', 'scatterplot', 'show', 'pairplot', 'show', 'enumerate', 'FacetGrid', 'map', 'add_legend', 'show', 'countplot', 'show', 'isnull', 'count', 'train_test_split', 'print', 'print', 'LogisticRegression', 'fit', 'predict', 'print', 'print']","['print', 'read_csv', 'get_dummies', 'drop', 'concat', 'fillna', 'scatterplot', 'show', 'pairplot', 'enumerate', 'FacetGrid', 'map', 'add_legend', 'countplot', 'isnull', 'count', 'train_test_split', 'LogisticRegression', 'fit', 'predict']",20,"[1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv print print print print print print get dummies get dummies drop concat fillna print scatterplot show pairplot show enumerate facetgrid map add legend show countplot show isnull count train test split print print logisticregression fit predict print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.11306336243589468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10259436058211903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15074065502890688, 0.0, 0.0, 0.11685493341999632, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05255498983811353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06725788674318779, 0.0, 0.0, 0.0, 0.18994872557028347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1801105440731928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12183075982558794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06841502390127475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057917814754961966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13800805633020216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09348531074222484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1008585535355792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08794503821667737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09204027659660416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19713813072074746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060090917515451946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6727687935027424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05234381558956554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.231023852329658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4581795714392906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09156793705235221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09548096589401579, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0939766391243625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ayang98_first-titanic.py,"['numpy', 'pandas', 'os\n', 'sklearn\n', 'pandas\n', 'sklearn', 'random\n', 'catboost\n', 'xgboost']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,174,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Create regularization hyperparameter space', '# Create hyperparameter options']",10,"['print', 'pd.read_csv', 'training_data.mean', 'training_data.fillna', 'training_data.fillna', 'pd.read_csv', 'test_data.mean', 'test_data.mean', 'test_data.fillna', 'test_data.fillna', 'LabelEncoder', 'LabelEncoder', 'OneHotEncoder', 'OneHotEncoder', 'OneHotEncoder', 'le_Sex.fit_transform', 'le_Embarked.fit_transform', 'Sex_ohe.fit_transform', 'None.toarray', 'Embarked_ohe.fit_transform', 'None.toarray', 'Class_ohe.fit_transform', 'None.toarray', 'pd.DataFrame', 'pd.concat', 'pd.DataFrame', 'pd.concat', 'pd.DataFrame', 'pd.concat', 'training_data.drop', 'le_Sex.fit_transform', 'le_Embarked.fit_transform', 'Sex_ohe.fit_transform', 'None.toarray', 'Embarked_ohe.fit_transform', 'None.toarray', 'Class_ohe.fit_transform', 'None.toarray', 'pd.DataFrame', 'pd.concat', 'pd.DataFrame', 'pd.concat', 'pd.DataFrame', 'pd.concat', 'test_data.drop', 'StandardScaler', 'StandardScaler', 'StandardScaler', 'scaler1.fit', 'scaler2.fit', 'scaler1.transform', 'scaler2.transform', 'print', 'print', 'np.random.seed', 'xgb.XGBClassifier', 'list', 'enumerate', 'print', 'best_estimator.fit', 'roc_auc_score', 'print', 'y_preds.append', 'np.concatenate', 'pd.read_csv', 'y_preds.mean', 'mean_preds.astype', 'subs.to_csv']","['print', 'read_csv', 'mean', 'fillna', 'fillna', 'read_csv', 'mean', 'mean', 'fillna', 'fillna', 'LabelEncoder', 'LabelEncoder', 'OneHotEncoder', 'OneHotEncoder', 'OneHotEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'toarray', 'fit_transform', 'toarray', 'fit_transform', 'toarray', 'DataFrame', 'concat', 'DataFrame', 'concat', 'DataFrame', 'concat', 'drop', 'fit_transform', 'fit_transform', 'fit_transform', 'toarray', 'fit_transform', 'toarray', 'fit_transform', 'toarray', 'DataFrame', 'concat', 'DataFrame', 'concat', 'DataFrame', 'concat', 'drop', 'StandardScaler', 'StandardScaler', 'StandardScaler', 'fit', 'fit', 'transform', 'transform', 'print', 'print', 'random', 'XGBClassifier', 'list', 'enumerate', 'print', 'fit', 'roc_auc_score', 'print', 'append', 'concatenate', 'read_csv', 'mean', 'astype', 'to_csv']","['print', 'read_csv', 'mean', 'fillna', 'LabelEncoder', 'OneHotEncoder', 'fit_transform', 'toarray', 'DataFrame', 'concat', 'drop', 'StandardScaler', 'fit', 'transform', 'random', 'XGBClassifier', 'list', 'enumerate', 'roc_auc_score', 'append', 'concatenate', 'astype', 'to_csv']",23,"[1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv mean fillna fillna read csv mean mean fillna fillna labelencoder labelencoder onehotencoder onehotencoder onehotencoder fit transform fit transform fit transform toarray fit transform toarray fit transform toarray dataframe concat dataframe concat dataframe concat drop fit transform fit transform fit transform toarray fit transform toarray fit transform toarray dataframe concat dataframe concat dataframe concat drop standardscaler standardscaler standardscaler fit fit transform transform print print random xgbclassifier list enumerate print fit roc auc score print append concatenate read csv mean astype csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045634596271451146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03463492862028551, 0.08358958638768037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2436289754703402, 0.08845212317080461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08320092356905702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15637030966459722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05323869637853142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07128420944221844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10830928123321833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2979955091621789, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10850132054469656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05332913283875489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1495621479618668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25760550563109946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11094527120602936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0573120445732556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062149956839425334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07802339319809311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034980445278682194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1914667508625515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.595678822473363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5077147865657501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057872907573691096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sanchitvj_titanic.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'plotly', 're\n', 'warnings\n', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",10,790,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ' #   Column       Non-Null Count  Dtype  ', ""train_df['Title'] = train_df['Title'].astype(int)                     # this is performed beacuse it was giving float values of title"", '# We will use GridSearchCV to find best parameters']",12,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'py.init_notebook_mode', 'warnings.filterwarnings', 'pd.read_csv', 'print', 'train_df.head', 'pd.read_csv', 'print', 'test_df.head', 'train_df.info', 'train_df.describe', 'sns.heatmap', 'sns.set_style', 'plt.subplots', 'sns.barplot', 'sns.barplot', 'sns.barplot', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'data.str.extract', 'pd.crosstab', 'None.transpose', 'data.replace', 'data.replace', 'data.replace', 'data.replace', 'train_df.groupby', 'None.mean', 'test_df.replace', 'train_df.replace', 'train_df.fillna', 'train_df.astype', 'pd.DataFrame', 'None.transpose', 'print', 'print', 'print', 'plt.subplots', 'sns.heatmap', 'sns.heatmap', 'train_df.fillna', 'test_df.fillna', 'pd.cut', 'pd.cut', 'train_dftrain_df.mode', 'train_dftrain_df.mode', 'train_dftrain_df.mode', 'train_dftrain_df.mode', 'train_dftrain_df.mode', 'range', 'range', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'train_df.map', 'None.astype', 'test_df.map', 'None.astype', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'train_df.fillna', 'train_df.replace', 'test_df.replace', 'train_df.fillna', 'test_df.fillna', 'data.map', 'data.map', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'test_df.fillna', 'pd.qcut', 'pd.qcut', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'pd.to_numeric', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'train_df.replace', 'test_df.replace', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'df_m.value_counts', 'df_f.value_counts', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'train_test_split', 'LogisticRegression', 'lr.fit', 'lr.predict', 'print', 'round', 'print', 'round', 'print', 'range', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'error_rate.append', 'plt.figure', 'plt.plot', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'print', 'round', 'print', 'round', 'print', 'SVC', 'GridSearchCV', 'gcv.fit', 'SVC', 'svc.fit', 'svc.predict', 'print', 'round', 'print', 'round', 'print', 'DecisionTreeClassifier', 'dt.fit', 'dt.predict', 'print', 'round', 'print', 'round', 'print', 'RandomForestClassifier', 'GridSearchCV', 'gcv.fit', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'print', 'round', 'print', 'round', 'print', 'AdaBoostClassifier', 'adb.fit', 'adb.predict', 'print', 'round', 'print', 'round', 'print', 'GradientBoostingClassifier', 'GridSearchCV', 'gcv.fit', 'GradientBoostingClassifier', 'gdb.fit', 'gdb.predict', 'print', 'round', 'print', 'round', 'print', 'XGBClassifier', 'xgbc.fit', 'xgbc.predict', 'print', 'round', 'print', 'round', 'print', 'go.Bar', 'go.Bar', 'go.Layout', 'go.Figure', 'py.iplot', 'pd.to_numeric', 'rf.predict', 'test_df.to_csv']","['walk', 'print', 'get_ipython', 'run_line_magic', 'init_notebook_mode', 'filterwarnings', 'read_csv', 'print', 'head', 'read_csv', 'print', 'head', 'info', 'describe', 'heatmap', 'set_style', 'subplots', 'barplot', 'barplot', 'barplot', 'subplots', 'distplot', 'distplot', 'legend', 'set_title', 'distplot', 'distplot', 'legend', 'set_title', 'str', 'crosstab', 'transpose', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'replace', 'replace', 'fillna', 'astype', 'DataFrame', 'transpose', 'print', 'print', 'print', 'subplots', 'heatmap', 'heatmap', 'fillna', 'fillna', 'cut', 'cut', 'mode', 'mode', 'mode', 'mode', 'mode', 'range', 'range', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'map', 'astype', 'map', 'astype', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'fillna', 'replace', 'replace', 'fillna', 'fillna', 'map', 'map', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'fillna', 'qcut', 'qcut', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'to_numeric', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'replace', 'replace', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'value_counts', 'value_counts', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'head', 'head', 'drop', 'drop', 'head', 'head', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'range', 'KNeighborsClassifier', 'fit', 'predict', 'append', 'figure', 'plot', 'KNeighborsClassifier', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'SVC', 'GridSearchCV', 'fit', 'SVC', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'RandomForestClassifier', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'AdaBoostClassifier', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'GradientBoostingClassifier', 'GridSearchCV', 'fit', 'GradientBoostingClassifier', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'XGBClassifier', 'fit', 'predict', 'print', 'round', 'print', 'round', 'print', 'Bar', 'Bar', 'Layout', 'Figure', 'iplot', 'to_numeric', 'predict', 'to_csv']","['walk', 'print', 'get_ipython', 'run_line_magic', 'init_notebook_mode', 'filterwarnings', 'read_csv', 'head', 'info', 'describe', 'heatmap', 'set_style', 'subplots', 'barplot', 'distplot', 'legend', 'set_title', 'str', 'crosstab', 'transpose', 'replace', 'groupby', 'mean', 'fillna', 'astype', 'DataFrame', 'cut', 'mode', 'range', 'value_counts', 'Bar', 'Layout', 'Figure', 'iplot', 'map', 'qcut', 'to_numeric', 'sort_values', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'append', 'figure', 'plot', 'SVC', 'GridSearchCV', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'XGBClassifier', 'to_csv']",56,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0
 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic init notebook mode filterwarnings read csv print head read csv print head info describe heatmap set style subplots barplot barplot barplot subplots distplot distplot legend set title distplot distplot legend set title str crosstab transpose replace replace replace replace groupby mean replace replace fillna astype dataframe transpose print print print subplots heatmap heatmap fillna fillna cut cut mode mode mode mode mode range range value counts value counts bar bar layout figure iplot map astype map astype value counts value counts bar bar layout figure iplot value counts value counts bar bar layout figure iplot fillna replace replace fillna fillna map map value counts value counts bar bar layout figure iplot fillna qcut qcut value counts value counts bar bar layout figure iplot numeric value counts value counts bar bar layout figure iplot replace replace value counts value counts bar bar layout figure iplot groupby mean sort values groupby mean value counts value counts bar bar layout figure iplot head head drop drop head head drop train test split logisticregression fit predict print round print round print range kneighborsclassifier fit predict append figure plot kneighborsclassifier fit predict print round print round print svc gridsearchcv fit svc fit predict print round print round print decisiontreeclassifier fit predict print round print round print randomforestclassifier gridsearchcv fit randomforestclassifier fit predict print round print round print adaboostclassifier fit predict print round print round print gradientboostingclassifier gridsearchcv fit gradientboostingclassifier fit predict print round print round print xgbclassifier fit predict print round print round print bar bar layout figure iplot numeric predict csv,"[0.0, 0.0, 0.0, 0.027536890821959085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01817728140520426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041387602526503496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.511093738778361, 0.0, 0.06372656277746061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3008672767005921, 0.0, 0.0, 0.0, 0.0, 0.021423534979641987, 0.024855592978595704, 0.0, 0.0, 0.0, 0.041113354938192244, 0.0, 0.0, 0.0, 0.010380965884175405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01817728140520426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014815244621342897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.090446240569487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03180924708840493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18298652549144495, 0.0, 0.0, 0.0, 0.07549852037927918, 0.0, 0.02219486902287785, 0.0, 0.0, 0.0, 0.1095676459413973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01087835835213417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05147288514573847, 0.0, 0.0, 0.0, 0.0, 0.06598403498885162, 0.0, 0.0, 0.043085298839807315, 0.0, 0.0, 0.0, 0.0, 0.05923580322560194, 0.05978157710765733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013660655122153103, 0.03782562170090421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3559083174137627, 0.01372796479329913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037094568115611445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2690139528829864, 0.0, 0.031800331586811274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013933494529625988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013864373811977006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013864373811977006, 0.0, 0.0, 0.05803992249564298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04468046405349296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14566783094518698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03954536860152919, 0.0, 0.0, 0.0, 0.06840669360489592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015900165793405637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09473222822261664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2651519128109826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04213001896467575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026794290814816223, 0.0, 0.0, 0.056024021619489064, 0.0, 0.0, 0.0, 0.01650381285390825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16361795281376776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32631073238060804, 0.0, 0.013795867508834497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04468046405349296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017058376960123477, 0.0, 0.0, 0.0, 0.014435517161952228, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023052074799716597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020556677469096122, 0.0, 0.0, 0.0, 0.0, 0.057619186833174726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035420106001270726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015052398974706768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031099582885331066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014815244621342897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06659120748106843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3008672767005921, 0.017058376960123477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01759754139136183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023052074799716597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
alagappan_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,392,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04458423492702482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07865667322233022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172539892595686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21253464566011832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04293086506933447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431745498221466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06217197055832407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1038647689272524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5834791208246738, 0.04516844628469951, 0.0, 0.0, 0.22470723731702552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048041479577273886, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053956143394937324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045677422002361044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19047233475457281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14369390600990528, 0.0, 0.0, 0.0, 0.0, 0.02469468754518843, 0.0, 0.0, 0.09820578880126213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06833953619962328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03433813161044625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11647254395745248, 0.07372805772905346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3815299057393845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039771517035677564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034852228728417936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.03629420907111263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2235209192601581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07954303407135513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047391259657758644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022107722972670885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11420394854594243, 0.03351064408530649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041281435841698653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0345079785191372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06970445745683587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050615630922711694, 0.18626743271679844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051418976303892444, 0.0, 0.0, 0.0, 0.0, 0.2402073978863694, 0.07334442273431843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07779023229049523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06140362395662589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
trinkwasserpsprudler_titanic.py,"['numpy', 'pandas', 'seaborn', 'os\n', 'pandas_profiling\n', 'sklearn']","[1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,379,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', 'import seaborn as sns # data visualisation', '# show columns and dtypes', '# Column Description', '# PassengerId -> id', '# Survived -> if the passenger survived or not (0=not survived / 1=survived)', '# Pclass -> The class which the passenger travelled [3,2,1]', '# Name -> The name of the passenger', ""# Sex -> gender ['male', 'female']"", '# Age -> the age of the passenger', '# SibSp -> Amount of Siblings/Spouses', '# Parch -> Amount of family members on board (mother, father, daughter, son, stepdaughter, stepson)', '# Ticket -> Ticket Number', '# Fare -> Passenger Fare', '# Cabine -> Cabine Number', '# Embarked -> Port of Embarkation (Port where the passengers went on board) C = Cherbourg, Q = Queenstown, S = Southampton', '# Save the report in output', '# Show numerical description of the columns (-> object columsn are ignored)', '# Show columsn with nan values', '# Print correlation Matrix', '# drop embarked as it is not neccessary for prediction', '# only for test_data, since there is a missing ""Fare"" values', '# Man kÃ¶nnte die Werte hier auch normalisieren...', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '      5 # get average, std, and number of NaN values in titanic_df', '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '      9 # average survived passengers by age', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# combine the values in train_data', '# combine the values in test_data', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '     19 # plot', ""     22 # sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', ""     29 # sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# from sklearn.model_selection import train_test_split', '# # if we set the random state to a fix value we alwas get the same result in splitting', '# train_set, test_set = train_test_split(train_data_selected, test_size=0.2, random_state=42)', '# Random Forests', '    248         # Validate or convert input data']",70,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_data.head', 'train_data.info', 'test_data.info', 'train_data.profile_report', 'train_data.profile_report', 'profile.to_file', 'train_data.describe', 'train_data.isna', 'None.sum', 'test_data.isna', 'None.sum', 'train_data.corr', 'corr.style.background_gradient', 'train_data.drop', 'test_data.drop', 'test_data.fillna', 'train_data.astype', 'test_data.astype', 'pd.DataFrame', 'pd.DataFrame', 'train_data.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'train_data.mean', 'train_data.std', 'train_data.isnull', 'None.sum', 'test_data.mean', 'test_data.std', 'test_data.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'train_data.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'train_data.astype', 'test_data.astype', 'train_data.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'train_data.groupby', 'None.mean', 'sns.barplot', 'train_data.drop', 'test_data.drop', 'train_data.drop', 'test_data.drop', 'plt.subplots', 'sns.countplot', 'train_data.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'train_data.apply', 'test_data.apply', 'train_data.drop', 'test_data.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'train_data.join', 'test_data.join', 'plt.subplots', 'sns.countplot', 'train_data.groupby', 'None.mean', 'sns.barplot', 'train_data.drop', 'test_data.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'train_data.drop', 'test_data.drop', 'train_data.join', 'test_data.join', 'train_data.drop', 'test_data.drop', 'None.copy', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'pd.DataFrame', 'submission.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'head', 'info', 'info', 'profile_report', 'profile_report', 'to_file', 'describe', 'isna', 'sum', 'isna', 'sum', 'corr', 'style', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'info', 'profile_report', 'to_file', 'describe', 'isna', 'sum', 'corr', 'style', 'drop', 'fillna', 'astype', 'DataFrame', 'plot', 'subplots', 'set_title', 'mean', 'std', 'isnull', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'groupby', 'barplot', 'countplot', 'set_xticklabels', 'apply', 'get_dummies', 'join', 'factorplot', 'copy', 'RandomForestClassifier', 'fit', 'predict', 'score', 'to_csv']",44,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv head info info profile report profile report file describe isna sum isna sum corr style drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy randomforestclassifier fit predict score dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.051607826309474816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09104787681976315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19972101849697052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18451226811326218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049693992314551114, 0.061504089371087395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10667698142736017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0719662513698737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09017035331959226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04289568224921787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5525981071114017, 0.05228407158595533, 0.0, 0.0, 0.1734043747813596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05560970907614005, 0.06880564468369756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12996580784412637, 0.0, 0.031228070653368738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02643661447618049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12598768773457503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12474807779970672, 0.0, 0.0, 0.0, 0.0, 0.028584972865068316, 0.0, 0.0, 0.11367666843080472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07910542639192884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1644230894035995, 0.13482108256915187, 0.08534283034448907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2944228924491179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046036935401069914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04201182863959799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21561113094111814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09207387080213983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027428528279200403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025590470020155208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24183620555757157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1321951032705206, 0.03878975387384838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047784719738069095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19806299980818282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04034268547297708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1724889047528945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1376112893673951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05951928080510326, 0.0, 0.0, 0.0, 0.0, 0.2224388363045602, 0.16979751858193393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09004494084495614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050951473511538545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07107686304615751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
daniel83fr_titanic-how-to-start-a-beginners-path.py,"['pandas', 'warnings\n', 'seaborn', 'sklearn', 'sys\n']","[1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,1140,"['# Supress unnecessary warnings so that presentation looks clean', '# Print all rows and columns', '# Required imports']",3,"['warnings.filterwarnings', 'pd.set_option', 'pd.set_option', 'pd.read_csv', 'train_data.info', 'pd.read_csv', 'print', 'print', 'print', 'train_data.info', 'pd.read_csv', 'print', 'print', 'print', 'test_data.info', 'pd.read_csv', 'print', 'print', 'KNeighborsClassifier', 'cross_val_score', 'print', 'extract_survived', 'create_useless_column', 'apply_model', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'train_data.corr', 'print', 'sns.heatmap', 'data.drop', 'data.drop', 'pd.read_csv', 'drop_survived', 'drop_passenger_id', 'apply_model', 'print', 'print', 'print', 'print', 'pclass.astype', 'pclass.astype', 'pclass.astype', 'pclass.drop', 'pclass.corr', 'print', 'sns.heatmap', 'test_data.groupby', 'None.size', 'groups.plot.bar', 'train_data.copy', 'preprocessing.maxabs_scale', 'print', 'preprocessing.maxabs_scale', 'train_data.copy', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'apply_model', 'print', 'print', 'print', 'print', 'train_data.copy', 'data.str.replace', 'data.str.replace', 'data.str.split', 'data.unique', 'print', 'test_data.copy', 'data2.str.replace', 'data2.str.replace', 'data2.str.split', 'data2.unique', 'print', 'unique1.__contains__', 'print', 'data.corr', 'print', 'pd.get_dummies', 'sns.heatmap', 'data.groupby', 'None.count', 'test_data.copy', 'test_data.str.replace', 'data.str.replace', 'data.str.split', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.str.replace', 'data.groupby', 'None.size', 'groups.plot.bar', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.split', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'apply_model', 'data.str.contains', 'None.astype', 'pd.read_csv', 'handle_sex', 'None.groupby', 'None.size', 'groups.plot.bar', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'apply_model', 'print', 'print', 'print', 'print', 'sex.astype', 'sex.corr', 'print', 'sns.heatmap', 'new_data.fillna', 'new_data.astype', 'preprocessing.maxabs_scale', 'pd.read_csv', 'groups.plot.bar', 'handle_age', 'None.groupby', 'None.size', 'groups.plot.bar', 'print', 'print', 'print', 'print', 'age.fillna', 'age.astype', 'ageage.astype', 'ageage.astype', 'ageage.astype', 'ageage.astype', 'age.astype', 'age.drop', 'age.corr', 'print', 'sns.heatmap', 'train_data.copy', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'apply_model', 'groups.plot.bar', 'test_data.groupby', 'None.size', 'groups.plot.bar', 'print', 'print', 'print', 'print', 'sib.corr', 'print', 'sns.heatmap', 'groups.plot.bar', 'test_data.groupby', 'None.size', 'groups.plot.bar', 'print', 'print', 'print', 'print', 'sib.corr', 'print', 'sns.heatmap', 'preprocessing.maxabs_scale', 'preprocessing.maxabs_scale', 'train_data.copy', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'apply_model', 'train_data.copy', 'print', 'data.drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'apply_model', 'new_data.fillna', 'new_data.astype', 'preprocessing.maxabs_scale', 'pd.read_csv', 'handle_fare', 'None.groupby', 'None.size', 'groups.plot.bar', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'apply_model', 'train_data.copy', 'print', 'new_data.isna', 'None.astype', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'apply_model', 'print', 'print', 'print', 'print', 'embarked.isna', 'None.astype', 'embarked.fillna', 'embarked.str.contains', 'None.astype', 'embarked.str.contains', 'None.astype', 'embarked.str.contains', 'None.astype', 'embarked.drop', 'embarked.corr', 'print', 'sns.heatmap', 'new_data.isna', 'None.astype', 'new_data.fillna', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.drop', 'print', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'handle_embarked', 'train_data.copy', 'process_data', 'print', 'apply_model', 'KNeighborsClassifier', 'pd.read_csv', 'process_data', 'pd.read_csv', 'process_data', 'model.fit', 'model.predict', 'print', 'pd.DataFrame', 'test_labels.astype', 'result.astype', 'print', 'df.to_csv', 'print', 'pd.read_csv', 'pd.read_csv', 'data.drop', 'data.drop', 'KNeighborsClassifier', 'cross_val_score', 'print', 'preprocessing.maxabs_scale', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.split', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.replace', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.drop', 'data.str.contains', 'None.astype', 'new_data.fillna', 'new_data.astype', 'preprocessing.maxabs_scale', 'preprocessing.maxabs_scale', 'preprocessing.maxabs_scale', 'data.drop', 'new_data.fillna', 'new_data.astype', 'preprocessing.maxabs_scale', 'new_data.isna', 'None.astype', 'new_data.isna', 'None.astype', 'new_data.fillna', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.str.contains', 'None.astype', 'new_data.drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'handle_embarked', 'train_data.copy', 'process_data', 'apply_model', 'KNeighborsClassifier', 'pd.read_csv', 'process_data', 'pd.read_csv', 'process_data', 'model.fit', 'model.predict', 'print', 'pd.DataFrame', 'test_labels.astype', 'result.astype', 'print', 'df.to_csv', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'data.drop', 'data.drop', 'preprocessing.maxabs_scale', 'string.replace', 'new_datacolumn.str.contains', 'None.astype', 'new_datacolumn.str.contains', 'None.astype', 'x.replace', 'None.replace', 'None.split', 'new_data.apply', 'to_replace.keys', 'new_data.str.replace', 'filter_data_contains', 'new_data.drop', 'new_datacolumn.fillna', 'new_datacolumn.fillna', 'new_datacolumn.isna', 'None.astype', 'filter_data_contains', 'fill_na_with_mean', 'preprocessing.maxabs_scale', 'preprocessing.maxabs_scale', 'preprocessing.maxabs_scale', 'data.drop', 'fill_na_with_mean', 'preprocessing.maxabs_scale', 'is_na', 'new_data.isna', 'None.astype', 'new_data.fillna', 'filter_data_contains', 'filter_data_contains', 'filter_data_contains', 'new_data.drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'handle_embarked', 'train_data.copy', 'extract_survived', 'process_data', 'KNeighborsClassifier', 'linear_model.LinearRegression', 'linear_model.Ridge', 'linear_model.Lasso', 'linear_model.ElasticNet', 'linear_model.Lars', 'linear_model.LassoLars', 'linear_model.OrthogonalMatchingPursuit', 'linear_model.BayesianRidge', 'linear_model.ARDRegression', 'linear_model.LogisticRegression', 'linear_model.SGDClassifier', 'linear_model.Perceptron', 'linear_model.PassiveAggressiveClassifier', 'linear_model.TheilSenRegressor', 'linear_model.RANSACRegressor', 'linear_model.HuberRegressor', 'SVC', 'SVC', 'GaussianProcessClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'MLPClassifier', 'AdaBoostClassifier', 'GaussianNB', 'QuadraticDiscriminantAnalysis', 'classifiers.keys', 'cross_val_score', 'scores.mean', 'scores.mean', 'print', 'print', 'pd.DataFrame', 'pd.read_csv', 'process_data', 'pd.read_csv', 'process_data', 'best_model_names.keys', 'model.fit', 'model.predict_proba', 'print', 'list', 'resmodels_list.min', 'resmodels_list.max', 'res.astype', 'res.to_csv', 'res_filtered.to_csv', 'res.head']","['filterwarnings', 'set_option', 'set_option', 'read_csv', 'info', 'read_csv', 'print', 'print', 'print', 'info', 'read_csv', 'print', 'print', 'print', 'info', 'read_csv', 'print', 'print', 'KNeighborsClassifier', 'cross_val_score', 'print', 'extract_survived', 'create_useless_column', 'apply_model', 'read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'corr', 'print', 'heatmap', 'drop', 'drop', 'read_csv', 'drop_survived', 'drop_passenger_id', 'apply_model', 'print', 'print', 'print', 'print', 'astype', 'astype', 'astype', 'drop', 'corr', 'print', 'heatmap', 'groupby', 'size', 'plot', 'copy', 'maxabs_scale', 'print', 'maxabs_scale', 'copy', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'apply_model', 'print', 'print', 'print', 'print', 'copy', 'str', 'str', 'str', 'unique', 'print', 'copy', 'str', 'str', 'str', 'unique', 'print', '__contains__', 'print', 'corr', 'print', 'get_dummies', 'heatmap', 'groupby', 'count', 'copy', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'groupby', 'size', 'plot', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'astype', 'str', 'astype', 'str', 'astype', 'drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'apply_model', 'str', 'astype', 'read_csv', 'handle_sex', 'groupby', 'size', 'plot', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'apply_model', 'print', 'print', 'print', 'print', 'astype', 'corr', 'print', 'heatmap', 'fillna', 'astype', 'maxabs_scale', 'read_csv', 'plot', 'handle_age', 'groupby', 'size', 'plot', 'print', 'print', 'print', 'print', 'fillna', 'astype', 'astype', 'astype', 'astype', 'astype', 'astype', 'drop', 'corr', 'print', 'heatmap', 'copy', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'apply_model', 'plot', 'groupby', 'size', 'plot', 'print', 'print', 'print', 'print', 'corr', 'print', 'heatmap', 'plot', 'groupby', 'size', 'plot', 'print', 'print', 'print', 'print', 'corr', 'print', 'heatmap', 'maxabs_scale', 'maxabs_scale', 'copy', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'apply_model', 'copy', 'print', 'drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'apply_model', 'fillna', 'astype', 'maxabs_scale', 'read_csv', 'handle_fare', 'groupby', 'size', 'plot', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'apply_model', 'copy', 'print', 'isna', 'astype', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'apply_model', 'print', 'print', 'print', 'print', 'isna', 'astype', 'fillna', 'str', 'astype', 'str', 'astype', 'str', 'astype', 'drop', 'corr', 'print', 'heatmap', 'isna', 'astype', 'fillna', 'str', 'astype', 'str', 'astype', 'str', 'astype', 'drop', 'print', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'handle_embarked', 'copy', 'process_data', 'print', 'apply_model', 'KNeighborsClassifier', 'read_csv', 'process_data', 'read_csv', 'process_data', 'fit', 'predict', 'print', 'DataFrame', 'astype', 'astype', 'print', 'to_csv', 'print', 'read_csv', 'read_csv', 'drop', 'drop', 'KNeighborsClassifier', 'cross_val_score', 'print', 'maxabs_scale', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'astype', 'str', 'astype', 'str', 'astype', 'drop', 'str', 'astype', 'fillna', 'astype', 'maxabs_scale', 'maxabs_scale', 'maxabs_scale', 'drop', 'fillna', 'astype', 'maxabs_scale', 'isna', 'astype', 'isna', 'astype', 'fillna', 'str', 'astype', 'str', 'astype', 'str', 'astype', 'drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'handle_embarked', 'copy', 'process_data', 'apply_model', 'KNeighborsClassifier', 'read_csv', 'process_data', 'read_csv', 'process_data', 'fit', 'predict', 'print', 'DataFrame', 'astype', 'astype', 'print', 'to_csv', 'filterwarnings', 'read_csv', 'read_csv', 'drop', 'drop', 'maxabs_scale', 'replace', 'str', 'astype', 'str', 'astype', 'replace', 'replace', 'split', 'apply', 'keys', 'str', 'filter_data_contains', 'drop', 'fillna', 'fillna', 'isna', 'astype', 'filter_data_contains', 'fill_na_with_mean', 'maxabs_scale', 'maxabs_scale', 'maxabs_scale', 'drop', 'fill_na_with_mean', 'maxabs_scale', 'is_na', 'isna', 'astype', 'fillna', 'filter_data_contains', 'filter_data_contains', 'filter_data_contains', 'drop', 'drop_survived', 'drop_passenger_id', 'handle_pclass', 'handle_name', 'handle_sex', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'handle_cabin', 'handle_embarked', 'copy', 'extract_survived', 'process_data', 'KNeighborsClassifier', 'LinearRegression', 'Ridge', 'Lasso', 'ElasticNet', 'Lars', 'LassoLars', 'OrthogonalMatchingPursuit', 'BayesianRidge', 'ARDRegression', 'LogisticRegression', 'SGDClassifier', 'Perceptron', 'PassiveAggressiveClassifier', 'TheilSenRegressor', 'RANSACRegressor', 'HuberRegressor', 'SVC', 'SVC', 'GaussianProcessClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'MLPClassifier', 'AdaBoostClassifier', 'GaussianNB', 'QuadraticDiscriminantAnalysis', 'keys', 'cross_val_score', 'mean', 'mean', 'print', 'print', 'DataFrame', 'read_csv', 'process_data', 'read_csv', 'process_data', 'keys', 'fit', 'predict_proba', 'print', 'list', 'min', 'max', 'astype', 'to_csv', 'to_csv', 'head']","['filterwarnings', 'set_option', 'read_csv', 'info', 'print', 'KNeighborsClassifier', 'cross_val_score', 'extract_survived', 'create_useless_column', 'apply_model', 'corr', 'heatmap', 'drop', 'drop_survived', 'drop_passenger_id', 'astype', 'groupby', 'size', 'plot', 'copy', 'maxabs_scale', 'handle_pclass', 'str', 'unique', '__contains__', 'get_dummies', 'count', 'handle_name', 'handle_sex', 'fillna', 'handle_age', 'handle_sibsp', 'handle_parch', 'drop_ticket', 'handle_fare', 'isna', 'handle_cabin', 'handle_embarked', 'process_data', 'fit', 'predict', 'DataFrame', 'to_csv', 'replace', 'split', 'apply', 'keys', 'filter_data_contains', 'fill_na_with_mean', 'is_na', 'LinearRegression', 'Ridge', 'Lasso', 'ElasticNet', 'Lars', 'LassoLars', 'OrthogonalMatchingPursuit', 'BayesianRidge', 'ARDRegression', 'LogisticRegression', 'SGDClassifier', 'Perceptron', 'PassiveAggressiveClassifier', 'TheilSenRegressor', 'RANSACRegressor', 'HuberRegressor', 'SVC', 'GaussianProcessClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'MLPClassifier', 'AdaBoostClassifier', 'GaussianNB', 'QuadraticDiscriminantAnalysis', 'mean', 'predict_proba', 'list', 'min', 'max', 'head']",80,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1
 0 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",filterwarnings set option set option read csv info read csv print print print info read csv print print print info read csv print print kneighborsclassifier cross val score print extract survived create useless column apply model read csv read csv print print print print corr print heatmap drop drop read csv drop survived drop passenger id apply model print print print print astype astype astype drop corr print heatmap groupby size plot copy maxabs scale print maxabs scale copy drop survived drop passenger id handle pclass apply model print print print print copy str str str unique print copy str str str unique print contains print corr print get dummies heatmap groupby count copy str str str str str str str str str str str str str str str str str str groupby size plot str str str str str str str str str str str str str str str str str str str astype str astype str astype drop drop survived drop passenger id handle pclass handle name apply model str astype read csv handle sex groupby size plot drop survived drop passenger id handle pclass handle name handle sex apply model print print print print astype corr print heatmap fillna astype maxabs scale read csv plot handle age groupby size plot print print print print fillna astype astype astype astype astype astype drop corr print heatmap copy drop survived drop passenger id handle pclass handle name handle sex handle age apply model plot groupby size plot print print print print corr print heatmap plot groupby size plot print print print print corr print heatmap maxabs scale maxabs scale copy drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch apply model copy print drop drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch drop ticket apply model fillna astype maxabs scale read csv handle fare groupby size plot drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch drop ticket handle fare apply model copy print isna astype drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch drop ticket handle fare handle cabin apply model print print print print isna astype fillna str astype str astype str astype drop corr print heatmap isna astype fillna str astype str astype str astype drop print drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch drop ticket handle fare handle cabin handle embarked copy process data print apply model kneighborsclassifier read csv process data read csv process data fit predict print dataframe astype astype print csv print read csv read csv drop drop kneighborsclassifier cross val score print maxabs scale str str str str str str str str str str str str str str str str str str str astype str astype str astype drop str astype fillna astype maxabs scale maxabs scale maxabs scale drop fillna astype maxabs scale isna astype isna astype fillna str astype str astype str astype drop drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch drop ticket handle fare handle cabin handle embarked copy process data apply model kneighborsclassifier read csv process data read csv process data fit predict print dataframe astype astype print csv filterwarnings read csv read csv drop drop maxabs scale replace str astype str astype replace replace split apply keys str filter data contains drop fillna fillna isna astype filter data contains fill na mean maxabs scale maxabs scale maxabs scale drop fill na mean maxabs scale na isna astype fillna filter data contains filter data contains filter data contains drop drop survived drop passenger id handle pclass handle name handle sex handle age handle sibsp handle parch drop ticket handle fare handle cabin handle embarked copy extract survived process data kneighborsclassifier linearregression ridge lasso elasticnet lars lassolars orthogonalmatchingpursuit bayesianridge ardregression logisticregression sgdclassifier perceptron passiveaggressiveclassifier theilsenregressor ransacregressor huberregressor svc svc gaussianprocessclassifier decisiontreeclassifier randomforestclassifier mlpclassifier adaboostclassifier gaussiannb quadraticdiscriminantanalysis keys cross val score mean mean print print dataframe read csv process data read csv process data keys fit predict proba print list min max astype csv csv head,"[0.0, 0.0, 0.0, 0.007053632278044875, 0.0, 0.0, 0.0, 0.04305201155019118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052357191082707775, 0.0, 0.011497999097068062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1590228165078664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011497999097068062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025737712472108192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010129629020880281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06898799458240837, 0.0, 0.0, 0.05275678164038639, 0.04352984685959253, 0.0, 0.0, 0.006087195190562535, 0.0, 0.0, 0.0, 0.0, 0.009024868704673738, 0.0, 0.017891313623484374, 0.0, 0.0, 0.0509344977419045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1035004441590661, 0.0, 0.007977318482830759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004656148716129161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.130368084590962, 0.0, 0.0, 0.0, 0.003835245934559533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010697553915389261, 0.014450209366845193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019378224498304553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036147112753901645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017057477315045352, 0.030390020848165916, 0.04844556124576138, 0.01137052440371419, 0.0, 0.0, 0.0, 0.00701649551721839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005737909074433468, 0.010129629020880281, 0.0, 0.0, 0.0, 0.0, 0.0027865142837245572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0294303721816287, 0.0, 0.0, 0.7167361123310805, 0.0, 0.002528895850718358, 0.0408351366071425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011497999097068062, 0.0, 0.0, 0.13797598916481674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010497616292107187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050912451336315764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030388887062640844, 0.0, 0.02375462835402601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011497999097068062, 0.010697553915389261, 0.011497999097068062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009024868704673738, 0.0, 0.0, 0.005441230857449067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003551388399922617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0071603685813348954, 0.183967985553089, 0.0, 0.0, 0.015259992639615418, 0.0, 0.0, 0.0, 0.0, 0.007656498628485959, 0.0, 0.0, 0.0087612589446925, 0.0, 0.09024356389542831, 0.0, 0.0, 0.0, 0.0, 0.03209266174616778, 0.0, 0.05265636003093918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015605596388429656, 0.0, 0.011497999097068062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06782378574406593, 0.0, 0.0, 0.13797598916481674, 0.0, 0.010129629020880281, 0.0, 0.08272326690414261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006952372096776714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04072860781261286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007279757621321283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14942227960080284, 0.0, 0.0073928888685047215, 0.0, 0.0, 0.09116666118792253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0087612589446925, 0.0, 0.0, 0.0, 0.0, 0.0034317068651772906, 0.0, 0.0, 0.0, 0.011497999097068062, 0.0, 0.0, 0.04227486240541994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012573324425368529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011497999097068062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1492669414272237, 0.0, 0.0, 0.010707281449700654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007629996319807709, 0.0, 0.07053632278044876, 0.0, 0.0, 0.0, 0.006952372096776714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07090740314616197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04799237412765009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003697687965651487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4723869806057292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09875085189262825, 0.0, 0.0, 0.0, 0.009072934362767668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011497999097068062, 0.0, 0.047764882578082195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012868856236054096, 0.0, 0.0, 0.0, 0.0, 0.011497999097068062, 0.0, 0.017891313623484374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
bkonovalov_titanic-bkonovalov-submit.py,"['numpy', 'pandas', 'os\n', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,198,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# test_df = test_df[x_cols]', ""#   test_df['Sex'] = le.transform(col_vals)"", '# mae = mean_absolute_error(yp, val_y)', '# gbtree: tree-based models', '# gblinear: linear models', '# from sklearn.metrics import accuracy_score', '# yp = np.rint(yp)', '# acc = accuracy_score(yp, y)', '# print(yp[:10])', '# print(y[:10])', '# print(acc)']",19,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'test_df.fillna', 'df.fillna', 'list', 'list', 'print', 'print', 'print', 'LabelEncoder', 'tmp1.append', 'tmp2.append', 'le.fit_transform', 'le.fit_transform', 'print', 'print', 'print', 'test_df.fillna', 'df.fillna', 'print', 'print', 'train_test_split', 'KNeighborsClassifier', 'model.fit', 'round', 'print', 'cross_val_score', 'print', 'print', 'model.fit', 'model.predict', 'np.rint', 'print', 'yp.astype', 'print', 'pd.DataFrame', 'print', 'sub.to_csv', 'print']","['walk', 'print', 'read_csv', 'read_csv', 'fillna', 'fillna', 'list', 'list', 'print', 'print', 'print', 'LabelEncoder', 'append', 'append', 'fit_transform', 'fit_transform', 'print', 'print', 'print', 'fillna', 'fillna', 'print', 'print', 'train_test_split', 'KNeighborsClassifier', 'fit', 'round', 'print', 'cross_val_score', 'print', 'print', 'fit', 'predict', 'rint', 'print', 'astype', 'print', 'DataFrame', 'print', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'fillna', 'list', 'LabelEncoder', 'append', 'fit_transform', 'train_test_split', 'KNeighborsClassifier', 'fit', 'round', 'cross_val_score', 'predict', 'rint', 'astype', 'DataFrame', 'to_csv']",18,"[1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0
 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv fillna fillna list list print print print labelencoder append append fit transform fit transform print print print fillna fillna print print train test split kneighborsclassifier fit round print cross val score print print fit predict rint print astype print dataframe print csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19653135643844136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07457992464098614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12586239362403456, 0.0, 0.0, 0.13436837154775622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05611909891470513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2332240415694614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19743948135596465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10026589820758394, 0.0, 0.0, 0.0, 0.0, 0.1168187813866533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22966888437321642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05121187513138364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7644805098606244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08921897214112928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.242659491421201, 0.0, 0.0, 0.0, 0.0, 0.11025144764775796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07532393097713136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07803784585511815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08137268500736189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0800906377717797, 0.0, 0.0, 0.0, 0.1822116768129195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12586239362403456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.095131626191246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
tonypythoneer_titanic-try-to-make-complex.py,"['pprint', 'pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,543,"['# data analysis and wrangling', '# visualization', '# machine learning', '# data of Embarked C is too few', '# data of Embarked Q is too few']",5,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train_df.append', 'df.head', 'df.info', 'df.describe', 'df.corr', 'df.isnull', 'None.any', 'dfrow_namecolumn_name.groupby', 'None.mean', 'None.sort_values', 'extract_mean_survived_groupby_column', 'extract_mean_survived_groupby_column', 'extract_mean_survived_groupby_column', 'extract_mean_survived_groupby_column', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'df.drop', 'df.Name.str.extract', 'pd.crosstab', 'df.Title.value_counts', 'df.Title.value_counts', 'title_seriestitle_series.index.tolist', 'title_seriestitle_series.index.tolist', 'df.Title.isin', 'df.Title.isin', 'plt.subplots', 'sns.swarmplot', 'plt.subplots', 'sns.swarmplot', 'pd.get_dummies', 'df.drop', 'pd.concat', 'tmp_df.corr', 'df.Title.replace', 'df.Title.value_counts', 'extract_mean_survived_groupby_column', 'df.drop', 'pd.get_dummies', 'pd.concat', 'df.drop', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'tmp_df.corr', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'df.Embarked.value_counts', 'df.Embarked.value_counts', 'df.Sex.value_counts', 'dfthe_embark_seriesthe_sex_series.Age.median', 'df.Age.isnull', 'df.Age.astype', 'enumerate', 'df.Age.apply', 'None.astype', 'df.groupby', 'None.mean', 'None.sort_values', 'pd.get_dummies', 'pd.concat', 'df.drop', 'df.Embarked.value_counts', 'df.Embarked.value_counts', 'df.Pclass.value_counts', 'dfthe_embark_seriesthe_pclass_series.Fare.median', 'df.Fare.isnull', 'df.Embarked.value_counts', 'df.Embarked.value_counts', 'df.Embarked.fillna', 'pd.get_dummies', 'pd.concat', 'df.drop', 'is_alone_series.astype', 'pd.get_dummies', 'pd.concat', 'df.drop', 'df.Survived.notnull', 'df.Survived.isnull', 'train_df.Survived.astype', 'test_df.drop', 'list', 'RandomForestClassifier', 'cross_val_score', 'scores.append', 'plt.plot', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'pprint', 'list', 'RandomForestClassifier', 'cross_val_score', 'scores.append', 'plt.plot', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'pprint', 'test_df.info', 'RandomForestClassifier', 'clf.fit', 'clf.predict', 'pd.read_csv', 'predict_result.astype', 'test_df.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'append', 'head', 'info', 'describe', 'corr', 'isnull', 'any', 'groupby', 'mean', 'sort_values', 'extract_mean_survived_groupby_column', 'extract_mean_survived_groupby_column', 'extract_mean_survived_groupby_column', 'extract_mean_survived_groupby_column', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'Title', 'Title', 'index', 'index', 'Title', 'Title', 'subplots', 'swarmplot', 'subplots', 'swarmplot', 'get_dummies', 'drop', 'concat', 'corr', 'Title', 'Title', 'extract_mean_survived_groupby_column', 'drop', 'get_dummies', 'concat', 'drop', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'corr', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'Embarked', 'Embarked', 'Sex', 'Age', 'Age', 'Age', 'enumerate', 'Age', 'astype', 'groupby', 'mean', 'sort_values', 'get_dummies', 'concat', 'drop', 'Embarked', 'Embarked', 'Pclass', 'Fare', 'Fare', 'Embarked', 'Embarked', 'Embarked', 'get_dummies', 'concat', 'drop', 'astype', 'get_dummies', 'concat', 'drop', 'Survived', 'Survived', 'Survived', 'drop', 'list', 'RandomForestClassifier', 'cross_val_score', 'append', 'plot', 'xlabel', 'ylabel', 'show', 'pprint', 'list', 'RandomForestClassifier', 'cross_val_score', 'append', 'plot', 'xlabel', 'ylabel', 'show', 'pprint', 'info', 'RandomForestClassifier', 'fit', 'predict', 'read_csv', 'astype', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'append', 'head', 'info', 'describe', 'corr', 'isnull', 'any', 'groupby', 'mean', 'sort_values', 'extract_mean_survived_groupby_column', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'Title', 'index', 'subplots', 'swarmplot', 'get_dummies', 'concat', 'Embarked', 'Sex', 'Age', 'enumerate', 'astype', 'Pclass', 'Fare', 'Survived', 'list', 'RandomForestClassifier', 'cross_val_score', 'plot', 'xlabel', 'ylabel', 'show', 'pprint', 'fit', 'predict', 'to_csv']",45,"[0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0
 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv append head info describe corr isnull groupby mean sort values extract mean survived groupby column extract mean survived groupby column extract mean survived groupby column extract mean survived groupby column facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend facetgrid map add legend facetgrid map add legend drop name crosstab title title index index title title subplots swarmplot subplots swarmplot get dummies drop concat corr title title extract mean survived groupby column drop get dummies concat drop facetgrid map add legend facetgrid map add legend get dummies get dummies get dummies concat corr facetgrid map add legend facetgrid map add legend facetgrid map add legend embarked embarked sex age age age enumerate age astype groupby mean sort values get dummies concat drop embarked embarked pclass fare fare embarked embarked embarked get dummies concat drop astype get dummies concat drop survived survived survived drop list randomforestclassifier cross val score append plot xlabel ylabel show pprint list randomforestclassifier cross val score append plot xlabel ylabel show pprint info randomforestclassifier fit predict read csv astype csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.283321300281795, 0.0, 0.1187357307692777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08667993905963335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06578678781955692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31429251933220814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1542524493282391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10129520938609088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0740152940948, 0.0, 0.03405332669724058, 0.05267824248787307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0235492585919897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13483124163826218, 0.0, 0.0, 0.0, 0.1903941958066416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20922878078393722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04513323541939709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3006245828550582, 0.0, 0.0, 0.0, 0.0, 0.3358203170230584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0747692214630375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014513411092969946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1556231789581927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15979909183118735, 0.0, 0.0, 0.0, 0.0, 0.01569283626108491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07055876880792479, 0.0, 0.0, 0.043428010570157216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0218209959485521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023426138429017796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2527377208372266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022147691391847853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06753013959072726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02203782201772798, 0.0, 0.0, 0.25370435930803265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.165715401090534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03267543168436683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046666528115601354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05054754416744533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1426996031561652, 0.0, 0.0, 0.0, 0.01505796088034874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06388544698189606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039349929743035895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02192892927318564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04429538278369571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04377068211560336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05740676252058971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05422956427123437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061058239458737895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35016545692482687, 0.0, 0.0, 0.0, 0.0, 0.1202498331420233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14830105169130053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0740152940948, 0.0, 0.0, 0.0, 0.05422956427123437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06753013959072726, 0.0, 0.0, 0.0, 0.0, 0.06535086336873366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
monthepp_titanic-machine-learning-from-disaster.py,"['python', 're\n', 'data', 'numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,692,"['# import python standard library', '# import data manipulation library', '# import data visualization library', '# import sklearn model class', '# import sklearn model selection', '# import sklearn model evaluation classification metrics', '# acquiring training and testing data', '# visualize head of the training data', '# visualize tail of the testing data', '# combine training and testing dataframe', '# describe training and testing data', '# convert dtypes numeric to object', '# list all features type number', '# list all features type object', '# feature extraction: surname', '# feature extraction: title', '# feature exploration: sex', '# feature exploration: age', '# feature extraction: age', '# feature extraction: family size', '# feature extraction: ticket string', '# feature extraction: has ticket string', '# feature exploration: fare', '# feature extraction: fare', '# feature extraction: cabin', '# feature extraction: cabin string', '# feature extraction: has cabin', '# feature exploration: embarked', '# feature extraction: embarked', '# list all features type number', '# list all features type object', '# feature exploration: survived', '# feature exploration: survived where family size equal to 1', '# feature exploration: survived where family size more than 1', '# feature extraction: ticket dataframe', '# describe ticket dataframe', '# convert dtypes numeric to object', '# convert dtypes object to numeric', '# feature extraction: together', '# feature exploration: survived', '# feature extraction: with sex and title', '# feature extraction: ticket_self dataframe', '# feature extraction: survived peer', '# feature extraction: ticket_title dataframe', '# feature extraction: survived peer title', '# feature exploration: survived peer and with sex and title', '# feature extraction: survived', '# convert category codes for data dataframe', '# convert dtypes object to numeric for data dataframe', '# describe data dataframe', '# verify dtypes object', '# compute pairwise correlation of columns, excluding NA/null values and present through heat map', '# select all features to evaluate the feature importances', '# set up random forest classifier to find the feature importances', '# plot the feature importances', '# list feature importances', '# select the important features', '# perform train-test (validate) split', '# logistic regression model setup', '# logistic regression model fit', '# logistic regression model prediction', '# logistic regression model metrics', '# decision tree classifier model setup', '# decision tree classifier model fit', '# decision tree classifier model prediction', '# decision tree classifier model metrics', '# random forest classifier model setup', '# random forest classifier model fit', '# random forest classifier model prediction', '# random forest classifier model metrics', '# specify the hyperparameter space', '# random forest classifier grid search model setup', '# random forest classifier grid search model fit', '# random forest classifier grid search model prediction', '# random forest classifier grid search model metrics', '# model selection', '# prepare testing data and compute the observed value', '# submit the results']",78,"['pd.read_csv', 'pd.read_csv', 'df_train.head', 'df_test.tail', 'df_test.insert', 'pd.concat', 'type', 'type', 'len', 'len', 'plt.subplots', 'axes.flatten', 'sns.countplot', 'enumerate', 'enumerate', 'type', 'type', 'len', 'len', 'plt.subplots', 'axes.flatten', 'sns.swarmplot', 'enumerate', 'enumerate', 'type', 'type', 'len', 'len', 'plt.subplots', 'axes.flatten', 'sns.violinplot', 'enumerate', 'enumerate', 'df_data.describe', 'df_datacol_convert.astype', 'df_data.select_dtypes', 'None.columns.tolist', 'print', 'df_data.select_dtypes', 'None.columns.tolist', 'print', 'df_data.str.extract', 'df_data.str.extract', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.value_counts', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'countplot', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'df_data.fillna', 'df_data.apply', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.value_counts', 'df_data.apply', 'None.astype', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'df_data.fillna', 'df_data.fillna', 'df_data.str.extract', 'df_data.apply', 'None.astype', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'countplot', 'df_data.fillna', 'df_data.select_dtypes', 'None.columns.tolist', 'print', 'df_data.select_dtypes', 'None.columns.tolist', 'print', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'countplot', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'countplot', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'countplot', 'pd.get_dummies', 'df_ticket.astype', 'df_ticket.groupby', 'None.agg', 'df_ticket.describe', 'df_ticket.columns.drop', 'None.tolist', 'df_ticketcol_convert.astype', 'df_ticketcol_convert.astype', 'df_ticket.apply', 'None.astype', 'df_ticket.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'violinplot', 'pd.merge', 'None.rename', 'df_datacol_fillna.fillna', 'df_data.copy', 'df_temp.astype', 'df_temp.groupby', 'df_ticket_self.transform', 'df_ticket_self.transform', 'df_data.astype', 'df_data.astype', 'None.fillna', 'df_data.copy', 'df_temp.astype', 'df_temp.groupby', 'df_ticket_titlecol_revise.transform', 'df_ticket_titlecol_revise.transform', 'df_tempcol_revise.astype', 'df_datacol_revise.astype', 'None.fillna', 'df_data.select_dtypes', 'None.columns.drop', 'None.tolist', 'swarmplot', 'violinplot', 'df_data.fillna', 'pd.get_dummies', 'df_datacol_convert.astype', 'df_data.describe', 'df_data.info', 'df_datadf_data.corr', 'plt.subplots', 'sns.heatmap', 'df_datadf_data.drop', 'RandomForestClassifier', 'None.fit', 'pd.DataFrame', 'None.sort_values', 'feat.plot', 'plt.axhline', 'train_test_split', 'LogisticRegression', 'model_logreg.fit', 'model_logreg.predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'DecisionTreeClassifier', 'model_treeclf.fit', 'model_treeclf.predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'RandomForestClassifier', 'model_forestclf.fit', 'model_forestclf.predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'GridSearchCV', 'model_forestclf_cv.fit', 'model_forestclf_cv.predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'print', 'pd.DataFrame', 'pd.DataFrame', 'out.to_csv']","['read_csv', 'read_csv', 'head', 'tail', 'insert', 'concat', 'type', 'type', 'len', 'len', 'subplots', 'flatten', 'countplot', 'enumerate', 'enumerate', 'type', 'type', 'len', 'len', 'subplots', 'flatten', 'swarmplot', 'enumerate', 'enumerate', 'type', 'type', 'len', 'len', 'subplots', 'flatten', 'violinplot', 'enumerate', 'enumerate', 'describe', 'astype', 'select_dtypes', 'columns', 'print', 'select_dtypes', 'columns', 'print', 'str', 'str', 'replace', 'replace', 'replace', 'value_counts', 'select_dtypes', 'columns', 'tolist', 'countplot', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'fillna', 'apply', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'apply', 'astype', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'fillna', 'fillna', 'str', 'apply', 'astype', 'select_dtypes', 'columns', 'tolist', 'countplot', 'fillna', 'select_dtypes', 'columns', 'print', 'select_dtypes', 'columns', 'print', 'select_dtypes', 'columns', 'tolist', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'countplot', 'select_dtypes', 'columns', 'tolist', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'countplot', 'select_dtypes', 'columns', 'tolist', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'countplot', 'get_dummies', 'astype', 'groupby', 'agg', 'describe', 'columns', 'tolist', 'astype', 'astype', 'apply', 'astype', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'violinplot', 'merge', 'rename', 'fillna', 'copy', 'astype', 'groupby', 'transform', 'transform', 'astype', 'astype', 'fillna', 'copy', 'astype', 'groupby', 'transform', 'transform', 'astype', 'astype', 'fillna', 'select_dtypes', 'columns', 'tolist', 'swarmplot', 'violinplot', 'fillna', 'get_dummies', 'astype', 'describe', 'info', 'corr', 'subplots', 'heatmap', 'drop', 'RandomForestClassifier', 'fit', 'DataFrame', 'sort_values', 'plot', 'axhline', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'RandomForestClassifier', 'fit', 'predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'GridSearchCV', 'fit', 'predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'print', 'print', 'DataFrame', 'DataFrame', 'to_csv']","['read_csv', 'head', 'tail', 'insert', 'concat', 'type', 'len', 'subplots', 'flatten', 'countplot', 'enumerate', 'swarmplot', 'violinplot', 'describe', 'astype', 'select_dtypes', 'columns', 'print', 'str', 'replace', 'value_counts', 'tolist', 'fillna', 'apply', 'get_dummies', 'groupby', 'agg', 'merge', 'rename', 'copy', 'transform', 'info', 'corr', 'heatmap', 'drop', 'RandomForestClassifier', 'fit', 'DataFrame', 'sort_values', 'plot', 'axhline', 'train_test_split', 'LogisticRegression', 'predict', 'f1_score', 'accuracy_score', 'cross_val_score', 'DecisionTreeClassifier', 'GridSearchCV', 'to_csv']",50,"[1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head tail insert concat type type len len subplots flatten countplot enumerate enumerate type type len len subplots flatten swarmplot enumerate enumerate type type len len subplots flatten violinplot enumerate enumerate describe astype select dtypes columns print select dtypes columns print str str replace replace replace value counts select dtypes columns tolist countplot select dtypes columns tolist swarmplot fillna apply replace replace replace replace value counts apply astype select dtypes columns tolist swarmplot fillna fillna str apply astype select dtypes columns tolist countplot fillna select dtypes columns print select dtypes columns print select dtypes columns tolist select dtypes columns tolist swarmplot countplot select dtypes columns tolist select dtypes columns tolist swarmplot countplot select dtypes columns tolist select dtypes columns tolist swarmplot countplot get dummies astype groupby agg describe columns tolist astype astype apply astype select dtypes columns tolist swarmplot violinplot merge rename fillna copy astype groupby transform transform astype astype fillna copy astype groupby transform transform astype astype fillna select dtypes columns tolist swarmplot violinplot fillna get dummies astype describe info corr subplots heatmap drop randomforestclassifier fit dataframe sort values plot axhline train test split logisticregression fit predict f1 score accuracy score cross val score print decisiontreeclassifier fit predict f1 score accuracy score cross val score print randomforestclassifier fit predict f1 score accuracy score cross val score print gridsearchcv fit predict f1 score accuracy score cross val score print print dataframe dataframe csv,"[0.0, 0.0, 0.07672322813821539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027814757594370593, 0.0, 0.0, 0.0, 0.0, 0.05385254003753629, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16538197626213527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035760015491893546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4621583723853576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013849163204076056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029392752519007578, 0.01818906464938976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09464514628011794, 0.03220298240803873, 0.0, 0.0, 0.07974329551178792, 0.0, 0.0, 0.021283118116634005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026666753426632887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015564675021811311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03805758343497169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009079109660438922, 0.0, 0.0, 0.43497258577445425, 0.025641086760548496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14587821233983037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1140402110357485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07388248837409526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03909148925992289, 0.10158463147151121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01862964089594811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01883340048373535, 0.0, 0.0, 0.03689268266855492, 0.0, 0.0, 0.0, 0.0, 0.008453647956751907, 0.017063072657015312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011697219887924484, 0.0, 0.0, 0.0, 0.03843576102434351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0993886990855828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011871658250421881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031185798291387103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013614847448883317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03244657577793649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06811255097475148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02294316843513883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014131732791369396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02928732662333063, 0.0, 0.09807089105117009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14317013161916917, 0.0, 0.0, 0.0, 0.4173338114670682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014606589834047405, 0.0, 0.0, 0.0, 0.012360711615172444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05921645456839585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0657835018037133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25911179835901627, 0.0, 0.0, 0.02102009265143476, 0.0, 0.0, 0.012888929489361337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3615918487268177, 0.0, 0.0, 0.0, 0.0, 0.012685861144990563, 0.0, 0.0, 0.0, 0.057722402901355475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18101116231468586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07974329551178792, 0.0, 0.0, 0.03220298240803873, 0.014606589834047405, 0.0, 0.0, 0.0, 0.0935573948741613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kaushikmishra_titanicpredictor.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'tensorflow', 'keras', 'sklearn', 'scipy']","[1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,537,"['# of siblings / spouses aboard the Titanic', '# of parents / children aboard the Titanic', '# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', ""# Import the libraries we'll use below."", 'import seaborn as sns  # for nicer plots', 'sns.set(style=""darkgrid"")  # default style', '    #  The baseline is that Nobody survived the tragedy Titanic.', '    #  1502 out of 2224 people died in the tragic event.', '    #  We choose 68% of the people died', '# Change NaN in Ages column to the median values', '#  Change NaN in the Embarked column `Southampton` or `S` which is the heighest in frequency.', ""#  Drop Name table as it is not co-related with one's survival."", '#  Drop the Cabin column beacause it is very sparse.', '#  Drop the ticket number table, since its numeric value does not really mean anything.', '#  Separiting X_train and Y_train', '    # This is not strictly necessary, but each time you build a model, TF adds', '    # new nodes (rather than overwriting), so the colab session can end up', '    # storing lots of copies of the graph when you only care about the most', '    # recent. Also, as there is some randomness built into training with SGD,', '    # setting a random seed ensures that results are the same on each identical', '    # training run.', '    # Build a model using keras.Sequential. While this is intended for neural', '    # networks (which may have multiple layers), we want just a single layer for', '    # logistic regression.', '    # Keras layers can do pre-processing.', '      units=512,                   # number of units/neurons', '      use_bias=True,               # use a bias param', '      activation=""relu"",          # apply the relu function ', '      units=256,                   # number of units/neurons', '      use_bias=True,               # use a bias param', '      activation=""relu"",            # apply the relu function', '      units=128,                   # number of units/neurons', '      use_bias=True,               # use a bias param', '      activation=""relu"",            # apply the relu function', '    # This layer constructs the linear set of parameters for each input feature', '    # (as well as a bias), and applies a sigmoid to the result. The result is', '    # binary logistic regression.', '      units=1,                     # output dim (for binary classification)', '      use_bias=True,               # use a bias param', '      activation=""sigmoid""         # apply the sigmoid function!', '    # Finally, we compile the model. This finalizes the graph for training.', '    # We specify the binary_crossentropy loss (equivalent to log loss).', ""    # Notice that we are including 'binary accuracy' as one of the metrics that we"", '    # ask Tensorflow to report when evaluating the model.', '# Fit the model.', '  x = X_train,   # our binary training examples', '  y = Y_train,   # corresponding binary labels', '  epochs=5,             # number of passes through the training data', '  batch_size=64,        # mini-batch size for SGD', '  validation_split=0.1, # use a fraction of the examples for validation', '  verbose=1             # display some progress output during training', '#  Trying to find outliers', ""#  Drop Name table as it is not co-related with one's survival."", '#  Drop the Cabin column beacause it is very sparse.', '#  Drop the ticket number table, since its numeric value does not really mean anything.', '# Change NaN in Ages column to the median values', '#  Change NaN in the Embarked column `Southampton` or `S` which is the heighest in frequency.', '      units=64,                                   # number of units/neurons', '      use_bias=True,                              # use a bias param', '      activation=""relu"",                          # apply the relu function', '      kernel_regularizer=regularizers.l2(0.01)    # addred L2 regularisaiton', '#  Apply one-hot encoding for `Sex` and `Embarked` feature']",69,"['os.walk', 'print', 'sns.set', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'pd.DataFrame', 'generateBaselineOutputNobodySurvives', 'generateBaselineOutputNobodySurvives', 'print', 'print', 'output_test.to_csv', 'print', 'print', 'print', 'train_data.copy', 'test_data.copy', 'train_data.median', 'train_data.replace', 'train_data.replace', 'train_data.drop', 'stats.zscore', 'pd.get_dummies', 'train_data.drop', 'train_data.join', 'print', 'print', 'pd.DataFrame', 'None.to_numpy', 'None.flatten', 'train_data.drop', 'train_data.to_numpy', 'plt.ylabel', 'plt.xlabel', 'plt.xticks', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.show', 'tf.keras.backend.clear_session', 'np.random.seed', 'tf.compat.v1.set_random_seed', 'keras.Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'build_model', 'model.fit', 'pd.DataFrame', 'display', 'plot_history', 'model.predict', 'None.flatten', 'np.copy', 'confusion_matrix', 'cf_matrix.ravel', '.format', 'cf_matrix.flatten', '.format', 'cf_matrix.flatten', 'np.sum', 'zip', 'np.asarray', 'None.reshape', 'plt.figure', 'plt.title', 'sns.heatmap', 'pd.set_option', 'abs', 'train_data_copy.sort_values', 'train_data_copy.head', 'test_data.copy', 'test_data.drop', 'test_data.replace', 'test_data.replace', 'test_data.replace', 'stats.zscore', 'pd.get_dummies', 'test_data.drop', 'test_data.join', 'test_data.to_numpy', 'test_data.head', 'test_data_copy.head', 'model.predict', 'None.flatten', 'np.array', 'pd.DataFrame', 'output_test_logit.to_csv', 'print']","['walk', 'print', 'set', 'read_csv', 'head', 'read_csv', 'head', 'DataFrame', 'generateBaselineOutputNobodySurvives', 'generateBaselineOutputNobodySurvives', 'print', 'print', 'to_csv', 'print', 'print', 'print', 'copy', 'copy', 'median', 'replace', 'replace', 'drop', 'zscore', 'get_dummies', 'drop', 'join', 'print', 'print', 'DataFrame', 'to_numpy', 'flatten', 'drop', 'to_numpy', 'ylabel', 'xlabel', 'xticks', 'plot', 'plot', 'legend', 'show', 'keras', 'random', 'compat', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'compile', 'build_model', 'fit', 'DataFrame', 'display', 'plot_history', 'predict', 'flatten', 'copy', 'confusion_matrix', 'ravel', 'format', 'flatten', 'format', 'flatten', 'sum', 'zip', 'asarray', 'reshape', 'figure', 'title', 'heatmap', 'set_option', 'abs', 'sort_values', 'head', 'copy', 'drop', 'replace', 'replace', 'replace', 'zscore', 'get_dummies', 'drop', 'join', 'to_numpy', 'head', 'head', 'predict', 'flatten', 'array', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'set', 'read_csv', 'head', 'DataFrame', 'generateBaselineOutputNobodySurvives', 'to_csv', 'copy', 'median', 'replace', 'drop', 'zscore', 'get_dummies', 'join', 'to_numpy', 'flatten', 'ylabel', 'xlabel', 'xticks', 'plot', 'legend', 'show', 'keras', 'random', 'compat', 'Sequential', 'add', 'compile', 'build_model', 'fit', 'display', 'plot_history', 'predict', 'confusion_matrix', 'ravel', 'format', 'sum', 'zip', 'asarray', 'reshape', 'figure', 'title', 'heatmap', 'set_option', 'abs', 'sort_values', 'array']",48,"[1 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0
 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1
 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print set read csv head read csv head dataframe generatebaselineoutputnobodysurvives generatebaselineoutputnobodysurvives print print csv print print print copy copy median replace replace drop zscore get dummies drop join print print dataframe numpy flatten drop numpy ylabel xlabel xticks plot plot legend show keras random compat sequential add add add add add compile build model fit dataframe display plot history predict flatten copy confusion matrix ravel format flatten format flatten sum zip asarray reshape figure title heatmap set option abs sort values head copy drop replace replace replace zscore get dummies drop join numpy head head predict flatten array dataframe csv print,"[0.0, 0.09364985436114026, 0.0, 0.0, 0.0, 0.23688902749834673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08439076101985499, 0.10511380426471398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11100708486516063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11931319735735407, 0.07547309881552106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06757265094569301, 0.0, 0.0, 0.0, 0.18248335345591696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08809007738467012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11037275459717848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08439076101985499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14091793343950204, 0.0, 0.0, 0.0, 0.07959566725323125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04863884319147315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024269744887361607, 0.5255690213235699, 0.0, 0.0, 0.0, 0.0, 0.172686455210407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23862639471470815, 0.05783057136574172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13121006845873434, 0.052967593230687504, 0.0, 0.0, 0.0, 0.11100708486516063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13514530189138602, 0.0, 0.0, 0.0, 0.09364985436114026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04226353108060072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06383772202036994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05508136296438861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07803711511301004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33302125459548193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08096859227649049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12679059324180217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050360713515095586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.211436589789812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060679884608989675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09680769177252053, 0.0, 0.043868058771365195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2174528405532998, 0.0, 0.0, 0.0, 0.09091441117207388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08260829867988044, 0.0, 0.0791754503592925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04799862252433991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04534212122101169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038970028312471386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04133221643553638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04534212122101169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046775250472195155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056462924173240815, 0.0, 0.0, 0.06525106817586007, 0.0, 0.05464079987702706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07945046126850017, 0.23862639471470815]"
ishida66_titanic-random-forest-82-78.py,"['os\n', 'pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,605,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.info', 'train.head', 'train.value_counts', 'sns.countplot', 'train.groupby', 'None.mean', 'sns.countplot', 'train.head', 'train.apply', 'None.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.head', 'train.apply', 'train.value_counts', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'pd.crosstab', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.replace', 'train.apply', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.corr', 'train.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'sns.countplot', 'i.apply', 'i.apply', 'None.apply', 'i.apply', 'train.groupby', 'data.transform', 'np.where', 'i.apply', 'i.apply', 'np.where', 'i.apply', 'i.apply', 'i.apply', 'i.replace', 'i.apply', 'pd.qcut', 'pd.concat', 'pd.concat', 'i.fillna', 'test.fillna', 'traincolumn.apply', 'testcolumn.apply', 'traincolumn.unique', 'testcolumn.unique', 'pd.concat', 'pd.concat', 'pd.read_csv', 'pd.read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'test.fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'rf.fit', 'print', 'pd.concat', 'None.sort_values', 'rf.predict', 'pd.DataFrame', 'pd.read_csv', 'pd.concat', 'predictions.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'countplot', 'head', 'apply', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'groupby', 'mean', 'qcut', 'value_counts', 'value_counts', 'groupby', 'mean', 'groupby', 'mean', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'value_counts', 'groupby', 'mean', 'value_counts', 'head', 'apply', 'value_counts', 'apply', 'value_counts', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'crosstab', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'replace', 'apply', 'qcut', 'value_counts', 'groupby', 'mean', 'corr', 'value_counts', 'value_counts', 'groupby', 'mean', 'countplot', 'apply', 'apply', 'apply', 'apply', 'groupby', 'transform', 'where', 'apply', 'apply', 'where', 'apply', 'apply', 'apply', 'replace', 'apply', 'qcut', 'concat', 'concat', 'fillna', 'fillna', 'apply', 'apply', 'unique', 'unique', 'concat', 'concat', 'read_csv', 'read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'print', 'concat', 'sort_values', 'predict', 'DataFrame', 'read_csv', 'concat', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'apply', 'qcut', 'crosstab', 'replace', 'corr', 'transform', 'where', 'concat', 'fillna', 'unique', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'sort_values', 'predict', 'DataFrame', 'to_csv']",35,"[1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv info head value counts countplot groupby mean countplot head apply apply value counts groupby mean apply groupby mean qcut value counts value counts groupby mean groupby mean groupby mean qcut value counts groupby mean value counts groupby mean value counts head apply value counts apply value counts groupby mean qcut value counts groupby mean crosstab apply value counts groupby mean apply replace apply qcut value counts groupby mean corr value counts value counts groupby mean countplot apply apply apply apply groupby transform apply apply apply apply apply replace apply qcut concat concat fillna fillna apply apply unique unique concat concat read csv read csv names age impute cabin num cabin embarked impute fam size fillna ticket grouped dummies drop print randomforestclassifier fit print concat sort values predict dataframe read csv concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030776142480056994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5182343878545368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279482535978527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599281135565975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03500744357704521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09107902693483415, 0.43385455930515493, 0.0, 0.0, 0.0, 0.0, 0.03530630678951032, 0.08192477963803933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017107987389869215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01747403867621555, 0.0, 0.0, 0.0, 0.024674960349160606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03098961137893964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06233719157670034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053324011424110244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015047426912689897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017927697633077517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33135768561103374, 0.06233719157670034, 0.0, 0.0, 0.0, 0.04881074583614578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12004301432041745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022512964417251976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022623891764286017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0229626078506844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02284869587186554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3190809896266202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06002150716020872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05636762824542156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015612013216585905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029131621799502194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1735772569779223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022078696457289073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06799632744671416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392896778056414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022735796457363545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044110038792367946, 0.0, 0.0, 0.0, 0.02811246093875487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0512177751573511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027773744852356484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279482535978527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43385455930515493, 0.02811246093875487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
raviagheda_titanic-survival-using-logistic-regression.py,"['numpy', 'pandas', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,121,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '# replacing male with 0 and femlae with 1', '# Dealing with null value in AGE column']",11,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train.replace', 'test.replace', 'train.mean', 'train.fillna', 'test.fillna', 'StandardScaler', 'scaler.fit_transform', 'scaler.fit_transform', 'LogisticRegression', 'model.fit', 'model.predict', 'model.score', 'pd.read_csv', 'model.score', 'pd.DataFrame', 'output.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'replace', 'replace', 'mean', 'fillna', 'fillna', 'StandardScaler', 'fit_transform', 'fit_transform', 'LogisticRegression', 'fit', 'predict', 'score', 'read_csv', 'score', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'replace', 'mean', 'fillna', 'StandardScaler', 'fit_transform', 'LogisticRegression', 'fit', 'predict', 'score', 'DataFrame', 'to_csv']",14,"[1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv replace replace mean fillna fillna standardscaler fit transform fit transform logisticregression fit predict score read csv score dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3812596470009006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194251347756234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24815805257031778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.315123154954828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15949909955864375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1713382775412023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10898223970013333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10167905143822513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28479576414861985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3764600767310572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32058856192420143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2924588763155445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3877584366446982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20244635959998955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
maimahdi_titanicrf.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,187,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'print', 'train_df.drop', 'train_df.Age.mean', 'train_df.Age.fillna', 'train_df.isna', 'None.sum', 'print', 'print', 'print', 'LabelEncoder', 'sex_le.fit_transform', 'LabelEncoder', 'embarked_le.fit_transform', 'train_df.drop', 'train_test_split', 'list', 'print', 'print', 'RandomForestClassifier', 'model.fit', 'model.predict', 'accuracy_score', 'f1_score', 'print', 'print', 'max', 'print', 'print', 'pd.read_csv', 'test_df.drop', 'sex_le.transform', 'embarked_le.transform', 'RandomForestClassifier', 'final_model.fit', 'test_df.isna', 'None.sum', 'test_df.Age.fillna', 'test_df.Fare.fillna', 'final_model.predict', 'pd.DataFrame', 'sub_df.to_csv']","['walk', 'print', 'read_csv', 'print', 'drop', 'Age', 'Age', 'isna', 'sum', 'print', 'print', 'print', 'LabelEncoder', 'fit_transform', 'LabelEncoder', 'fit_transform', 'drop', 'train_test_split', 'list', 'print', 'print', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'f1_score', 'print', 'print', 'max', 'print', 'print', 'read_csv', 'drop', 'transform', 'transform', 'RandomForestClassifier', 'fit', 'isna', 'sum', 'Age', 'Fare', 'predict', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'drop', 'Age', 'isna', 'sum', 'LabelEncoder', 'fit_transform', 'train_test_split', 'list', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'f1_score', 'max', 'transform', 'Fare', 'DataFrame', 'to_csv']",21,"[1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv print drop age age isna sum print print print labelencoder fit transform labelencoder fit transform drop train test split list print print randomforestclassifier fit predict accuracy score f1 score print print max print print read csv drop transform transform randomforestclassifier fit isna sum age fare predict dataframe csv,"[0.0, 0.0, 0.12397854664238322, 0.0, 0.0, 0.0, 0.0, 0.3100738005653391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1375672070192346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05745509608552714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17605330450594694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18427978027113864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13017130010289094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20213981677833212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3143032289187135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23919964642930586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1175682439197296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.154713516478184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10486209733573107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.538092558938189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1482972365467039, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09134296017139615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15423425448824085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07989565083231394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16228836395868976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08330988070462814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08199731246082019, 0.0, 0.0, 0.0, 0.3730989841837276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09739637359284582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
jimchen65_titanic.py,"['numpy', 'pandas', 'subprocess']","[1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,21,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,['print'],['print'],['print'],1,"[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kerneler_starter-titanic-all-zeros-csv-file-eb06f941-e.py,"['libraries', 'mpl_toolkits', 'sklearn', 'matplotlib', 'numpy', 'os', 'pandas']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,151,"['import matplotlib.pyplot as plt # plotting', 'import numpy as np # linear algebra', 'import os # accessing directory structure', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Distribution graphs (histogram/bar graph) of column data', '    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values', '# Correlation matrix', ""    df = df.dropna('columns') # drop columns with NaN"", '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '# Scatter and density plots', '    df = df.select_dtypes(include =[np.number]) # keep only numerical columns', '    # Remove rows and columns that would lead to df being singular', '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots', ""nRowsRead = 1000 # specify 'None' if want to read whole file"", '# all_0s.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows']",16,"['os.walk', 'print', 'df.nunique', 'list', 'plt.figure', 'range', 'plt.subplot', 'np.issubdtype', 'columnDf.value_counts', 'valueCounts.plot.bar', 'columnDf.hist', 'plt.ylabel', 'plt.xticks', 'plt.title', 'plt.tight_layout', 'plt.show', 'df.dropna', 'dfcol.nunique', 'print', 'df.corr', 'plt.figure', 'plt.matshow', 'plt.xticks', 'plt.yticks', 'plt.gca', 'None.xaxis.tick_bottom', 'plt.colorbar', 'plt.title', 'plt.show', 'df.select_dtypes', 'df.dropna', 'dfcol.nunique', 'list', 'len', 'pd.plotting.scatter_matrix', 'df.corr', 'df.corr', 'zip', 'axij.annotate', 'plt.suptitle', 'plt.show', 'pd.read_csv', 'print', 'df1.head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['walk', 'print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'nunique', 'print', 'corr', 'figure', 'matshow', 'xticks', 'yticks', 'gca', 'xaxis', 'colorbar', 'title', 'show', 'select_dtypes', 'dropna', 'nunique', 'list', 'len', 'plotting', 'corr', 'corr', 'zip', 'annotate', 'suptitle', 'show', 'read_csv', 'print', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['walk', 'print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'corr', 'matshow', 'yticks', 'gca', 'xaxis', 'colorbar', 'select_dtypes', 'len', 'plotting', 'zip', 'annotate', 'suptitle', 'read_csv', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']",34,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print nunique list figure range subplot issubdtype value counts plot hist ylabel xticks title tight layout show dropna nunique print corr figure matshow xticks yticks gca xaxis colorbar title show select dtypes dropna nunique list len plotting corr corr zip annotate suptitle show read csv print head plotpercolumndistribution plotcorrelationmatrix plotscattermatrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1543884081863955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29549374335041534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719323031194817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03841763880099134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16746437717682094, 0.0, 0.14721720635317656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16969806951294641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04577842287583891, 0.0, 0.0, 0.0910257746807462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16887817770593153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1385989983982722, 0.0, 0.0, 0.08970206154581574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1969958289002769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41579699519481655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0737274898474115, 0.0, 0.16887817770593153, 0.16887817770593153, 0.16887817770593153, 0.0, 0.0, 0.15062322702083364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12294830892833276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08659260829584371, 0.0, 0.0, 0.0, 0.03826327066145258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1412473333957713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2511965657652314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12585280241810667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14410775310320456, 0.0, 0.14420567755261537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719323031194817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08159805194038416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16887817770593153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22765714759109046, 0.0, 0.09531927208129282, 0.0, 0.0, 0.0, 0.14721720635317656, 0.0, 0.0, 0.1385989983982722, 0.0]"
vinicius150987_titanic.py,"['os\n', 'numpy', 'pandas', 'matplotlib', 'seaborn', 'warnings\n', 'collections', 're\n', 'sklearn', 'xgboost', 'scipy', 'eli5\n', 'eli5']","[1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",13,879,"['# Replace columns', '# Family', '# Class', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set', '# Predicting Test Set']",13,"['os.walk', 'print', 'warnings.filterwarnings', 'sns.set', 'get_ipython', 'None.run_line_magic', 'rect.get_height', 'ax.annotate', 'rect.get_height', 'ax.annotate', 'rect.get_width', 'ax.text', 'pd.read_excel', 'np.array', 'np.append', 'np.append', 'np.append', 'df.info', 'df.rename', 'print', 'print', 'print', 'print', 'print', 'len', 'print', 'print', 'print', 'print', 'np.array', 'np.array', 'np.array', 'np.array', 'np.append', 'np.append', 'np.append', 'np.append', 'print', 'print', 'print', 'print', 'dfdf.dropna', 'dfdf.dropna', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'plt.figure', 'fig.add_subplot', 'ax.set_title', 'ax.bar', 'ax.bar', 'ax.grid', 'ax.set_xlabel', 'ax.set_ylabel', 'autolabel', 'autolabel', 'plt.tight_layout', 'np.arange', 'plt.figure', 'fig.add_subplot', 'ax.bar', 'ax.bar', 'ax.bar', 'ax.bar', 'ax.set_xticks', 'ax.set_title', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_xticklabels', 'ax.legend', 'ax.grid', 'autolabel', 'autolabel', 'autolabel', 'autolabel', 'plt.tight_layout', 'np.arange', 'None.round', 'bins.astype', 'np.array', 'np.append', 'survived.groupby', 'None.value_counts', 'survived.groupby', 'None.value_counts', 'survived.groupby', 'None.std', 'survived.groupby', 'None.mean', 'survived.groupby', 'None.value_counts', 'survived.groupby', 'None.std', 'survived.groupby', 'None.mean', 'not_survided.groupby', 'None.value_counts', 'not_survided.groupby', 'None.std', 'not_survided.groupby', 'None.mean', 'not_survided.groupby', 'None.value_counts', 'not_survided.groupby', 'None.std', 'not_survided.groupby', 'None.mean', 'np.arange', 'plt.figure', 'fig.add_subplot', 'ax.bar', 'ax.bar', 'ax.set_title', 'ax.grid', 'ax.set_xticks', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.set_xticklabels', 'ax.legend', 'fig.add_subplot', 'ax2.bar', 'ax2.bar', 'ax2.set_title', 'ax2.grid', 'ax2.set_xticks', 'ax2.set_xlabel', 'ax2.set_ylabel', 'ax2.set_xticklabels', 'ax2.legend', 'autolabel_without_pct', 'autolabel_without_pct', 'autolabel_without_pct', 'autolabel_without_pct', 'plt.tight_layout', 'Counter', 'pd.DataFrame', 'pd.DataFrame', 'pd.DataFrame', 'pd.concat', 'print', 'plt.figure', 'fig.add_subplot', 'ax.set_title', 'ax.set_ylabel', 'ax.set_xlabel', 'ax.grid', 'ax.bar', 'ax.bar', 'autolabel', 'autolabel', 'plt.tight_layout', 'df_family.groupby', 'None.count', 'None.sort_values', 'None.head', 'plt.figure', 'fig.add_subplot', 'range', 'df_familydf_familygrouped_family.indexi.values.split', 'ax.barh', 'autolabel_horizontal', 'ax.set_title', 'ax.legend', 'ax.set_xlabel', 'ax.set_ylabel', 'ax.grid', 'plt.tight_layout', 'df_familydf_familygrouped_family.index.values.split', 'print', 'plt.figure', 'fig.add_subplot', 'ax.set_title', 'ax.bar', 'ax.bar', 'ax.bar', 'ax.grid', 'ax.set_ylabel', 'autolabel', 'autolabel', 'autolabel', 'value.strip', 're.sub', 'value.title', 'result.append', 'df.dropna', 'destination.apply', 'destination.apply', 'clean_strings', 'Counter', 'Counter', 'Counter', 'sorted', 'sorted', 'sorted', 'list', 'list', 'list', 'list', 'list', 'list', 'plt.figure', 'fig.add_subplot', 'fig.add_subplot', 'fig.add_subplot', 'ax1.set_title', 'ax2.set_title', 'ax3.set_title', 'range', 'ax1.barh', 'ax2.barh', 'ax3.barh', 'ax1.grid', 'ax2.grid', 'ax3.grid', 'ax1.set_xlabel', 'ax2.set_xlabel', 'ax3.set_xlabel', 'ax1.set_ylabel', 'ax2.set_ylabel', 'ax3.set_ylabel', 'autolabel_horizontal', 'autolabel_horizontal', 'autolabel_horizontal', 'plt.tight_layout', 'ax1.get_yticklabels', 'tick.set_rotation', 'ax2.get_yticklabels', 'tick.set_rotation', 'ax3.get_yticklabels', 'tick.set_rotation', 'np.array', 'np.array', 'len', 'len', 'np.append', 'np.append', 'np.arange', 'plt.figure', 'fig.add_subplot', 'ax.barh', 'ax.barh', 'ax.legend', 'ax.grid', 'ax.set_yticks', 'ax.set_yticklabels', 'ax.set_xlabel', 'ax.set_title', 'autolabel_horizontal', 'autolabel_horizontal', 'plt.tight_layout', 'df.copy', 'df_feature.describe', 'df_feature.info', 'df_feature.drop', 'np.array', 'np.append', 'df_feature.isnull', 'None.sum', 'df_feature.isnull', 'None.any', 'df_feature.isna', 'None.sum', 'df_feature.isnull', 'None.sum', 'len', 'pd.DataFrame', 'df_feature.fillna', 'df_feature.fillna', 'df_feature.drop', 'pd.get_dummies', 'X.drop', 'train_test_split', 'StandardScaler', 'pd.DataFrame', 'pd.DataFrame', 'LogisticRegression', 'lr_classifier.fit', 'lr_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'range', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'error_rate.append', 'plt.figure', 'plt.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'print', 'KNeighborsClassifier', 'kn_classifier.fit', 'kn_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'SVC', 'svm_linear_classifier.fit', 'svm_linear_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'SVC', 'svm_rbf_classifier.fit', 'svm_rbf_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'GaussianNB', 'gb_classifier.fit', 'gb_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'DecisionTreeClassifier', 'dt_classifier.fit', 'dt_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'RandomForestClassifier', 'rf_classifier.fit', 'rf_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'AdaBoostClassifier', 'ad_classifier.fit', 'ad_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'GradientBoostingClassifier', 'gr_classifier.fit', 'gr_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'XGBClassifier', 'xg_classifier.fit', 'xg_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'VotingClassifier', 'clf.fit', 'clf.predict', 'print', 'voting_classifier.predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'pd.DataFrame', 'results.append', 'print', 'print', 'cross_val_score', 'accuracies.mean', 'accuracies.std', 'print', 'kn_classifier.predict_proba', 'np.sum', 'len', 'float', 'float', 'pd.DataFrame', 'np.arange', 'float', 'pd.DataFrame', 'y_cap_df_s.sort_values', 'None.reset_index', 'print', 'np.cumsum', 'float', 'np.append', 'int', 'integrate.simps', 'integrate.simps', 'plt.subplots', 'ax.plot', 'ax.plot', 'ax.plot', 'ax.plot', 'ax.plot', 'plt.xlim', 'plt.ylim', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.legend', 'capcurve', 'PermutationImportance', 'None.fit', 'eli5.show_weights']","['walk', 'print', 'filterwarnings', 'set', 'get_ipython', 'run_line_magic', 'get_height', 'annotate', 'get_height', 'annotate', 'get_width', 'text', 'read_excel', 'array', 'append', 'append', 'append', 'info', 'rename', 'print', 'print', 'print', 'print', 'print', 'len', 'print', 'print', 'print', 'print', 'array', 'array', 'array', 'array', 'append', 'append', 'append', 'append', 'print', 'print', 'print', 'print', 'dropna', 'dropna', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'figure', 'add_subplot', 'set_title', 'bar', 'bar', 'grid', 'set_xlabel', 'set_ylabel', 'autolabel', 'autolabel', 'tight_layout', 'arange', 'figure', 'add_subplot', 'bar', 'bar', 'bar', 'bar', 'set_xticks', 'set_title', 'set_xlabel', 'set_ylabel', 'set_xticklabels', 'legend', 'grid', 'autolabel', 'autolabel', 'autolabel', 'autolabel', 'tight_layout', 'arange', 'round', 'astype', 'array', 'append', 'groupby', 'value_counts', 'groupby', 'value_counts', 'groupby', 'std', 'groupby', 'mean', 'groupby', 'value_counts', 'groupby', 'std', 'groupby', 'mean', 'groupby', 'value_counts', 'groupby', 'std', 'groupby', 'mean', 'groupby', 'value_counts', 'groupby', 'std', 'groupby', 'mean', 'arange', 'figure', 'add_subplot', 'bar', 'bar', 'set_title', 'grid', 'set_xticks', 'set_xlabel', 'set_ylabel', 'set_xticklabels', 'legend', 'add_subplot', 'bar', 'bar', 'set_title', 'grid', 'set_xticks', 'set_xlabel', 'set_ylabel', 'set_xticklabels', 'legend', 'autolabel_without_pct', 'autolabel_without_pct', 'autolabel_without_pct', 'autolabel_without_pct', 'tight_layout', 'Counter', 'DataFrame', 'DataFrame', 'DataFrame', 'concat', 'print', 'figure', 'add_subplot', 'set_title', 'set_ylabel', 'set_xlabel', 'grid', 'bar', 'bar', 'autolabel', 'autolabel', 'tight_layout', 'groupby', 'count', 'sort_values', 'head', 'figure', 'add_subplot', 'range', 'indexi', 'barh', 'autolabel_horizontal', 'set_title', 'legend', 'set_xlabel', 'set_ylabel', 'grid', 'tight_layout', 'index', 'print', 'figure', 'add_subplot', 'set_title', 'bar', 'bar', 'bar', 'grid', 'set_ylabel', 'autolabel', 'autolabel', 'autolabel', 'strip', 'sub', 'title', 'append', 'dropna', 'apply', 'apply', 'clean_strings', 'Counter', 'Counter', 'Counter', 'sorted', 'sorted', 'sorted', 'list', 'list', 'list', 'list', 'list', 'list', 'figure', 'add_subplot', 'add_subplot', 'add_subplot', 'set_title', 'set_title', 'set_title', 'range', 'barh', 'barh', 'barh', 'grid', 'grid', 'grid', 'set_xlabel', 'set_xlabel', 'set_xlabel', 'set_ylabel', 'set_ylabel', 'set_ylabel', 'autolabel_horizontal', 'autolabel_horizontal', 'autolabel_horizontal', 'tight_layout', 'get_yticklabels', 'set_rotation', 'get_yticklabels', 'set_rotation', 'get_yticklabels', 'set_rotation', 'array', 'array', 'len', 'len', 'append', 'append', 'arange', 'figure', 'add_subplot', 'barh', 'barh', 'legend', 'grid', 'set_yticks', 'set_yticklabels', 'set_xlabel', 'set_title', 'autolabel_horizontal', 'autolabel_horizontal', 'tight_layout', 'copy', 'describe', 'info', 'drop', 'array', 'append', 'isnull', 'sum', 'isnull', 'any', 'isna', 'sum', 'isnull', 'sum', 'len', 'DataFrame', 'fillna', 'fillna', 'drop', 'get_dummies', 'drop', 'train_test_split', 'StandardScaler', 'DataFrame', 'DataFrame', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'range', 'KNeighborsClassifier', 'fit', 'predict', 'append', 'figure', 'plot', 'title', 'xlabel', 'ylabel', 'print', 'KNeighborsClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'SVC', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'SVC', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'GaussianNB', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'DecisionTreeClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'AdaBoostClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'GradientBoostingClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'XGBClassifier', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'VotingClassifier', 'fit', 'predict', 'print', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'DataFrame', 'append', 'print', 'print', 'cross_val_score', 'mean', 'std', 'print', 'predict_proba', 'sum', 'len', 'float', 'float', 'DataFrame', 'arange', 'float', 'DataFrame', 'sort_values', 'reset_index', 'print', 'cumsum', 'float', 'append', 'int', 'simps', 'simps', 'subplots', 'plot', 'plot', 'plot', 'plot', 'plot', 'xlim', 'ylim', 'title', 'xlabel', 'ylabel', 'legend', 'capcurve', 'PermutationImportance', 'fit', 'show_weights']","['walk', 'print', 'filterwarnings', 'set', 'get_ipython', 'run_line_magic', 'get_height', 'annotate', 'get_width', 'text', 'read_excel', 'array', 'append', 'info', 'rename', 'len', 'dropna', 'figure', 'add_subplot', 'set_title', 'bar', 'grid', 'set_xlabel', 'set_ylabel', 'autolabel', 'tight_layout', 'arange', 'set_xticks', 'set_xticklabels', 'legend', 'round', 'astype', 'groupby', 'value_counts', 'std', 'mean', 'autolabel_without_pct', 'Counter', 'DataFrame', 'concat', 'count', 'sort_values', 'head', 'range', 'indexi', 'barh', 'autolabel_horizontal', 'index', 'strip', 'sub', 'title', 'apply', 'clean_strings', 'sorted', 'list', 'get_yticklabels', 'set_rotation', 'set_yticks', 'set_yticklabels', 'copy', 'describe', 'drop', 'isnull', 'sum', 'any', 'isna', 'fillna', 'get_dummies', 'train_test_split', 'StandardScaler', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score', 'KNeighborsClassifier', 'plot', 'xlabel', 'ylabel', 'SVC', 'GaussianNB', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'XGBClassifier', 'VotingClassifier', 'cross_val_score', 'predict_proba', 'float', 'reset_index', 'cumsum', 'int', 'simps', 'subplots', 'xlim', 'ylim', 'capcurve', 'PermutationImportance', 'show_weights']",102,"[1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 0
 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print filterwarnings set get ipython run line magic get height annotate get height annotate get width text read excel array append append append info rename print print print print print len print print print print array array array array append append append append print print print print dropna dropna print print print print print print print figure add subplot set title bar bar grid set xlabel set ylabel autolabel autolabel tight layout arange figure add subplot bar bar bar bar set xticks set title set xlabel set ylabel set xticklabels legend grid autolabel autolabel autolabel autolabel tight layout arange round astype array append groupby value counts groupby value counts groupby std groupby mean groupby value counts groupby std groupby mean groupby value counts groupby std groupby mean groupby value counts groupby std groupby mean arange figure add subplot bar bar set title grid set xticks set xlabel set ylabel set xticklabels legend add subplot bar bar set title grid set xticks set xlabel set ylabel set xticklabels legend autolabel without pct autolabel without pct autolabel without pct autolabel without pct tight layout counter dataframe dataframe dataframe concat print figure add subplot set title set ylabel set xlabel grid bar bar autolabel autolabel tight layout groupby count sort values head figure add subplot range indexi barh autolabel horizontal set title legend set xlabel set ylabel grid tight layout index print figure add subplot set title bar bar bar grid set ylabel autolabel autolabel autolabel strip sub title append dropna apply apply clean strings counter counter counter sorted sorted sorted list list list list list list figure add subplot add subplot add subplot set title set title set title range barh barh barh grid grid grid set xlabel set xlabel set xlabel set ylabel set ylabel set ylabel autolabel horizontal autolabel horizontal autolabel horizontal tight layout get yticklabels set rotation get yticklabels set rotation get yticklabels set rotation array array len len append append arange figure add subplot barh barh legend grid set yticks set yticklabels set xlabel set title autolabel horizontal autolabel horizontal tight layout copy describe info drop array append isnull sum isnull isna sum isnull sum len dataframe fillna fillna drop get dummies drop train test split standardscaler dataframe dataframe logisticregression fit predict accuracy score precision score recall score f1 score dataframe range kneighborsclassifier fit predict append figure plot title xlabel ylabel print kneighborsclassifier fit predict accuracy score precision score recall score f1 score dataframe append svc fit predict accuracy score precision score recall score f1 score dataframe append svc fit predict accuracy score precision score recall score f1 score dataframe append gaussiannb fit predict accuracy score precision score recall score f1 score dataframe append decisiontreeclassifier fit predict accuracy score precision score recall score f1 score dataframe append randomforestclassifier fit predict accuracy score precision score recall score f1 score dataframe append adaboostclassifier fit predict accuracy score precision score recall score f1 score dataframe append gradientboostingclassifier fit predict accuracy score precision score recall score f1 score dataframe append xgbclassifier fit predict accuracy score precision score recall score f1 score dataframe append votingclassifier fit predict print predict accuracy score precision score recall score f1 score dataframe append print print cross val score mean std print predict proba sum len float float dataframe arange float dataframe sort values reset index print cumsum float append int simps simps subplots plot plot plot plot plot xlim ylim title xlabel ylabel legend capcurve permutationimportance fit show weights,"[0.0, 0.0, 0.12569189444515316, 0.014046681659341347, 0.0, 0.10001435463226138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03489453673796107, 0.22253535039843303, 0.01604072181920634, 0.07361140500760409, 0.0, 0.0, 0.0, 0.0, 0.14575790710784098, 0.0, 0.0, 0.0070373289549637685, 0.0, 0.4808421051818995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21725918795987262, 0.12781936607398312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022897243103899977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020172255736440256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00825032855388173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008755036741619714, 0.0, 0.0, 0.0, 0.012122108109639908, 0.0, 0.06478129204792932, 0.0, 0.047960512372869774, 0.0, 0.0, 0.011876320219619813, 0.0, 0.0, 0.0, 0.0, 0.022897243103899977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10061209730072553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009272306266601377, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007557317427257293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016226028223848925, 0.02763406277598341, 0.0, 0.0, 0.007637551350064597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022897243103899977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18682647375298128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0840079636924664, 0.0, 0.0, 0.0, 0.011003459098619588, 0.0, 0.011321694291881625, 0.0, 0.0, 0.0, 0.06054848410595294, 0.0, 0.06793689954653864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011426535858650288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04439276394321548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013128265576618019, 0.0, 0.0, 0.0, 0.1919199520587859, 0.0, 0.0, 0.0, 0.10256394755175048, 0.0, 0.0, 0.0, 0.0, 0.005036071284186101, 0.0, 0.042606455357994365, 0.0, 0.0, 0.0, 0.0, 0.13738345862339985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02264338858376325, 0.022897243103899977, 0.0, 0.013936713116930156, 0.0, 0.0, 0.0, 0.0, 0.012522249037857418, 0.0, 0.0, 0.0, 0.0, 0.007002691499519108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014483945863991508, 0.0, 0.02255341884901351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018922092293558273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10673065483721998, 0.0, 0.04866444116906906, 0.04934049142632227, 0.0, 0.0, 0.0, 0.0, 0.007107533066287768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06501436537382739, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007072274302937978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007072274302937978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0379861485336715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0915889724155999, 0.0, 0.0, 0.0, 0.0, 0.022897243103899977, 0.0, 0.0, 0.0, 0.0, 0.04866444116906906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1919199520587859, 0.0, 0.06765262083716601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13074658223201385, 0.0, 0.014722281001520817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0068339391654086675, 0.0, 0.0, 0.028578084652079585, 0.0, 0.0, 0.0, 0.004209331525898502, 0.0, 0.18682647375298128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017447268368980536, 0.0, 0.0, 0.0, 0.0, 0.012665222094272142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06869172931169992, 0.010403278209158298, 0.0, 0.0070373289549637685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3198389879829495, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3266808773895749, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009211354258661137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04579448620779995, 0.0, 0.0, 0.0, 0.0, 0.017403096982381135, 0.05573472093461238, 0.0, 0.0, 0.007363616882999853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012967781017923943, 0.0, 0.0, 0.0, 0.0, 0.060610540548199546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022897243103899977, 0.017447268368980536, 0.0, 0.0, 0.021303227678997182, 0.0, 0.15229534110694617, 0.0, 0.009797261670397699, 0.029914753163943215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01806794225814413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007678290841698577, 0.017447268368980536, 0.0, 0.0, 0.0, 0.0, 0.11097277060854417, 0.0, 0.11104817909439887, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007557317427257293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011876320219619813, 0.0, 0.0, 0.047960512372869774, 0.017403096982381135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015247236405317138, 0.0, 0.0, 0.008976578492820436, 0.0, 0.0, 0.021303227678997182, 0.021303227678997182, 0.0915889724155999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011758958496531788, 0.0, 0.0, 0.0, 0.13002873074765478, 0.016570018377182104, 0.03756674711357225, 0.03756674711357225, 0.0, 0.1258325522292665, 0.0, 0.01797222377277686, 0.08068902294576102, 0.01619532301198233, 0.0, 0.0, 0.0, 0.0]"
rohitvijay_titanic-prediction-using-logistic-regression.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,239,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'train.head', 'sns.heatmap', 'sns.set_style', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.distplot', 'sns.countplot', 'train.hist', 'plt.figure', 'sns.boxplot', 'pd.isnull', 'train.apply', 'sns.heatmap', 'train.drop', 'train.head', 'train.info', 'pd.get_dummies', 'pd.get_dummies', 'train.drop', 'pd.concat', 'train.head', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'heatmap', 'set_style', 'countplot', 'countplot', 'countplot', 'distplot', 'countplot', 'hist', 'figure', 'boxplot', 'isnull', 'apply', 'heatmap', 'drop', 'head', 'info', 'get_dummies', 'get_dummies', 'drop', 'concat', 'head', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'heatmap', 'set_style', 'countplot', 'distplot', 'hist', 'figure', 'boxplot', 'isnull', 'apply', 'drop', 'info', 'get_dummies', 'concat', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print']",22,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv head heatmap set style countplot countplot countplot distplot countplot hist figure boxplot isnull apply heatmap drop head info get dummies get dummies drop concat head train test split logisticregression fit predict print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1256898460592953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18801373242291067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12929374844396008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5890620997222321, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06623201896331349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18075721807514264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16952246186057313, 0.0, 0.0, 0.0, 0.23938141045751996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14627975727817416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07299047753563438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26088537640596626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23676603768357377, 0.3185966677247103, 0.0, 0.15692845846241635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10920352250870115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1097415972292999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11781413892273225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11138460563456881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11083205337568355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11083205337568355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07572911346126864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07065430518024214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06596588825189147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11028441275740318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11905881082897371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11539778357800519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16433044906170852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1203291478736387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11843333171152727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
amigosmomo_titanic-data-science-xgboost-with-tunning.py,"['numpy', 'pandas', 'os\n', 'random', 'seaborn', 'matplotlib', 'xgboost', 'sklearn', 'IPython', 'warnings\n', 'time\n']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",11,436,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# æ•¸æ“šåˆ†æžçš„ Class', '# åœ–åƒåŒ–çš„ Class', '# æ©Ÿå™¨å\xad¸ç¿’çš„ Class', '# ç”¨ä»¥é¡¯ç¤ºå‘Šè¨´çš„ Class', '# ç”¨ä»¥ç„¡è¦–ç¨‹å¼è\xad¦å‘Š', '# è¼‰å…¥æ•¸æ“š', '# Convert Sex', '# Filling missing values', '# Making Bins', '# cross tab', '# plots', '# close FacetGrid object', '# Filling missing values', '# Making Bins', '# cross tab', '# plots', '# close FacetGrid object', '# Ticket', '# the same ticket family or friends', ""df_data['Connected_Survival'] = 0.5 # default "", '# Masks', '# Plot', '# extracted title using name', '# Filling the missing age', ' # 0 1 2 3 4 5', '# split training set the testing set', '# åˆ†é–‹è¿” training set åŒ test set', '# Training set and labels', '# Using default parameter', '# Submission with hyperparameter tunning', '# Using default parameter']",39,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'df.to_html', 'display_html', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'df_train.append', 'df_data.head', 'df_data.map', 'None.astype', 'df_data.fillna', 'pd.qcut', 'pd.qcut', 'pd.qcut', 'LabelEncoder', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'pd.crosstab', 'pd.crosstab', 'pd.crosstab', 'display_side_by_side', 'plt.subplots', 'fig.set_figwidth', 'axi.axhline', 'sns.factorplot', 'sns.factorplot', 'sns.factorplot', 'plt.close', 'plt.close', 'plt.close', 'df_data.fillna', 'pd.qcut', 'pd.qcut', 'pd.qcut', 'LabelEncoder', 'label.fit_transform', 'label.fit_transform', 'label.fit_transform', 'pd.crosstab', 'pd.crosstab', 'pd.crosstab', 'display_side_by_side', 'plt.subplots', 'fig.set_figwidth', 'axi.axhline', 'sns.factorplot', 'sns.factorplot', 'sns.factorplot', 'plt.close', 'plt.close', 'plt.close', 'sns.countplot', 'display', 'sns.countplot', 'display', 'df_data.Ticket.unique', 'tem.count', 'deplicate_ticket.append', 'pd.concat', 'deplicate_ticket.head', 'df_data.groupby', 'len', 'df_grp.iterrows', 'df_grp.drop', 'None.max', 'df_grp.drop', 'None.min', 'print', 'print', 'df_data.groupby', 'None.mean', 'None.round', 'df_data.isnull', 'None.map', 'plt.subplots', 'fig.set_figwidth', 'sns.countplot', 'sns.countplot', 'pd.crosstab', 'None.round', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'df_data.Name.str.extract', 'df_data.replace', 'df_data.replace', 'df_data.replace', 'df_data.map', 'df_data.groupby', 'None.median', 'df_data.groupby', 'None.median', 'df_data.groupby', 'None.median', 'range', 'df_data.Age.isnull', 'df_data.astype', 'len', 'len', 'df_train.drop', 'xgb.XGBClassifier', 'model1.fit', 'model1.predict', 'pd.DataFrame', 'submit.to_csv', 'print', 'train_test_split', 'xgb.XGBClassifier', 'RandomizedSearchCV', 'print', 'time.time', 'rs_clf.fit', 'print', 'print', 'print', 'sorted', 'print', 'xgb.XGBClassifier', 'model2.fit', 'model2.predict', 'pd.DataFrame', 'submit.to_csv', 'print']","['walk', 'print', 'get_ipython', 'run_line_magic', 'to_html', 'display_html', 'filterwarnings', 'read_csv', 'read_csv', 'append', 'head', 'map', 'astype', 'fillna', 'qcut', 'qcut', 'qcut', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'crosstab', 'crosstab', 'crosstab', 'display_side_by_side', 'subplots', 'set_figwidth', 'axhline', 'factorplot', 'factorplot', 'factorplot', 'close', 'close', 'close', 'fillna', 'qcut', 'qcut', 'qcut', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'crosstab', 'crosstab', 'crosstab', 'display_side_by_side', 'subplots', 'set_figwidth', 'axhline', 'factorplot', 'factorplot', 'factorplot', 'close', 'close', 'close', 'countplot', 'display', 'countplot', 'display', 'Ticket', 'count', 'append', 'concat', 'head', 'groupby', 'len', 'iterrows', 'drop', 'max', 'drop', 'min', 'print', 'print', 'groupby', 'mean', 'round', 'isnull', 'map', 'subplots', 'set_figwidth', 'countplot', 'countplot', 'crosstab', 'round', 'subplots', 'distplot', 'distplot', 'legend', 'set_title', 'Name', 'replace', 'replace', 'replace', 'map', 'groupby', 'median', 'groupby', 'median', 'groupby', 'median', 'range', 'Age', 'astype', 'len', 'len', 'drop', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print', 'train_test_split', 'XGBClassifier', 'RandomizedSearchCV', 'print', 'time', 'fit', 'print', 'print', 'print', 'sorted', 'print', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'get_ipython', 'run_line_magic', 'to_html', 'display_html', 'filterwarnings', 'read_csv', 'append', 'head', 'map', 'astype', 'fillna', 'qcut', 'LabelEncoder', 'fit_transform', 'crosstab', 'display_side_by_side', 'subplots', 'set_figwidth', 'axhline', 'factorplot', 'close', 'countplot', 'display', 'Ticket', 'count', 'concat', 'groupby', 'len', 'iterrows', 'drop', 'max', 'min', 'mean', 'round', 'isnull', 'distplot', 'legend', 'set_title', 'Name', 'replace', 'median', 'range', 'Age', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'train_test_split', 'RandomizedSearchCV', 'time', 'sorted']",54,"[1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0
 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic html display html filterwarnings read csv read csv append head map astype fillna qcut qcut qcut labelencoder fit transform fit transform fit transform crosstab crosstab crosstab display side side subplots set figwidth axhline factorplot factorplot factorplot close close close fillna qcut qcut qcut labelencoder fit transform fit transform fit transform crosstab crosstab crosstab display side side subplots set figwidth axhline factorplot factorplot factorplot close close close countplot display countplot display ticket count append concat head groupby len iterrows drop max drop min print print groupby mean round isnull map subplots set figwidth countplot countplot crosstab round subplots distplot distplot legend set title name replace replace replace map groupby median groupby median groupby median range age astype len len drop xgbclassifier fit predict dataframe csv print train test split xgbclassifier randomizedsearchcv print time fit print print print sorted print xgbclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03461936511845625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06739458435544893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051149934682451804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15483981369629116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4398584618907921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029983234359263387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04405400415340489, 0.0, 0.0, 0.13660356514287864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2780066892937057, 0.061436849671813315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03848875227138154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2942841380321583, 0.08383523715416978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05896841607923422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2643240249204293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2496385695484517, 0.0, 0.0, 0.0399886247877068, 0.0, 0.041145150896773314, 0.0, 0.0, 0.0, 0.1523384972789022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02016644907642256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13312019100519298, 0.0, 0.0, 0.0, 0.0, 0.036604046633431316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15483981369629116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025449088361083082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02732111165982761, 0.0, 0.0, 0.0, 0.0, 0.07012165338951694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08011905437521939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029475944200393435, 0.10758753483633836, 0.0, 0.0, 0.0, 0.0, 0.025830102189379426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025701965260306804, 0.0, 0.0, 0.08069639991991093, 0.0, 0.0, 0.0, 0.05182073144477012, 0.0, 0.0, 0.0, 0.02760975121057437, 0.1152465357040531, 0.0, 0.0, 0.0, 0.055411303863362474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0381082490520861, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035123179334731955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16384741073759782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2343036112263673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06340663078078013, 0.03461936511845625, 0.0, 0.0, 0.0, 0.03059499335392402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09099515772322464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07561491075480936, 0.0, 0.025574967341225902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11043900484229748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33285142606460233, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06751679398046036, 0.0, 0.0, 0.026760758591963602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14242031251196813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027904342509719453, 0.0, 0.0, 0.0, 0.05761368111277513, 0.0, 0.0, 0.07741990684814558, 0.02882641545045124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027464702535051202, 0.0, 0.0, 0.0, 0.18745222817452853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03262256223334603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12820275197033743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
luke3d_titanic-random-forest-82-78.py,"['os\n', 'pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,605,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.info', 'train.head', 'train.value_counts', 'sns.countplot', 'train.groupby', 'None.mean', 'sns.countplot', 'train.head', 'train.apply', 'None.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.head', 'train.apply', 'train.value_counts', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'pd.crosstab', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.replace', 'train.apply', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.corr', 'train.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'sns.countplot', 'i.apply', 'i.apply', 'None.apply', 'i.apply', 'train.groupby', 'data.transform', 'np.where', 'i.apply', 'i.apply', 'np.where', 'i.apply', 'i.apply', 'i.apply', 'i.replace', 'i.apply', 'pd.qcut', 'pd.concat', 'pd.concat', 'i.fillna', 'test.fillna', 'traincolumn.apply', 'testcolumn.apply', 'traincolumn.unique', 'testcolumn.unique', 'pd.concat', 'pd.concat', 'pd.read_csv', 'pd.read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'test.fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'rf.fit', 'print', 'pd.concat', 'None.sort_values', 'rf.predict', 'pd.DataFrame', 'pd.read_csv', 'pd.concat', 'predictions.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'countplot', 'head', 'apply', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'groupby', 'mean', 'qcut', 'value_counts', 'value_counts', 'groupby', 'mean', 'groupby', 'mean', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'value_counts', 'groupby', 'mean', 'value_counts', 'head', 'apply', 'value_counts', 'apply', 'value_counts', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'crosstab', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'replace', 'apply', 'qcut', 'value_counts', 'groupby', 'mean', 'corr', 'value_counts', 'value_counts', 'groupby', 'mean', 'countplot', 'apply', 'apply', 'apply', 'apply', 'groupby', 'transform', 'where', 'apply', 'apply', 'where', 'apply', 'apply', 'apply', 'replace', 'apply', 'qcut', 'concat', 'concat', 'fillna', 'fillna', 'apply', 'apply', 'unique', 'unique', 'concat', 'concat', 'read_csv', 'read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'print', 'concat', 'sort_values', 'predict', 'DataFrame', 'read_csv', 'concat', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'apply', 'qcut', 'crosstab', 'replace', 'corr', 'transform', 'where', 'concat', 'fillna', 'unique', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'sort_values', 'predict', 'DataFrame', 'to_csv']",35,"[1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv info head value counts countplot groupby mean countplot head apply apply value counts groupby mean apply groupby mean qcut value counts value counts groupby mean groupby mean groupby mean qcut value counts groupby mean value counts groupby mean value counts head apply value counts apply value counts groupby mean qcut value counts groupby mean crosstab apply value counts groupby mean apply replace apply qcut value counts groupby mean corr value counts value counts groupby mean countplot apply apply apply apply groupby transform apply apply apply apply apply replace apply qcut concat concat fillna fillna apply apply unique unique concat concat read csv read csv names age impute cabin num cabin embarked impute fam size fillna ticket grouped dummies drop print randomforestclassifier fit print concat sort values predict dataframe read csv concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030776142480056994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5182343878545368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279482535978527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1599281135565975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03500744357704521, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09107902693483415, 0.43385455930515493, 0.0, 0.0, 0.0, 0.0, 0.03530630678951032, 0.08192477963803933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017107987389869215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01747403867621555, 0.0, 0.0, 0.0, 0.024674960349160606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03098961137893964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06233719157670034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053324011424110244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015047426912689897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017927697633077517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33135768561103374, 0.06233719157670034, 0.0, 0.0, 0.0, 0.04881074583614578, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12004301432041745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022512964417251976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022623891764286017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0229626078506844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02284869587186554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3190809896266202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06002150716020872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05636762824542156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015612013216585905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029131621799502194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1735772569779223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022078696457289073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06799632744671416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392896778056414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022735796457363545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044110038792367946, 0.0, 0.0, 0.0, 0.02811246093875487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0512177751573511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027773744852356484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08279482535978527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43385455930515493, 0.02811246093875487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
altrev_titanic.py,"['sklearn', 'pandas', 'numpy', 'string\n']","[1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]",4,122,[],0,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
akkidhanani_titanic-dataset-apply-logistic-regression.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,199,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'titanic_data.head', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'titanic_data.plot.hist', 'titanic_data.plot.hist', 'titanic_data.plot.hist', 'titanic_data.info', 'sns.countplot', 'titanic_data.isnull', 'None.sum', 'sns.heatmap', 'sns.heatmap', 'sns.boxplot', 'titanic_data.head', 'titanic_data.drop', 'titanic_data.dropna', 'sns.heatmap', 'titanic_data.head', 'pd.get_dummies', 'pd.get_dummies', 'embark.head', 'pd.get_dummies', 'pd.get_dummies', 'embark.head', 'pd.get_dummies', 'PcI.head', 'pd.concat', 'titanic_data.head', 'titanic_data.drop', 'titanic_data.drop', 'titanic_data.head', 'titanic_data.drop', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'classification_report', 'accuracy_score', 'confusion_matrix']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'countplot', 'countplot', 'countplot', 'plot', 'plot', 'plot', 'info', 'countplot', 'isnull', 'sum', 'heatmap', 'heatmap', 'boxplot', 'head', 'drop', 'dropna', 'heatmap', 'head', 'get_dummies', 'get_dummies', 'head', 'get_dummies', 'get_dummies', 'head', 'get_dummies', 'head', 'concat', 'head', 'drop', 'drop', 'head', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'classification_report', 'accuracy_score', 'confusion_matrix']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'countplot', 'plot', 'info', 'isnull', 'sum', 'heatmap', 'boxplot', 'drop', 'dropna', 'get_dummies', 'concat', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'classification_report', 'accuracy_score', 'confusion_matrix']",22,"[0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv head countplot countplot countplot plot plot plot info countplot isnull sum heatmap heatmap boxplot head drop dropna heatmap head get dummies get dummies head get dummies get dummies head get dummies head concat head drop drop head drop train test split logisticregression fit predict classification report accuracy score confusion matrix,"[0.0, 0.0, 0.11602052224832922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12181577078205925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1886360984696672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08377057048458143, 0.0, 0.0, 0.13166971553872345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3816585777615141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04291231462986928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21967022398095387, 0.09352844509696162, 0.0, 0.0, 0.38774336653488384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0472911800971747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3380599151255171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4090741955034495, 0.3096324253606909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07075393427428371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07110255767526297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07633282929363516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07216707744576058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07180907391885823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07180907391885823, 0.0, 0.0, 0.0, 0.0, 0.12439196304163892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24705973661668465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04906556669050166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04273988617305991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17715265702714753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07145425268762322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07216707744576058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07476725115735744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07593564068639162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07796232597949061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0767340098130458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
rmelick_titanic-notebook-complete.py,[],"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",0,95,"['    # gender is categorical male, female, or unknown', '    # age is continuous, but there is some missing data', '    # we replace all the missing data with 0 (which means it will be)']",3,"['pd.concat', 'pd.get_dummies', 'rawData.fillna']","['concat', 'get_dummies', 'fillna']","['concat', 'get_dummies', 'fillna']",3,"[0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",concat get dummies fillna,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6025805137260158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5578250109767355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4018306660823706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4052901397792625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sanjaynandakumar_titanic-survival-analysis-using-logistic-reg.py,"['numpy', 'pandas', 'os\n', 'collections', 'sklearn', 'matplotlib']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,198,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", '    #    inputData = inputData.drop(uniqueId, axis=1)']",10,"['os.walk', 'print', 'pd.read_csv', 'pd.DataFrame', 'pd.concat', 'range', 'pd.concat', 'pd.concat', 'range', 'Counter', 'mode.most_common', 'inputDatacolName.replace', 'inputDatacolName.replace', 'preprocessing.LabelEncoder', 'preprocessing.OneHotEncoder', 'pd.DataFrame', 'pd.DataFrame', 'range', 'colNames.append', 'range', 'labelencoder.fit_transform', 'np.array', 'df.reshape', 'onehotencoder.fit_transform', 'pd.DataFrame', 'pd.concat', 'pd.concat', 'pd.concat', 'pd.DataFrame', 'pd.concat', 'pd.DataFrame', 'pd.DataFrame', 'pd.DataFrame', 'train_test_split', 'LogisticRegression', 'regressor.fit', 'regressor.predict', 'regressor.predict', 'regressor.score', 'metrics.confusion_matrix', 'getData', 'print', 'np.arange', 'pd.DataFrame', 'pd.concat', 'dataCleaning', 'dataPreProcess', 'datasplit', 'logisticRegression', 'len', 'len', 'pd.DataFrame', 'pd.DataFrame', 'pd.concat', 'len', 'len', 'pd.DataFrame', 'testStart.reset_index', 'prednactual.reset_index', 'pd.concat', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'plt.subplots', 'axes.plot', 'axes.plot', 'axes.scatter', 'axes.scatter', 'plt.show']","['walk', 'print', 'read_csv', 'DataFrame', 'concat', 'range', 'concat', 'concat', 'range', 'Counter', 'most_common', 'replace', 'replace', 'LabelEncoder', 'OneHotEncoder', 'DataFrame', 'DataFrame', 'range', 'append', 'range', 'fit_transform', 'array', 'reshape', 'fit_transform', 'DataFrame', 'concat', 'concat', 'concat', 'DataFrame', 'concat', 'DataFrame', 'DataFrame', 'DataFrame', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'predict', 'score', 'confusion_matrix', 'getData', 'print', 'arange', 'DataFrame', 'concat', 'dataCleaning', 'dataPreProcess', 'datasplit', 'logisticRegression', 'len', 'len', 'DataFrame', 'DataFrame', 'concat', 'len', 'len', 'DataFrame', 'reset_index', 'reset_index', 'concat', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'subplots', 'plot', 'plot', 'scatter', 'scatter', 'show']","['walk', 'print', 'read_csv', 'DataFrame', 'concat', 'range', 'Counter', 'most_common', 'replace', 'LabelEncoder', 'OneHotEncoder', 'append', 'fit_transform', 'array', 'reshape', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'score', 'confusion_matrix', 'getData', 'arange', 'dataCleaning', 'dataPreProcess', 'datasplit', 'logisticRegression', 'len', 'reset_index', 'subplots', 'plot', 'scatter', 'show']",33,"[1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv dataframe concat range concat concat range counter common replace replace labelencoder onehotencoder dataframe dataframe range append range fit transform array reshape fit transform dataframe concat concat concat dataframe concat dataframe dataframe dataframe train test split logisticregression fit predict predict score confusion matrix getdata print arange dataframe concat datacleaning datapreprocess datasplit logisticregression len len dataframe dataframe concat len len dataframe reset index reset index concat print print print print print print print print print print print print print print print subplots plot plot scatter scatter show,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054908393335430225, 0.0, 0.08718184805197714, 0.0, 0.0, 0.0, 0.0, 0.09590485264053027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13559203012679752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48856484283182994, 0.0, 0.0, 0.07679211625964563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09590485264053027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025027223918155077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13559203012679752, 0.37629531848923714, 0.0, 0.13559203012679752, 0.0, 0.13559203012679752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08274316805241475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13559203012679752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13408876400929973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06527540147877754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23374612811127038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0837606541536531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07254760176686026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1033185754102506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09605975041272231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057231819575615225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.453870793182673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22564349763434716, 0.0, 0.0, 0.0, 0.024926660580202986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09884865299234519, 0.0, 0.0, 0.15000086848679436, 0.1033185754102506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21285447301984076, 0.0, 0.04208912109105196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05454745003498922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043605588572881514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05801705443510002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045469012946479086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04475263714608107, 0.0, 0.0, 0.0, 0.1018153092927528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053157163764696175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
yananhe_titanic-ml.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn\n', 'lightgbm', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,370,"['# sorted(a)', '# sorted(a)']",2,"['sns.set', 'pd.read_csv', 'pd.read_csv', 'df_train.head', 'df_test.head', 'df_train.info', 'df_test.info', 'df_train.describe', 'print', 'df_test.describe', 'df_train.describe', 'df_test.describe', 'df_train.describe', 'df_train.describe', 'df_trainnumerical.corr', 'plt.subplots', 'sns.heatmap', 'get_ipython', 'None.run_line_magic', 'sns.pairplot', 'pd.concat', 'df.head', 'df.unique', 'df.map', 'list', 'df.str.split', 'df.str.split', 'np.where', 'np.where', 'pd.to_numeric', 'df.fillna', 'list', 'df.str.extract', 'df.str.replace', 'df.fillna', 'df.fillna', 'np.where', 'df.fillna', 'df.fillna', 'df.map', 'df.describe', 'df.set_index', 'pd.get_dummies', 'df.join', 'pd.get_dummies', 'df.join', 'pd.get_dummies', 'df.join', 'pd.get_dummies', 'df.join', 'pd.get_dummies', 'df.join', 'pd.get_dummies', 'df.join', 'df.head', 'df.head', 'df_use.describe', 'df_use.describe', 'pd.DataFrame', 'range', 'range', 'lgb.LGBMClassifier', 'cross_val_score', 'df_score.append', 'df_score.sort_values', 'df_score.head', 'lgb.LGBMClassifier', 'clf_final.fit', 'df_test_final.describe', 'df_test_final.describe', 'df_test_finalnumeric.drop', 'clf_final.predict', 'pd.Series', 'None.to_frame', 'df_result.reset_index', 'df_result.astype', 'df_result.to_csv']","['set', 'read_csv', 'read_csv', 'head', 'head', 'info', 'info', 'describe', 'print', 'describe', 'describe', 'describe', 'describe', 'describe', 'corr', 'subplots', 'heatmap', 'get_ipython', 'run_line_magic', 'pairplot', 'concat', 'head', 'unique', 'map', 'list', 'str', 'str', 'where', 'where', 'to_numeric', 'fillna', 'list', 'str', 'str', 'fillna', 'fillna', 'where', 'fillna', 'fillna', 'map', 'describe', 'set_index', 'get_dummies', 'join', 'get_dummies', 'join', 'get_dummies', 'join', 'get_dummies', 'join', 'get_dummies', 'join', 'get_dummies', 'join', 'head', 'head', 'describe', 'describe', 'DataFrame', 'range', 'range', 'LGBMClassifier', 'cross_val_score', 'append', 'sort_values', 'head', 'LGBMClassifier', 'fit', 'describe', 'describe', 'drop', 'predict', 'Series', 'to_frame', 'reset_index', 'astype', 'to_csv']","['set', 'read_csv', 'head', 'info', 'describe', 'print', 'corr', 'subplots', 'heatmap', 'get_ipython', 'run_line_magic', 'pairplot', 'concat', 'unique', 'map', 'list', 'str', 'where', 'to_numeric', 'fillna', 'set_index', 'get_dummies', 'join', 'DataFrame', 'range', 'LGBMClassifier', 'cross_val_score', 'append', 'sort_values', 'fit', 'drop', 'predict', 'Series', 'to_frame', 'reset_index', 'astype', 'to_csv']",37,"[1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set read csv read csv head head info info describe print describe describe describe describe describe corr subplots heatmap get ipython run line magic pairplot concat head unique map list str str numeric fillna list str str fillna fillna fillna fillna map describe set index get dummies join get dummies join get dummies join get dummies join get dummies join get dummies join head head describe describe dataframe range range lgbmclassifier cross val score append sort values head lgbmclassifier fit describe describe drop predict series frame reset index astype csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056873967898504435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043165185614875874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050605416585055574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0664635964145449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07284632706277007, 0.0, 0.0, 0.07776939607471842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032480474240940395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5099012888900181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033175443152600674, 0.0, 0.0, 0.0, 0.2810807825910831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16873104747455087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02856838452660291, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11835065686677831, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23825718100584573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1853398809202818, 0.06234917498662969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13888878542170324, 0.0, 0.0, 0.08548425296066932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04295272827444684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47724641968620285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21403421168436051, 0.0, 0.0, 0.04359579977482506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1329271928290898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04337953148975773, 0.0, 0.0, 0.09079907537503933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10701710584218026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0972398207203341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029640283311806667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027654009495467077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11686046760251256, 0.0, 0.0, 0.0, 0.05163793757340223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07768525047664175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043165185614875874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04359579977482506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06331385371012825, 0.0931989487911393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05337308489667124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2885058404339034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06009391080431635, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07859531139162892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07284632706277007, 0.0, 0.0, 0.0, 0.05337308489667124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
liyanageskydisc_starter-titanic-0cbe8c70-9.py,"['libraries', 'mpl_toolkits', 'sklearn', 'matplotlib', 'numpy', 'os', 'pandas']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,149,"['import matplotlib.pyplot as plt # plotting', 'import numpy as np # linear algebra', 'import os # accessing directory structure', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Distribution graphs (histogram/bar graph) of column data', '    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values', '# Correlation matrix', ""    df = df.dropna('columns') # drop columns with NaN"", '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '# Scatter and density plots', '    df = df.select_dtypes(include =[np.number]) # keep only numerical columns', '    # Remove rows and columns that would lead to df being singular', '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots', ""nRowsRead = 1000 # specify 'None' if want to read whole file"", '# train_and_test2.csv has 1309 rows in reality, but we are only loading/previewing the first 1000 rows']",16,"['print', 'df.nunique', 'list', 'plt.figure', 'range', 'plt.subplot', 'np.issubdtype', 'columnDf.value_counts', 'valueCounts.plot.bar', 'columnDf.hist', 'plt.ylabel', 'plt.xticks', 'plt.title', 'plt.tight_layout', 'plt.show', 'df.dropna', 'dfcol.nunique', 'print', 'df.corr', 'plt.figure', 'plt.matshow', 'plt.xticks', 'plt.yticks', 'plt.gca', 'None.xaxis.tick_bottom', 'plt.colorbar', 'plt.title', 'plt.show', 'df.select_dtypes', 'df.dropna', 'dfcol.nunique', 'list', 'len', 'pd.plotting.scatter_matrix', 'df.corr', 'df.corr', 'zip', 'axij.annotate', 'plt.suptitle', 'plt.show', 'pd.read_csv', 'print', 'df1.head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'nunique', 'print', 'corr', 'figure', 'matshow', 'xticks', 'yticks', 'gca', 'xaxis', 'colorbar', 'title', 'show', 'select_dtypes', 'dropna', 'nunique', 'list', 'len', 'plotting', 'corr', 'corr', 'zip', 'annotate', 'suptitle', 'show', 'read_csv', 'print', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'corr', 'matshow', 'yticks', 'gca', 'xaxis', 'colorbar', 'select_dtypes', 'len', 'plotting', 'zip', 'annotate', 'suptitle', 'read_csv', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']",33,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print nunique list figure range subplot issubdtype value counts plot hist ylabel xticks title tight layout show dropna nunique print corr figure matshow xticks yticks gca xaxis colorbar title show select dtypes dropna nunique list len plotting corr corr zip annotate suptitle show read csv print head plotpercolumndistribution plotcorrelationmatrix plotscattermatrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15490496684997576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2964824176618775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08748496476955596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03854617801186908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16802468591947814, 0.0, 0.14770977133433763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17026585182918047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045931590080678576, 0.0, 0.0, 0.09133033221244688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16944321679667937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13906272824837684, 0.0, 0.0, 0.09000219014728794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19765494510791834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4171881847451306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07397417011357971, 0.0, 0.16944321679667937, 0.16944321679667937, 0.16944321679667937, 0.0, 0.0, 0.1511271879967127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12335967410072833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08688233316925019, 0.0, 0.0, 0.0, 0.038391293381482366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14171992414678877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2520370288792172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12627388555633323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1445899143562999, 0.0, 0.1446881664450932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08748496476955596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16944321679667937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2284188516159948, 0.0, 0.0956381949614375, 0.0, 0.0, 0.0, 0.14770977133433763, 0.0, 0.0, 0.13906272824837684, 0.0]"
keenank_titanic-data-science.py,"['numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,280,[],0,"['pd.read_csv', 'pd.read_csv', 'print', 'test_data.info', 'print', 'print', 'train_data.info', 'train_data.groupby', 'f_survive.describe', 'plt.subplots', 'sns.countplot', 'sns.barplot', 'sns.countplot', 'plt.subplots', 'train_data.groupby', 'None.mean', 'sns.barplot', 'plt.subplots', 'sns.barplot', 'plt.scatter', 'plt.xlabel', 'plt.ylabel', 'sns.distplot', 'len', 'len', 'len', 'print', 'sns.distplot', 'sns.distplot', 'sns.barplot', 'plt.subplots', 'sns.countplot', 'ax1.title.set_text', 'sns.countplot', 'ax2.title.set_text', 'sns.countplot', 'ax3.title.set_text', 'sns.countplot', 'sns.barplot', 'print', 'sns.countplot', 'sns.barplot', 'sns.barplot', 'plt.subplots', 'sns.barplot', 'sns.barplot', 'sns.barplot']","['read_csv', 'read_csv', 'print', 'info', 'print', 'print', 'info', 'groupby', 'describe', 'subplots', 'countplot', 'barplot', 'countplot', 'subplots', 'groupby', 'mean', 'barplot', 'subplots', 'barplot', 'scatter', 'xlabel', 'ylabel', 'distplot', 'len', 'len', 'len', 'print', 'distplot', 'distplot', 'barplot', 'subplots', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'barplot', 'print', 'countplot', 'barplot', 'barplot', 'subplots', 'barplot', 'barplot', 'barplot']","['read_csv', 'print', 'info', 'groupby', 'describe', 'subplots', 'countplot', 'barplot', 'mean', 'scatter', 'xlabel', 'ylabel', 'distplot', 'len', 'title']",15,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv print info print print info groupby describe subplots countplot barplot countplot subplots groupby mean barplot subplots barplot scatter xlabel ylabel distplot len len len print distplot distplot barplot subplots countplot title countplot title countplot title countplot barplot print countplot barplot barplot subplots barplot barplot barplot,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7171017008236898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.435326918273022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05593895927566484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05001385601095821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2289988472106365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09696597378526915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09223229933179393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1959193793929269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05027799299052089, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1491849547239829, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0557141877035271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1189390574923352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32418833746327175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1574806997976002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07171017008236898, 0.0, 0.0, 0.0, 0.0, 0.06939599941009213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
rutwikdeshmukh_titanic-survival-predictions.py,"['pandas', 'numpy', 'seaborn', 'matplotlib', 'warnings\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,335,[],0,"['warnings.filterwarnings', 'sns.set', 'pd.read_csv', 'df.head', 'df.isnull', 'None.sum', 'df.drop', 'df.dropna', 'pd.get_dummies', 'df_dummies.head', 'sns.distplot', 'sns.distplot', 'StandardScaler', 'scaler.fit_transform', 'train_test_split', 'LogisticRegression', 'reg.fit', 'reg.predict', 'accuracy_score', 'RandomForestClassifier', 'model.fit', 'model.predict', 'accuracy_score', 'SVC', 'svm_model.fit', 'svm_model.predict', 'accuracy_score', 'pd.read_csv', 'test.drop', 'test2.fillna', 'pd.get_dummies', 'scaler.fit_transform', 'model.predict', 'pd.DataFrame', 'submissions.to_csv']","['filterwarnings', 'set', 'read_csv', 'head', 'isnull', 'sum', 'drop', 'dropna', 'get_dummies', 'head', 'distplot', 'distplot', 'StandardScaler', 'fit_transform', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'RandomForestClassifier', 'fit', 'predict', 'accuracy_score', 'SVC', 'fit', 'predict', 'accuracy_score', 'read_csv', 'drop', 'fillna', 'get_dummies', 'fit_transform', 'predict', 'DataFrame', 'to_csv']","['filterwarnings', 'set', 'read_csv', 'head', 'isnull', 'sum', 'drop', 'dropna', 'get_dummies', 'distplot', 'StandardScaler', 'fit_transform', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'accuracy_score', 'RandomForestClassifier', 'SVC', 'fillna', 'DataFrame', 'to_csv']",22,"[0 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",filterwarnings set read csv head isnull sum drop dropna get dummies head distplot distplot standardscaler fit transform train test split logisticregression fit predict accuracy score randomforestclassifier fit predict accuracy score svc fit predict accuracy score read csv drop fillna get dummies fit transform predict dataframe csv,"[0.0, 0.0, 0.47821603893801884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17687695871627235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07387285733683849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3218160188941716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15090695787990496, 0.12850256051128647, 0.0, 0.0, 0.21309459542214715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07675161702332296, 0.0, 0.1579427590101468, 0.0, 0.0, 0.0, 0.32487644404797006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15482478674382946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14051094698193467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10487679983489545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09866142708724764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26965276483021866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09533654406002842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11744415944273082, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29745990837704445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10598479253903613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1027257879263407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18090641377580594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1043310861433678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12602798557869518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10711563205604485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1054279981780099, 0.0, 0.0, 0.0, 0.23985590407938306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sunnynevarekar_titanic-survival-prediction.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn', 'warnings\n', 'joblib\n', 'time\n']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,358,[],0,"['pd.read_csv', 'titanic.head', 'titanic.isnull', 'None.sum', 'titanic.describe', 'titanic.groupby', 'None.mean', 'titanic.fillna', 'titanic.head', 'enumerate', 'plt.figure', 'sns.catplot', 'titanic.drop', 'titanic.head', 'titanic.isnull', 'None.sum', 'titanic.groupby', 'None.mean', 'np.where', 'titanic.head', 'titanic.map', 'titanic.head', 'titanic.drop', 'titanic.head', 'titanic.to_csv', 'titanic.drop', 'train_test_split', 'train_test_split', 'print', 'X_train.to_csv', 'X_val.to_csv', 'X_test.to_csv', 'y_train.to_csv', 'y_val.to_csv', 'y_test.to_csv', 'warnings.filterwarnings', 'warnings.filterwarnings', 'print', 'zip', 'print', 'LogisticRegression', 'GridSearchCV', 'cv.fit', 'print_result', 'joblib.dump', 'SVC', 'GridSearchCV', 'cv.fit', 'print_result', 'joblib.dump', 'MLPClassifier', 'GridSearchCV', 'cv.fit', 'print_result', 'joblib.dump', 'RandomForestClassifier', 'GridSearchCV', 'cv.fit', 'print_result', 'joblib.dump', 'GradientBoostingClassifier', 'GridSearchCV', 'cv.fit', 'print_result', 'joblib.dump', 'time.time', 'model.predict', 'time.time', 'accuracy_score', 'precision_score', 'recall_score', 'print', 'joblib.load', 'models.items', 'evaluate_model', 'evaluate_model']","['read_csv', 'head', 'isnull', 'sum', 'describe', 'groupby', 'mean', 'fillna', 'head', 'enumerate', 'figure', 'catplot', 'drop', 'head', 'isnull', 'sum', 'groupby', 'mean', 'where', 'head', 'map', 'head', 'drop', 'head', 'to_csv', 'drop', 'train_test_split', 'train_test_split', 'print', 'to_csv', 'to_csv', 'to_csv', 'to_csv', 'to_csv', 'to_csv', 'filterwarnings', 'filterwarnings', 'print', 'zip', 'print', 'LogisticRegression', 'GridSearchCV', 'fit', 'print_result', 'dump', 'SVC', 'GridSearchCV', 'fit', 'print_result', 'dump', 'MLPClassifier', 'GridSearchCV', 'fit', 'print_result', 'dump', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print_result', 'dump', 'GradientBoostingClassifier', 'GridSearchCV', 'fit', 'print_result', 'dump', 'time', 'predict', 'time', 'accuracy_score', 'precision_score', 'recall_score', 'print', 'load', 'items', 'evaluate_model', 'evaluate_model']","['read_csv', 'head', 'isnull', 'sum', 'describe', 'groupby', 'mean', 'fillna', 'enumerate', 'figure', 'catplot', 'drop', 'where', 'map', 'to_csv', 'train_test_split', 'print', 'filterwarnings', 'zip', 'LogisticRegression', 'GridSearchCV', 'fit', 'print_result', 'dump', 'SVC', 'MLPClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier', 'time', 'predict', 'accuracy_score', 'precision_score', 'recall_score', 'load', 'items', 'evaluate_model']",36,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0
 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv head isnull sum describe groupby mean fillna head enumerate figure catplot drop head isnull sum groupby mean head map head drop head csv drop train test split train test split print csv csv csv csv csv csv filterwarnings filterwarnings print zip print logisticregression gridsearchcv fit print result dump svc gridsearchcv fit print result dump mlpclassifier gridsearchcv fit print result dump randomforestclassifier gridsearchcv fit print result dump gradientboostingclassifier gridsearchcv fit print result dump time predict time accuracy score precision score recall score print load items evaluate model evaluate model,"[0.0, 0.0, 0.058232178800361134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0777033221222202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1723059010484595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038513777501689335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08269146383814759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5140116030711661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07381342304616297, 0.0, 0.0, 0.0, 0.16158343550954946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04756926064138055, 0.0, 0.0, 0.0, 0.028038042569489777, 0.0, 0.11539576552044434, 0.0, 0.0, 0.0, 0.11868023008913901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06690457351669735, 0.0, 0.0, 0.0, 0.0, 0.2858873306039687, 0.0, 0.0, 0.07466982627338811, 0.0, 0.0, 0.0, 0.0, 0.1539896642866159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07662483977188644, 0.0, 0.0, 0.09833165872624298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09833165872624298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036041889407988074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037720211821414225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07743435878425957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08891517637615584, 0.0, 0.15264211173356892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08891517637615584, 0.0, 0.024626633263611964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20678703663329456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034827280316072545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021451693590980613, 0.0, 0.08655540337147095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5428300311546473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10866472782270786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07505327253204026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07622613172358157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04603913457000821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0782605700810852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21713201246185895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07702755500337867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0777033221222202, 0.0]"
mikeaalv_titanic-competition.py,"['numpy', 'pandas', 'xgboost', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,122,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', 'from sklearn.model_selection import KFold, GridSearchCV # cv and parameter search', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# train_data.head()', '# test_data.head()', '# check nan value', '# type(allx)', '# allx.isnull().sum()', ""# np.flatnonzero(allx['Fare'].isnull()==True)"", '# use median in train and test data set to replace nan', '# deal with the only nan in Fare', '# allx.head()', '# # parameter searching? 6 100', '# gbm=xgb.XGBClassifier()', ""# clf = GridSearchCV(gbm,{'max_depth': [2,4,6],'n_estimators': [50,100,200,500]},verbose=1)"", '# clf.fit(trainvalid_x,trainvalid_y[:,0])', '# print(clf.best_score_)', '# print(clf.best_params_)', '#     print(confusion_matrix(actuals,predictions))']",25,"['np.random.RandomState', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'train_dataselefeature.append', 'tempx.copy', 'allx.isnull', 'allx.locagenanind.median', 'allx.isnull', 'allx.locfarenanind.median', 'agenanind.astype', 'LabelEncoder', 'le.fit_transform', 'allx.ilocindcut.values.copy', 'allx.ilocindcutalllen.values.copy', 'train_datapredfeature.values.copy', 'KFold', 'kf.split', 'xgb.XGBClassifier', 'None.fit', 'gbm.predict', 'print', 'xgb.XGBClassifier', 'None.fit', 'gbm.predict', 'pd.DataFrame', 'submission.to_csv']","['random', 'walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'append', 'copy', 'isnull', 'locagenanind', 'isnull', 'locfarenanind', 'astype', 'LabelEncoder', 'fit_transform', 'ilocindcut', 'ilocindcutalllen', 'values', 'KFold', 'split', 'XGBClassifier', 'fit', 'predict', 'print', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']","['random', 'walk', 'print', 'read_csv', 'append', 'copy', 'isnull', 'locagenanind', 'locfarenanind', 'astype', 'LabelEncoder', 'fit_transform', 'ilocindcut', 'ilocindcutalllen', 'values', 'KFold', 'split', 'XGBClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",22,"[1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1
 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",random walk print read csv read csv read csv append copy isnull locagenanind isnull locfarenanind astype labelencoder fit transform ilocindcut ilocindcutalllen values kfold split xgbclassifier fit predict print xgbclassifier fit predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13583502983754542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10309363831275843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12825726877792384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.247654211035158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07757479125650704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20469403707721373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33543409921853223, 0.33543409921853223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2202648211574016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20001341909222262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16148143423832761, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33543409921853223, 0.0, 0.0, 0.33543409921853223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14158283365203472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13209499332447008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17059388973994644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1849943229796223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10787360665785685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12593780964608903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12747369046589463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13150275372194548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3445266867398917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
jmda527_titanic-predict-by-randomforest-jmda.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,326,"['    456     # Create the parser.', '# final model for predicting survived', '      1 # final model for predicting survived', '    456     # Create the parser.']",4,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kvinaya_titanic-survived-count.py,"['numpy', 'pandas', 'subprocess', 'matplotlib', 'seaborn']","[1 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,175,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'data.head', 'data.unique', 'data.unique', 'data.unique', 'get_ipython', 'None.run_line_magic', 'data.hist', 'data.groupby', 'None.count', 'None.unstack', 'pclass_sex.plot', 'plt.xticks', 'data.Sex.value_counts', 'plt.pie', 'plt.axis', 'plt.xticks', 'plt.show', 'data.Pclass.value_counts', 'plt.pie', 'plt.axis', 'plt.xticks', 'plt.show', 'data.Embarked.value_counts', 'plt.pie', 'plt.axis', 'plt.xticks', 'plt.show', 'plt.subplots', 'plt.subplot', 'datadata.Sex.value_counts', 'plt.pie', 'plt.axis', 'plt.title', 'plt.xticks', 'plt.subplot', 'datadata.Sex.value_counts', 'plt.pie', 'plt.axis', 'plt.title', 'plt.xticks', 'plt.subplot', 'datadata.Sex.value_counts', 'plt.pie', 'plt.axis', 'plt.title', 'plt.xticks', 'plt.show', 'plt.subplots', 'plt.subplot', 'datadata.Sex.value_counts', 'plt.pie', 'plt.axis', 'plt.title', 'plt.xticks', 'plt.subplot', 'datadata.Sex.value_counts', 'plt.pie', 'plt.axis', 'plt.title', 'plt.xticks', 'plt.show', 'data.Agedata.Pclasspclass.plot', 'plt.xlabel', 'plt.legend']","['print', 'read_csv', 'head', 'unique', 'unique', 'unique', 'get_ipython', 'run_line_magic', 'hist', 'groupby', 'count', 'unstack', 'plot', 'xticks', 'Sex', 'pie', 'axis', 'xticks', 'show', 'Pclass', 'pie', 'axis', 'xticks', 'show', 'Embarked', 'pie', 'axis', 'xticks', 'show', 'subplots', 'subplot', 'Sex', 'pie', 'axis', 'title', 'xticks', 'subplot', 'Sex', 'pie', 'axis', 'title', 'xticks', 'subplot', 'Sex', 'pie', 'axis', 'title', 'xticks', 'show', 'subplots', 'subplot', 'Sex', 'pie', 'axis', 'title', 'xticks', 'subplot', 'Sex', 'pie', 'axis', 'title', 'xticks', 'show', 'Agedata', 'xlabel', 'legend']","['print', 'read_csv', 'head', 'unique', 'get_ipython', 'run_line_magic', 'hist', 'groupby', 'count', 'unstack', 'plot', 'xticks', 'Sex', 'pie', 'axis', 'show', 'Pclass', 'Embarked', 'subplots', 'subplot', 'title', 'Agedata', 'xlabel', 'legend']",24,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0
 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv head unique unique unique get ipython run line magic hist groupby count unstack plot xticks sex pie axis xticks show pclass pie axis xticks show embarked pie axis xticks show subplots subplot sex pie axis title xticks subplot sex pie axis title xticks subplot sex pie axis title xticks show subplots subplot sex pie axis title xticks subplot sex pie axis title xticks show agedata xlabel legend,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07554399765395961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4818260460146946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04298656149173682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014987053770865212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03401483464170842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01967780954200997, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025978929209295044, 0.0, 0.0, 0.0, 0.0, 0.017858559416928557, 0.0, 0.0, 0.03550994340755273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024832448781112442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02876173261084339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025204230522046355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025079198391896235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05310684131719971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6043519812316769, 0.0, 0.0, 0.0, 0.02876173261084339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01598773353815386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01492683342208844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02495527767316012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29886808768383366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16332326138356434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2454813434559087, 0.0, 0.06948471131193323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1406397107550327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13631595404820718, 0.05406867018410736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03842488987491377, 0.0, 0.0, 0.3996496162803329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
eqchee_titanic.py,"['numpy', 'pandas', 'matplotlib', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,355,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", '# Data analysis and handling', 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Visualisation', '# Machine Learning', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",11,"['get_ipython', 'None.run_line_magic', 'os.walk', 'print', 'pd.read_csv', 'train.head', 'train.describe', 'train.value_counts', 'train.groupby', 'None.mean', 'pd.crosstab', 'train.groupby', 'None.mean', 'train.groupby', 'None.size', 'None.unstack', 'train.groupby', 'None.size', 'None.unstack', 'train.groupby', 'None.size', 'None.unstack', 'train.value_counts', 'pd.crosstab', 'pd.read_csv', 'train.drop', 'test.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'pd.crosstab', 'train.drop', 'test.drop', 'train.head', 'train.isnull', 'train.groupby', 'None.mean', 'train.fillna', 'test.fillna', 'train.Age.isnull', 'None.sum', 'test.Age.isnull', 'None.sum', 'train.fillna', 'train.Embarked.isnull', 'None.sum', 'test.fillna', 'train.astype', 'test.astype', 'pd.get_dummies', 'train.head', 'pd.get_dummies', 'test.head', 'train.drop', 'train_test_split', 'MinMaxScaler', 'mms.fit_transform', 'mms.transform', 'KNeighborsClassifier', 'knn.fit', 'knn.score', 'LogisticRegression', 'logreg.fit', 'logreg.score', 'RandomForestClassifier', 'rf.fit', 'rf.score', 'SVC', 'svm.fit', 'svm.score', 'GridSearchCV', 'grid.fit', 'GridSearchCV', 'grid_rf.fit', 'SVC', 'svc.fit', 'test.drop', 'mms.transform', 'svc.predict', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'walk', 'print', 'read_csv', 'head', 'describe', 'value_counts', 'groupby', 'mean', 'crosstab', 'groupby', 'mean', 'groupby', 'size', 'unstack', 'groupby', 'size', 'unstack', 'groupby', 'size', 'unstack', 'value_counts', 'crosstab', 'read_csv', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'crosstab', 'drop', 'drop', 'head', 'isnull', 'groupby', 'mean', 'fillna', 'fillna', 'Age', 'sum', 'Age', 'sum', 'fillna', 'Embarked', 'sum', 'fillna', 'astype', 'astype', 'get_dummies', 'head', 'get_dummies', 'head', 'drop', 'train_test_split', 'MinMaxScaler', 'fit_transform', 'transform', 'KNeighborsClassifier', 'fit', 'score', 'LogisticRegression', 'fit', 'score', 'RandomForestClassifier', 'fit', 'score', 'SVC', 'fit', 'score', 'GridSearchCV', 'fit', 'GridSearchCV', 'fit', 'SVC', 'fit', 'drop', 'transform', 'predict', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'walk', 'print', 'read_csv', 'head', 'describe', 'value_counts', 'groupby', 'mean', 'crosstab', 'size', 'unstack', 'drop', 'Name', 'replace', 'isnull', 'fillna', 'Age', 'sum', 'Embarked', 'astype', 'get_dummies', 'train_test_split', 'MinMaxScaler', 'fit_transform', 'transform', 'KNeighborsClassifier', 'fit', 'score', 'LogisticRegression', 'RandomForestClassifier', 'SVC', 'GridSearchCV', 'predict', 'DataFrame', 'to_csv']",37,"[1 1 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic walk print read csv head describe value counts groupby mean crosstab groupby mean groupby size unstack groupby size unstack groupby size unstack value counts crosstab read csv drop drop name crosstab replace replace replace replace crosstab drop drop head isnull groupby mean fillna fillna age sum age sum fillna embarked sum fillna astype astype get dummies head get dummies head drop train test split minmaxscaler fit transform transform kneighborsclassifier fit score logisticregression fit score randomforestclassifier fit score svc fit score gridsearchcv fit gridsearchcv fit svc fit drop transform predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13936162579944636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10295304423537387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14032826327927933, 0.0, 0.0, 0.0, 0.0, 0.31975055472586167, 0.0927436771113931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03873449926925646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05528012406187055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.237379695078208, 0.0, 0.0, 0.0, 0.11173403531726593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07016413163963967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1609757933119302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2725531804396461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12177125953677717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1641374918657219, 0.0, 0.0, 0.32152836162774423, 0.0, 0.0, 0.0, 0.0, 0.14735103986508957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05122315670693122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05499110868344502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0692054832661493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051990049837145516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05173213969495477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05173213969495477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1667162209701777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11366130671696109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07670313314667959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03534743747166696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0329787121532856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049988770292023026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06158067891390952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24420307491283297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05147652211768693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20796019934858206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29961097581500706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053863246946350314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16411490738286755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132163045840911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05616501812949069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05528012406187055, 0.0, 0.0, 0.0, 0.18864909270248328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3345905983966967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14032826327927933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06566170833905591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
milanlamichhane_titanic-ml.py,"['numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,148,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'test_data.head', 'pd.read_csv', 'train_data.head', 'train_data.describe', 'train_data.head', 'plt.subplots', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'sns.distplot', 'sns.distplot', 'ax.legend', 'ax.set_title', 'dataset.map', 'train_data.head', 'dataset.map', 'train_data.head', 'train_data.fillna', 'test_data.fillna', 'np.asarray', 'np.asarray', 'np.asarray', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'read_csv', 'head', 'describe', 'head', 'subplots', 'distplot', 'distplot', 'legend', 'set_title', 'distplot', 'distplot', 'legend', 'set_title', 'map', 'head', 'map', 'head', 'fillna', 'fillna', 'asarray', 'asarray', 'asarray', 'LogisticRegression', 'fit', 'predict', 'round']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'describe', 'subplots', 'distplot', 'legend', 'set_title', 'map', 'fillna', 'asarray', 'LogisticRegression', 'fit', 'predict', 'round']",16,"[0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv head read csv head describe head subplots distplot distplot legend set title distplot distplot legend set title map head map head fillna fillna asarray asarray asarray logisticregression fit predict round,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666946366843008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09311999590710845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08325664487407086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5082771647550425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12122172918871434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05131108092251433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06113268064651251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2774042525696555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07714650138094403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17870706704273503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07830150872005846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07791307375392555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07791307375392555, 0.0, 0.0, 0.16308232969629965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053236296023743405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09274582505823094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11460972067444218, 0.0, 0.0775280915887202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1673926923961096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10793342260425302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1747690972503864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
youngwancha_notebook-cha-titanic.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,463,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ' #   Column       Non-Null Count  Dtype  ']",10,"['os.walk', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train.info', 'train.head', 'train.value_counts', 'sns.countplot', 'train.groupby', 'None.mean', 'sns.countplot', 'train.head', 'train.apply', 'None.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.groupby', 'None.mean', 'train.value_counts', 'train.head', 'train.apply', 'train.value_counts', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'pd.crosstab', 'train.apply', 'train.value_counts', 'train.groupby', 'None.mean', 'train.apply', 'train.replace', 'train.apply', 'pd.qcut', 'None.value_counts', 'train.groupby', 'None.mean', 'train.corr', 'train.value_counts', 'train.value_counts', 'train.groupby', 'None.mean', 'sns.countplot', 'i.apply', 'i.apply', 'None.apply', 'i.apply', 'train.groupby', 'data.transform', 'np.where', 'i.apply', 'i.apply', 'np.where', 'i.apply', 'i.apply', 'i.apply', 'i.replace', 'i.apply', 'pd.qcut', 'pd.concat', 'pd.concat', 'i.fillna', 'test.fillna', 'traincolumn.apply', 'testcolumn.apply', 'traincolumn.unique', 'testcolumn.unique', 'pd.concat', 'pd.concat', 'pd.read_csv', 'pd.read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'test.fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'rf.fit', 'print', 'pd.concat', 'None.sort_values', 'rf.predict', 'pd.DataFrame', 'pd.read_csv', 'pd.concat', 'predictions.to_csv']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'countplot', 'head', 'apply', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'groupby', 'mean', 'qcut', 'value_counts', 'value_counts', 'groupby', 'mean', 'groupby', 'mean', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'value_counts', 'groupby', 'mean', 'value_counts', 'head', 'apply', 'value_counts', 'apply', 'value_counts', 'groupby', 'mean', 'qcut', 'value_counts', 'groupby', 'mean', 'crosstab', 'apply', 'value_counts', 'groupby', 'mean', 'apply', 'replace', 'apply', 'qcut', 'value_counts', 'groupby', 'mean', 'corr', 'value_counts', 'value_counts', 'groupby', 'mean', 'countplot', 'apply', 'apply', 'apply', 'apply', 'groupby', 'transform', 'where', 'apply', 'apply', 'where', 'apply', 'apply', 'apply', 'replace', 'apply', 'qcut', 'concat', 'concat', 'fillna', 'fillna', 'apply', 'apply', 'unique', 'unique', 'concat', 'concat', 'read_csv', 'read_csv', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'fillna', 'ticket_grouped', 'dummies', 'drop', 'print', 'RandomForestClassifier', 'fit', 'print', 'concat', 'sort_values', 'predict', 'DataFrame', 'read_csv', 'concat', 'to_csv']","['walk', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'info', 'head', 'value_counts', 'countplot', 'groupby', 'mean', 'apply', 'qcut', 'crosstab', 'replace', 'corr', 'transform', 'where', 'concat', 'fillna', 'unique', 'names', 'age_impute', 'cabin_num', 'cabin', 'embarked_impute', 'fam_size', 'ticket_grouped', 'dummies', 'drop', 'RandomForestClassifier', 'fit', 'sort_values', 'predict', 'DataFrame', 'to_csv']",36,"[1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print get ipython run line magic read csv read csv info head value counts countplot groupby mean countplot head apply apply value counts groupby mean apply groupby mean qcut value counts value counts groupby mean groupby mean groupby mean qcut value counts groupby mean value counts groupby mean value counts head apply value counts apply value counts groupby mean qcut value counts groupby mean crosstab apply value counts groupby mean apply replace apply qcut value counts groupby mean corr value counts value counts groupby mean countplot apply apply apply apply groupby transform apply apply apply apply apply replace apply qcut concat concat fillna fillna apply apply unique unique concat concat read csv read csv names age impute cabin num cabin embarked impute fam size fillna ticket grouped dummies drop print randomforestclassifier fit print concat sort values predict dataframe read csv concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030746918003204046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5177422817082883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08271620486799236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15977624866788384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03497420113201945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09099253991274649, 0.43344257874150327, 0.0, 0.0, 0.0, 0.0, 0.03527278054930001, 0.08184698532617045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017091741949694258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017457445640257536, 0.0, 0.0, 0.0, 0.024651529446212364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03096018419582166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06227799728964856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05327337589242917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01503313814405064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017910673810652596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.331043034253429, 0.06227799728964856, 0.0, 0.0, 0.0, 0.04876439602109707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11992902361168459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022491586507140938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022602408519541574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022940802967176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02282699915714374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31877799600090506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059964511805842294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05631410254940617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015597188326846338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04365593839530405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17341243110567284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022057730920299588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06793175934501527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05387775779309974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022714206949915296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04406815268502017, 0.0, 0.0, 0.0, 0.02808576584646004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05116913967012214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027747371398825608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08271620486799236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43344257874150327, 0.02808576584646004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02897347315905483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
varun0727_titanic-machine-learning-from-disaster.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,163,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'pd.read_csv', 'train_data.info', 'train_data.head', 'get_ipython', 'None.run_line_magic', 'sns.heatmap', 'train_data.fillna', 'test_data.fillna', 'test_data.fillna', 'train_data.dropna', 'train_data.reset_index', 'train_data.drop', 'test_data.drop', 'train_data.head', 'OneHotEncoder', 'encoder.fit_transform', 'encoder.fit_transform', 'pd.DataFrame', 'pd.DataFrame', 'temp1.head', 'train_data.drop', 'pd.concat', 'test_data.drop', 'pd.concat', 'train_data.head', 'MaxAbsScaler', 'maxabs.fit_transform', 'train_data.drop', 'pd.concat', 'maxabs.fit_transform', 'test_data.drop', 'pd.concat', 'train_data.head', 'test_data.head', 'test_data.info', 'SVC', 'model.fit', 'model.predict', 'pd.concat', 'Submission.to_csv']","['print', 'read_csv', 'read_csv', 'info', 'head', 'get_ipython', 'run_line_magic', 'heatmap', 'fillna', 'fillna', 'fillna', 'dropna', 'reset_index', 'drop', 'drop', 'head', 'OneHotEncoder', 'fit_transform', 'fit_transform', 'DataFrame', 'DataFrame', 'head', 'drop', 'concat', 'drop', 'concat', 'head', 'MaxAbsScaler', 'fit_transform', 'drop', 'concat', 'fit_transform', 'drop', 'concat', 'head', 'head', 'info', 'SVC', 'fit', 'predict', 'concat', 'to_csv']","['print', 'read_csv', 'info', 'head', 'get_ipython', 'run_line_magic', 'heatmap', 'fillna', 'dropna', 'reset_index', 'drop', 'OneHotEncoder', 'fit_transform', 'DataFrame', 'concat', 'MaxAbsScaler', 'SVC', 'fit', 'predict', 'to_csv']",20,"[1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv info head get ipython run line magic heatmap fillna fillna fillna dropna reset index drop drop head onehotencoder fit transform fit transform dataframe dataframe head drop concat drop concat head maxabsscaler fit transform drop concat fit transform drop concat head head info svc fit predict concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46518646200372055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1429778575238442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1194297204999835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36595530044792923, 0.10387458559655573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18612568606669103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26261271262841135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06257603155572092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34074456566753336, 0.11462801446217669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12767246485111627, 0.0, 0.0, 0.15716150513242994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07896794077690786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08015021799647613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07975261202793325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25820759596612325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19674932922221236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05449321221744122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0508414778714127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09493556660902483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1428231571154534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07935854038141774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10187427179247421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3877733259166434, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
danielhung_titanic-prediction.py,"['pandas', 'numpy', 're\n', 'plotly', 'cufflinks', 'GridSearchCV\\nfrom']","[1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,88,"['# Plotly', '    # Get passenger title from name.', ""#     df = df.join(pd.get_dummies(df['cabin_'], prefix='cabin_', drop_first=True))"", ""#     df = df.join(pd.get_dummies(df['Pclass'], prefix='Pclass', drop_first=True))"", '# feature_extract(df_test).head()']",5,"['init_notebook_mode', 'cf.go_offline', 'pd.read_csv', 'df.info', 'iplot', 'df.Age.fillna', 'df.Fare.fillna', 'df.fillna', 'df.Embarked.map', 'None.astype', 'df.Parchdf.SibSp.apply', 'df.apply', 'df.replace', 'df.replace', 'df.join', 'df.join', 'df.join', 'df.drop', 'feature_extract', 'None.head', 'get_ipython', 'None.run_cell_magic', 'pd.read_csv', 'CV_rfc.predict', 'df_test.head']","['init_notebook_mode', 'go_offline', 'read_csv', 'info', 'iplot', 'Age', 'Fare', 'fillna', 'Embarked', 'astype', 'Parchdf', 'apply', 'replace', 'replace', 'join', 'join', 'join', 'drop', 'feature_extract', 'head', 'get_ipython', 'run_cell_magic', 'read_csv', 'predict', 'head']","['init_notebook_mode', 'go_offline', 'read_csv', 'info', 'iplot', 'Age', 'Fare', 'fillna', 'Embarked', 'astype', 'Parchdf', 'apply', 'replace', 'join', 'drop', 'feature_extract', 'head', 'get_ipython', 'run_cell_magic', 'predict']",20,"[0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",init notebook mode go offline read csv info iplot age fare fillna embarked astype parchdf apply replace replace join join join drop feature extract head get ipython run cell magic read csv predict head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11724395078395858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09871257761356014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08661366844816788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2621947490124106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10403280006142329, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06656861989376295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11805717606359592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2374780603503145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14765966174750644, 0.0, 0.0, 0.0, 0.0, 0.22865629232223056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06771389857216926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06829686665001229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2374780603503145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12396538836859863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08576477360175042, 0.2374780603503145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24827503181804642, 0.08618735938957883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47881252650666756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08704376697029381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15242275999160282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24827503181804642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24827503181804642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2818134885082264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05947509862192837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10361477984212562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20544632090884582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08661366844816788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
abinayajayaprakash_titanic-data-analysis.py,"['numpy', 'pandas', 'os\n', 'csv\n', 'matplotlib', 'seaborn']","[1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,423,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'open', 'csv.DictReader', 'list', 'print', 'print', 'set', 'unique_passenger_records.add', 'print', 'passenger_record.pop', 'passenger_record.pop', 'passenger_record.pop', 'print', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'print', 'titanic_df.drop', 'print', 'titanic_df_new.isnull', 'None.sum', 'print', 'print', 'survived.sum', 'print', 'survived.sum', 'non_survived.sum', 'plt.bar', 'plt.title', 'print', 'print', 'female_survived.sum', 'survived.sum', 'print', 'female_survived.sum', 'male_survived.sum', 'plt.bar', 'plt.title', 'titanic_df_newsurvived.argmin', 'print', 'titanic_df_newsurvived.argmax', 'print', 'titanic_df_newnon_survived.argmin', 'print', 'titanic_df_newnon_survived.argmax', 'print', 'below_12.sum', 'below_19.sum', 'below_12.sum', 'below_59.sum', 'below_19.sum', 'below_100.sum', 'below_59.sum', 'print', 'print', 'print', 'print', 'below_12_all.sum', 'below_19_all.sum', 'below_12_all.sum', 'below_59_all.sum', 'below_19_all.sum', 'below_100_all.sum', 'below_59_all.sum', 'plt.bar', 'plt.title', 'titanic_df_new.groupby', 'None.size', 'None.astype', 'print', 'survival', 'survival', 'survival', 'plt.bar', 'plt.title', 'titanic_df_new.groupby', 'None.size', 'None.astype', 'print', 'print', 'titanic_df_new.groupby', 'None.size', 'None.astype', 'survival', 'total', 'survival', 'total', 'survival', 'total', 'print', 'print', 'print', 'print', 'Port_S_s.sum', 'Port_C_s.sum', 'Port_Q_s.sum', 'plt.bar', 'plt.title', 'titanic_df_newtitanic_df_new.Parchtitanic_df_new.SibSp.count', 'titanic_df_newtitanic_df_new.Survivedtitanic_df_new.Parchtitanic_df_new.SibSp.count', 'print', 'titanic_df_newtitanic_df_new.Parchtitanic_df_new.SibSp.count', 'titanic_df_newtitanic_df_new.Survivedtitanic_df_new.Parchtitanic_df_new.SibSp.count', 'print', 'titanic_df_newtitanic_df_new.Parchtitanic_df_new.SibSptitanic_df_new.Age.count', 'print', 'titanic_df_newtitanic_df_new.Survivedtitanic_df_new.Parchtitanic_df_new.SibSptitanic_df_new.Age.count', 'print']","['walk', 'print', 'open', 'DictReader', 'list', 'print', 'print', 'set', 'add', 'print', 'pop', 'pop', 'pop', 'print', 'get_ipython', 'run_line_magic', 'read_csv', 'print', 'drop', 'print', 'isnull', 'sum', 'print', 'print', 'sum', 'print', 'sum', 'sum', 'bar', 'title', 'print', 'print', 'sum', 'sum', 'print', 'sum', 'sum', 'bar', 'title', 'argmin', 'print', 'argmax', 'print', 'argmin', 'print', 'argmax', 'print', 'sum', 'sum', 'sum', 'sum', 'sum', 'sum', 'sum', 'print', 'print', 'print', 'print', 'sum', 'sum', 'sum', 'sum', 'sum', 'sum', 'sum', 'bar', 'title', 'groupby', 'size', 'astype', 'print', 'survival', 'survival', 'survival', 'bar', 'title', 'groupby', 'size', 'astype', 'print', 'print', 'groupby', 'size', 'astype', 'survival', 'total', 'survival', 'total', 'survival', 'total', 'print', 'print', 'print', 'print', 'sum', 'sum', 'sum', 'bar', 'title', 'Parchtitanic_df_new', 'Survivedtitanic_df_new', 'print', 'Parchtitanic_df_new', 'Survivedtitanic_df_new', 'print', 'Parchtitanic_df_new', 'print', 'Survivedtitanic_df_new', 'print']","['walk', 'print', 'open', 'DictReader', 'list', 'set', 'add', 'pop', 'get_ipython', 'run_line_magic', 'read_csv', 'drop', 'isnull', 'sum', 'bar', 'title', 'argmin', 'argmax', 'groupby', 'size', 'astype', 'survival', 'total', 'Parchtitanic_df_new', 'Survivedtitanic_df_new']",25,"[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print open dictreader list print print set add print pop pop pop print get ipython run line magic read csv print drop print isnull sum print print sum print sum sum bar title print print sum sum print sum sum bar title argmin print argmax print argmin print argmax print sum sum sum sum sum sum sum print print print print sum sum sum sum sum sum sum bar title groupby size astype print survival survival survival bar title groupby size astype print print groupby size astype survival total survival total survival total print print print print sum sum sum bar title parchtitanic df new survivedtitanic df new print parchtitanic df new survivedtitanic df new print parchtitanic df new print survivedtitanic df new print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.024803499101032724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11623012508169002, 0.11623012508169002, 0.0, 0.0, 0.0, 0.0, 0.05759335887980391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19756053693073597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011529355001656933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28557618808999397, 0.0, 0.0, 0.0, 0.06246352595236023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014754832135103733, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015137895368458911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059955806257093125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01910329554661896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020508525228667633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019389302639133296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02955979227409407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01929311696867707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3747811557141614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05068131523883106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873905778570807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16508933595103883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3935732980241516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011483028232567685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019197786293267967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020725191797077627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11173768638961111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5100452902057429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3486903752450701, 0.0, 0.0, 0.1873905778570807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10819238907231271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1873905778570807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024488046054513227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
dvitsios_titanic-keras-dnn-classifier-one-hot-encoding.py,"['pandas', 'numpy', 'keras\n', 'sklearn', 'keras', 'sys\n', 'subprocess', 'matplotlib']","[1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,280,"['    # Make dummy variables for annotation', '    # Drop the previous rank column', '    # imputing missing values', ""    # label_mapping = {'YES': 1, 'NO': 0}"", ""    # data = data.replace({'Survived': label_mapping})"", '    # imputing missing values', ""    # data = data.interpolate(method='spline', order=2) # interpolate missing values"", '    # normalise data', ""# test = pd.read_csv('test.csv', sep=',')"", '# test_data = prepare_input_df(test, False)', '# test_data[:10]', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# from subprocess import check_output', '# print(check_output([""ls"", ""../input""]).decode(""utf8""))', '# Any results you write to the current directory are saved as output.', '    # Building the model', '    # Compiling the model', '    # sgd_optim = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)', '    # adam=keras.optimizers.Adam(lr=0.00001)', '# model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)', '# # # Split X into training and test sets', '# Creating the model', '# Fit the model', ""# early_stopping = [EarlyStopping(monitor='acc', patience=2)] # do not apply without checking"", '# y_pred = y.values.argmax']",26,"['range', 'data.drop', 'pd.concat', 'one_hot_data.drop', 'data.isnull', 'data.isnull', 'data.isnull', 'data.max', 'Imputer', 'pd.DataFrame', 'data.min', 'data.max', 'data.min', 'pd.read_csv', 'prepare_input_df', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'KerasClassifier', 'np.random.choice', 'data.drop', 'np.array', 'np.array', 'np.array', 'np.array', 'create_model', 'ModelCheckpoint', 'model.fit', 'get_ipython', 'None.run_line_magic', 'np.array', 'np.array', 'np.array', 'np.array', 'np.array', 'plt.figure', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.title', 'plt.show', 'plt.figure', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.title', 'plt.show', 'f.savefig', 'model.load_weights', 'model.evaluate', 'print', 'model.evaluate', 'print', 'model.predict', 'model.predict_classes', 'model.predict_proba', 'print', 'print', 'print', 'confusion_matrix', 'None.ravel', 'print', 'print', 'print', 'print', 'pd.concat', 'pd.read_csv', 'prepare_input_df', 'model.predict_classes', 'model.predict_proba', 'pd.DataFrame', 'type', 'open', 'f.write', 'range', 'f.write']","['range', 'drop', 'concat', 'drop', 'isnull', 'isnull', 'isnull', 'max', 'Imputer', 'DataFrame', 'min', 'max', 'min', 'read_csv', 'prepare_input_df', 'Sequential', 'add', 'add', 'add', 'add', 'add', 'add', 'add', 'compile', 'KerasClassifier', 'random', 'drop', 'array', 'array', 'array', 'array', 'create_model', 'ModelCheckpoint', 'fit', 'get_ipython', 'run_line_magic', 'array', 'array', 'array', 'array', 'array', 'figure', 'plot', 'plot', 'legend', 'title', 'show', 'figure', 'plot', 'plot', 'legend', 'title', 'show', 'savefig', 'load_weights', 'evaluate', 'print', 'evaluate', 'print', 'predict', 'predict_classes', 'predict_proba', 'print', 'print', 'print', 'confusion_matrix', 'ravel', 'print', 'print', 'print', 'print', 'concat', 'read_csv', 'prepare_input_df', 'predict_classes', 'predict_proba', 'DataFrame', 'type', 'open', 'write', 'range', 'write']","['range', 'drop', 'concat', 'isnull', 'max', 'Imputer', 'DataFrame', 'min', 'read_csv', 'prepare_input_df', 'Sequential', 'add', 'compile', 'KerasClassifier', 'random', 'array', 'create_model', 'ModelCheckpoint', 'fit', 'get_ipython', 'run_line_magic', 'figure', 'plot', 'legend', 'title', 'show', 'savefig', 'load_weights', 'evaluate', 'print', 'predict', 'predict_classes', 'predict_proba', 'confusion_matrix', 'ravel', 'type', 'open', 'write']",38,"[1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0
 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",range drop concat drop isnull isnull isnull max imputer dataframe min max min read csv prepare input df sequential add add add add add add add compile kerasclassifier random drop array array array array create model modelcheckpoint fit get ipython run line magic array array array array array figure plot plot legend title show figure plot plot legend title show savefig load weights evaluate print evaluate print predict predict classes predict proba print print print confusion matrix ravel print print print print concat read csv prepare input df predict classes predict proba dataframe type open write range write,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.28762614860792823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6587077877142326, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14976614804907068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06545571438799369, 0.0, 0.0, 0.07456961721633623, 0.0, 0.0, 0.05860387621756534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08121990769881286, 0.0, 0.0, 0.0, 0.0, 0.03819903406776145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047861606416797264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1576950681719748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07332851690037238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14328774859728807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08436622526618058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02104847309237443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025077421105121102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09627334978967986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20695401915404643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03164649875413417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10192320217958856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10347700957702322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0733079643702396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032120297794453696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719781177005324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03196095671674121, 0.0, 0.0, 0.0, 0.0, 0.05536467649167404, 0.0, 0.1288804290226013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1378103399065899, 0.0, 0.0, 0.0, 0.0, 0.06767941423719195, 0.10347700957702322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08395861204416194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1466159287404792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10919110689614901, 0.0, 0.19254669957935971, 0.0, 0.0, 0.0, 0.1833730594033483, 0.0, 0.13306559268093898, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05262597214632496, 0.0, 0.0, 0.0, 0.08609987749231225, 0.0, 0.08395861204416194, 0.0, 0.03804554431656243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03180303202289963, 0.0, 0.0, 0.0, 0.10347700957702322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07164387429864404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08325573419609493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07169255791762551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08121990769881286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09627334978967986, 0.0, 0.0, 0.0, 0.20695401915404643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
rajshree07_random-forest-titanic-prediction.py,"['numpy', 'pandas', 're\n', 'matplotlib', 'seaborn', 'sklearn', 'xgboost', 'os\n']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,328,['# Name length column'],1,"['get_ipython', 'None.run_line_magic', 'print', 'pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'train.head', 'test.head', 'print', 'print', 'np.sum', 'np.sum', 'train.fillna', 'train.fillna', 'train.fillna', 'test.fillna', 'test.fillna', 'test.fillna', 'print', 'print', 'print', 'sns.countplot', 'print', 'print', 'train.drop', 'plt.subplots', 'sns.countplot', 'None.set_title', 'sns.barplot', 'None.set_title', 'sns.countplot', 'None.set_title', 'print', 'train.apply', 'test.apply', 'plt.subplots', 'sns.countplot', 'None.set_title', 'sns.countplot', 'None.set_title', 'sns.countplot', 'None.set_title', 'train.apply', 'test.apply', 'plt.subplots', 'sns.countplot', 'a.set_xticklabels', 'a.set_title', 'sns.countplot', 'None.set_title', 'train.isin', 'test.isin', 'plt.subplots', 'sns.countplot', 'None.set_title', 'sns.countplot', 'None.set_title', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'plt.subplots', 'sns.countplot', 'sns.barplot', 'sns.countplot', 'pd.crosstab', 'np.count_nonzero', 'train.isin', 'train.isin', 'test.isin', 'test.isin', 'pd.cut', 'pd.cut', 'train.groupby', 'None.mean', 'a.fillna', 'None.reset_index', 'pd.merge', 'pd.merge', 'LabelEncoder', 'pd.concat', 'label.fit_transform', 'pd.concat', 'pd.concat', 'RandomForestRegressor', 'None.fit', 'regr.predict', 'test_val_y.astype', 'len', 'KFold', 'range', 'range', 'enumerate', 'L.append', 'np.mean', 'print', 'RandomForestRegressor', 'None.fit', 'regr.predict', 'test_y.astype', 'pd.read_csv', 'pd.concat', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'head', 'head', 'print', 'print', 'sum', 'sum', 'fillna', 'fillna', 'fillna', 'fillna', 'fillna', 'fillna', 'print', 'print', 'print', 'countplot', 'print', 'print', 'drop', 'subplots', 'countplot', 'set_title', 'barplot', 'set_title', 'countplot', 'set_title', 'print', 'apply', 'apply', 'subplots', 'countplot', 'set_title', 'countplot', 'set_title', 'countplot', 'set_title', 'apply', 'apply', 'subplots', 'countplot', 'set_xticklabels', 'set_title', 'countplot', 'set_title', 'isin', 'isin', 'subplots', 'countplot', 'set_title', 'countplot', 'set_title', 'subplots', 'countplot', 'countplot', 'subplots', 'countplot', 'barplot', 'countplot', 'crosstab', 'count_nonzero', 'isin', 'isin', 'isin', 'isin', 'cut', 'cut', 'groupby', 'mean', 'fillna', 'reset_index', 'merge', 'merge', 'LabelEncoder', 'concat', 'fit_transform', 'concat', 'concat', 'RandomForestRegressor', 'fit', 'predict', 'astype', 'len', 'KFold', 'range', 'range', 'enumerate', 'append', 'mean', 'print', 'RandomForestRegressor', 'fit', 'predict', 'astype', 'read_csv', 'concat', 'to_csv']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'head', 'sum', 'fillna', 'countplot', 'drop', 'subplots', 'set_title', 'barplot', 'apply', 'set_xticklabels', 'isin', 'crosstab', 'count_nonzero', 'cut', 'groupby', 'mean', 'reset_index', 'merge', 'LabelEncoder', 'concat', 'fit_transform', 'RandomForestRegressor', 'fit', 'predict', 'astype', 'len', 'KFold', 'range', 'enumerate', 'append', 'to_csv']",35,"[1 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0
 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic print read csv read csv print print print print head head print print sum sum fillna fillna fillna fillna fillna fillna print print print countplot print print drop subplots countplot set title barplot set title countplot set title print apply apply subplots countplot set title countplot set title countplot set title apply apply subplots countplot set xticklabels set title countplot set title isin isin subplots countplot set title countplot set title subplots countplot countplot subplots countplot barplot countplot crosstab count nonzero isin isin isin isin cut cut groupby mean fillna reset index merge merge labelencoder concat fit transform concat concat randomforestregressor fit predict astype len kfold range range enumerate append mean print randomforestregressor fit predict astype read csv concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03731907240252912, 0.12912102809114975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056647522469503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08722302516867651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13282331268801792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048788922325012064, 0.0, 0.0, 0.5294999399041421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04398382988087929, 0.0680400736353922, 0.0, 0.0, 0.0, 0.08440823660297146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02176877771579658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0582948199542953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1550030879486447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05623727251495084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022333936187383937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02948558608305826, 0.0, 0.0, 0.0, 0.0, 0.04053824441839237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04556742592939583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02818435279952382, 0.0, 0.0, 0.0, 0.44864093702028585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05495132792702406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044365119536629916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03971700931725595, 0.0, 0.0, 0.0, 0.0, 0.028606317940507924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02846440887231698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061154486776499234, 0.0, 0.0, 0.0, 0.14954697900676195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09215656263325298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038898213710665895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25404079036521426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14044313308192685, 0.0, 0.0766804992265408, 0.0, 0.0, 0.0, 0.050825008406080056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05097484128978171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0283237612347515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3363496772707458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23659144151077055, 0.060200278502997515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3192467452954315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03459992788325106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05039940496460653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
pankeshpatel_titanic-survival-prediction.py,"['numpy', 'pandas', 'os\n', 'warnings\n', 'IPython', 'base64\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]",7,397,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# download .csv file from Kaggle Kernel', '# function that takes in a dataframe and creates a text link to  ', '# download it (will only work for files < 2MB or so)', '# create a random sample dataframe', '# create a link to download the dataframe', '# Copying the IDs to a variable ', '# We will use this, when making submission to the competition  ', '# Early observation', '# those passengers who has less # of siblings / spouses aboard the Titanic, they survived more', '# There is a strong linear relationship among these two variables', '# Early observation ', '# those passengers who has less #  of parents/children aboard the Titanic, they survived more', '# There is a strong linear relationship among these two variables', '# The relationship is not so clear to me, Need more work', '# There is not linear relationship between Pclass and Survived ', '# The relationship is not so clear to me, need more work', '# There is not linear relationship between Pclass and Survived ', '# The relationship is not so clear to me, need more work', '# There is not linear relationship between Pclass and Survived', '# It has been obvious that PassengerId and Name has no correlation with our target variable. ', '# Therefore, we will delete this column for simplicity reasons.', '# get information about missing values ', '# Data inmputation', '# It seems that NA values in ""Cabin""  be replaced with None', '# Data imputation for Age and Fare -  Mean Imputation', '# They are not categorical variables', '# Data Imputation for Embarked -- Mode imputation', '# Simplify ""Age"" attribute ', '# Kernel Reference: https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish/output', '# Simplify Fare attribute', '# Kernel Reference: https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish/output', '# reduce the feature', '# drop the column now', '# Data is now ready for encoder', '# all_data = pd.get_dummies(all_data)', '# all_data.head()', ""# Since, we have finished data imputation. Let's separate train_data and test_data"", '# X', ""# We won't touch test data now for a moment."", '# We will use the test data, once our model is ready.', '# Our target variable is ', ""# Let's first have train-test split"", '# Choose the type of classifier. ', '# Choose some parameter combinations to try', '# Type of scoring used to compare parameter combinations', '# Run the grid search', '# Set the clf to the best combination of parameters', '# Fit the best algorithm to the data. ', '# get the accuracy score of a model', '# Testing Logistic Regression as some  Kernel is getting high score than Random Forest Classifier', '# Kernel -- https://www.kaggle.com/patilneha09/pneha-titanic-dataset-solution', '# Results for the submission', '# choose the algorithm ', '# make predictions using test_data', '# Prepare dataset', '# you could use any filename. We choose submission here']",64,"['print', 'warnings.simplefilter', 'df.to_csv', 'base64.b64encode', 'b64.decode', 'html.format', 'HTML', 'pd.DataFrame', 'pd.read_csv', 'pd.read_csv', 'train_data.head', 'test_data.head', 'train_data.groupby', 'None.count', 'None.sort_values', 'train_data.groupby', 'None.count', 'None.sort_values', 'train_data.groupby', 'None.count', 'None.sort_values', 'train_data.groupby', 'None.count', 'None.sort_values', 'train_data.groupby', 'None.count', 'None.sort_values', 'None.head', 'train_data.drop', 'pd.concat', 'all_data.head', 'all_data.head', 'all_data.drop', 'all_data.isnull', 'None.sum', 'None.sort_values', 'all_data.isnull', 'None.sum', 'all_data.isnull', 'None.count', 'None.sort_values', 'pd.concat', 'all_data.fillna', 'all_data.fillna', 'all_data.fillna', 'all_data.mode', 'all_data.fillna', 'pd.cut', 'print', 'simplify_ages', 'pd.cut', 'simplify_fares', 'df.Name.apply', 'df.Name.apply', 'format_name', 'all_data.drop', 'all_data.drop', 'all_data.head', 'preprocessing.LabelEncoder', 'le.fit', 'le.transform', 'encode_features', 'all_data.head', 'train_test_split', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'grid_obj.fit', 'clf.fit', 'clf.predict', 'print', 'LogisticRegression', 'lreg.fit', 'lreg.predict', 'print', 'lreg.predict', 'pd.DataFrame', 'my_submission.to_csv']","['print', 'simplefilter', 'to_csv', 'b64encode', 'decode', 'format', 'HTML', 'DataFrame', 'read_csv', 'read_csv', 'head', 'head', 'groupby', 'count', 'sort_values', 'groupby', 'count', 'sort_values', 'groupby', 'count', 'sort_values', 'groupby', 'count', 'sort_values', 'groupby', 'count', 'sort_values', 'head', 'drop', 'concat', 'head', 'head', 'drop', 'isnull', 'sum', 'sort_values', 'isnull', 'sum', 'isnull', 'count', 'sort_values', 'concat', 'fillna', 'fillna', 'fillna', 'mode', 'fillna', 'cut', 'print', 'simplify_ages', 'cut', 'simplify_fares', 'Name', 'Name', 'format_name', 'drop', 'drop', 'head', 'LabelEncoder', 'fit', 'transform', 'encode_features', 'head', 'train_test_split', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'fit', 'fit', 'predict', 'print', 'LogisticRegression', 'fit', 'predict', 'print', 'predict', 'DataFrame', 'to_csv']","['print', 'simplefilter', 'to_csv', 'b64encode', 'decode', 'format', 'HTML', 'DataFrame', 'read_csv', 'head', 'groupby', 'count', 'sort_values', 'drop', 'concat', 'isnull', 'sum', 'fillna', 'mode', 'cut', 'simplify_ages', 'simplify_fares', 'Name', 'format_name', 'LabelEncoder', 'fit', 'transform', 'encode_features', 'train_test_split', 'RandomForestClassifier', 'make_scorer', 'GridSearchCV', 'predict', 'LogisticRegression']",34,"[1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print simplefilter csv b64encode decode format html dataframe read csv read csv head head groupby count sort values groupby count sort values groupby count sort values groupby count sort values groupby count sort values head drop concat head head drop isnull sum sort values isnull sum isnull count sort values concat fillna fillna fillna mode fillna cut print simplify ages cut simplify fares name name format name drop drop head labelencoder fit transform encode features head train test split randomforestclassifier make scorer gridsearchcv fit fit predict print logisticregression fit predict print predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12004928529397928, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13626625131765066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09819883896720741, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4328471046070801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1006066796411343, 0.0, 0.0, 0.0, 0.12480927731640402, 0.0, 0.0, 0.0, 0.0630277364519621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13626625131765066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12875262055524878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12677993431833384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12677993431833384, 0.0, 0.0, 0.0, 0.0, 0.11056296829466246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13096774280573548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1108728029919866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19722324458690865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06677002913659567, 0.0, 0.0, 0.21799262953371368, 0.0, 0.0, 0.0, 0.0, 0.2097949462760149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12677993431833384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13422008173675978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06559997851237813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04208857385924179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10383231927030791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07370150459969696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18721391597460604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627460075305628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10732414861870518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04067019193435128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0501012130573657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11056296829466246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12677993431833384, 0.0, 0.2725325026353013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3624930615974186, 0.0, 0.0, 0.0, 0.04382241408856977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08901445589423519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04569510419997697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04497516627469012, 0.0, 0.0, 0.0, 0.05116078913744585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3624930615974186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
simo333_titanic-3-0-xgboost.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'sklearn', 'tensorflow', 'xgboost']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,175,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_df.head', 'train_df.drop', 'train_df.pop', 'pd.Categorical', 'pd.Categorical', 'train_df.astype', 'test_df.drop', 'pd.Categorical', 'pd.Categorical', 'test_df.astype', 'train_df.set_index', 'test_df.set_index', 'train_df.head', 'test_df.head', 'train_test_split', 'train_test_split', 'StandardScaler', 'SC.fit_transform', 'SC.transform', 'SC.transform', 'tf.keras.Sequential', 'model.compile', 'model.fit', 'model.evaluate', 'pd.DataFrame', 'plt.xlabel', 'plt.ylabel', 'plt.plot', 'plt.plot', 'plt.ylim', 'plt.legend', 'plt.show', 'plt.xlabel', 'plt.ylabel', 'plt.plot', 'plt.plot', 'plt.legend', 'plt.show', 'plot_history', 'np.concatenate', 'np.concatenate', 'XGBClassifier', 'model1.fit', 'plot_importance', 'plt.show', 'model1.predict', 'pred.reshape', 'pd.read_csv', 'sub_df.copy', 'sub_df1.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'head', 'drop', 'pop', 'Categorical', 'Categorical', 'astype', 'drop', 'Categorical', 'Categorical', 'astype', 'set_index', 'set_index', 'head', 'head', 'train_test_split', 'train_test_split', 'StandardScaler', 'fit_transform', 'transform', 'transform', 'keras', 'compile', 'fit', 'evaluate', 'DataFrame', 'xlabel', 'ylabel', 'plot', 'plot', 'ylim', 'legend', 'show', 'xlabel', 'ylabel', 'plot', 'plot', 'legend', 'show', 'plot_history', 'concatenate', 'concatenate', 'XGBClassifier', 'fit', 'plot_importance', 'show', 'predict', 'reshape', 'read_csv', 'copy', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'drop', 'pop', 'Categorical', 'astype', 'set_index', 'train_test_split', 'StandardScaler', 'fit_transform', 'transform', 'keras', 'compile', 'fit', 'evaluate', 'DataFrame', 'xlabel', 'ylabel', 'plot', 'ylim', 'legend', 'show', 'plot_history', 'concatenate', 'XGBClassifier', 'plot_importance', 'predict', 'reshape', 'copy', 'to_csv']",32,"[1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0
 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv head drop pop categorical categorical astype drop categorical categorical astype set index set index head head train test split train test split standardscaler fit transform transform transform keras compile fit evaluate dataframe xlabel ylabel plot plot ylim legend show xlabel ylabel plot plot legend show plot history concatenate concatenate xgbclassifier fit plot importance show predict reshape read csv copy csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10141113192222133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6139785268955138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10436014531703222, 0.0, 0.0, 0.0, 0.25898797222932146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06308204374630252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12180622527933392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03815437847913666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07794149832097776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11422631626266563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10067669711468721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10885813906924365, 0.0, 0.0, 0.0, 0.0, 0.15349463172387845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12949398611466073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16315079780478714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12949398611466073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11687947929535265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.350638437886058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14534571999892118, 0.0, 0.0, 0.0, 0.0, 0.034818044198444774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03248479492413782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09098759147307531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12571156226831476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10947955807716218, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19910974772221854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10611309033946373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09343583055184418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11064768614169283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10890440385810235, 0.0, 0.0, 0.0, 0.18582372351536147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06467830277448461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08472598758642581, 0.0, 0.0, 0.0, 0.15614779475656548, 0.0, 0.0, 0.0, 0.0, 0.1511087236352547, 0.0, 0.12949398611466073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
waiyankhinemyo_titanic-logistics-regression-knn-decision-tree.py,"['pandas', 'numpy', 'matplotlib', 'math\n', 'seaborn', 'mpl_toolkits', 'time\n', 'datetime', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",10,880,"[' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ']",3,"['get_ipython', 'None.run_line_magic', 'sns.set', 'os.walk', 'print', 'pd.read_csv', 'print', 'pd.read_csv', 'print', 'train_dataset.describe', 'test_dataset.describe', 'train_dataset.head', 'test_dataset.head', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'pd.concat', 'total_dataset.head', 'total_dataset.tail', 'train_dataset.plot.hist', 'test_dataset.plot.hist', 'total_dataset.plot.hist', 'sns.boxplot', 'train_dataset.plot.hist', 'test_dataset.plot.hist', 'total_dataset.plot.hist', 'sns.boxplot', 'sns.boxplot', 'sns.boxplot', 'train_dataset.plot.hist', 'test_dataset.plot.hist', 'total_dataset.plot.hist', 'train_dataset.info', 'test_dataset.info', 'total_dataset.info', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'sns.countplot', 'total_dataset.isnull', 'train_dataset.isnull', 'None.sum', 'test_dataset.isnull', 'None.sum', 'sns.heatmap', 'sns.heatmap', 'train_dataset.head', 'test_dataset.head', 'train_dataset.drop', 'test_dataset.drop', 'train_dataset.head', 'test_dataset.head', 'sns.heatmap', 'sns.heatmap', 'train_dataset.dropna', 'test_dataset.describe', 'test_dataset.fillna', 'test_dataset.fillna', 'sns.heatmap', 'sns.heatmap', 'train_dataset.isnull', 'None.sum', 'test_dataset.isnull', 'None.sum', 'train_dataset.head', 'test_dataset.head', 'train_dataset.Pclass.unique', 'test_dataset.Pclass.unique', 'train_dataset.Sex.unique', 'test_dataset.Sex.unique', 'train_dataset.Embarked.unique', 'test_dataset.Embarked.unique', 'pd.get_dummies', 'pd.get_dummies', 'LabelEncoder', 'le.fit_transform', 'le.transform', 'le.fit_transform', 'le.transform', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'train_dataset.head', 'pd.concat', 'test_dataset.head', 'train_dataset.drop', 'train_dataset.head', 'test_dataset.drop', 'test_dataset.head', 'train_dataset.corr', 'plt.figure', 'sns.heatmap', 'plt.show', 'train_dataset.drop', 'dropped_passengerId.drop', 'test_dataset.drop', 'train_dataset.drop', 'dropped_passengerId.drop', 'dropped_survived.head', 'test_dataset.drop', 'test_dropped_passengerId.head', 'StandardScaler', 'None.fit_transform', 'StandardScaler', 'None.fit_transform', 'MinMaxScaler', 'None.fit_transform', 'MinMaxScaler', 'None.fit_transform', 'RobustScaler', 'None.fit_transform', 'RobustScaler', 'None.fit_transform', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'pd.DataFrame', 'output.to_csv', 'print', 'math.sqrt', 'KNeighborsClassifier', 'knnmodel.fit', 'knnmodel.predict', 'print', 'pd.DataFrame', 'output.to_csv', 'print', 'DecisionTreeRegressor', 'decisionmodel.fit', 'decisionmodel.predict', 'print', 'pd.DataFrame', 'output.to_csv', 'print']","['get_ipython', 'run_line_magic', 'set', 'walk', 'print', 'read_csv', 'print', 'read_csv', 'print', 'describe', 'describe', 'head', 'head', 'countplot', 'countplot', 'countplot', 'concat', 'head', 'tail', 'plot', 'plot', 'plot', 'boxplot', 'plot', 'plot', 'plot', 'boxplot', 'boxplot', 'boxplot', 'plot', 'plot', 'plot', 'info', 'info', 'info', 'countplot', 'countplot', 'countplot', 'countplot', 'countplot', 'countplot', 'isnull', 'isnull', 'sum', 'isnull', 'sum', 'heatmap', 'heatmap', 'head', 'head', 'drop', 'drop', 'head', 'head', 'heatmap', 'heatmap', 'dropna', 'describe', 'fillna', 'fillna', 'heatmap', 'heatmap', 'isnull', 'sum', 'isnull', 'sum', 'head', 'head', 'Pclass', 'Pclass', 'Sex', 'Sex', 'Embarked', 'Embarked', 'get_dummies', 'get_dummies', 'LabelEncoder', 'fit_transform', 'transform', 'fit_transform', 'transform', 'get_dummies', 'get_dummies', 'concat', 'head', 'concat', 'head', 'drop', 'head', 'drop', 'head', 'corr', 'figure', 'heatmap', 'show', 'drop', 'drop', 'drop', 'drop', 'drop', 'head', 'drop', 'head', 'StandardScaler', 'fit_transform', 'StandardScaler', 'fit_transform', 'MinMaxScaler', 'fit_transform', 'MinMaxScaler', 'fit_transform', 'RobustScaler', 'fit_transform', 'RobustScaler', 'fit_transform', 'LogisticRegression', 'fit', 'predict', 'print', 'DataFrame', 'to_csv', 'print', 'sqrt', 'KNeighborsClassifier', 'fit', 'predict', 'print', 'DataFrame', 'to_csv', 'print', 'DecisionTreeRegressor', 'fit', 'predict', 'print', 'DataFrame', 'to_csv', 'print']","['get_ipython', 'run_line_magic', 'set', 'walk', 'print', 'read_csv', 'describe', 'head', 'countplot', 'concat', 'tail', 'plot', 'boxplot', 'info', 'isnull', 'sum', 'heatmap', 'drop', 'dropna', 'fillna', 'Pclass', 'Sex', 'Embarked', 'get_dummies', 'LabelEncoder', 'fit_transform', 'transform', 'corr', 'figure', 'show', 'StandardScaler', 'MinMaxScaler', 'RobustScaler', 'LogisticRegression', 'fit', 'predict', 'DataFrame', 'to_csv', 'sqrt', 'KNeighborsClassifier', 'DecisionTreeRegressor']",41,"[1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0
 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic set walk print read csv print read csv print describe describe head head countplot countplot countplot concat head tail plot plot plot boxplot plot plot plot boxplot boxplot boxplot plot plot plot info info info countplot countplot countplot countplot countplot countplot isnull isnull sum isnull sum heatmap heatmap head head drop drop head head heatmap heatmap dropna describe fillna fillna heatmap heatmap isnull sum isnull sum head head pclass pclass sex sex embarked embarked get dummies get dummies labelencoder fit transform transform fit transform transform get dummies get dummies concat head concat head drop head drop head corr figure heatmap show drop drop drop drop drop head drop head standardscaler fit transform standardscaler fit transform minmaxscaler fit transform minmaxscaler fit transform robustscaler fit transform robustscaler fit transform logisticregression fit predict print dataframe csv print sqrt kneighborsclassifier fit predict print dataframe csv print decisiontreeregressor fit predict print dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20524885130618184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1058595282132148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634421526775852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.361721873922866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09037934115718896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06794465713978175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09793110405773725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09696753919340115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2313281197541315, 0.03939679935808422, 0.0, 0.0, 0.1306626885368732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08205050549600736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03992228621252794, 0.0, 0.0, 0.0, 0.04706160008400449, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2191240584551894, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.118666916727879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32308781808527587, 0.30432697299850253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08941061351471953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029950387774274535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16076762299419073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040464727150382136, 0.0, 0.0, 0.0, 0.0, 0.0471450433233492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030398793302320357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03024799219465481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03024799219465481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1329164553672696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1281041998666506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31220543213964513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06200337077000731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17354508247987138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036006473076758125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1958622081154745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030098531559011158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03249321717836007, 0.0, 0.12015481837746363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03939679935808422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627638124993929, 0.0, 0.0, 0.0, 0.0, 0.11092594042886807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12794487055346263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053557437810250706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36767963573135914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0383926675571311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
ioanaandreeaanton_titanic-competition.py,"['numpy', 'pandas', 'matplotlib', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,507,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",8,"['os.walk', 'print', 'pd.read_csv', 'test_data.info', 'test_data.describe', 'pd.read_csv', 'train_data.info', 'train_data.describe', 'plt.figure', 'train_data.Survived.value_counts', 'None.plot', 'plt.title', 'plt.figure', 'train_data.Sex.value_counts', 'None.plot', 'plt.title', 'plt.figure', 'train_data.Pclass.value_counts', 'None.plot', 'plt.title', 'plt.figure', 'train_data.Embarked.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sex.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sex.value_counts', 'None.plot', 'plt.title', 'plt.figure', 'train_data.Sextrain_data.Survived.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sextrain_data.Pclass.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sextrain_data.Pclass.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sextrain_data.Pclass.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sextrain_data.Pclass.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sextrain_data.Pclass.value_counts', 'None.plot', 'plt.title', 'sum', 'len', 'print', 'plt.figure', 'train_data.Survivedtrain_data.Sextrain_data.Pclass.value_counts', 'None.plot', 'plt.title', 'print', 'print', 'train_data.fillna', 'train_data.info', 'test_data.fillna', 'test_data.info', 'test_data.fillna', 'test_data.info', 'train_data.fillna', 'train_data.info', 'train_data.head', 'test_data.head', 'train_data.head', 'test_data.head', 'train_data.info', 'test_data.info', 'train_data.fillna', 'train_data.astype', 'test_data.fillna', 'test_data.astype', 'train_data.fillna', 'train_data.astype', 'test_data.fillna', 'test_data.astype', 'train_data.info', 'test_data.info', 'train_data.astype', 'train_data.head', 'train_data.tail', 'test_data.astype', 'test_data.head', 'train_data.astype', 'train_data.head', 'test_data.astype', 'test_data.head', 'train_data.info', 'test_data.info', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'info', 'describe', 'read_csv', 'info', 'describe', 'figure', 'Survived', 'plot', 'title', 'figure', 'Sex', 'plot', 'title', 'figure', 'Pclass', 'plot', 'title', 'figure', 'Embarked', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'figure', 'Sextrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'sum', 'len', 'print', 'figure', 'Survivedtrain_data', 'plot', 'title', 'print', 'print', 'fillna', 'info', 'fillna', 'info', 'fillna', 'info', 'fillna', 'info', 'head', 'head', 'head', 'head', 'info', 'info', 'fillna', 'astype', 'fillna', 'astype', 'fillna', 'astype', 'fillna', 'astype', 'info', 'info', 'astype', 'head', 'tail', 'astype', 'head', 'astype', 'head', 'astype', 'head', 'info', 'info', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'info', 'describe', 'figure', 'Survived', 'plot', 'title', 'Sex', 'Pclass', 'Embarked', 'sum', 'len', 'Survivedtrain_data', 'Sextrain_data', 'fillna', 'head', 'astype', 'tail', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",26,"[1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv info describe read csv info describe figure survived plot title figure sex plot title figure pclass plot title figure embarked plot title sum len print figure survivedtrain data plot title sum len print figure survivedtrain data plot title figure sextrain data plot title sum len print figure survivedtrain data plot title sum len print figure survivedtrain data plot title sum len print figure survivedtrain data plot title sum len print figure survivedtrain data plot title sum len print figure survivedtrain data plot title sum len print figure survivedtrain data plot title print print fillna info fillna info fillna info fillna info head head head head info info fillna astype fillna astype fillna astype fillna astype info info astype head tail astype head astype head astype head info info get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1682645489507665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03789463709666142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.39601569524649355, 0.0, 0.01582673707412292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045174405527763285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045654009540809996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028668739352366034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.362673720074321, 0.0, 0.0, 0.0, 0.13154792777034288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013920495962619758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0331701152586906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12041390540934925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24992309882243072, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23594905362504892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044760064471499446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3151364431127193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014442799304549055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1616993892700198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020425180110654417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025161580307041357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041982522218123396, 0.0, 0.0, 0.06843495429427483, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17881757696412587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041982522218123396, 0.0, 0.0, 0.5093662694385729, 0.0, 0.0, 0.0, 0.0, 0.03742631969616192, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3081921301989534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026829070036405573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
srolka_titanic-survival-logistic-regression.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'cufflinks', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,309,[],0,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'train.head', 'sns.heatmap', 'sns.set_style', 'sns.countplot', 'sns.countplot', 'sns.distplot', 'train.info', 'sns.countplot', 'train.hist', 'cf.go_offline', 'plt.figure', 'sns.boxplot', 'pd.isnull', 'train.apply', 'sns.heatmap', 'train.drop', 'train.head', 'sns.heatmap', 'train.dropna', 'sns.heatmap', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'train.head', 'train.drop', 'train.head', 'train.drop', 'train.head', 'train.drop', 'train_test_split', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'confusion_matrix']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'heatmap', 'set_style', 'countplot', 'countplot', 'distplot', 'info', 'countplot', 'hist', 'go_offline', 'figure', 'boxplot', 'isnull', 'apply', 'heatmap', 'drop', 'head', 'heatmap', 'dropna', 'heatmap', 'get_dummies', 'get_dummies', 'concat', 'head', 'drop', 'head', 'drop', 'head', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'heatmap', 'set_style', 'countplot', 'distplot', 'info', 'hist', 'go_offline', 'figure', 'boxplot', 'isnull', 'apply', 'drop', 'dropna', 'get_dummies', 'concat', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'print', 'confusion_matrix']",25,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv head heatmap set style countplot countplot distplot info countplot hist go offline figure boxplot isnull apply heatmap drop head heatmap dropna heatmap get dummies get dummies concat head drop head drop head drop train test split logisticregression fit predict print confusion matrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09847989411081944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14731160106324975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10130360609993337, 0.0, 0.0, 0.1592279594261589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.346154293828011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05189378791327216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14162601239410053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2656468221873526, 0.11310378700340523, 0.0, 0.0, 0.1875589531936717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11461240075443312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05718914235455719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20440763553326666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23691828136123064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3091829484926036, 0.4992506091031058, 0.0, 0.1229558190807409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08556261042846623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08598420010471801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09230915853293785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08727152202328999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0868385889769718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0868385889769718, 0.0, 0.0, 0.0, 0.0, 0.1504269859101297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24768980240308128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0593349049950597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05535871600432429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051685270478473856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08640950427530392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09328437778391492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0904159075986454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12875539059174176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09427970605875934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09279430544167022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sabarostami_titanic.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'sklearn', 'warnings']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,398,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'df.head', 'df.drop', 'cdf.head', 'cdf.describe', 'cdf.groupby', 'None.mean', 'cdf.groupby', 'None.mean', 'list', 'list', 'min', 'max', 'sns.distplot', 'sns.distplot', 'plt.legend', 'plt.title', 'plt.show', 'enumerate', 'plt.figure', 'sns.catplot', 'cdf.drop', 'sns.catplot', 'cdf.fillna', 'cdf.isnull', 'None.sum', 'cdf.head', 'df.drop', 'idf.head', 'idf.info', 'idf.groupby', 'None.mean', 'np.where', 'idf.head', 'enumerate', 'plt.figure', 'sns.catplot', 'idf.pivot_table', 'idf.pivot_table', 'idf.head', 'idf.map', 'idf.head', 'idf.drop', 'idf.head', 'df.drop', 'df.head', 'df.head', 'df.drop', 'train_test_split', 'print', 'warnings.filterwarnings', 'RandomForestClassifier', 'cross_val_score', 'print', 'zip', 'print', 'GridSearchCV', 'cv.fit', 'print_result', 'RandomForestClassifier', 'rf.fit', 'rf.predict', 'print', 'print']","['print', 'read_csv', 'head', 'drop', 'head', 'describe', 'groupby', 'mean', 'groupby', 'mean', 'list', 'list', 'min', 'max', 'distplot', 'distplot', 'legend', 'title', 'show', 'enumerate', 'figure', 'catplot', 'drop', 'catplot', 'fillna', 'isnull', 'sum', 'head', 'drop', 'head', 'info', 'groupby', 'mean', 'where', 'head', 'enumerate', 'figure', 'catplot', 'pivot_table', 'pivot_table', 'head', 'map', 'head', 'drop', 'head', 'drop', 'head', 'head', 'drop', 'train_test_split', 'print', 'filterwarnings', 'RandomForestClassifier', 'cross_val_score', 'print', 'zip', 'print', 'GridSearchCV', 'fit', 'print_result', 'RandomForestClassifier', 'fit', 'predict', 'print', 'print']","['print', 'read_csv', 'head', 'drop', 'describe', 'groupby', 'mean', 'list', 'min', 'max', 'distplot', 'legend', 'title', 'show', 'enumerate', 'figure', 'catplot', 'fillna', 'isnull', 'sum', 'info', 'where', 'pivot_table', 'map', 'train_test_split', 'filterwarnings', 'RandomForestClassifier', 'cross_val_score', 'zip', 'GridSearchCV', 'fit', 'print_result', 'predict']",33,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv head drop head describe groupby mean groupby mean list list min max distplot distplot legend title show enumerate figure catplot drop catplot fillna isnull sum head drop head info groupby mean head enumerate figure catplot pivot table pivot table head map head drop head drop head head drop train test split print filterwarnings randomforestclassifier cross val score print zip print gridsearchcv fit print result randomforestclassifier fit predict print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37214790210157983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09662401624635393, 0.0, 0.0, 0.03438467292623525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06148523687192549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18768196772055692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2640252175290648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2356785594517133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15188368672635938, 0.0, 0.0, 0.0, 0.04476127247540423, 0.0, 0.09211166025885772, 0.0, 0.0, 0.0, 0.07578671875253222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0912808422393595, 0.0, 0.0, 0.17880972421116365, 0.0, 0.0, 0.0, 0.0, 0.4097274446819956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05669353679123607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06116377994136154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06598780412319766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1763158110694152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06021835065638858, 0.0, 0.0, 0.0, 0.11601108527178841, 0.0, 0.0, 0.0, 0.1854298721412238, 0.0, 0.0, 0.0, 0.0, 0.12404930070052661, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2924388042240731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039315135460415554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25676366940574485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11119987281147593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034246509880459144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1733199660577268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.057825856643201196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07494224027990104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059909317379258115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060845521640267956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28389688239525074, 0.0, 0.0, 0.0, 0.06246945900017708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0645337039379015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06148523687192549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09662401624635393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12404930070052661, 0.0]"
flygare_titanic.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'check_output\n']","[1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,274,"['   3052         # else, only a single dtype is given', '    503                 # _astype_nansafe works fine with 1-d only']",2,"['pd.read_csv', 'pd.read_csv', 'print', 'print', 'print', 'print', 'pd.concat', 'print', 'print', 'full.map', 'full.groupby', 'None.agg', 'len', 'g.unstack', 'print', 'full.fillna', 'full.groupby', 'None.agg', 'len', 'g.unstack', 'print', 'full.groupby', 'None.agg', 'len', 'g.unstack', 'print', 'full.groupby', 'None.agg', 'len', 'g.unstack', 'print', 'full.groupby', 'None.agg', 'len', 'g.unstack', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'full.groupby', 'None.agg', 'len', 'g.sort_index', 'g.unstack', 'print', 'print', 'print', 'print', 'print', 'print', 'full.Cabin.replace', 'None.fillna', 'print', 'print', 'full.groupby', 'None.agg', 'len', 'full.corr', 'plt.subplots', 'sns.diverging_palette', 'sns.heatmap', 'plt.figure', 'plt.title', 'sns.heatmap']","['read_csv', 'read_csv', 'print', 'print', 'print', 'print', 'concat', 'print', 'print', 'map', 'groupby', 'agg', 'len', 'unstack', 'print', 'fillna', 'groupby', 'agg', 'len', 'unstack', 'print', 'groupby', 'agg', 'len', 'unstack', 'print', 'groupby', 'agg', 'len', 'unstack', 'print', 'groupby', 'agg', 'len', 'unstack', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'print', 'groupby', 'agg', 'len', 'sort_index', 'unstack', 'print', 'print', 'print', 'print', 'print', 'print', 'Cabin', 'fillna', 'print', 'print', 'groupby', 'agg', 'len', 'corr', 'subplots', 'diverging_palette', 'heatmap', 'figure', 'title', 'heatmap']","['read_csv', 'print', 'concat', 'map', 'groupby', 'agg', 'len', 'unstack', 'fillna', 'sort_index', 'Cabin', 'corr', 'subplots', 'diverging_palette', 'heatmap', 'figure', 'title']",17,"[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv print print print print concat print print map groupby agg len unstack print fillna groupby agg len unstack print groupby agg len unstack print groupby agg len unstack print groupby agg len unstack print print print print print print print print groupby agg len sort index unstack print print print print print print cabin fillna print print groupby agg len corr subplots diverging palette heatmap figure title heatmap,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5457062843708668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06028493590990347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03881585607979374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05097955055139947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03976762290356882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09490572046395172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.043915301971137286, 0.0, 0.0, 0.0, 0.05176868799376029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24126962951500716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09564733446694283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05326590975656788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3249895761415548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03482279249704549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07795804062440953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5514975915834985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03960783031471912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04093873979679103, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04609381268765508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03731825526272366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43040797470660275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
surenj_titanic.py,"['os\n', 'pandas', 'matplotlib', 'seaborn', 'numpy', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,153,[],0,"['get_ipython', 'None.run_line_magic', 'pd.set_option', 'pd.read_csv', 'pd.read_csv', 'train.drop', 'train_test_split', 'Pipeline', 'Pipeline', 'ColumnTransformer', 'preprocessing', 'Pipeline', 'GridSearchCV', 'grid.fit', 'grid.score', 'LogisticRegression', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'preprocessing', 'Pipeline', 'StratifiedShuffleSplit', 'cross_val_score', 'np.mean', 'full_pipeline.fit', 'full_pipeline.predict', 'accuracy_score', 'print', 'test.drop', 'full_pipeline.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['get_ipython', 'run_line_magic', 'set_option', 'read_csv', 'read_csv', 'drop', 'train_test_split', 'Pipeline', 'Pipeline', 'ColumnTransformer', 'preprocessing', 'Pipeline', 'GridSearchCV', 'fit', 'score', 'LogisticRegression', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'preprocessing', 'Pipeline', 'StratifiedShuffleSplit', 'cross_val_score', 'mean', 'fit', 'predict', 'accuracy_score', 'print', 'drop', 'predict', 'DataFrame', 'to_csv', 'print']","['get_ipython', 'run_line_magic', 'set_option', 'read_csv', 'drop', 'train_test_split', 'Pipeline', 'ColumnTransformer', 'preprocessing', 'GridSearchCV', 'fit', 'score', 'LogisticRegression', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StratifiedShuffleSplit', 'cross_val_score', 'mean', 'predict', 'accuracy_score', 'print', 'DataFrame', 'to_csv']",26,"[1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic set option read csv read csv drop train test split pipeline pipeline columntransformer preprocessing pipeline gridsearchcv fit score logisticregression svc decisiontreeclassifier randomforestclassifier gradientboostingclassifier votingclassifier preprocessing pipeline stratifiedshufflesplit cross val score mean fit predict accuracy score print drop predict dataframe csv print,"[0.0, 0.0, 0.11010590981143804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18592635498731622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11444002444566592, 0.0, 0.0, 0.12217406074909688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05102613152941983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0893477892305881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10423582570217922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08976064423345545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053470992034211164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12650374911880372, 0.0, 0.0, 0.0, 0.0, 0.10811164990968236, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06747781901893496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06848807061556221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06814831775734877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06814831775734877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07320677931213991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14972948910555817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.672486353258718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09312850444351922, 0.0, 0.0, 0.0, 0.44127490874148095, 0.0, 0.08688771693197259, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06585172432935608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08112209738634979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06781158496449058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20546421184668662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07320677931213991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07095569002146676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18592635498731622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08705119580259542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07398788306274275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07282218524979009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11444002444566592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1469221168414402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
amyhurd_titanic-data-science-solutions-d22403.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,949,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
manishshah120_titanic-kaggle-competition.py,"['os\n', 'pandas', 'numpy', 'seaborn', 'sklearn', 'matplotlib', 'warnings\n', 'statistics']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,495,"['# # Pclass Column', ""# train_dataset = train_dataset.astype({'Pclass': 'object'})"", ""# train_dataset['Pclass']= label_encoder.fit_transform(train_dataset['Pclass'])"", ""# checktestDataset = test_dataset[test_dataset['Age'] >= 60]"", '# checktestDataset.head(20)', ""# checktestDataset = test_dataset[test_dataset['Fare'].isnull()==True]"", '# checktestDataset', '# # Pclass Column', ""# train_dataset = train_dataset.astype({'Pclass': 'object'})"", ""# train_dataset['Pclass']= label_encoder.fit_transform(train_dataset['Pclass'])"", ""# test_df = pd.read_csv('/content/test.csv')"", '# submission = pd.DataFrame({', ""#                             'PassengerId': test_df['PassengerId'],"", ""#                             'Survived': y_pred_SVC"", '#                           })', ""# submission.to_csv('prediction_without_Ensemble2.csv', index = False)"", ""# print('Done Saving')"", '# from statistics import mode', '# final_pred_Max_Voting = np.array([])', '# for i in range(0, len(test_dataset)):', '#     final_pred_Max_Voting = np.append(final_pred_Max_Voting, mode([y_pred_Logistic[i], y_pred_KNN[i], y_pred_RF[i], y_pred_SVC[i], y_pred_SVC[i]]))', ""# test_df = pd.read_csv('/content/test.csv')"", '# submission = pd.DataFrame({', ""#                             'PassengerId': test_df['PassengerId'],"", ""#                             'Survived': final_pred_Max_Voting"", '#                           })', ""# submission.to_csv('prediction_with_Ensemble_Max_Voting3.csv', index = False)"", ""# print('Done Saving')""]",28,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
echarl2_titanic-with-hyperopt.py,"['sklearn', 'scipy', 'numpy', 'pandas', 'xgboost', 'matplotlib', 'gc\n', 'os\n', 'seaborn', 'collections', 'warnings\n', 'hyperopt']","[1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",12,332,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# One hot encoded', '# of columns: 12', ""#                            gamma = space['gamma'],"", ""#                            min_child_weight = space['min_child_weight'],"", ""#                            subsample = space['subsample'],"", ""#                            colsample_bytree = space['colsample_bytree'],"", '#                            ', ""#                            base_score=space['base_score'], "", ""# #                           max_delta_step=space['max_delta_step'], "", ""#                            scale_pos_weight=space['scale_pos_weight'],"", '#                            ', '#                            random_state=0,                             ', '#                            seed=None, ', '#                            silent=True, ', '#                            missing=None,', '#                            nthread=-1', '#                            #n_jobs=1,', '    # Applying Cross Validation', ""#    'base_score' : hp.quniform('base_score', .25, .75, .5),"", ""#    'scale_pos_weight' :  hp.quniform('scale_pos_weight', .25, .75, .5),"", ""#    'gamma' : hp.quniform('gamma', 0, 0.95, 0.01),"", ""#    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),"", ""#    'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),"", ""#    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)"", '# Fitting XGBoost to the Training set', ""#                            gamma = best['gamma'],"", ""#                            min_child_weight = best['min_child_weight'],"", ""#                            subsample = best['subsample'],"", ""#                            colsample_bytree = best['colsample_bytree'],"", '#                            ', ""#                            base_score=best['base_score'], "", ""# #                           max_delta_step=best['max_delta_step'], "", ""#                            scale_pos_weight=best['scale_pos_weight'],"", '#                            ', '#                            random_state=0,                             ', '#                            seed=None, ', '#                            silent=True, ', ""#                            booster='gbtree'"", ""#                            objective='binary:logistic',"", '# Applying k-Fold Cross Validation']",48,"['print', 'pd.read_csv', 'pd.read_csv', 'data.columns.str.strip', 'None.str.upper', 'None.str.replace', 'None.str.replace', 'None.str.replace', 'clean', 'itemcolumns.fillna', 'train.head', 'sns.set_style', 'plt.figure', 'plt.subplots', 'plt.subplot', 'sns.distplot', 'sns.distplot', 'plt.xlabel', 'plt.xticks', 'plt.tick_params', 'plt.tick_params', 'plt.show', 'trainnumeric_cols.drop', 'plot_feature_distribution', 'train.drop', 'proposed_Xcname.nunique', 'pd.get_dummies', 'print', 'list', 'test.drop', 'pd.get_dummies', 'gc.collect', 'LogisticRegression', 'propensity.fit', 'propensity.predict_proba', 'propensity.predict_proba', 'print', 'print', 'Counter', 'Counter', 'round', 'None.astype', 'pd.cut', 'None.astype', 'train_test_split', 'warnings.filterwarnings', 'xgb.XGBClassifier', 'classifier.fit', 'cross_val_score', 'accuracies.mean', 'print', 'hp.choice', 'hp.choice', 'hp.choice', 'hp.quniform', 'hp.choice', 'Trials', 'fmin', 'print', 'XGBClassifier', 'classifier.fit', 'cross_val_score', 'accuracies.mean', 'print', 'accuracies.std', 'train_test_split', 'print', 'xgb.plot_importance', 'xgb.to_graphviz', 'classifier.predict_proba', 'roc_curve', 'plt.figure', 'plt.plot', 'plt.plot', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.legend', 'plt.show', 'plt.close', 'average_precision_score', 'print', 'precision_recall_curve', 'signature', 'signature', 'plt.step', 'plt.fill_between', 'plt.xlabel', 'plt.ylabel', 'plt.ylim', 'plt.xlim', 'plt.title', 'plt.show', 'plt.close', 'classifier.predict', 'pd.read_csv', 'print']","['print', 'read_csv', 'read_csv', 'columns', 'str', 'str', 'str', 'str', 'clean', 'fillna', 'head', 'set_style', 'figure', 'subplots', 'subplot', 'distplot', 'distplot', 'xlabel', 'xticks', 'tick_params', 'tick_params', 'show', 'drop', 'plot_feature_distribution', 'drop', 'nunique', 'get_dummies', 'print', 'list', 'drop', 'get_dummies', 'collect', 'LogisticRegression', 'fit', 'predict_proba', 'predict_proba', 'print', 'print', 'Counter', 'Counter', 'round', 'astype', 'cut', 'astype', 'train_test_split', 'filterwarnings', 'XGBClassifier', 'fit', 'cross_val_score', 'mean', 'print', 'choice', 'choice', 'choice', 'quniform', 'choice', 'Trials', 'fmin', 'print', 'XGBClassifier', 'fit', 'cross_val_score', 'mean', 'print', 'std', 'train_test_split', 'print', 'plot_importance', 'to_graphviz', 'predict_proba', 'roc_curve', 'figure', 'plot', 'plot', 'xlabel', 'ylabel', 'title', 'legend', 'show', 'close', 'average_precision_score', 'print', 'precision_recall_curve', 'signature', 'signature', 'step', 'fill_between', 'xlabel', 'ylabel', 'ylim', 'xlim', 'title', 'show', 'close', 'predict', 'read_csv', 'print']","['print', 'read_csv', 'columns', 'str', 'clean', 'fillna', 'head', 'set_style', 'figure', 'subplots', 'subplot', 'distplot', 'xlabel', 'xticks', 'tick_params', 'show', 'drop', 'plot_feature_distribution', 'nunique', 'get_dummies', 'list', 'collect', 'LogisticRegression', 'fit', 'predict_proba', 'Counter', 'round', 'astype', 'cut', 'train_test_split', 'filterwarnings', 'XGBClassifier', 'cross_val_score', 'mean', 'choice', 'quniform', 'Trials', 'fmin', 'std', 'plot_importance', 'to_graphviz', 'roc_curve', 'plot', 'ylabel', 'title', 'legend', 'close', 'average_precision_score', 'precision_recall_curve', 'signature', 'step', 'fill_between', 'ylim', 'xlim', 'predict']",55,"[1 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv columns str str str str clean fillna head set style figure subplots subplot distplot distplot xlabel xticks tick params tick params show drop plot feature distribution drop nunique get dummies print list drop get dummies collect logisticregression fit predict proba predict proba print print counter counter round astype cut astype train test split filterwarnings xgbclassifier fit cross val score mean print choice choice choice quniform choice trials fmin print xgbclassifier fit cross val score mean print std train test split print plot importance graphviz predict proba roc curve figure plot plot xlabel ylabel title legend show close average precision score print precision recall curve signature signature step fill xlabel ylabel ylim xlim title show close predict read csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06856235552129024, 0.0, 0.0, 0.11154011217847667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4461604487139067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0982657893583805, 0.0, 0.0, 0.196531578716761, 0.0, 0.0, 0.11154011217847667, 0.0, 0.0, 0.0, 0.0, 0.07889282291873355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1577856458374671, 0.0, 0.0, 0.0, 0.0, 0.11570703805282805, 0.0, 0.0, 0.06176335056130641, 0.0, 0.0, 0.16547165442786757, 0.05108102944849662, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11237436314748289, 0.10377513110625332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07904239825234569, 0.0, 0.0, 0.0, 0.07441012269376501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09050080828615716, 0.0, 0.0, 0.09094018341591047, 0.0, 0.0, 0.08273582721393379, 0.026800760612142514, 0.0, 0.055151751048658125, 0.0, 0.0, 0.0, 0.06806581653758197, 0.0, 0.0, 0.0, 0.11154011217847667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05406299185965658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09399241190198712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024532383808304286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08754869949259429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03951012211725109, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05278444493734726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03445140821220963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07401728233303916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07427437667249813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17509739898518858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15804048846900437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16998293307656867, 0.0, 0.09415956925599328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21962421840761523, 0.0, 0.21515143115456453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11154011217847667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06151517566520679, 0.0, 0.08273582721393379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07722648546606098, 0.0, 0.0, 0.05067783982586865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1038694962439745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03700864116651958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13461474152122976, 0.0, 0.0, 0.0, 0.0, 0.22308022435695335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07174127028674764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05905083386036812, 0.10377513110625332, 0.0, 0.22912724363428874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05108102944849662, 0.0, 0.0, 0.06744376626179478, 0.0, 0.0477257310323058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07480703401154495, 0.0, 0.0, 0.196531578716761, 0.0, 0.0, 0.0, 0.0, 0.07727896259450376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07362843026818897, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11154011217847667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11570703805282805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11456362181714437, 0.0, 0.0, 0.0, 0.15835333481204178, 0.08071808908189096, 0.0, 0.06100005385240196, 0.0, 0.10216205889699324, 0.0, 0.08754869949259429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
wildwatermelon_titanic-tutorial.py,"['pandas', 'numpy', 're', 'sklearn']","[1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,218,"['# Tutorial from https://towardsdatascience.com/your-first-kaggle-competition-submission-64da366e48cb', '# print train data', '# test_data.head(10)', '# In this column, there are plenty of NAs. To deal with it, we are going to replace NAs with â€˜Sâ€™ because it is the most occurred value.', '# When you cut with qcut, the bins will be chosen so that you have the same number of records in each bin (equal parts).', '# Age has some missing values. ', '# We will fill it with random numbers between (average age minus average standard deviation) and (average age plus average standard deviation).', '# After that, we will group it in the set of 5', '# print(X_train.head(10))', '# print(test_data.head(10))']",10,"['pd.read_csv', 'pd.read_csv', 'print', 'train_data.head', 'print', 'train_data.dtypes.reset_index', 'print', 'data.fillna', 'print', 'print', 'print', 'data.fillna', 'print', 'data.fillna', 'pd.qcut', 'print', 'data.mean', 'data.std', 'data.isnull', 'None.sum', 'np.random.randint', 'np.isnan', 'data.astype', 'pd.cut', 'print', 're.search', 'title_search.group', 'data.apply', 'data.replace', 'data.replace', 'data.replace', 'data.replace', 'print', 'print', 'print', 'data.map', 'None.astype', 'data.map', 'data.fillna', 'data.map', 'None.astype', 'data.astype', 'train_data.drop', 'train_data.drop', 'test_data.drop', 'print', 'train_data.drop', 'test_data.drop', 'None.copy', 'tree.DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'print', 'round', 'print', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'read_csv', 'print', 'head', 'print', 'dtypes', 'print', 'fillna', 'print', 'print', 'print', 'fillna', 'print', 'fillna', 'qcut', 'print', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'cut', 'print', 'search', 'group', 'apply', 'replace', 'replace', 'replace', 'replace', 'print', 'print', 'print', 'map', 'astype', 'map', 'fillna', 'map', 'astype', 'astype', 'drop', 'drop', 'drop', 'print', 'drop', 'drop', 'copy', 'DecisionTreeClassifier', 'fit', 'predict', 'print', 'round', 'print', 'DataFrame', 'to_csv']","['read_csv', 'print', 'head', 'dtypes', 'fillna', 'qcut', 'mean', 'std', 'isnull', 'sum', 'random', 'isnan', 'astype', 'cut', 'search', 'group', 'apply', 'replace', 'map', 'drop', 'copy', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'DataFrame', 'to_csv']",27,"[1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv print head print dtypes print fillna print print print fillna print fillna qcut print mean std isnull sum random isnan astype cut print search group apply replace replace replace replace print print print map astype map fillna map astype astype drop drop drop print drop drop copy decisiontreeclassifier fit predict print round print dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07876228565787284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27643449947775506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08597701681516257, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12451089791673016, 0.0, 0.0, 0.0, 0.10297603328417487, 0.0, 0.0, 0.0, 0.05200211415574318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09105675456610794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2655738905151774, 0.0, 0.0, 0.15904280016426178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21611436156507732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04573875314680624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14457709757036724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04945569027991556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11662893182051937, 0.07382705250502858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21805764816714776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07460701371353758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04745489197464727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6641222113844584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10552245716000248, 0.0, 0.0, 0.0, 0.0, 0.11435729036247755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08267372897759317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3278492408156645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10216322922662481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14457709757036724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11904264065771514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07344290240299886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
multiw_exploring-the-titanic-dataset-in-progress.py,"['the', 'pandas']","[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",2,86,"['import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Import csv data as DataFrame objects.', '# Display the first 5 samples (passengers) of our dataset.', '# of siblings / spouses aboard the Titanic', '# of parents / children aboard the Titanic', '# Display the last 5 samples of our dataset.']",6,"['pd.read_csv', 'pd.read_csv', 'train_df.head', 'train_df.tail', 'train_df.info']","['read_csv', 'read_csv', 'head', 'tail', 'info']","['read_csv', 'head', 'tail', 'info']",4,"[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head tail info,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43763256240081194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26074127836956446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3607848449037126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43587408565503005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6483361807140647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sumeetpisal_titanic-prediction.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,76,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session""]",9,"['os.walk', 'print', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'pd.get_dummies', 'pd.get_dummies', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'get_dummies', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'sum', 'len', 'get_dummies', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv']",12,"[1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head sum len print sum len print get dummies get dummies randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29651471721459643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12383969942746267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3572295914637062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10892390691892337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2595466825772223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23555110859145806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4615584966167075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1130107814636607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4217505198327656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1598212034362369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19688218283721298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3497991228367539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20992981393866597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
orhunyildiz_titanic-notebook.py,"['numpy', 'pandas', 'matplotlib', 'seaborn', 'collections', 'warnings\n', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,984,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load"", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the read-only ""../input/"" directory', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" ', ""# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"", ' #   Column       Non-Null Count  Dtype  ', '    # get feature', '    # count number of categorical variable(value/sample)', '    # visualize', '# Pclass vs Survived', '# Sex vs Survived', '# SibSp vs Survived', '# Parch vs Survived', '# Parch vs Survived', '        # 1st quartile', '        # 3rd quartile', '        # IQR', '        # Outlier step', '        # Detect outliers and their indices', '        # Store indices', '# drop outliers', '# convert to categorical']",26,"['plt.style.use', 'warnings.filterwarnings', 'os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'train_df.head', 'train_df.describe', 'train_df.info', 'var.value_counts', 'plt.figure', 'plt.bar', 'plt.xticks', 'plt.ylabel', 'plt.title', 'plt.show', 'print', 'bar_plot', 'print', 'plt.figure', 'plt.hist', 'plt.xlabel', 'plt.ylabel', 'plt.title', 'plt.show', 'plot_hist', 'train_df.groupby', 'None.mean', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'np.percentile', 'np.percentile', 'outlier_indices.extend', 'Counter', 'list', 'detect_outliers', 'train_df.drop', 'None.reset_index', 'len', 'pd.concat', 'None.reset_index', 'train_df.head', 'train_df.isnull', 'None.any', 'train_df.isnull', 'None.sum', 'train_df.isnull', 'train_df.boxplot', 'plt.show', 'train_df.fillna', 'train_df.isnull', 'train_df.isnull', 'train_df.fillna', 'train_df.isnull', 'sns.heatmap', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'sns.FacetGrid', 'g.map', 'plt.show', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'plt.show', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'plt.show', 'sns.FacetGrid', 'g.map', 'g.add_legend', 'plt.show', 'train_df.isnull', 'sns.factorplot', 'plt.show', 'sns.factorplot', 'plt.show', 'sns.factorplot', 'sns.factorplot', 'plt.show', 'sns.heatmap', 'plt.show', 'list', 'train_dftrain_dftrain_df.ilocitrain_dftrain_df.ilocitrain_dftrain_df.iloci.median', 'train_df.median', 'np.isnan', 'train_df.isnull', 'train_df.head', 's.split', 'None.split', 'None.strip', 'i.split', 'None.split', 'None.strip', 'train_df.head', 'sns.countplot', 'plt.xticks', 'plt.show', 'train_df.replace', 'train_df.head', 'sns.countplot', 'plt.xticks', 'plt.show', 'sns.factorplot', 'g.set_xticklabels', 'g.set_ylabels', 'plt.show', 'train_df.drop', 'train_df.head', 'pd.get_dummies', 'train_df.head', 'train_df.head', 'train_df.head', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'train_df.head', 'sns.countplot', 'plt.show', 'sns.factorplot', 'g.set_ylabels', 'plt.show', 'pd.get_dummies', 'train_df.head', 'train_df.head', 'sns.countplot', 'plt.show', 'pd.get_dummies', 'train_df.head', 'train_df.head', 'a.replace', 'None.replace', 'None.strip', 'None.split', 'list', 'i.isdigit', 'tickets.append', 'tickets.append', 'train_df.head', 'train_df.head', 'pd.get_dummies', 'train_df.head', 'sns.countplot', 'plt.show', 'train_df.astype', 'pd.get_dummies', 'train_df.head', 'train_df.astype', 'pd.get_dummies', 'train_df.head', 'train_df.drop', 'test.drop', 'test.head', 'train.drop', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'LogisticRegression', 'logreg.fit', 'round', 'round', 'print', 'print', 'DecisionTreeClassifier', 'SVC', 'RandomForestClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'range', 'range', 'np.logspace', 'np.linspace', 'None.tolist', 'range', 'GridSearchCV', 'clf.fit', 'cv_results.append', 'best_estimators.append', 'print', 'pd.DataFrame', 'sns.barplot', 'g.set_xlabel', 'g.set_title', 'VotingClassifier', 'votingC.fit', 'print', 'pd.Series', 'None.astype', 'pd.concat', 'results.to_csv']","['style', 'filterwarnings', 'walk', 'print', 'read_csv', 'read_csv', 'head', 'describe', 'info', 'value_counts', 'figure', 'bar', 'xticks', 'ylabel', 'title', 'show', 'print', 'bar_plot', 'print', 'figure', 'hist', 'xlabel', 'ylabel', 'title', 'show', 'plot_hist', 'groupby', 'mean', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'percentile', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'drop', 'reset_index', 'len', 'concat', 'reset_index', 'head', 'isnull', 'any', 'isnull', 'sum', 'isnull', 'boxplot', 'show', 'fillna', 'isnull', 'isnull', 'fillna', 'isnull', 'heatmap', 'show', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'factorplot', 'set_ylabels', 'show', 'FacetGrid', 'map', 'show', 'FacetGrid', 'map', 'add_legend', 'show', 'FacetGrid', 'map', 'add_legend', 'show', 'FacetGrid', 'map', 'add_legend', 'show', 'isnull', 'factorplot', 'show', 'factorplot', 'show', 'factorplot', 'factorplot', 'show', 'heatmap', 'show', 'list', 'ilocitrain_dftrain_df', 'median', 'isnan', 'isnull', 'head', 'split', 'split', 'strip', 'split', 'split', 'strip', 'head', 'countplot', 'xticks', 'show', 'replace', 'head', 'countplot', 'xticks', 'show', 'factorplot', 'set_xticklabels', 'set_ylabels', 'show', 'drop', 'head', 'get_dummies', 'head', 'head', 'head', 'factorplot', 'set_ylabels', 'show', 'head', 'countplot', 'show', 'factorplot', 'set_ylabels', 'show', 'get_dummies', 'head', 'head', 'countplot', 'show', 'get_dummies', 'head', 'head', 'replace', 'replace', 'strip', 'split', 'list', 'isdigit', 'append', 'append', 'head', 'head', 'get_dummies', 'head', 'countplot', 'show', 'astype', 'get_dummies', 'head', 'astype', 'get_dummies', 'head', 'drop', 'drop', 'head', 'drop', 'train_test_split', 'print', 'print', 'print', 'print', 'print', 'LogisticRegression', 'fit', 'round', 'round', 'print', 'print', 'DecisionTreeClassifier', 'SVC', 'RandomForestClassifier', 'LogisticRegression', 'KNeighborsClassifier', 'range', 'range', 'logspace', 'linspace', 'tolist', 'range', 'GridSearchCV', 'fit', 'append', 'append', 'print', 'DataFrame', 'barplot', 'set_xlabel', 'set_title', 'VotingClassifier', 'fit', 'print', 'Series', 'astype', 'concat', 'to_csv']","['style', 'filterwarnings', 'walk', 'print', 'read_csv', 'head', 'describe', 'info', 'value_counts', 'figure', 'bar', 'xticks', 'ylabel', 'title', 'show', 'bar_plot', 'hist', 'xlabel', 'plot_hist', 'groupby', 'mean', 'sort_values', 'percentile', 'extend', 'Counter', 'list', 'detect_outliers', 'drop', 'reset_index', 'len', 'concat', 'isnull', 'any', 'sum', 'boxplot', 'fillna', 'heatmap', 'factorplot', 'set_ylabels', 'FacetGrid', 'map', 'add_legend', 'ilocitrain_dftrain_df', 'median', 'isnan', 'split', 'strip', 'countplot', 'replace', 'set_xticklabels', 'get_dummies', 'isdigit', 'append', 'astype', 'train_test_split', 'LogisticRegression', 'fit', 'round', 'DecisionTreeClassifier', 'SVC', 'RandomForestClassifier', 'KNeighborsClassifier', 'range', 'logspace', 'linspace', 'tolist', 'GridSearchCV', 'DataFrame', 'barplot', 'set_xlabel', 'set_title', 'VotingClassifier', 'Series', 'to_csv']",74,"[1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1
 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",style filterwarnings walk print read csv read csv head describe info value counts figure bar xticks ylabel title show print bar plot print figure hist xlabel ylabel title show plot hist groupby mean groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values percentile percentile extend counter list detect outliers drop reset index len concat reset index head isnull isnull sum isnull boxplot show fillna isnull isnull fillna isnull heatmap show factorplot set ylabels show factorplot set ylabels show factorplot set ylabels show facetgrid map show facetgrid map add legend show facetgrid map add legend show facetgrid map add legend show isnull factorplot show factorplot show factorplot factorplot show heatmap show list ilocitrain dftrain df median isnan isnull head split split strip split split strip head countplot xticks show replace head countplot xticks show factorplot set xticklabels set ylabels show drop head get dummies head head head factorplot set ylabels show head countplot show factorplot set ylabels show get dummies head head countplot show get dummies head head replace replace strip split list isdigit append append head head get dummies head countplot show astype get dummies head astype get dummies head drop drop head drop train test split print print print print print logisticregression fit round round print print decisiontreeclassifier svc randomforestclassifier logisticregression kneighborsclassifier range range logspace linspace tolist range gridsearchcv fit append append print dataframe barplot set xlabel set title votingclassifier fit print series astype concat csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.07387554989742179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10045176674344865, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05717931221927102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07845609871057992, 0.0, 0.029347282819615517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03249324674548029, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0446900725462723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04386311136513915, 0.12725493444031544, 0.025979071782438322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034339406599068645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014341891126666641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025112941685862162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020468097838384453, 0.0, 0.0, 0.0, 0.050316960220575455, 0.04725385686471654, 0.0, 0.05769726528019358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07324378798228742, 0.0, 0.0, 0.0, 0.1241124114080317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04725385686471654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10613888451724382, 0.3283129194768121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05056124556282127, 0.0, 0.0, 0.0, 0.029801563790201185, 0.0, 0.03066346606359405, 0.0, 0.0, 0.0, 0.03784347397509775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09017440160997074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030386891305584997, 0.0, 0.0, 0.11904955126812784, 0.0, 0.0, 0.0, 0.0, 0.2727920343639952, 0.05506108518382523, 0.0, 0.05424194346333597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05769726528019358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0613269321271881, 0.0, 0.0, 0.0188729671850206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052258234376804255, 0.0, 0.0, 0.0, 0.0, 0.03216560460176181, 0.16288869272641052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02562412126388941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06590093327999216, 0.02672657369837247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04599975851681623, 0.08804184845884655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03830883213938565, 0.0, 0.0, 0.054634161924334665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08018543348664536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12345717307884972, 0.02862919979216915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048675636308165335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10063392044115091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04393395551999478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146528941834186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018508913619884368, 0.0, 0.0, 0.07740035248257193, 0.0, 0.0, 0.0, 0.022800950293695634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0678142349701846, 0.0, 0.0, 0.06860450350687775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056352090083442136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027956500572759745, 0.18518575961827458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5738007892505004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1178355597587839, 0.0, 0.0, 0.0, 0.11966089734064778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14176157059414962, 0.0, 0.028400211837436014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02025514014941034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024467439236053705, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020795739982102938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06444874737129426, 0.0, 0.0, 0.0, 0.0, 0.04487792931718612, 0.0, 0.0, 0.0, 0.0, 0.020468097838384453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025979071782438322, 0.1178355597587839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04129533124854721, 0.0, 0.0, 0.02431199808840993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05869456563923103, 0.0, 0.03391502618892908, 0.10174507856678724, 0.0, 0.05680042367487203, 0.3135494062608255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
okanerayger_titanic-survive-prediction.py,"['numpy', 'pandas', 'statsmodels', 'seaborn', 'matplotlib', 'warnings', 'sklearn', 'lightgbm', 'xgboost']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,1136,"['Passenger ID(Unique identifing # for each passenger)', '# There is no Royal Category at test_df,', '# new field family size']",3,"['filterwarnings', 'pd.read_csv', 'pd.read_csv', 'train.head', 'test.head', 'train.copy', 'test.copy', 'train_df.describe', 'train_df.describe', 'test_df.describe', 'train_df.info', 'test_df.info', 'train_df.value_counts', 'train_df.groupby', 'None.mean', 'sns.barplot', 'train_df.value_counts', 'train_df.groupby', 'None.mean', 'sns.barplot', 'plt.figure', 'sns.kdeplot', 'sns.kdeplot', 'plt.title', 'plt.ylabel', 'plt.xlabel', 'plt.xticks', 'train_df.value_counts', 'train_df.groupby', 'None.mean', 'sns.barplot', 'train_df.value_counts', 'None.plot.barh', 'None.set_title', 'train_df.value_counts', 'train_df.value_counts', 'train_df.groupby', 'None.mean', 'sns.barplot', 'train_df.value_counts', 'train_df.groupby', 'None.mean', 'sns.barplot', 'train_df.isnull', 'None.sum', 'test_df.isnull', 'None.sum', 'train_df.isnull', 'None.sum', 'len', 'test_df.isnull', 'None.sum', 'len', 'train_df.drop', 'test_df.drop', 'train_df.isnull', 'None.sum', 'test_df.isnull', 'None.sum', 'train.str.extract', 'test.str.extract', 'train_df.head', 'test_df.head', 'train_df.replace', 'train_df.replace', 'train_df.replace', 'train_df.replace', 'train_df.replace', 'test_df.replace', 'test_df.replace', 'test_df.replace', 'test_df.replace', 'test_df.replace', 'train_df.value_counts', 'test_df.value_counts', 'train_df.groupby', 'None.median', 'train_df.groupby', 'None.std', 'train_df.groupby', 'None.mean', 'train_df.fillna', 'train_df.isnull', 'None.sum', 'test_df.fillna', 'test_df.isnull', 'None.sum', 'train_df.value_counts', 'train_df.Embarked.isnull', 'train_df.groupby', 'None.count', 'train_df.fillna', 'train_df.isnull', 'None.sum', 'test.Fare.isnull', 'test_df.groupby', 'None.mean', 'test_df.fillna', 'test_df.isnull', 'None.sum', 'train_df.describe', 'train_df.describe', 'sns.boxplot', 'train_df.quantile', 'train_df.quantile', 'print', 'print', 'print', 'train_dftrain_dfupper_limit.count', 'train_dftrain_dfupper_limit.sort_values', 'None.head', 'train_df.replace', 'test_df.replace', 'train_df.map', 'test_df.map', 'train_df.head', 'train_df.map', 'None.astype', 'test_df.map', 'None.astype', 'train_df.head', 'test_df.head', 'train_df.unique', 'test_df.unique', 'train_df.map', 'test_df.map', 'train_df.head', 'test_df.head', 'train_df.drop', 'train_df.head', 'test_df.drop', 'test_df.head', 'train_df.head', 'train_df.map', 'test_df.map', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'train_df.head', 'test_df.head', 'train_df.astype', 'pd.get_dummies', 'train_df.head', 'test_df.astype', 'pd.get_dummies', 'test_df.head', 'train_df.head', 'train_df.drop', 'train_test_split', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'print', 'print', 'SVC', 'None.fit', 'svm_model.predict', 'round', 'print', 'print', 'np.arange', 'SVC', 'GridSearchCV', 'svc_cv.fit', 'print', 'SVC', 'None.fit', 'svc_tuned.predict', 'round', 'print', 'print', 'DecisionTreeClassifier', 'cart.fit', 'cart_model.predict', 'round', 'print', 'print', 'range', 'list', 'tree.DecisionTreeClassifier', 'GridSearchCV', 'cart_cv.fit', 'print', 'tree.DecisionTreeClassifier', 'cart.fit', 'cart_tuned.predict', 'round', 'print', 'print', 'GradientBoostingClassifier', 'gb.fit', 'gb.predict', 'round', 'print', 'print', 'GradientBoostingClassifier', 'GridSearchCV', 'gbm_cv.fit', 'print', 'GradientBoostingClassifier', 'gbm.fit', 'gbm_tuned.predict', 'round', 'print', 'print', 'RandomForestClassifier', 'rfc.fit', 'rfc.predict', 'round', 'print', 'print', 'RandomForestClassifier', 'GridSearchCV', 'rf_cv_model.fit', 'print', 'RandomForestClassifier', 'rf_tuned.fit', 'rf_tuned.predict', 'round', 'print', 'print', 'LGBMClassifier', 'None.fit', 'lgbm.predict', 'round', 'print', 'print', 'LGBMClassifier', 'GridSearchCV', 'lgbm_cv_model.fit', 'print', 'LGBMClassifier', 'lgbm.fit', 'lgbm_tuned.predict', 'round', 'print', 'print', 'XGBClassifier', 'None.fit', 'xgb_model.predict', 'round', 'print', 'print', 'XGBClassifier', 'GridSearchCV', 'xgb_cv_model.fit', 'print', 'XGBClassifier', 'xgb.fit', 'xgb_tuned.predict', 'round', 'print', 'print', 'lgbm_tuned.predict', 'pd.DataFrame', 'output.to_csv', 'output.head']","['filterwarnings', 'read_csv', 'read_csv', 'head', 'head', 'copy', 'copy', 'describe', 'describe', 'describe', 'info', 'info', 'value_counts', 'groupby', 'mean', 'barplot', 'value_counts', 'groupby', 'mean', 'barplot', 'figure', 'kdeplot', 'kdeplot', 'title', 'ylabel', 'xlabel', 'xticks', 'value_counts', 'groupby', 'mean', 'barplot', 'value_counts', 'plot', 'set_title', 'value_counts', 'value_counts', 'groupby', 'mean', 'barplot', 'value_counts', 'groupby', 'mean', 'barplot', 'isnull', 'sum', 'isnull', 'sum', 'isnull', 'sum', 'len', 'isnull', 'sum', 'len', 'drop', 'drop', 'isnull', 'sum', 'isnull', 'sum', 'str', 'str', 'head', 'head', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'value_counts', 'value_counts', 'groupby', 'median', 'groupby', 'std', 'groupby', 'mean', 'fillna', 'isnull', 'sum', 'fillna', 'isnull', 'sum', 'value_counts', 'Embarked', 'groupby', 'count', 'fillna', 'isnull', 'sum', 'Fare', 'groupby', 'mean', 'fillna', 'isnull', 'sum', 'describe', 'describe', 'boxplot', 'quantile', 'quantile', 'print', 'print', 'print', 'count', 'sort_values', 'head', 'replace', 'replace', 'map', 'map', 'head', 'map', 'astype', 'map', 'astype', 'head', 'head', 'unique', 'unique', 'map', 'map', 'head', 'head', 'drop', 'head', 'drop', 'head', 'head', 'map', 'map', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'head', 'head', 'astype', 'get_dummies', 'head', 'astype', 'get_dummies', 'head', 'head', 'drop', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'round', 'print', 'print', 'SVC', 'fit', 'predict', 'round', 'print', 'print', 'arange', 'SVC', 'GridSearchCV', 'fit', 'print', 'SVC', 'fit', 'predict', 'round', 'print', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'print', 'print', 'range', 'list', 'DecisionTreeClassifier', 'GridSearchCV', 'fit', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'print', 'print', 'GradientBoostingClassifier', 'fit', 'predict', 'round', 'print', 'print', 'GradientBoostingClassifier', 'GridSearchCV', 'fit', 'print', 'GradientBoostingClassifier', 'fit', 'predict', 'round', 'print', 'print', 'RandomForestClassifier', 'fit', 'predict', 'round', 'print', 'print', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print', 'RandomForestClassifier', 'fit', 'predict', 'round', 'print', 'print', 'LGBMClassifier', 'fit', 'predict', 'round', 'print', 'print', 'LGBMClassifier', 'GridSearchCV', 'fit', 'print', 'LGBMClassifier', 'fit', 'predict', 'round', 'print', 'print', 'XGBClassifier', 'fit', 'predict', 'round', 'print', 'print', 'XGBClassifier', 'GridSearchCV', 'fit', 'print', 'XGBClassifier', 'fit', 'predict', 'round', 'print', 'print', 'predict', 'DataFrame', 'to_csv', 'head']","['filterwarnings', 'read_csv', 'head', 'copy', 'describe', 'info', 'value_counts', 'groupby', 'mean', 'barplot', 'figure', 'kdeplot', 'title', 'ylabel', 'xlabel', 'xticks', 'plot', 'set_title', 'isnull', 'sum', 'len', 'drop', 'str', 'replace', 'median', 'std', 'fillna', 'Embarked', 'count', 'Fare', 'boxplot', 'quantile', 'print', 'sort_values', 'map', 'astype', 'unique', 'get_dummies', 'train_test_split', 'LogisticRegression', 'fit', 'predict', 'round', 'SVC', 'arange', 'GridSearchCV', 'DecisionTreeClassifier', 'range', 'list', 'GradientBoostingClassifier', 'RandomForestClassifier', 'LGBMClassifier', 'XGBClassifier', 'DataFrame', 'to_csv']",55,"[1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0
 0 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",filterwarnings read csv read csv head head copy copy describe describe describe info info value counts groupby mean barplot value counts groupby mean barplot figure kdeplot kdeplot title ylabel xlabel xticks value counts groupby mean barplot value counts plot set title value counts value counts groupby mean barplot value counts groupby mean barplot isnull sum isnull sum isnull sum len isnull sum len drop drop isnull sum isnull sum str str head head replace replace replace replace replace replace replace replace replace replace value counts value counts groupby median groupby std groupby mean fillna isnull sum fillna isnull sum value counts embarked groupby count fillna isnull sum fare groupby mean fillna isnull sum describe describe boxplot quantile quantile print print print count sort values head replace replace map map head map astype map astype head head unique unique map map head head drop head drop head head map map get dummies get dummies get dummies get dummies head head astype get dummies head astype get dummies head head drop train test split logisticregression fit predict round print print svc fit predict round print print arange svc gridsearchcv fit print svc fit predict round print print decisiontreeclassifier fit predict round print print range list decisiontreeclassifier gridsearchcv fit print decisiontreeclassifier fit predict round print print gradientboostingclassifier fit predict round print print gradientboostingclassifier gridsearchcv fit print gradientboostingclassifier fit predict round print print randomforestclassifier fit predict round print print randomforestclassifier gridsearchcv fit print randomforestclassifier fit predict round print print lgbmclassifier fit predict round print print lgbmclassifier gridsearchcv fit print lgbmclassifier fit predict round print print xgbclassifier fit predict round print print xgbclassifier gridsearchcv fit print xgbclassifier fit predict round print print predict dataframe csv head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03856842956505996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0737436613518352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14193350718878123, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03142969316023983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045871698532828, 0.0, 0.0, 0.0, 0.06351334725351225, 0.0, 0.0, 0.0, 0.2512873709129901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033215425382616355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013872459129108063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0728728702662591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09899072870021419, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07084640695368986, 0.0, 0.0, 0.0, 0.12005002265507607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025128737091299008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03142969316023983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024453149392651145, 0.0, 0.0, 0.0, 0.05765222619691723, 0.0, 0.029659803994263573, 0.0, 0.0, 0.0, 0.23183039545579265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08722285574321191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10317760939712166, 0.0, 0.0, 0.0, 0.0, 0.17635369170258874, 0.0, 0.0, 0.19192146276476957, 0.0, 0.0, 0.0, 0.0, 0.25066997778299965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036510452297659736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19694637134006102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08898823235198948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051703544256083034, 0.0, 0.13712149790964023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028386701437756245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018527462781716367, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15512168360070921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13931893648983212, 0.027692122364356794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021247965032936116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.177231730693118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41338740860932144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10109548512798683, 0.0, 0.0, 0.0, 0.05370926583844069, 0.0, 0.0, 0.02495564025018029, 0.0, 0.0, 0.0, 0.02205464037207715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2623782860117881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35429940079153216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01990270521283316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02279572438909222, 0.0, 0.0, 0.0, 0.019290702240143936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031756673626756125, 0.0, 0.0, 0.061610637982674056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1959215848142883, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07099974775955069, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020115063656066964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0415594943016551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019798145740042843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06713635009956839, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2512873709129901, 0.02279572438909222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09241595697401109, 0.0, 0.0, 0.0, 0.028386701437756245, 0.0, 0.0, 0.032804935591356624, 0.0, 0.02747062953506129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
omkarsabnis_svm-knn-rf-and-dt-implementation-titanic.py,"['warnings', 'pandas', 'numpy', 'seaborn', 'matplotlib', 'warnings\n', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,398,[],0,"['get_ipython', 'None.run_line_magic', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'trainingset.head', 'print', 'print', 'trainingset.describe', 'sns.barplot', 'sns.barplot', 'sns.barplot', 'print', 'sns.barplot', 'print', 'trainingset.fillna', 'testingset.fillna', 'pd.cut', 'pd.cut', 'sns.barplot', 'print', 'trainingset.notnull', 'None.astype', 'testingset.notnull', 'None.astype', 'testingset.describe', 'trainingset.drop', 'trainingset.drop', 'testingset.drop', 'testingset.drop', 'testingset.head', 'print', 'print', 'print', 'print', 'print', 'print', 'trainingset.fillna', 'i.Name.str.extract', 'pd.crosstab', 'i.replace', 'i.replace', 'i.replace', 'i.replace', 'i.replace', 'trainingset.groupby', 'None.mean', 'i.map', 'i.fillna', 'trainingset.head', 'trainingsettrainingset.mode', 'trainingsettrainingset.mode', 'trainingsettrainingset.mode', 'trainingsettrainingset.mode', 'trainingsettrainingset.mode', 'trainingsettrainingset.mode', 'range', 'range', 'testingset.head', 'trainingset.map', 'testingset.map', 'trainingset.drop', 'testingset.drop', 'testingset.head', 'trainingset.drop', 'testingset.drop', 'testingset.head', 'trainingset.map', 'testingset.map', 'testingset.head', 'trainingset.map', 'testingset.map', 'testingset.head', 'range', 'pd.isnull', 'round', 'pd.qcut', 'pd.qcut', 'trainingset.drop', 'testingset.drop', 'testingset.head', 'trainingset.drop', 'train_test_split', 'SVC', 'svm.fit', 'svm.predict', 'round', 'print', 'DecisionTreeClassifier', 'dt.fit', 'dt.predict', 'round', 'print', 'RandomForestClassifier', 'rmfr.fit', 'rmfr.predict', 'round', 'print', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'print', 'rmfr.predict', 'pd.DataFrame', 'output.to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'read_csv', 'read_csv', 'head', 'print', 'print', 'describe', 'barplot', 'barplot', 'barplot', 'print', 'barplot', 'print', 'fillna', 'fillna', 'cut', 'cut', 'barplot', 'print', 'notnull', 'astype', 'notnull', 'astype', 'describe', 'drop', 'drop', 'drop', 'drop', 'head', 'print', 'print', 'print', 'print', 'print', 'print', 'fillna', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'mode', 'mode', 'mode', 'mode', 'mode', 'mode', 'range', 'range', 'head', 'map', 'map', 'drop', 'drop', 'head', 'drop', 'drop', 'head', 'map', 'map', 'head', 'map', 'map', 'head', 'range', 'isnull', 'round', 'qcut', 'qcut', 'drop', 'drop', 'head', 'drop', 'train_test_split', 'SVC', 'fit', 'predict', 'round', 'print', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'print', 'RandomForestClassifier', 'fit', 'predict', 'round', 'print', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'print', 'predict', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'filterwarnings', 'read_csv', 'head', 'print', 'describe', 'barplot', 'fillna', 'cut', 'notnull', 'astype', 'drop', 'Name', 'crosstab', 'replace', 'groupby', 'mean', 'map', 'mode', 'range', 'isnull', 'round', 'qcut', 'train_test_split', 'SVC', 'fit', 'predict', 'DecisionTreeClassifier', 'RandomForestClassifier', 'KNeighborsClassifier', 'DataFrame', 'to_csv']",33,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic filterwarnings read csv read csv head print print describe barplot barplot barplot print barplot print fillna fillna cut cut barplot print notnull astype notnull astype describe drop drop drop drop head print print print print print print fillna name crosstab replace replace replace replace replace groupby mean map fillna head mode mode mode mode mode mode range range head map map drop drop head drop drop head map map head map map head range isnull round qcut qcut drop drop head drop train test split svc fit predict round print decisiontreeclassifier fit predict round print randomforestclassifier fit predict round print kneighborsclassifier fit predict round print predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07873034687568914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3030626375043086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061129984728056, 0.0709230302390424, 0.0, 0.0, 0.0, 0.11731298134874087, 0.0, 0.0, 0.0, 0.029621081981341515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051867114169236034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08454773484447987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.332803568541207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12310155702693566, 0.0, 0.06333091180792609, 0.0, 0.0, 0.0, 0.10421355967399727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0310403432750105, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04097991084079508, 0.0, 0.0, 0.0, 0.0, 0.25353545178068154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03917141960741393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04205285131567557, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052922880947424644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03975787882876845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0395606495471261, 0.0, 0.0, 0.289819782940048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04249712738549686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4156490648956912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05865649067437043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19001156906219163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13515462480879625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3782926672968018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12021393380460577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03822745849051702, 0.0, 0.0, 0.15985912638871502, 0.0, 0.0, 0.0, 0.04709203353567961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23343400065035752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2909675344484262, 0.0, 0.03936517343784457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04119035184857605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05053392311262695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04295056442920455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04227386742223994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
thelazydatascientist_titanic.py,"['numpy', 'pandas', 'data', 'matplotlib', 'seaborn', 'sklearn', 'catboost', 'os\n', 'xgboost', 'lightgbm']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",10,479,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# import data visualization library', '# import sklearn model class', '# import sklearn model selection', '# import sklearn model evaluation classification metrics', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",12,"['print', 'pd.read_csv', 'pd.read_csv', 'train.append', 'pd.set_option', 'pd.set_option', 'dataset.describe', 'dataset.isna', 'None.sum', 'dataset.Embarked.value_counts', 'dataset.Embarked.fillna', 'dataset.Fare.fillna', 'print', 'print', 'print', 'print', 'print', 'print', 'dataset.head', 'sns.distplot', 'plt.title', 'sns.distplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'sns.countplot', 'plt.title', 'dataset.head', 'dataset.groupby', 'None.size', 'dataset.apply', 'dataset.Name.str.split', 'None.str.str.split', 'None.str.str.strip', 'dataset.Name.str.split', 'dataset.Name.str.split', 'dataset.duplicated', 'train.groupby', 'None.size', 'dataset.apply', 'LabelEncoder', 'lb.fit_transform', 'dataset.apply', 'dataset.Fare.value_counts', 'dataset.apply', 'dataset.apply', 'dataset.Name.str.extract', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.map', 'len', 'len', 'len', 'len', 'len', 'dataset.apply', 'dataset.drop', 'dataset.info', 'dataset.corr', 'dataset.Cabin.str.get', 'dataset.fillna', 'dataset.Deck.replace', 'dataset.drop', 'train.groupby', 'None.median', 'range', 'pd.to_numeric', 'dataset.Age.isna', 'dataset.info', 'pd.to_numeric', 'len', 'None.Ticket.median', 'dataset.Ticket.fillna', 'pd.get_dummies', 'len', 'len', 'new_train.drop', 'train_test_split', 'GradientBoostingClassifier', 'XGBClassifier', 'alg.fit', 'alg.predict', 'print', 'print', 'LGBMClassifier', 'lgb.fit', 'lgb.predict', 'pd.read_csv', 'subbmissions.Survived.astype', 'subbmissions.to_csv', 'subbmissions.Survived.value_counts']","['print', 'read_csv', 'read_csv', 'append', 'set_option', 'set_option', 'describe', 'isna', 'sum', 'Embarked', 'Embarked', 'Fare', 'print', 'print', 'print', 'print', 'print', 'print', 'head', 'distplot', 'title', 'distplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'countplot', 'title', 'head', 'groupby', 'size', 'apply', 'Name', 'str', 'str', 'Name', 'Name', 'duplicated', 'groupby', 'size', 'apply', 'LabelEncoder', 'fit_transform', 'apply', 'Fare', 'apply', 'apply', 'Name', 'replace', 'replace', 'replace', 'replace', 'replace', 'replace', 'map', 'len', 'len', 'len', 'len', 'len', 'apply', 'drop', 'info', 'corr', 'Cabin', 'fillna', 'Deck', 'drop', 'groupby', 'median', 'range', 'to_numeric', 'Age', 'info', 'to_numeric', 'len', 'Ticket', 'Ticket', 'get_dummies', 'len', 'len', 'drop', 'train_test_split', 'GradientBoostingClassifier', 'XGBClassifier', 'fit', 'predict', 'print', 'print', 'LGBMClassifier', 'fit', 'predict', 'read_csv', 'Survived', 'to_csv', 'Survived']","['print', 'read_csv', 'append', 'set_option', 'describe', 'isna', 'sum', 'Embarked', 'Fare', 'head', 'distplot', 'title', 'countplot', 'groupby', 'size', 'apply', 'Name', 'str', 'duplicated', 'LabelEncoder', 'fit_transform', 'replace', 'map', 'len', 'drop', 'info', 'corr', 'Cabin', 'fillna', 'Deck', 'median', 'range', 'to_numeric', 'Age', 'Ticket', 'get_dummies', 'train_test_split', 'GradientBoostingClassifier', 'XGBClassifier', 'fit', 'predict', 'LGBMClassifier', 'Survived', 'to_csv']",44,"[1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0
 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0
 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv append set option set option describe isna sum embarked embarked fare print print print print print print head distplot title distplot title countplot title countplot title countplot title countplot title countplot title countplot title head groupby size apply name str str name name duplicated groupby size apply labelencoder fit transform apply fare apply apply name replace replace replace replace replace replace map len len len len len apply drop info corr cabin fillna deck drop groupby median range numeric age info numeric len ticket ticket get dummies len len drop train test split gradientboostingclassifier xgbclassifier fit predict print print lgbmclassifier fit predict read csv survived csv survived,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05215212297950348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05076307204698133, 0.26345429949621935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07015053814863348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.059322330724559016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3086783612752617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09255115247187269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10171024600834111, 0.0, 0.0, 0.0, 0.0, 0.04137402691535385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1262930612135693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0888325963445019, 0.0, 0.0, 0.0, 0.041813283372913894, 0.0, 0.0, 0.0, 0.11662872756882715, 0.0, 0.0, 0.10502771910214315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13136310721493472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030120305074541796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07649645429581212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03037961928807267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07187328288736904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12032284038605841, 0.0, 0.0, 0.0, 0.0, 0.055141933858182654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07629928862478652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0792952223835325, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060347420619657664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43219882503314455, 0.0, 0.09551851672843942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04052152659093453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05787080422025881, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2296317202002536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19103703345687884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17013803941823902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052911090709735625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22214420330586673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05215212297950348, 0.0, 0.0, 0.0, 0.06913445049431143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27415815627369555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08318506914499868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14949450986074211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0403135750276614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1287534816460929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0409435561786485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15380266626061623, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04203631976639695, 0.0, 0.0, 0.0, 0.17358352889571013, 0.0, 0.0, 0.0, 0.3474029655913528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04137402691535385, 0.0, 0.0, 0.0, 0.04706437000933603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06437674082304645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kmisiunas_titanic-classification-using-decision-treed.py,"['numpy', 'pandas', 'subprocess', 'random\n', 'sklearn', 'IPython']","[1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,251,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# Baseline models', '# load data', '    # to do', '# simple decision tree', '# results on test set: 0.70813', '# results on test set: ', '# Random forrests ']",15,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
hyzyzs_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,394,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04458423492702482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07865667322233022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172539892595686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21253464566011832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04293086506933447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431745498221466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06217197055832407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1038647689272524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5834791208246738, 0.04516844628469951, 0.0, 0.0, 0.22470723731702552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048041479577273886, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053956143394937324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045677422002361044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19047233475457281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14369390600990528, 0.0, 0.0, 0.0, 0.0, 0.02469468754518843, 0.0, 0.0, 0.09820578880126213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06833953619962328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03433813161044625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11647254395745248, 0.07372805772905346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3815299057393845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039771517035677564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034852228728417936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.03629420907111263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2235209192601581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07954303407135513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047391259657758644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022107722972670885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11420394854594243, 0.03351064408530649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041281435841698653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0345079785191372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06970445745683587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050615630922711694, 0.18626743271679844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051418976303892444, 0.0, 0.0, 0.0, 0.0, 0.2402073978863694, 0.07334442273431843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07779023229049523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06140362395662589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
bittelc_bittelc-titanic.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,937,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
plasticgrammer_titanic-training.py,"['numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn', 'lightgbm', 'shap\n']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,347,[],0,"['pd.read_csv', 'pd.read_csv', 'train.head', 'train.append', 'None.isnull', 'None.sum', 'train.value_counts', 'plt.subplots', 'train.value_counts', 'None.plot.pie', 'ax.set_title', 'ax.set_ylabel', 'sns.countplot', 'ax.set_title', 'plt.show', 'train.groupby', 'None.agg', 'print', 'train.unique', 'train.str.unique', 'train.median', 'train.mode', 'train.fillna', 'test.fillna', 'train.append', 'dataset.str.extract', 'pd.crosstab', 'None.join', 'data.Name.str.extract', 'data.replace', 'put_title', 'put_title', 'train.append', 'None.groupby', 'None.mean', 'train.Age.isnull', 'test.Age.isnull', 'pd.crosstab', 'LabelEncoder', 'data.copy', 'data.Embarked.replace', 'data.Sex.replace', 'le.fit_transform', 'le.fit_transform', 'pd.qcut', 'le.fit_transform', 'pd.cut', 'le.fit_transform', 'data.drop', 'data.drop', 'transDataFrame', 'None.drop', 'train_1.describe', 'train_1.corr', 'plt.figure', 'plt.title', 'sns.heatmap', 'plt.show', 'pd.DataFrame', 'pd.DataFrame', 'print', 'print', 'print', 'sns.pairplot', 'a.set', 'sns.FacetGrid', 'a.map', 'a.set', 'a.add_legend', 'transDataFrame', '_train.drop', '_train.head', '_train.isnull', 'None.any', 'transDataFrame', '_test.head', '_test.isnull', 'None.any', '_train.head', '_train.drop', '_test.drop', 'None.copy', 'lgb.LGBMClassifier', 'clf.fit', 'clf.predict', 'shap.TreeExplainer', 'explainer.shap_values', 'shap.summary_plot', 'shap.summary_plot', 'pd.DataFrame', 'submission.to_csv', 'submission.head']","['read_csv', 'read_csv', 'head', 'append', 'isnull', 'sum', 'value_counts', 'subplots', 'value_counts', 'plot', 'set_title', 'set_ylabel', 'countplot', 'set_title', 'show', 'groupby', 'agg', 'print', 'unique', 'str', 'median', 'mode', 'fillna', 'fillna', 'append', 'str', 'crosstab', 'join', 'Name', 'replace', 'put_title', 'put_title', 'append', 'groupby', 'mean', 'Age', 'Age', 'crosstab', 'LabelEncoder', 'copy', 'Embarked', 'Sex', 'fit_transform', 'fit_transform', 'qcut', 'fit_transform', 'cut', 'fit_transform', 'drop', 'drop', 'transDataFrame', 'drop', 'describe', 'corr', 'figure', 'title', 'heatmap', 'show', 'DataFrame', 'DataFrame', 'print', 'print', 'print', 'pairplot', 'set', 'FacetGrid', 'map', 'set', 'add_legend', 'transDataFrame', 'drop', 'head', 'isnull', 'any', 'transDataFrame', 'head', 'isnull', 'any', 'head', 'drop', 'drop', 'copy', 'LGBMClassifier', 'fit', 'predict', 'TreeExplainer', 'shap_values', 'summary_plot', 'summary_plot', 'DataFrame', 'to_csv', 'head']","['read_csv', 'head', 'append', 'isnull', 'sum', 'value_counts', 'subplots', 'plot', 'set_title', 'set_ylabel', 'countplot', 'show', 'groupby', 'agg', 'print', 'unique', 'str', 'median', 'mode', 'fillna', 'crosstab', 'join', 'Name', 'replace', 'put_title', 'mean', 'Age', 'LabelEncoder', 'copy', 'Embarked', 'Sex', 'fit_transform', 'qcut', 'cut', 'drop', 'transDataFrame', 'describe', 'corr', 'figure', 'title', 'heatmap', 'DataFrame', 'pairplot', 'set', 'FacetGrid', 'map', 'add_legend', 'any', 'LGBMClassifier', 'fit', 'predict', 'TreeExplainer', 'shap_values', 'summary_plot', 'to_csv']",55,"[1 1 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv head append isnull sum value counts subplots value counts plot set title set ylabel countplot set title show groupby agg print unique str median mode fillna fillna append str crosstab join name replace put title put title append groupby mean age age crosstab labelencoder copy embarked sex fit transform fit transform qcut fit transform cut fit transform drop drop transdataframe drop describe corr figure title heatmap show dataframe dataframe print print print pairplot set facetgrid map set add legend transdataframe drop head isnull transdataframe head isnull head drop drop copy lgbmclassifier fit predict treeexplainer shap values summary plot summary plot dataframe csv head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.05735542198252184, 0.0, 0.12018400903676453, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10452683914758226, 0.0, 0.0, 0.0, 0.17547443405207327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11045688621355466, 0.06835383800851565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05927883155645111, 0.1210176270929912, 0.0, 0.0, 0.0, 0.0, 0.13787476767092974, 0.07998117748783268, 0.0, 0.0, 0.0, 0.06614798007964481, 0.0, 0.0, 0.0, 0.10021268157943723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047673001026597585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20471376718494838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0605088135464956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06180299691873896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058882030236882155, 0.0, 0.0, 0.0, 0.06941192055962014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1469043832594243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09242756580890965, 0.0, 0.0, 0.0, 0.0, 0.15884249524513774, 0.06412240138825871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1422712715578648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0818032382165722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0695349923525531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051164097493207016, 0.0, 0.0, 0.11006069956328365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04669071209145565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04792477530481151, 0.06668132436435892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07812248837466579, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06614798007964481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10000534596470095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15349229247962104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030483260511288954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11376198624878782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28888036118780186, 0.06778370822376302, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053106533657479756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05264954465364417, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23962387652405756, 0.0, 0.0886091494252741, 0.0, 0.0, 0.0, 0.0, 0.14444018059390093, 0.0, 0.11621396223100737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14835550997368285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06180299691873896, 0.04717699342465786, 0.2545008801571846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2501832545989977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43332054178170276, 0.2169186735786273, 0.0, 0.0, 0.0, 0.14444018059390093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08083058204651374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1210176270929912, 0.054891029012138055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06614798007964481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mattleedev_titanic-lunch-and-learn.py,"['numpy', 'pandas', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,652,"['import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# inline plotting', ""# machine learning (we'll talk more about these later!)"", '# get titanic & test csv files as a DataFrame', '# preview the data', ""# Let's look at the columns (nomenclature: features, classes)"", ""# Let's get some aggregate data quickly"", '# checking if there is any missing values in the data sets', '# Same thing for the test data', '# Visual tools can help us get a better sense of the data', ""# First let's look at where people boarded from"", ""# Next let's look at where survivors boarded from"", ""# Finally let's look at your chances of surviving depending on where you boarded"", '# What to do about those pesky', '# null values we found in our aggregate exploration?', '# How do we look now?', ""# Let's take a look at the total numbers"", ""# Let's look at those that survived"", ""# Finally let's look at your chances of surviving depending on where your age"", ""# Let's fill in the null values here aswell.  This can be tricky.  "", '# There is no right way to do this.  ', ""# Get average,std, and count of NaN's in train_df"", ""# Get average,std, and count of NaN's in test_df"", '# generate random numbers between (mean - std) & (mean + std)', '# We can now fill in our NaN values using these randomly generated values', '# Convert from float to int to make things ', '# How do we look now?', ""# Let's now look at what our data looks like after this"", ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", ""# First let's look at where people boarded from"", ""# Next let's look at where survivors boarded from"", ""# Finally let's look at your chances of surviving depending on where you boarded"", ""# First let's look at where people boarded from"", ""# We'll first create percentil bins and group all our fares into one of these 20 "", '# percentile bins.', ""# Next let's look at where survivors boarded from"", ""# Finally let's look at your chances of surviving depending on where you boarded"", '# There was one sneaky NaN ""Fare"" in the test data.  Let\'s fill this using the median value', '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# Plots', '# Total number of individuals with family on board', '# Number of survivors based on whether or not they had family on board', '# Average number of survivors based on having family on board', '# As we saw previously, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child in order to seperate the men ', ""# from the boys.  Unfortunately, men don't traditionally fair so well in maritime disasters"", '# Here we can create our own custom function', '# Can you figure out what this function does?', '# Let\'s create a new feature called ""Person""', '# No need to use Sex column since we created Person column', '# Create dummy variables for our ""Person"" feature. The goal is to create 2 new', '# features ""Child"" and ""Female"" that we will ultimately use to train our model.', '# These features will only output a 1 if that person falls into this category, and', '# a 0 otherwise.  We don\'t need the ""Male"" feature since 2 zeros in both ""Child"" and', '# ""Female"" will be enough information to indicate maleness.  ', '# We can now add these features using the .join() method', ""# Let's plot these now"", '# Total number of individuals with family on board', '# Number of survivors based on whether or not they had family on board', '# Average number of survivors based on having family on board', ""# Let's see what our data looks like now."", '# We can now drop the features that we don\'t find very useful like ""Name"", ""Ticket"", and', '# ""Person"" (since this information is captured in ""Child"" and ""Female"")', ""# Let's see where we are at"", '# It might be nice to ""one-hot-encode"" our ""Pclass"" feature.  ', '# Question: Why might we want to do this?', ""# We'll make sure of SK-Learns binarizer"", '# Since we don\'t need ""Pclass"" anymore, let\'s drop it', '# Check to see what our data looks like here', '# Up to you to decide what to do with ""Embarked"" feature. ', '# Either keep it and ""one-hot"" it, or drop it.  We drop it out of laziness.', '# One last thing that we might want to do is scale our data.  ', '# Why might this be desirable?  What can go wrong otherwise?', '# What can go wrong doing this?', '# Ok time to exchange our old un-scaled values out for our newly scaled data', ""# Finally, as a last sanity check, let's take a look at our data a final time."", '# As a first step we split the data into our training features (variables we wish to ', '# use to train our model), and training labels (survived or not).', ""# We do the same thing with the test data, but of course are missing our labels (that's"", '# what we wish to predict!)', '# Question: why use .copy()?', '# How can we quickly assess the quality of our models without having to submit our ', ""# results every time to Kaggle and wait for their response?  Let's further split"", '# our X_train and Y_train into a 70%-30% split.  This way we can train on 70%', '# chunk and then test it on the 30% chunk.  This 30% chunk is known as the ""validation set"".', '# Your code here:', '# Finally we can submit our results', '# submission = pd.DataFrame({', '#         ""PassengerId"": test_df[""PassengerId""],', '#         ""Survived"": Y_predict', '#     })', ""# submission.to_csv('titanic.csv', index=False)""]",97,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'test_df.head', 'train_df.isnull', 'None.sum', 'test_df.isnull', 'None.sum', 'train_df.value_counts', 'train_df.groupby', 'None.count', 'embarked_count.plot', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.groupby', 'None.sum', 'embarked_survival.plot', 'ax2.set_xlabel', 'ax2.set_ylabel', 'plt.show', 'train_df.groupby', 'None.mean', 'embarked_perc.plot', 'ax3.set_xlabel', 'ax3.set_ylabel', 'plt.show', 'train_df.Embarked.fillna', 'test_df.Embarked.fillna', 'train_df.Embarked.isnull', 'None.sum', 'test_df.Embarked.isnull', 'None.sum', 'train_df.dropna', 'None.hist', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.dropna', 'None.groupby', 'None.sum', 'age_survived.plot', 'ax2.set_xlabel', 'ax2.set_ylabel', 'plt.show', 'train_df.dropna', 'None.groupby', 'None.mean', 'age_perct.plot', 'ax3.set_xlabel', 'ax3.set_ylabel', 'plt.show', 'train_df.mean', 'train_df.std', 'train_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'np.isnan', 'np.isnan', 'train_df.astype', 'test_df.astype', 'print', 'train_df.dropna', 'None.hist', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.drop', 'test_df.drop', 'train_df.groupby', 'None.count', 'class_count.plot', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.groupby', 'None.sum', 'class_survival.plot', 'ax2.set_xlabel', 'ax2.set_ylabel', 'plt.show', 'train_df.groupby', 'None.mean', 'class_perc.plot', 'ax3.set_xlabel', 'ax3.set_ylabel', 'plt.show', 'np.arange', 'train_df.groupby', 'None.count', 'fare_count.plot', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.groupby', 'None.sum', 'fare_survival.plot', 'ax2.set_xlabel', 'ax2.set_ylabel', 'plt.show', 'train_df.groupby', 'None.mean', 'fare_perc.plot', 'ax3.set_xlabel', 'ax3.set_ylabel', 'plt.show', 'np.isnan', 'test_df.Fare.median', 'train_df.drop', 'test_df.drop', 'train_df.groupby', 'None.count', 'family_count.plot', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.groupby', 'None.sum', 'family_survival.plot', 'ax2.set_xlabel', 'ax2.set_ylabel', 'plt.show', 'train_df.groupby', 'None.mean', 'family_perc.plot', 'ax3.set_xlabel', 'ax3.set_ylabel', 'plt.show', 'train_df.apply', 'test_df.apply', 'train_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'train_df.join', 'test_df.join', 'train_df.groupby', 'None.count', 'person_count.plot', 'ax1.set_xlabel', 'ax1.set_ylabel', 'plt.show', 'train_df.groupby', 'None.sum', 'person_survival.plot', 'ax2.set_xlabel', 'ax2.set_ylabel', 'plt.show', 'train_df.groupby', 'None.mean', 'person_perc.plot', 'ax3.set_xlabel', 'ax3.set_ylabel', 'plt.show', 'train_df.head', 'train_df.drop', 'test_df.drop', 'train_df.drop', 'test_df.drop', 'train_df.drop', 'test_df.drop', 'train_df.head', 'LabelBinarizer', 'lb.fit_transform', 'lb.fit_transform', 'lb.fit_transform', 'lb.fit_transform', 'lb.fit_transform', 'lb.fit_transform', 'train_df.drop', 'test_df.drop', 'train_df.drop', 'test_df.drop', 'train_df.copy', 'test_df.copy', 'MinMaxScaler', 'scaler.fit_transform', 'scaler.fit_transform', 'test_scaling.head', 'train_df.head', 'train_df.copy', 'train_df.copy', 'test_df.copy', 'train_test_split', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'print', 'print', 'print', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'print', 'print', 'print', 'SVC', 'svc.fit', 'svc.predict', 'print', 'print', 'print', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'print', 'print', 'print']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'isnull', 'sum', 'isnull', 'sum', 'value_counts', 'groupby', 'count', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'sum', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'mean', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'Embarked', 'Embarked', 'Embarked', 'sum', 'Embarked', 'sum', 'dropna', 'hist', 'set_xlabel', 'set_ylabel', 'show', 'dropna', 'groupby', 'sum', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'dropna', 'groupby', 'mean', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'isnan', 'isnan', 'astype', 'astype', 'print', 'dropna', 'hist', 'set_xlabel', 'set_ylabel', 'show', 'drop', 'drop', 'groupby', 'count', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'sum', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'mean', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'arange', 'groupby', 'count', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'sum', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'mean', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'isnan', 'Fare', 'drop', 'drop', 'groupby', 'count', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'sum', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'mean', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'groupby', 'count', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'sum', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'groupby', 'mean', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'head', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'head', 'LabelBinarizer', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'drop', 'drop', 'drop', 'drop', 'copy', 'copy', 'MinMaxScaler', 'fit_transform', 'fit_transform', 'head', 'head', 'copy', 'copy', 'copy', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'print', 'print', 'print', 'LogisticRegression', 'fit', 'predict', 'print', 'print', 'print', 'SVC', 'fit', 'predict', 'print', 'print', 'print', 'KNeighborsClassifier', 'fit', 'predict', 'print', 'print', 'print']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'isnull', 'sum', 'value_counts', 'groupby', 'count', 'plot', 'set_xlabel', 'set_ylabel', 'show', 'mean', 'Embarked', 'dropna', 'hist', 'std', 'random', 'isnan', 'astype', 'print', 'drop', 'arange', 'Fare', 'apply', 'get_dummies', 'join', 'LabelBinarizer', 'fit_transform', 'copy', 'MinMaxScaler', 'train_test_split', 'RandomForestClassifier', 'fit', 'predict', 'LogisticRegression', 'SVC', 'KNeighborsClassifier']",39,"[1 1 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv head isnull sum isnull sum value counts groupby count plot set xlabel set ylabel show groupby sum plot set xlabel set ylabel show groupby mean plot set xlabel set ylabel show embarked embarked embarked sum embarked sum dropna hist set xlabel set ylabel show dropna groupby sum plot set xlabel set ylabel show dropna groupby mean plot set xlabel set ylabel show mean std isnull sum mean std isnull sum random random isnan isnan astype astype print dropna hist set xlabel set ylabel show drop drop groupby count plot set xlabel set ylabel show groupby sum plot set xlabel set ylabel show groupby mean plot set xlabel set ylabel show arange groupby count plot set xlabel set ylabel show groupby sum plot set xlabel set ylabel show groupby mean plot set xlabel set ylabel show isnan fare drop drop groupby count plot set xlabel set ylabel show groupby sum plot set xlabel set ylabel show groupby mean plot set xlabel set ylabel show apply apply drop drop get dummies drop get dummies drop join join groupby count plot set xlabel set ylabel show groupby sum plot set xlabel set ylabel show groupby mean plot set xlabel set ylabel show head drop drop drop drop drop drop head labelbinarizer fit transform fit transform fit transform fit transform fit transform fit transform drop drop drop drop copy copy minmaxscaler fit transform fit transform head head copy copy copy train test split randomforestclassifier fit predict print print print logisticregression fit predict print print print svc fit predict print print print kneighborsclassifier fit predict print print print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030316611576490297, 0.02782478741752362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026600794012670053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08273413479304347, 0.0, 0.0, 0.0, 0.11455258908864967, 0.0, 0.0, 0.0, 0.018128862790660758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015975279275067738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1840010196433675, 0.06963702813396123, 0.0, 0.0, 0.028869608273882998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07251545116264303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02267462120298312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10563258810197516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03146300544737292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23538152152601644, 0.0, 0.0, 0.0, 0.0, 0.04759032003515563, 0.0, 0.0, 0.037851419742037526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013234932977063197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0673379523280168, 0.05683395437136819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04901764204384611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017881169212455358, 0.0, 0.0, 0.0, 0.04327528606114513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013433081233271372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013366442945718556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013366442945718556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11486877694028005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029367572660371596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26059505105555003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0365319902890828, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1107726260938139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044017584353998565, 0.01291599477568334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015911088080156493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013300397006335027, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5456266904663303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3307758836363159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013917074016750085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04582103563545986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1696146773754205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.017074006818407393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014511800880455387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.014283163786811203, 0.0, 0.0, 0.0, 0.12998069668040335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018128862790660758, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38910645043247255, 0.0, 0.0, 0.0, 0.0, 0.3765495322861305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
fernandot44_starter-titanic-0ff4440a-2.py,"['libraries', 'mpl_toolkits', 'sklearn', 'matplotlib', 'numpy', 'os', 'pandas']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,149,"['import matplotlib.pyplot as plt # plotting', 'import numpy as np # linear algebra', 'import os # accessing directory structure', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Distribution graphs (histogram/bar graph) of column data', '    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values', '# Correlation matrix', ""    df = df.dropna('columns') # drop columns with NaN"", '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '# Scatter and density plots', '    df = df.select_dtypes(include =[np.number]) # keep only numerical columns', '    # Remove rows and columns that would lead to df being singular', '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots', ""nRowsRead = 1000 # specify 'None' if want to read whole file"", '# train_and_test2.csv has 1309 rows in reality, but we are only loading/previewing the first 1000 rows']",16,"['print', 'df.nunique', 'list', 'plt.figure', 'range', 'plt.subplot', 'np.issubdtype', 'columnDf.value_counts', 'valueCounts.plot.bar', 'columnDf.hist', 'plt.ylabel', 'plt.xticks', 'plt.title', 'plt.tight_layout', 'plt.show', 'df.dropna', 'dfcol.nunique', 'print', 'df.corr', 'plt.figure', 'plt.matshow', 'plt.xticks', 'plt.yticks', 'plt.gca', 'None.xaxis.tick_bottom', 'plt.colorbar', 'plt.title', 'plt.show', 'df.select_dtypes', 'df.dropna', 'dfcol.nunique', 'list', 'len', 'pd.plotting.scatter_matrix', 'df.corr', 'df.corr', 'zip', 'axij.annotate', 'plt.suptitle', 'plt.show', 'pd.read_csv', 'print', 'df1.head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'nunique', 'print', 'corr', 'figure', 'matshow', 'xticks', 'yticks', 'gca', 'xaxis', 'colorbar', 'title', 'show', 'select_dtypes', 'dropna', 'nunique', 'list', 'len', 'plotting', 'corr', 'corr', 'zip', 'annotate', 'suptitle', 'show', 'read_csv', 'print', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'corr', 'matshow', 'yticks', 'gca', 'xaxis', 'colorbar', 'select_dtypes', 'len', 'plotting', 'zip', 'annotate', 'suptitle', 'read_csv', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']",33,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print nunique list figure range subplot issubdtype value counts plot hist ylabel xticks title tight layout show dropna nunique print corr figure matshow xticks yticks gca xaxis colorbar title show select dtypes dropna nunique list len plotting corr corr zip annotate suptitle show read csv print head plotpercolumndistribution plotcorrelationmatrix plotscattermatrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15490496684997576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2964824176618775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08748496476955596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03854617801186908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16802468591947814, 0.0, 0.14770977133433763, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17026585182918047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045931590080678576, 0.0, 0.0, 0.09133033221244688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16944321679667937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13906272824837684, 0.0, 0.0, 0.09000219014728794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19765494510791834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4171881847451306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07397417011357971, 0.0, 0.16944321679667937, 0.16944321679667937, 0.16944321679667937, 0.0, 0.0, 0.1511271879967127, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12335967410072833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08688233316925019, 0.0, 0.0, 0.0, 0.038391293381482366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14171992414678877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2520370288792172, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12627388555633323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15912816430300347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1445899143562999, 0.0, 0.1446881664450932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08748496476955596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16944321679667937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2284188516159948, 0.0, 0.0956381949614375, 0.0, 0.0, 0.0, 0.14770977133433763, 0.0, 0.0, 0.13906272824837684, 0.0]"
shep312_applying-lightgbm-to-titanic-dataset.py,"['pandas', 'numpy', 'matplotlib', 'lightgbm', 'sklearn']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,192,"['# Not sure passenger ID is useful as a feature, but need to save it from the test set for the submission', ""# 'Embarked' is stored as letters, so fit a label encoder to the train set to use in the loop"", '# Dataframes to work on', '    # Record anyone travelling alone', ""    # Transform 'Embarked'"", ""    # Transform 'Sex'"", '    # Drop features that seem unusable. Save passenger ids if test', '# Separate the label', '# Take a hold out set randomly', '# Create an LGBM dataset for training', '# Create an LGBM dataset from the test', '# Finally, create a dataset for the FULL training data to give us maximum amount of data to train on after ', '# performance has been calibrate', ""    'boosting': 'dart',          # dart (drop out trees) often performs better"", ""    'learning_rate': 0.05,       # Learning rate, controls size of a gradient descent step"", ""    'min_data_in_leaf': 20,      # Data set is quite small so reduce this a bit"", ""    'feature_fraction': 0.7,     # Proportion of features in each boost, controls overfitting"", ""    'num_leaves': 41,            # Controls size of tree since LGBM uses leaf wise splits"", ""    'metric': 'binary_logloss',  # Area under ROC curve as the evaulation metric"", '# Plot the log loss during training', '# Plot feature importance']",21,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train_df.info', 'test_df.pop', 'train_df.drop', 'LabelEncoder', 'embarked_encoder.fit', 'df.fillna', 'embarked_encoder.transform', 'df.astype', 'df.drop', 'train_df.pop', 'train_test_split', 'lgbm.Dataset', 'lgbm.Dataset', 'lgbm.Dataset', 'lgbm.train', 'plt.subplots', 'axs.plot', 'axs.plot', 'axs.set_ylabel', 'axs.set_xlabel', 'axs.set_title', 'axs.legend', 'pd.DataFrame', 'None.sort_values', 'axs.bar', 'axs.set_xticks', 'axs.set_xticklabels', 'axs.set_ylabel', 'axs.set_title', 'plt.show', 'np.round', 'print', 'print', 'print', 'print', 'lgbm.train', 'np.round', 'None.astype', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'info', 'pop', 'drop', 'LabelEncoder', 'fit', 'fillna', 'transform', 'astype', 'drop', 'pop', 'train_test_split', 'Dataset', 'Dataset', 'Dataset', 'train', 'subplots', 'plot', 'plot', 'set_ylabel', 'set_xlabel', 'set_title', 'legend', 'DataFrame', 'sort_values', 'bar', 'set_xticks', 'set_xticklabels', 'set_ylabel', 'set_title', 'show', 'round', 'print', 'print', 'print', 'print', 'train', 'round', 'astype', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'info', 'pop', 'drop', 'LabelEncoder', 'fit', 'fillna', 'transform', 'astype', 'train_test_split', 'Dataset', 'train', 'subplots', 'plot', 'set_ylabel', 'set_xlabel', 'set_title', 'legend', 'DataFrame', 'sort_values', 'bar', 'set_xticks', 'set_xticklabels', 'show', 'round', 'print']",28,"[1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv info pop drop labelencoder fit fillna transform astype drop pop train test split dataset dataset dataset train subplots plot plot set ylabel set xlabel set title legend dataframe sort values bar set xticks set xticklabels set ylabel set title show round print print print print train round astype dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1282887123179206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1320193198346452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07704461777123815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09653330934385271, 0.0, 0.0, 0.5080148750938195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09859878561849099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05014756336667802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04245320866473975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050579297903321566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06351568155891502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06382864016888778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10047295643422002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0739283627496139, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06478425768259359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06446287855018311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1478567254992278, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36773507811516415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16437771403343115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07673504033030198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18964910889899883, 0.0, 0.0641443561589603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4847344608646268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0839603196120534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07931350504223589, 0.0, 0.0, 0.0, 0.0671184290210159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08930079096632991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06998664203335261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14459857052949565, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20665195435480613, 0.0, 0.0, 0.0, 0.07835788752853005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07931350504223589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0987662751657607, 0.0, 0.1141387033824767, 0.1141387033824767, 0.0, 0.19115794496840222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
shotaku_titanic-prediction-using-neural-nework.py,"['numpy', 'pandas', 'os\n', 'sklearn', 'keras']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,137,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.']",8,"['print', 'pd.read_csv', 'pd.read_csv', 'dataset.head', 'dataset.fillna', 'dataset.fillna', 'dataset.isnull', 'None.sum', 'testset.fillna', 'testset.fillna', 'testset.fillna', 'testset.isnull', 'None.sum', 'LabelEncoder', 'LE.fit_transform', 'LE.fit_transform', 'LE.fit_transform', 'LE.fit_transform', 'train_test_split', 'Sequential', 'model.add', 'model.add', 'model.add', 'model.add', 'model.compile', 'model.fit', 'x_test.fillna', 'x_test.fillna', 'model.evaluate', 'model.predict', 'range', 'pdf.append', 'pdf.append', 'pd.DataFrame', 'output.to_csv']","['print', 'read_csv', 'read_csv', 'head', 'fillna', 'fillna', 'isnull', 'sum', 'fillna', 'fillna', 'fillna', 'isnull', 'sum', 'LabelEncoder', 'fit_transform', 'fit_transform', 'fit_transform', 'fit_transform', 'train_test_split', 'Sequential', 'add', 'add', 'add', 'add', 'compile', 'fit', 'fillna', 'fillna', 'evaluate', 'predict', 'range', 'append', 'append', 'DataFrame', 'to_csv']","['print', 'read_csv', 'head', 'fillna', 'isnull', 'sum', 'LabelEncoder', 'fit_transform', 'train_test_split', 'Sequential', 'add', 'compile', 'fit', 'evaluate', 'predict', 'range', 'append', 'DataFrame', 'to_csv']",19,"[1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",print read csv read csv head fillna fillna isnull sum fillna fillna fillna isnull sum labelencoder fit transform fit transform fit transform fit transform train test split sequential add add add add compile fit fillna fillna evaluate predict range append append dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.44273189804444957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22575061072640534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1763185733144876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1543455583319083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06446259305892729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1929876683979248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.46882250168835715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2834921886343799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061306008202177124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18303422157485943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1341867868836074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058825788906491885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05488371713203141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11596395902128645, 0.0, 0.0, 0.0, 0.10248358233639338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1929876683979248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08964010466738993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18208182523087532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.093470750264797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09199809495086782, 0.0, 0.0, 0.0, 0.41860391204172365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
musonda2day_titanic-prediction.py,"['numpy', 'pandas', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,297,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# Number of trees in random forest', '# Number of features to consider at every split', '# Maximum number of levels in tree', '# Minimum number of samples required to split a node', '# Minimum number of samples required at each leaf node', '# Method of selecting samples for training each tree', '# Create the random grid', '# Use the random grid to search for best hyperparameters', '# First create the base model to tune', '# Random search of parameters, using 3 fold cross validation, ', '# search across 100 different combinations, and use all available cores']",19,"['os.walk', 'print', 'pd.read_csv', 'train_data.head', 'pd.read_csv', 'test_data.head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'train_data.copy', 'train_set.fillna', 'test_data.copy', 'test_set.fillna', 'train_set.fillna', 'test_set.fillna', 'train_set.drop', 'train_set.fillna', 'test_set.drop', 'test_set.fillna', 'train_set.drop', 'train_set.drop', 'train_set.drop', 'test_set.drop', 'test_set.drop', 'test_set.drop', 'train_set.head', 'test_set.head', 'np.array', 'train_set.drop', 'X_features.head', 'test_features.head', 'X_features.fillna', 'test_features.fillna', 'LabelEncoder', 'None.fit_transform', 'LabelEncoder', 'None.fit_transform', 'LabelEncoder', 'None.fit_transform', 'LabelEncoder', 'None.fit_transform', 'LabelEncoder', 'None.fit_transform', 'LabelEncoder', 'None.fit_transform', 'X_features.head', 'test_features.head', 'X_features.astype', 'test_features.astype', 'StandardScaler', 'scaler.fit_transform', 'scaler.fit_transform', 'int', 'np.linspace', 'int', 'np.linspace', 'max_depth.append', 'print', 'RandomForestClassifier', 'RandomizedSearchCV', 'model.fit', 'pd.DataFrame', 'output.to_csv', 'print', 'output.head']","['walk', 'print', 'read_csv', 'head', 'read_csv', 'head', 'sum', 'len', 'print', 'sum', 'len', 'print', 'copy', 'fillna', 'copy', 'fillna', 'fillna', 'fillna', 'drop', 'fillna', 'drop', 'fillna', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'head', 'head', 'array', 'drop', 'head', 'head', 'fillna', 'fillna', 'LabelEncoder', 'fit_transform', 'LabelEncoder', 'fit_transform', 'LabelEncoder', 'fit_transform', 'LabelEncoder', 'fit_transform', 'LabelEncoder', 'fit_transform', 'LabelEncoder', 'fit_transform', 'head', 'head', 'astype', 'astype', 'StandardScaler', 'fit_transform', 'fit_transform', 'int', 'linspace', 'int', 'linspace', 'append', 'print', 'RandomForestClassifier', 'RandomizedSearchCV', 'fit', 'DataFrame', 'to_csv', 'print', 'head']","['walk', 'print', 'read_csv', 'head', 'sum', 'len', 'copy', 'fillna', 'drop', 'array', 'LabelEncoder', 'fit_transform', 'astype', 'StandardScaler', 'int', 'linspace', 'append', 'RandomForestClassifier', 'RandomizedSearchCV', 'fit', 'DataFrame', 'to_csv']",22,"[1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv head read csv head sum len print sum len print copy fillna copy fillna fillna fillna drop fillna drop fillna drop drop drop drop drop drop head head array drop head head fillna fillna labelencoder fit transform labelencoder fit transform labelencoder fit transform labelencoder fit transform labelencoder fit transform labelencoder fit transform head head astype astype standardscaler fit transform fit transform int linspace int linspace append print randomforestclassifier randomizedsearchcv fit dataframe csv print head,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.062746425668198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10959502440122461, 0.0, 0.0, 0.09524431688927407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11849204423048869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08579938784596892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03583420918097362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32940842695363143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29784509207229054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2836636292762532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30671541369165506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16947808794512145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.44755978582316724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13355639422160115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22986717085042885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15254696615607466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04624580374440911, 0.0, 0.11806703708338624, 0.0, 0.0, 0.0, 0.0, 0.056969754904224526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08775399391772641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1012177435588447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4653967343313267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060745212567374834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
tarunchoubisa_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,398,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04458423492702482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07865667322233022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172539892595686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21253464566011832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04293086506933447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431745498221466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06217197055832407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1038647689272524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5834791208246738, 0.04516844628469951, 0.0, 0.0, 0.22470723731702552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048041479577273886, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053956143394937324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045677422002361044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19047233475457281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14369390600990528, 0.0, 0.0, 0.0, 0.0, 0.02469468754518843, 0.0, 0.0, 0.09820578880126213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06833953619962328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03433813161044625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11647254395745248, 0.07372805772905346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3815299057393845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039771517035677564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034852228728417936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.03629420907111263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2235209192601581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07954303407135513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047391259657758644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022107722972670885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11420394854594243, 0.03351064408530649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041281435841698653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0345079785191372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06970445745683587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050615630922711694, 0.18626743271679844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051418976303892444, 0.0, 0.0, 0.0, 0.0, 0.2402073978863694, 0.07334442273431843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07779023229049523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06140362395662589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
junyeong00_titanic-surviver-with-cross-validation.py,"['numpy', 'pandas', 'os\n', 'seaborn', 'matplotlib', 'sklearn', 'graphviz\n', 'warnings\n', 'operator\n']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,410,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# 1. by using plot', '# 2. by using pivot', '# delete three outlier data', '# submission.to_csv(""./decision_tree.csv"")']",12,"['os.walk', 'print', 'pd.read_csv', 'print', 'pd.read_csv', 'print', 'test.head', 'get_ipython', 'None.run_line_magic', 'sns.countplot', 'pd.pivot_table', 'sns.countplot', 'pd.pivot_table', 'sns.countplot', 'pd.pivot_table', 'sns.lmplot', 'sns.lmplot', 'sns.lmplot', 'train.head', 'test.head', 'train.isnull', 'test.isnull', 'train.head', 'test.head', 'test.isnull', 'test.isnull', 'train.head', 'test.head', 'print', 'X_train.head', 'print', 'X_test.head', 'print', 'y_train.head', 'DecisionTreeClassifier', 'model.fit', 'export_graphviz', 'graphviz.Source', 'model.predict', 'print', 'pd.read_csv', 'print', 'submission.head', 'submission.head', 'warnings.filterwarnings', 'warnings.warn', 'all_estimators', 'KFold', 'algorithm', 'hasattr', 'cross_val_score', 'result.append', 'sorted', 'GradientBoostingClassifier', 'bestModel.fit', 'bestModel.predict', 'print', 'pd.read_csv', 'bestSubmission.to_csv']","['walk', 'print', 'read_csv', 'print', 'read_csv', 'print', 'head', 'get_ipython', 'run_line_magic', 'countplot', 'pivot_table', 'countplot', 'pivot_table', 'countplot', 'pivot_table', 'lmplot', 'lmplot', 'lmplot', 'head', 'head', 'isnull', 'isnull', 'head', 'head', 'isnull', 'isnull', 'head', 'head', 'print', 'head', 'print', 'head', 'print', 'head', 'DecisionTreeClassifier', 'fit', 'export_graphviz', 'Source', 'predict', 'print', 'read_csv', 'print', 'head', 'head', 'filterwarnings', 'warn', 'all_estimators', 'KFold', 'algorithm', 'hasattr', 'cross_val_score', 'append', 'sorted', 'GradientBoostingClassifier', 'fit', 'predict', 'print', 'read_csv', 'to_csv']","['walk', 'print', 'read_csv', 'head', 'get_ipython', 'run_line_magic', 'countplot', 'pivot_table', 'lmplot', 'isnull', 'DecisionTreeClassifier', 'fit', 'export_graphviz', 'Source', 'predict', 'filterwarnings', 'warn', 'all_estimators', 'KFold', 'algorithm', 'hasattr', 'cross_val_score', 'append', 'sorted', 'GradientBoostingClassifier', 'to_csv']",26,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0
 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv print read csv print head get ipython run line magic countplot pivot table countplot pivot table countplot pivot table lmplot lmplot lmplot head head isnull isnull head head isnull isnull head head print head print head print head decisiontreeclassifier fit export graphviz source predict print read csv print head head filterwarnings warn estimators kfold algorithm hasattr cross val score append sorted gradientboostingclassifier fit predict print read csv csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1442438830996159, 0.0, 0.0, 0.06278266755333502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1908833543300639, 0.0, 0.0, 0.0, 0.08041441284042485, 0.0, 0.0, 0.14308157492768253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06278266755333502, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15503694122551426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1365860864910784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07665904775255337, 0.0, 0.0, 0.0, 0.06307277141170646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037572854857852736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08889131889630834, 0.0, 0.0, 0.13064623797737804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15503694122551426, 0.4091900937510899, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04741513489221915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20361188210373687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09244578524472756, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04812501580457821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3919387139321341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047886279167318385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3650690943151853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06543929049130952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2747431371400238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1140053204515745, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04764966466157207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04812501580457821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12579302836518005, 0.1442438830996159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35440569526992766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08041441284042485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.060780298566187455, 0.15503694122551426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
suthirs_titanic-dataset-null-missing-values-treatment.py,"['numpy', 'pandas', 'os\n']","[1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,171,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', 'train.shape # Rows -891, Columns - 12', '# To check which are all the columns having numerical values', '# to check which are all the columns having categorical values (except numerical colums)', '# length of ""categorical"" & ""numerical"" should match with lenght of dataset columns', '# To check null values columns preset or not in the given dataset if yes what is the count of each columns', '# to check percentage of the null values present in the each columns inthe dataset', '# Based on client input you can drop the null values(if client says consider the null values if greate than 50%)', '# Below are the command to drop the null values based on client input', '# train.fillna(20,inplace=True) - beginer can use this code to treat Null value', '      2 # Below are the command to drop the null values based on client input', '      3 # train.fillna(20,inplace=True) - beginer can use this code to treat Null value', '# lengh of drop columns and length of retain columns should match', '      1 # lengh of drop columns and length of retain columns should match', '# Replace the null values in numerical columns with ""median""', '# Replace the null values in categorical cloumns with ""average counts""', '# Finally to check if any null values present or not ', '# Null values treatment done and you can see all the columns having zero null values ']",25,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'print', 'train.median', 'train.median', 'len', 'len', 'len', 'train.isna', 'None.sum', 'train.isna', 'None.sum', 'int', 'int', 'len', 'len', 'traini.fillna', 'traini.fillna', 'train.isna', 'None.sum']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'print', 'median', 'median', 'len', 'len', 'len', 'isna', 'sum', 'isna', 'sum', 'int', 'int', 'len', 'len', 'fillna', 'fillna', 'isna', 'sum']","['walk', 'print', 'read_csv', 'median', 'len', 'isna', 'sum', 'int', 'fillna']",9,"[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv print median median len len len isna sum isna sum int int len len fillna fillna isna sum,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15722319991931696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.136446656647298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3105603428170764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5388176492017945, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6118389710105738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26215796067811836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11181395466410023, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15659145227366913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2782148788666806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11131264382407231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
zzw922cn_a-journey-through-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,394,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc = SVC()', '# svc.fit(X_train, Y_train)', '# Y_pred = svc.predict(X_test)', '# svc.score(X_train, Y_train)', '# Random Forests', '# knn = KNeighborsClassifier(n_neighbors = 3)', '# knn.fit(X_train, Y_train)', '# Y_pred = knn.predict(X_test)', '# knn.score(X_train, Y_train)', '# Gaussian Naive Bayes', '# gaussian = GaussianNB()', '# gaussian.fit(X_train, Y_train)', '# Y_pred = gaussian.predict(X_test)', '# gaussian.score(X_train, Y_train)', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview']",79,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'logreg.score', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'DataFrame', 'pd.Series', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'fit', 'predict', 'score', 'DataFrame', 'Series', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'fit', 'predict', 'score', 'RandomForestClassifier', 'Series', 'to_csv']",42,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression fit predict score randomforestclassifier fit predict score dataframe series dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04458423492702482, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07865667322233022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.172539892595686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21253464566011832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04293086506933447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18431745498221466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06217197055832407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1038647689272524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5834791208246738, 0.04516844628469951, 0.0, 0.0, 0.22470723731702552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048041479577273886, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053956143394937324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045677422002361044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19047233475457281, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14369390600990528, 0.0, 0.0, 0.0, 0.0, 0.02469468754518843, 0.0, 0.0, 0.09820578880126213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06833953619962328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03433813161044625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11647254395745248, 0.07372805772905346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3815299057393845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039771517035677564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034852228728417936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03467933519792187, 0.0, 0.0, 0.03629420907111263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2235209192601581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07954303407135513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047391259657758644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022107722972670885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11420394854594243, 0.03351064408530649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041281435841698653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0345079785191372, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06970445745683587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050615630922711694, 0.18626743271679844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11888301624981135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051418976303892444, 0.0, 0.0, 0.0, 0.0, 0.2402073978863694, 0.07334442273431843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07779023229049523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06140362395662589, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
simulacra_titanic-with-xgboost.py,"['numpy', 'pandas', 'sklearn', 'matplotlib', 'xgboost']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,340,"[""X_full['Cabin_mapped'] = X_full['Cabin'].astype(str).str[0] # this captures the letter"", '# this transforms the letters into numbers', '# Create the parameter grid: gbm_param_grid ', '# Instantiate the regressor: gbm', '# Perform random search: grid_mse', '# Fit randomized_mse to the data', '# Print the best parameters and lowest RMSE']",7,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sadam25_titanic-beginners-model-built-using-log-reg.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,353,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",8,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'get_ipython', 'None.run_line_magic', 'train.head', 'test.head', 'train.info', 'test.info', 'sns.heatmap', 'sns.heatmap', 'train.isnull', 'train.drop', 'test.isnull', 'test.drop', 'sns.set_style', 'sns.countplot', 'sns.set_style', 'sns.countplot', 'sns.set_style', 'sns.countplot', 'sns.distplot', 'train.hist', 'sns.countplot', 'train.hist', 'plt.figure', 'sns.boxplot', 'plt.figure', 'sns.boxplot', 'pd.isnull', 'pd.isnull', 'train.apply', 'test.apply', 'sns.heatmap', 'sns.heatmap', 'train.drop', 'test.drop', 'print', 'print', 'pd.get_dummies', 'pd.get_dummies', 'train.drop', 'pd.concat', 'train.head', 'pd.get_dummies', 'pd.get_dummies', 'test.drop', 'pd.concat', 'test.head', 'train.drop', 'LogisticRegression', 'logmodel.fit', 'logmodel.predict', 'print', 'pd.DataFrame', 'my_submission.to_csv']","['walk', 'print', 'read_csv', 'read_csv', 'get_ipython', 'run_line_magic', 'head', 'head', 'info', 'info', 'heatmap', 'heatmap', 'isnull', 'drop', 'isnull', 'drop', 'set_style', 'countplot', 'set_style', 'countplot', 'set_style', 'countplot', 'distplot', 'hist', 'countplot', 'hist', 'figure', 'boxplot', 'figure', 'boxplot', 'isnull', 'isnull', 'apply', 'apply', 'heatmap', 'heatmap', 'drop', 'drop', 'print', 'print', 'get_dummies', 'get_dummies', 'drop', 'concat', 'head', 'get_dummies', 'get_dummies', 'drop', 'concat', 'head', 'drop', 'LogisticRegression', 'fit', 'predict', 'print', 'DataFrame', 'to_csv']","['walk', 'print', 'read_csv', 'get_ipython', 'run_line_magic', 'head', 'info', 'heatmap', 'isnull', 'drop', 'set_style', 'countplot', 'distplot', 'hist', 'figure', 'boxplot', 'apply', 'get_dummies', 'concat', 'LogisticRegression', 'fit', 'predict', 'DataFrame', 'to_csv']",24,"[1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv get ipython run line magic head head info info heatmap heatmap isnull drop isnull drop set style countplot set style countplot set style countplot distplot hist countplot hist figure boxplot figure boxplot isnull isnull apply apply heatmap heatmap drop drop print print get dummies get dummies drop concat head get dummies get dummies drop concat head drop logisticregression fit predict print dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.145442720896174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21756116079999793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14961299705692746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3408182810566772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11496113668474305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04801364582040113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1045821219562532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3432867931525596, 0.0, 0.0, 0.0, 0.27700156186427854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16926845387759273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04223067330071184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2515708320662983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18265011224672084, 0.36866594776857275, 0.0, 0.18159065907399216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12636547774606385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06349405698608146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2726586030963603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06444466525082888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06412497075485628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06412497075485628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04381518737665538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1635160629219832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07633280312207459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06380811802532718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2066543710952559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28523387195115574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08139147446411349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
itachiuchiha10_survival-titanic.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,372,"['# in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# drop Parch & SibSp', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column', '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# Logistic Regression', '# get Correlation Coefficient for each feature using Logistic Regression', '# Random Forests']",11,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'test_df.info', 'titanic_df.describe', 'titanic_df.value_counts', 'None.plot.bar', 'titanic_df.value_counts', 'None.plot', 'plt.hist', 'plt.xlabel', 'sns.boxplot', 'titanic_df.value_counts', 'None.plot', 'titanic_df.value_counts', 'None.plot', 'plt.hist', 'plt.xlabel', 'sns.boxplot', 'titanic_df.value_counts', 'None.plot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'titanic_df.fillna', 'test_df.fillna', 'test_df.fillna', 'titanic_df.info', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'pd.get_dummies', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'sns.FacetGrid', 'g.map', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pd.get_dummies', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'train_test_split', 'LogisticRegression', 'logreg.fit', 'print', 'DataFrame', 'pd.Series', 'RandomForestClassifier', 'random_forest.fit', 'print', 'random_forest.predict', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'info', 'describe', 'value_counts', 'plot', 'value_counts', 'plot', 'hist', 'xlabel', 'boxplot', 'value_counts', 'plot', 'value_counts', 'plot', 'hist', 'xlabel', 'boxplot', 'value_counts', 'plot', 'drop', 'drop', 'fillna', 'fillna', 'fillna', 'fillna', 'info', 'info', 'drop', 'drop', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'get_dummies', 'join', 'join', 'drop', 'drop', 'FacetGrid', 'map', 'set', 'add_legend', 'FacetGrid', 'map', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'get_dummies', 'drop', 'drop', 'join', 'join', 'info', 'drop', 'drop', 'copy', 'train_test_split', 'LogisticRegression', 'fit', 'print', 'DataFrame', 'Series', 'RandomForestClassifier', 'fit', 'print', 'predict', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'describe', 'value_counts', 'plot', 'hist', 'xlabel', 'boxplot', 'drop', 'fillna', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'set_xticklabels', 'apply', 'factorplot', 'copy', 'train_test_split', 'LogisticRegression', 'fit', 'print', 'DataFrame', 'Series', 'RandomForestClassifier', 'predict', 'to_csv']",37,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv head info info describe value counts plot value counts plot hist xlabel boxplot value counts plot value counts plot hist xlabel boxplot value counts plot drop drop fillna fillna fillna fillna info info drop drop countplot countplot groupby mean barplot get dummies get dummies join join drop drop facetgrid map set add legend facetgrid map drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies get dummies drop drop join join info drop drop copy train test split logisticregression fit print dataframe series randomforestclassifier fit print predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.048463606621790147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08550076221931677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1732708121654351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1278967071236117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04666637344027243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2003553194623286, 0.25564063827847305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06758168955847112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05645113470481838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04028225211100849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5189309296306489, 0.0, 0.0, 0.0, 0.24425950500723967, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10444334736584143, 0.06461364362283134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11730197064505915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04965191429309677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20704574877170698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11714777005051857, 0.0, 0.0, 0.0, 0.0, 0.02684342626484309, 0.0, 0.0, 0.10675088905836642, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1857147714049124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037325967468541145, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41472765645675047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04323212363122918, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037884797300017606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03769685992567152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03769685992567152, 0.0, 0.0, 0.07890449500593405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12148498141210673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2161606181561459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0257574383537593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.048062728505029996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03642647844583049, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04487342377164032, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037510593127862174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055019807561284766, 0.08098998760807116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.039249783350377175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10444334736584143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040927068426607115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04028225211100849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25564063827847305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11551387477695675, 0.0, 0.06674648744016991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
gracyf_titanic-survival-predictor-my-first-in-kaggle.py,"['pandas', 'numpy', 'matplotlib', 'sklearn', 'subprocess', 'seaborn', 'xgboost', 'vecstack']","[1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,1094,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory', '# Any results you write to the current directory are saved as output.', '# absolute numbers', '# percentages', '# Find potential outliers in values array', '# and visualize them on a plot', '# We will have to scale it', '# Can replace Lady, Mlle , Mme , the Countess - Lady', '# Capt, Col, Jonkheer, Rev  - Ranked Personal', '# Miss and Ms to - Miss', '# Make train/test split', '# As usual in machine learning task we have X_train, y_train, and X_test', '#    test_size = 0.2, random_state = 0)', '# Caution! All models and parameter values are just ', ""# demonstrational and shouldn't be considered as recommended."", '# Initialize 1st level models.', '# Compute stacking features', '# Initialize 2nd level model', '# Fit 2nd level model', '# Predict', '# Final prediction score', 'SEED = 0 # for reproducibility', 'NFOLDS = 5 # set folds for out-of-fold prediction', '# Put in our parameters for said classifiers', '# Random Forest parameters', '# Extra Trees Parameters', '# AdaBoost parameters', '# Gradient Boosting parameters', '# Support Vector Classifier parameters ', '# Create 5 objects that represent our 4 models', 'train_pred_val_rf, test_pred_val_rf = get_oof(rf,X_train, np.ravel(y_train), X_val,y_val,trainSet.iloc[:,1:11],testSet.iloc[:,1:11]) # Random Forest', 'train_pred_val_ada,test_pred_val_ada = get_oof(ada, X_train, np.ravel(y_train), X_val,y_val,trainSet.iloc[:,1:11],testSet.iloc[:,1:11]) # AdaBoost ', 'train_pred_val_gb, test_pred_val_gb = get_oof(gb,X_train, np.ravel(y_train), X_val,y_val,trainSet.iloc[:,1:11],testSet.iloc[:,1:11]) # Gradient Boost', 'train_pred_val_svc, test_pred_val_svc = get_oof(svc,X_train, np.ravel(y_train), X_val,y_val,trainSet.iloc[:,1:11],testSet.iloc[:,1:11]) # Support Vector Classifier', ""    # 'ExtraTrees' : train_pred_val_et.ravel(),"", ""    # 'AdaBoost': train_pred_val_ada.ravel(),"", ""     # 'SupportVector' : train_pred_val_svc.ravel(),"", ""     # 'XGBoost' :   train_pred_val_xgb.ravel() , "", ""     # 'BernouliNB' : train_pred_val_bernb.ravel(),"", ""     # 'SupportVector' : test_pred_val_svc.ravel(),"", ""     # 'XGBoost' :   test_pred_val_xgb.ravel(),"", ""     # 'BernouliNB' : test_pred_val_bernb.ravel(),"", '# create the sub models', '# create the ensemble model']",50,"['get_ipython', 'None.run_line_magic', 'print', 'pd.read_csv', 'pd.read_csv', 'train.info', 'test.info', 'pd.concat', 'titanic.fillna', 'titanic.info', 'titanic.describe', 'titanic.unique', 'train.describe', 'titanic.corr', 'titanic.nunique', 'titanic.duplicated', 'cm.get_cmap', 'pd.plotting.scatter_matrix', 'plt.figure', 'fig.gca', 'train.plot', 'plt.show', 'plt.figure', 'fig.gca', 'train.plot', 'plt.show', 'train.groupby', 'None.hist', 'sns.pairplot', 'train.value_counts', 'train.value_counts', 'plt.figure', 'train.groupby', 'None.hist', 'plt.legend', 'train.groupby', 'None.Age.value_counts', 'None.unstack', 'plt.figure', 'sns.barplot', 'plt.figure', 'sns.barplot', 'train.groupby', 'None.Sex.value_counts', 'None.unstack', 'sns.FacetGrid', 'g.map', 'plt.figure', 'sns.distplot', 'plt.show', 'sns.FacetGrid', 'g.map', 'plt.show', 'train.groupby', 'None.count', 'category_group.unstack', 'None.head', 'sns.FacetGrid', 'g.map', 'plt.show', 'traintrain.value_counts', 'traintrain.value_counts', 'train.groupby', 'None.count', 'category_group.unstack', 'None.head', 'train.groupby', 'None.count', 'category_group.unstack', 'None.head', 'plt.figure', 'sns.heatmap', 'train.groupby', 'None.count', 'category_group.unstack', 'None.head', 'category_group.unstack', 'None.plot', 'np.percentile', 'np.percentile', 'enumerate', 'is_outlier', 'indices_of_outliers.append', 'get_indices_of_outliers', 'plt.figure', 'fig.add_subplot', 'ax.plot', 'ax.plot', 'ax.legend', 'preprocessing.LabelEncoder', 'le.fit', 'le.transform', 'titanic.fillna', 'le.fit', 'le.transform', 'titanic.isnull', 'titanic.fillna', 'df.isnull', 'df.isnull', 'KNeighborsRegressor', 'knn.fit', 'knn.predict', 'pd.concat', 'df_complete.sort_values', 'plt.figure', 'sns.distplot', 'plt.show', 'MinMaxScaler', 'scaler.fit_transform', 'titanic.apply', 'le.fit', 'le.transform', 'titanic.apply', 'titanic.fillna', 'titanic.apply', 'titanic.apply', 'titanic.apply', 'titanic.apply', 'le.fit', 'le.transform', 'train.sort_values', 'traintrain.count', 'traintraintrain.count', 'traintrain.count', 'traintraintrain.count', 'traintrain.count', 'traintraintrain.count', 'titanic.apply', 'titanic.apply', 'sns.PairGrid', 'g.map', 'titanic.sort_values', 'X_train.head', 'RandomForestClassifier', 'None.fit', 'feature_df.tolist', 'clf.feature_importances_.tolist', 'pd.DataFrame', 'feat.sort_values', 'titanic.Survived.astype', 'titanic.isin', 'titanic.isin', 'train_test_split', 'RandomForestClassifier', 'None.fit', 'print', 'print', 'clf.predict', 'results.to_frame', 'results.to_csv', 'GaussianNB', 'model.fit', 'print', 'print', 'MLPClassifier', 'model.fit', 'print', 'print', 'GradientBoostingClassifier', 'None.fit', 'print', 'print', 'GradientBoostingClassifier', 'GridSearchCV', 'grid_clf_gb_acc.fit', 'grid_clf_gb_acc.decision_function', 'print', 'print', 'XGBClassifier', 'None.fit', 'print', 'print', 'XGBClassifier', 'GridSearchCV', 'clf_xgb_grid_acc.fit', 'print', 'print', 'ExtraTreesClassifier', 'RandomForestClassifier', 'XGBClassifier', 'stacking', 'XGBClassifier', 'model.fit', 'model.predict', 'print', 'KFold', 'clf', 'self.clf.fit', 'self.clf.predict', 'self.clf.fit', 'self.clf.score', 'print', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'clf.train', 'print', 'print', 'clf.predict', 'clf.predict', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'pd.DataFrame', 'base_predictions_train.head', 'pd.DataFrame', 'base_predictions_test.head', 'base_predictions_test.corr', 'plt.figure', 'sns.heatmap', 'np.ravel', 'XGBClassifier', 'None.fit', 'xgb1.predict', 'xgb1.score', 'results.to_csv', 'train_test_split', 'model_selection.KFold', 'LogisticRegression', 'estimators.append', 'DecisionTreeClassifier', 'estimators.append', 'SVC', 'estimators.append', 'VotingClassifier', 'model_selection.cross_val_score', 'print', 'ensemble.fit', 'ensemble.predict']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'read_csv', 'info', 'info', 'concat', 'fillna', 'info', 'describe', 'unique', 'describe', 'corr', 'nunique', 'duplicated', 'get_cmap', 'plotting', 'figure', 'gca', 'plot', 'show', 'figure', 'gca', 'plot', 'show', 'groupby', 'hist', 'pairplot', 'value_counts', 'value_counts', 'figure', 'groupby', 'hist', 'legend', 'groupby', 'Age', 'unstack', 'figure', 'barplot', 'figure', 'barplot', 'groupby', 'Sex', 'unstack', 'FacetGrid', 'map', 'figure', 'distplot', 'show', 'FacetGrid', 'map', 'show', 'groupby', 'count', 'unstack', 'head', 'FacetGrid', 'map', 'show', 'value_counts', 'value_counts', 'groupby', 'count', 'unstack', 'head', 'groupby', 'count', 'unstack', 'head', 'figure', 'heatmap', 'groupby', 'count', 'unstack', 'head', 'unstack', 'plot', 'percentile', 'percentile', 'enumerate', 'is_outlier', 'append', 'get_indices_of_outliers', 'figure', 'add_subplot', 'plot', 'plot', 'legend', 'LabelEncoder', 'fit', 'transform', 'fillna', 'fit', 'transform', 'isnull', 'fillna', 'isnull', 'isnull', 'KNeighborsRegressor', 'fit', 'predict', 'concat', 'sort_values', 'figure', 'distplot', 'show', 'MinMaxScaler', 'fit_transform', 'apply', 'fit', 'transform', 'apply', 'fillna', 'apply', 'apply', 'apply', 'apply', 'fit', 'transform', 'sort_values', 'count', 'count', 'count', 'count', 'count', 'count', 'apply', 'apply', 'PairGrid', 'map', 'sort_values', 'head', 'RandomForestClassifier', 'fit', 'tolist', 'feature_importances_', 'DataFrame', 'sort_values', 'Survived', 'isin', 'isin', 'train_test_split', 'RandomForestClassifier', 'fit', 'print', 'print', 'predict', 'to_frame', 'to_csv', 'GaussianNB', 'fit', 'print', 'print', 'MLPClassifier', 'fit', 'print', 'print', 'GradientBoostingClassifier', 'fit', 'print', 'print', 'GradientBoostingClassifier', 'GridSearchCV', 'fit', 'decision_function', 'print', 'print', 'XGBClassifier', 'fit', 'print', 'print', 'XGBClassifier', 'GridSearchCV', 'fit', 'print', 'print', 'ExtraTreesClassifier', 'RandomForestClassifier', 'XGBClassifier', 'stacking', 'XGBClassifier', 'fit', 'predict', 'print', 'KFold', 'clf', 'clf', 'clf', 'clf', 'clf', 'print', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'SklearnHelper', 'train', 'print', 'print', 'predict', 'predict', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'get_oof', 'DataFrame', 'head', 'DataFrame', 'head', 'corr', 'figure', 'heatmap', 'ravel', 'XGBClassifier', 'fit', 'predict', 'score', 'to_csv', 'train_test_split', 'KFold', 'LogisticRegression', 'append', 'DecisionTreeClassifier', 'append', 'SVC', 'append', 'VotingClassifier', 'cross_val_score', 'print', 'fit', 'predict']","['get_ipython', 'run_line_magic', 'print', 'read_csv', 'info', 'concat', 'fillna', 'describe', 'unique', 'corr', 'nunique', 'duplicated', 'get_cmap', 'plotting', 'figure', 'gca', 'plot', 'show', 'groupby', 'hist', 'pairplot', 'value_counts', 'legend', 'Age', 'unstack', 'barplot', 'Sex', 'FacetGrid', 'map', 'distplot', 'count', 'head', 'heatmap', 'percentile', 'enumerate', 'is_outlier', 'append', 'get_indices_of_outliers', 'add_subplot', 'LabelEncoder', 'fit', 'transform', 'isnull', 'KNeighborsRegressor', 'predict', 'sort_values', 'MinMaxScaler', 'fit_transform', 'apply', 'PairGrid', 'RandomForestClassifier', 'tolist', 'feature_importances_', 'DataFrame', 'Survived', 'isin', 'train_test_split', 'to_frame', 'to_csv', 'GaussianNB', 'MLPClassifier', 'GradientBoostingClassifier', 'GridSearchCV', 'decision_function', 'XGBClassifier', 'ExtraTreesClassifier', 'stacking', 'KFold', 'clf', 'SklearnHelper', 'train', 'get_oof', 'ravel', 'score', 'LogisticRegression', 'DecisionTreeClassifier', 'SVC', 'VotingClassifier', 'cross_val_score']",79,"[1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0
 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0
 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic print read csv read csv info info concat fillna info describe unique describe corr nunique duplicated get cmap plotting figure gca plot show figure gca plot show groupby hist pairplot value counts value counts figure groupby hist legend groupby age unstack figure barplot figure barplot groupby sex unstack facetgrid map figure distplot show facetgrid map show groupby count unstack head facetgrid map show value counts value counts groupby count unstack head groupby count unstack head figure heatmap groupby count unstack head unstack plot percentile percentile enumerate outlier append get indices outliers figure add subplot plot plot legend labelencoder fit transform fillna fit transform isnull fillna isnull isnull kneighborsregressor fit predict concat sort values figure distplot show minmaxscaler fit transform apply fit transform apply fillna apply apply apply apply fit transform sort values count count count count count count apply apply pairgrid map sort values head randomforestclassifier fit tolist feature importances dataframe sort values survived isin isin train test split randomforestclassifier fit print print predict frame csv gaussiannb fit print print mlpclassifier fit print print gradientboostingclassifier fit print print gradientboostingclassifier gridsearchcv fit decision function print print xgbclassifier fit print print xgbclassifier gridsearchcv fit print print extratreesclassifier randomforestclassifier xgbclassifier stacking xgbclassifier fit predict print kfold clf clf clf clf clf print sklearnhelper sklearnhelper sklearnhelper sklearnhelper sklearnhelper sklearnhelper sklearnhelper sklearnhelper train print print predict predict get oof get oof get oof get oof get oof get oof get oof get oof dataframe head dataframe head corr figure heatmap ravel xgbclassifier fit predict score csv train test split kfold logisticregression append decisiontreeclassifier append svc append votingclassifier cross val score print fit predict,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.021245022808294434, 0.0, 0.022258680390812993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08666331737203829, 0.14992409934750722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05063789254197821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24888742998650204, 0.0, 0.05350208969060868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03855571749522867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05063789254197821, 0.0, 0.0, 0.2832472505001021, 0.0, 0.0, 0.0, 0.08965228251933172, 0.0, 0.0, 0.027750412864169773, 0.0, 0.0, 0.03950110570728734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.037119781046755736, 0.0, 0.0, 0.0, 0.0, 0.05350208969060868, 0.021665829343009573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03531711420268335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05390225219086534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04977748599730041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03384343552509191, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.040767585551569036, 0.0, 0.0, 0.0686773473426633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04341023392778059, 0.0, 0.0, 0.21810493797124375, 0.0, 0.0, 0.0, 0.05142174129260282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18501050713884187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.045085040292680734, 0.05350208969060868, 0.026699439036760576, 0.0, 0.0, 0.08153517110313807, 0.0, 0.0, 0.14262722536394196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061351459577481886, 0.0, 0.0, 0.0, 0.0, 0.05243170708766639, 0.0, 0.0, 0.1369443847400376, 0.0, 0.0, 0.0, 0.0, 0.08237159181938884, 0.04750315952452763, 0.0, 0.046796456783532114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05350208969060868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05350208969060868, 0.04884714319912674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016362608676636727, 0.0, 0.0, 0.0, 0.08682046785556118, 0.0, 0.0, 0.0, 0.05269870405857994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06380469911990494, 0.0, 0.05350208969060868, 0.0, 0.0, 0.0, 0.02575645767116394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03790338840293856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01660758327393248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01652519704470128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01652519704470128, 0.0, 0.0, 0.0691788297623031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03630770930666129, 0.0, 0.040767585551569036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03562695325326074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280167175248694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05350208969060868, 0.04199420532278056, 0.05350208969060868, 0.037042981858260764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08682046785556118, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09475847100734641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03871778822316091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.079039135222753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21069289607082653, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04790489726323191, 0.0, 0.0, 0.0, 0.0, 0.04341023392778059, 0.0, 0.019671192013310083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016443543147194848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03321516654786496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03282171650898464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12914044703528108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4280167175248694, 0.081328747868963, 0.0, 0.0, 0.0, 0.03441190619620364, 0.0, 0.0, 0.0, 0.05350208969060868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.032350536153641085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03282171650898464, 0.0, 0.0, 0.0, 0.021108931386052264, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0358824512994026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03871778822316091, 0.0, 0.0, 0.0, 0.0, 0.05297567130402503, 0.0, 0.0, 0.0, 0.10043606184972499, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.029940457237141466, 0.2493886727728252, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027750412864169773, 0.0, 0.0, 0.08965228251933172, 0.081328747868963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03562695325326074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13738091727786045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sethzgold_titanic.py,[],"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",0,2,[],0,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mahsahassankashi_predict-titanic-survival-accuracy-0-83.py,"['numpy', 'csv', 'sklearn']","[0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",3,238,"['# -*- coding: utf-8 -*-', 'from sklearn.cross_validation import StratifiedKFold # Add important libs', ""with open(path3, 'w',  newline='') as f3, open(path2, 'r') as f4: # write output and other column from test""]",3,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
backtosept_titanic-data-science-solutions-488442.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn', 'pandas\n']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,955,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest', ""# submission.to_csv('../output/submission.csv', index=False)""]",25,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score']",47,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.1475055413903119, 0.0, 0.03863585757600293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11416856344136125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03550885478225471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04432295053020758, 0.03428233541713673, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.06443124877999497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03760680696542986, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.061302241209837786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2193661762546469, 0.03735959658099504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03890384288246168, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19867965845540314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06694207736067323, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17001260606804658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04634397483910219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022506133537238064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29712923518779355, 0.0, 0.0, 0.0, 0.0, 0.22467939552836227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0565248024441144, 0.0, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.028401657569212087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03837230198214322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13158281535757904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05392448701635977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02868387290820628, 0.0, 0.0, 0.2401565022762136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30812997633857053, 0.04287242823348542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0502284681384396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042529517159236176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17639155639840096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05485703048389958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04358120049241369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027717228445390322, 0.0, 0.0, 0.15454343030401171, 0.0, 0.0, 0.0, 0.03414458357963311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1354030590247559, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3797444322410113, 0.0, 0.028542140860340313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028826876112480436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0418650564167314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05615295630262467, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0366401625026139, 0.0, 0.0, 0.0, 0.05078799047395498, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35291916056227834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05537500931308193, 0.0, 0.0]"
noogakl81_titanic-script.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,443,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn', '# machine learning', '# get titanic & test csv files as a DataFrame', '# preview the data', ""# drop unnecessary columns, these columns won't be useful in analysis and prediction"", '# Embarked', '# only in titanic_df, fill the two missing values with the most occurred value, which is ""S"".', '# plot', ""# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)"", '# sns.factorplot(\'Survived\',hue=""Embarked"",data=titanic_df,kind=\'count\',order=[1,0],ax=axis2)', '# group by embarked, and get the mean for survived passengers for each value in Embarked', '# Either to consider Embarked column in predictions,', '# and remove ""S"" dummy variable, ', '# and leave ""C"" & ""Q"", since they seem to have a good rate for Survival.', ""# OR, don't create dummy variables for Embarked column, just drop it, "", ""# because logically, Embarked doesn't seem to be useful in prediction."", '# Fare', '# only for test_df, since there is a missing ""Fare"" values', '# convert from float to int', ""# get fare for survived & didn't survive passengers "", '# get average and std for fare of survived/not survived passengers', '# plot', '# Age ', ""# axis3.set_title('Original Age values - Test')"", ""# axis4.set_title('New Age values - Test')"", '# get average, std, and number of NaN values in titanic_df', '# get average, std, and number of NaN values in test_df', '# generate random numbers between (mean - std) & (mean + std)', '# plot original Age values', '# NOTE: drop all null values, and convert to int', ""# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)"", '# fill NaN values in Age column with random values generated', '# convert from float to int', '# plot new Age Values', ""# test_df['Age'].hist(bins=70, ax=axis4)"", '# .... continue with plot Age column', '# peaks for survived/not survived passengers by their age', '# average survived passengers by age', '# Cabin', ""# It has a lot of NaN values, so it won't cause a remarkable impact on prediction"", '# Family', '# Instead of having two columns Parch & SibSp, ', '# we can have only one column represent if the passenger had any family member aboard or not,', '# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.', '# drop Parch & SibSp', '# plot', ""# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)"", ""# average of survived for those who had/didn't have any family member"", '# Sex', '# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.', '# So, we can classify passengers as males, females, and child', '# No need to use Sex column since we created Person column', '# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers', ""# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)"", '# average of survived for each Person(male, female, or child)', '# Pclass', ""# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])"", '# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers', '# define training and testing sets', '# Logistic Regression', '# Support Vector Machines', '# svc.fit(X_train, Y_train)', '# Random Forests', '# Gaussian Naive Bayes', '# get Correlation Coefficient for each feature using Logistic Regression', '# preview', '# put ensemble together']",69,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'titanic_df.head', 'titanic_df.info', 'print', 'test_df.info', 'titanic_df.drop', 'test_df.drop', 'titanic_df.fillna', 'sns.factorplot', 'plt.subplots', 'sns.countplot', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'pd.get_dummies', 'embark_dummies_titanic.drop', 'pd.get_dummies', 'embark_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'test_df.fillna', 'titanic_df.astype', 'test_df.astype', 'DataFrame', 'DataFrame', 'titanic_df.plot', 'avgerage_fare.plot', 'plt.subplots', 'axis1.set_title', 'axis2.set_title', 'titanic_df.mean', 'titanic_df.std', 'titanic_df.isnull', 'None.sum', 'test_df.mean', 'test_df.std', 'test_df.isnull', 'None.sum', 'np.random.randint', 'np.random.randint', 'titanic_df.dropna', 'None.astype', 'None.hist', 'np.isnan', 'np.isnan', 'titanic_df.astype', 'test_df.astype', 'titanic_df.hist', 'sns.FacetGrid', 'facet.map', 'facet.set', 'facet.add_legend', 'plt.subplots', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'titanic_df.drop', 'test_df.drop', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'axis1.set_xticklabels', 'titanic_df.apply', 'test_df.apply', 'titanic_df.drop', 'test_df.drop', 'pd.get_dummies', 'person_dummies_titanic.drop', 'pd.get_dummies', 'person_dummies_test.drop', 'titanic_df.join', 'test_df.join', 'plt.subplots', 'sns.countplot', 'titanic_df.groupby', 'None.mean', 'sns.barplot', 'titanic_df.drop', 'test_df.drop', 'sns.factorplot', 'pd.get_dummies', 'pclass_dummies_titanic.drop', 'pd.get_dummies', 'pclass_dummies_test.drop', 'titanic_df.drop', 'test_df.drop', 'titanic_df.join', 'test_df.join', 'titanic_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'make_scorer', 'GridSearchCV', 'grid_search_CV.fit', 'print', 'print', 'logreg.predict', 'logreg.score', 'print', 'SVC', 'GridSearchCV', 'grid_search_CV.fit', 'print', 'svc.predict', 'svc.score', 'print', 'RandomForestClassifier', 'GridSearchCV', 'grid_search_CV.fit', 'print', 'print', 'random_forest.predict', 'random_forest.score', 'print', 'KNeighborsClassifier', 'GridSearchCV', 'grid_search_CV.fit', 'print', 'knn.predict', 'knn.score', 'print', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'gaussian.score', 'print', 'DataFrame', 'pd.Series', 'list', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'drop', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'drop', 'drop', 'fillna', 'astype', 'astype', 'DataFrame', 'DataFrame', 'plot', 'plot', 'subplots', 'set_title', 'set_title', 'mean', 'std', 'isnull', 'sum', 'mean', 'std', 'isnull', 'sum', 'random', 'random', 'dropna', 'astype', 'hist', 'isnan', 'isnan', 'astype', 'astype', 'hist', 'FacetGrid', 'map', 'set', 'add_legend', 'subplots', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'drop', 'drop', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'set_xticklabels', 'apply', 'apply', 'drop', 'drop', 'get_dummies', 'drop', 'get_dummies', 'drop', 'join', 'join', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'drop', 'drop', 'factorplot', 'get_dummies', 'drop', 'get_dummies', 'drop', 'drop', 'drop', 'join', 'join', 'drop', 'drop', 'copy', 'LogisticRegression', 'make_scorer', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'score', 'print', 'SVC', 'GridSearchCV', 'fit', 'print', 'predict', 'score', 'print', 'RandomForestClassifier', 'GridSearchCV', 'fit', 'print', 'print', 'predict', 'score', 'print', 'KNeighborsClassifier', 'GridSearchCV', 'fit', 'print', 'predict', 'score', 'print', 'GaussianNB', 'fit', 'predict', 'score', 'print', 'DataFrame', 'Series', 'list', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'drop', 'fillna', 'factorplot', 'subplots', 'countplot', 'groupby', 'mean', 'barplot', 'get_dummies', 'join', 'astype', 'DataFrame', 'plot', 'set_title', 'std', 'isnull', 'sum', 'random', 'dropna', 'hist', 'isnan', 'FacetGrid', 'map', 'set', 'add_legend', 'set_xticklabels', 'apply', 'copy', 'LogisticRegression', 'make_scorer', 'GridSearchCV', 'fit', 'predict', 'score', 'SVC', 'RandomForestClassifier', 'KNeighborsClassifier', 'GaussianNB', 'Series', 'list', 'to_csv']",48,"[1 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info print info drop drop fillna factorplot subplots countplot countplot groupby mean barplot get dummies drop get dummies drop join join drop drop fillna astype astype dataframe dataframe plot plot subplots set title set title mean std isnull sum mean std isnull sum random random dropna astype hist isnan isnan astype astype hist facetgrid map set add legend subplots groupby mean barplot drop drop drop drop subplots countplot groupby mean barplot set xticklabels apply apply drop drop get dummies drop get dummies drop join join subplots countplot groupby mean barplot drop drop factorplot get dummies drop get dummies drop drop drop join join drop drop copy logisticregression make scorer gridsearchcv fit print print predict score print svc gridsearchcv fit print predict score print randomforestclassifier gridsearchcv fit print print predict score print kneighborsclassifier gridsearchcv fit print predict score print gaussiannb fit predict score print dataframe series list dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04083140288881407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0720358287966943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15801652491062024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19464476084391413, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03931720373536723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16880272311811712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05693870899463743, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0951220590184797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5343653670091836, 0.041366438857390865, 0.0, 0.0, 0.20579273713996857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04399763753275431, 0.108876160846513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04941444061766088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10458143017108645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.051314397826378276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17443952222723527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20153992542751845, 0.0, 0.0, 0.13159861952462024, 0.0, 0.0, 0.0, 0.0, 0.022616037664913997, 0.0, 0.0, 0.08993941771394, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06258712615274925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03144775476197266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10666858757576547, 0.06752207443443091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.34941501902801936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04248775760520776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.036423790567251306, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03191857828473219, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04866119021097853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031760237889027085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031760237889027085, 0.07835236165575789, 0.0, 0.03323918141780576, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20470627618323098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07284758113450261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10850537301254712, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24296193803812427, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10459094884560227, 0.030689920146670813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03780661351350026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03160330498212405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15959289142366098, 0.08343134140156626, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04635511234093238, 0.17058856348602583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.108876160846513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04709083695236844, 0.0, 0.0, 0.0, 0.0, 0.21998818766377154, 0.0671707315201045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04056984498221995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07124231963757068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056235037176481525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
anshita2794_titanic-survival-problem-sample.py,"['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,260,"['# Imports', '# pandas', '# numpy, matplotlib, seaborn']",3,"['sns.set_style', 'get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'df_train.head', 'df_train.info', 'df_train.fillna', 'df_test.fillna', 'df_train.astype', 'df_test.astype', 'sns.countplot', 'df_train.apply', 'df_train.unique', 'df_test.apply', 'df_test.unique', 'df_train.apply', 'df_test.apply', 'df_train.unique', 'pd.get_dummies', 'p_dummies_train.drop', 'df_train.join', 'pd.get_dummies', 'p_dummies_test.drop', 'df_test.join', 'df_train.info', 'df_test.info', 'df_test.info', 'df_train.drop', 'df_test.drop', 'df_train.drop', 'df_test.drop', 'df_train.drop', 'df_test.drop', 'df_train.drop', 'df_test.drop', 'df_train.info', 'df_train.drop', 'df_test.drop', 'df_train.drop', 'df_test.drop', 'df_train.drop', 'df_test.drop', 'df_train.drop', 'df_test.drop', 'df_train.info', 'df_test.info', 'df_test.drop', 'df_train.drop', 'df_test.info', 'df_test.drop', 'df_train.drop', 'df_train.info', 'df_test.info', 'df_train.info', 'df_test.info', 'df_train.drop', 'LogisticRegression', 'log.fit', 'log.predict', 'log.score', 'pd.DataFrame', 'submission.to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'fillna', 'fillna', 'astype', 'astype', 'countplot', 'apply', 'unique', 'apply', 'unique', 'apply', 'apply', 'unique', 'get_dummies', 'drop', 'join', 'get_dummies', 'drop', 'join', 'info', 'info', 'info', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'info', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'drop', 'info', 'info', 'drop', 'drop', 'info', 'drop', 'drop', 'info', 'info', 'info', 'info', 'drop', 'LogisticRegression', 'fit', 'predict', 'score', 'DataFrame', 'to_csv']","['set_style', 'get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'fillna', 'astype', 'countplot', 'apply', 'unique', 'get_dummies', 'drop', 'join', 'LogisticRegression', 'fit', 'predict', 'score', 'DataFrame', 'to_csv']",20,"[0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",set style get ipython run line magic read csv read csv head info fillna fillna astype astype countplot apply unique apply unique apply apply unique get dummies drop join get dummies drop join info info info drop drop drop drop drop drop drop drop info drop drop drop drop drop drop drop drop info info drop drop info drop drop info info info info drop logisticregression fit predict score dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1939439037528637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08508638606802194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.056808985945796024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07664877104582596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03201244395882628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7520401690454342, 0.0, 0.0, 0.0, 0.09234350801912801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06651988097618033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028156725849135786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10063885412895382, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030444868237266005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5055147600923068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04233379711652301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1567898316531551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04296760222092718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0427544502729466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0427544502729466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02921317901346852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05089385611969588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04254319303401097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04296760222092718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04592799512510268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06339193219604528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2323883557875825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
zgh19971022_logisticregression-titanic.py,"['numpy', 'pandas', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,276,"[' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ']",2,"['pd.read_csv', 'data_train.info', 'data_train.describe', 'plt.figure', 'fig.set', 'plt.subplot2grid', 'data_train.Survived.value_counts', 'None.plot', 'plt.title', 'plt.ylabel', 'plt.subplot2grid', 'data_train.Pclass.value_counts', 'None.plot', 'plt.ylabel', 'plt.title', 'plt.figure', 'fig.set', 'data_train.Pclassdata_train.Survived.value_counts', 'data_train.Pclassdata_train.Survived.value_counts', 'pd.DataFrame', 'df.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'plt.figure', 'fig.set', 'data_train.Surviveddata_train.Sex.value_counts', 'data_train.Surviveddata_train.Sex.value_counts', 'pd.DataFrame', 'df.plot', 'plt.title', 'plt.xlabel', 'plt.ylabel', 'plt.show', 'data_train.Cabin.value_counts', 'age_df.Age.notnull', 'age_df.Age.notnull', 'age_df.Age.isnull', 'RandomForestRegressor', 'rfr.fit', 'rfr.predict', 'df.Age.isnull', 'df.Cabin.notnull', 'df.Cabin.isnull', 'set_missing_ages', 'set_Cabin_type', 'data_train.info', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'df.drop', 'df.head', 'preprocessing.StandardScaler', 'scalar.fit', 'scalar.fit_transform', 'scalar.fit', 'scalar.fit_transform', 'df.head', 'df.filter', 'linear_model.LogisticRegression', 'clf.fit', 'pd.read_csv', 'data_test.Fare.isnull', 'data_test.Age.isnull', 'data_test.Age.isnull', 'rfr.predict', 'data_test.Age.isnull', 'set_Cabin_type', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.get_dummies', 'pd.concat', 'df_test.drop', 'pd.concat', 'df_test.drop', 'scalar.fit_transform', 'scalar.fit_transform', 'df_test.head', 'df_test.filter', 'clf.predict', 'pd.DataFrame', 'output.to_csv', 'pd.read_csv', 'None.head', 'df.filter', 'linear_model.LogisticRegression', 'BaggingRegressor', 'bagging_clf.fit', 'df_test.filter', 'bagging_clf.predict', 'pd.DataFrame', 'output.to_csv', 'df.filter', 'print']","['read_csv', 'info', 'describe', 'figure', 'set', 'subplot2grid', 'Survived', 'plot', 'title', 'ylabel', 'subplot2grid', 'Pclass', 'plot', 'ylabel', 'title', 'figure', 'set', 'Pclassdata_train', 'Pclassdata_train', 'DataFrame', 'plot', 'title', 'xlabel', 'ylabel', 'show', 'figure', 'set', 'Surviveddata_train', 'Surviveddata_train', 'DataFrame', 'plot', 'title', 'xlabel', 'ylabel', 'show', 'Cabin', 'Age', 'Age', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'Age', 'Cabin', 'Cabin', 'set_missing_ages', 'set_Cabin_type', 'info', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'drop', 'head', 'StandardScaler', 'fit', 'fit_transform', 'fit', 'fit_transform', 'head', 'filter', 'LogisticRegression', 'fit', 'read_csv', 'Fare', 'Age', 'Age', 'predict', 'Age', 'set_Cabin_type', 'get_dummies', 'get_dummies', 'get_dummies', 'get_dummies', 'concat', 'drop', 'concat', 'drop', 'fit_transform', 'fit_transform', 'head', 'filter', 'predict', 'DataFrame', 'to_csv', 'read_csv', 'head', 'filter', 'LogisticRegression', 'BaggingRegressor', 'fit', 'filter', 'predict', 'DataFrame', 'to_csv', 'filter', 'print']","['read_csv', 'info', 'describe', 'figure', 'set', 'subplot2grid', 'Survived', 'plot', 'title', 'ylabel', 'Pclass', 'Pclassdata_train', 'DataFrame', 'xlabel', 'show', 'Surviveddata_train', 'Cabin', 'Age', 'RandomForestRegressor', 'fit', 'predict', 'set_missing_ages', 'set_Cabin_type', 'get_dummies', 'concat', 'drop', 'head', 'StandardScaler', 'fit_transform', 'filter', 'LogisticRegression', 'Fare', 'to_csv', 'BaggingRegressor', 'print']",35,"[1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0
 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv info describe figure set subplot2grid survived plot title ylabel subplot2grid pclass plot ylabel title figure set pclassdata train pclassdata train dataframe plot title xlabel ylabel show figure set surviveddata train surviveddata train dataframe plot title xlabel ylabel show cabin age age age randomforestregressor fit predict age cabin cabin set missing ages set cabin type info get dummies get dummies get dummies get dummies concat drop head standardscaler fit fit transform fit fit transform head filter logisticregression fit read csv fare age age predict age set cabin type get dummies get dummies get dummies get dummies concat drop concat drop fit transform fit transform head filter predict dataframe csv read csv head filter logisticregression baggingregressor fit filter predict dataframe csv filter print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30810408713278625, 0.0, 0.0, 0.09320560314586725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09843124193531844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2960250332974788, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11436155565294503, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0976380891553426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09786877408787889, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03491847110087206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07497211848914354, 0.0, 0.0, 0.0, 0.2823135258410813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05543331414645582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12938584273560588, 0.0, 0.0, 0.0, 0.0, 0.44576141400081065, 0.0, 0.0, 0.0, 0.0, 0.19368232399367244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2051160957257261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0930763654121668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06439437259303864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06535467333259924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08061484014606343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06919639559000566, 0.19686248387063687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1499022105801135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08931083240427298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02083146929951942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08061484014606343, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05834745833658327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21061731111450638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0851218466279736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05991743645484936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19686248387063687, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06490248058336076, 0.1864112062917345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14659898152018153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13967388440348824, 0.0, 0.0, 0.0, 0.15888381833501253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16608077733102974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10013263128966439, 0.0, 0.0, 0.0, 0.0, 0.1938024694105973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
smivvla_titanic-kernel.py,"['os\n', 're\n', 'numpy', 'pandas', 'seaborn', 'matplotlib', 'sklearn', 'xgboost']","[1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,508,"['# load dataframes', '# print some statistics', '    # if the title exists, extract and return it.', '# ', '    # Create new feature Last Name in order to group families', ""#     dataset['LastName'] = dataset['LastName'].astype('category')"", '    # Create a new feature Title, containing the titles of passenger names', '    # Group all non-common titles into one single grouping ""Rare""', '    # Mapping titles', ""#     dataset['Title'] = dataset['Title'].astype('category')"", '    # Feature that tells whether a passenger had a cabin on the Titanic', '    # Create new feature FamilySize as a combination of SibSp and Parch', '    # Create new feature IsAlone from FamilySize', '    # Mapping Embarked', '    # Remove all NULLS in the Fare column and create a new feature CategoricalFare', '    # Fill null age rows with median value', '    # Create new feature', ""#     dataset['Age*Class'] = dataset['Age'] * dataset['Pclass']"", '    # Mapping Sex', ""#     drop_columns = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']"", '# get all column names', '# numeric columns', '# categorical columns', ""#     'knn': {"", ""#         'model': KNeighborsClassifier,"", ""#         'params': {"", ""#             'n_neighbors' : range(1, 10),"", ""#             'weights' : ['uniform', 'distance'],"", ""#             'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],"", ""#             'leaf_size' : range(10, 100, 10),"", '#         }', '#     },', ""#     'lrcv': {"", ""#         'model': LogisticRegressionCV,"", ""#         'params': {"", ""#             'Cs': [1, 2, 4, 8, 16, 32],"", ""#             'fit_intercept': [True, False],"", ""#             'refit': [True, False],"", ""#             'multi_class': ['ovr'],"", ""#             'penalty': ['l2'],"", ""#             'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],"", ""#             'tol': [0.01, 0.05, 0.1, 0.5, 1, 5],"", ""#             'cv': [cv]"", '#         },', ""#         'best_params': {'tol': 0.05, 'solver': 'newton-cg', 'refit': True, 'penalty': 'l2', 'multi_class': 'ovr', 'fit_intercept': False, 'cv': 4, 'Cs': 2},"", ""#         'best_score': 0.8428731762065096"", '#     },', ""            'min_samples_split': [2, 5, 10], # Minimum number of samples required to split a node"", ""            'min_samples_leaf': [1, 2, 4], # Minimum number of samples required at each leaf node"", ""            'min_samples_split': range(2, 10), # Minimum number of samples required to split a node"", ""            'min_samples_leaf': range(1, 10), # Minimum number of samples required at each leaf node"", ""            'bootstrap': [True, False], # Method of selecting samples for training each tree,"", ""            'min_samples_split': range(2, 10), # Minimum number of samples required to split a node"", ""            'min_samples_leaf': range(1, 10), # Minimum number of samples required at each leaf node"", ""            'bootstrap': [True, False], # Method of selecting samples for training each tree,"", ""            'min_samples_split': range(2, 10), # Minimum number of samples required to split a node"", ""            'min_samples_leaf': range(1, 10), # Minimum number of samples required at each leaf node"", ""#     'xgb': {"", ""#         'model': XGBClassifier,"", ""#         'params': {"", ""#             'n_estimators': range(8, 20),"", ""#             'max_depth': range(5, 20),"", ""#             'learning_rate': [.01, .05, .1, .2, .5, 1, 2],"", ""#             'colsample_bytree': [.6, .7, .8, .9, 1]"", '#         }', '#     }', '        # Initialize with best parameters & fit to data', '        # Perform random search', '        # Fit to data', '        # Print the best parameters and best accuracy', '# """""" ----------------------------------- Fitting XGBoost classifier ------------------------------------- """"""', '# xgb_params = {', ""#     'n_estimators': range(20, 501, 20),"", ""#     'max_depth': range(4, 21, 4),"", ""#     'learning_rate': [.01, .05, .1, .2, .5, 1, 2],"", ""#     'colsample_bytree': [.6, .7, .8, .9, 1]"", '# }', ""# # xgb = XGBClassifier(**{'n_estimators': 20, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.8})"", '# # Perform random search', '# xgb = RandomizedSearchCV(param_distributions=xgb_params,', '#                               estimator=XGBClassifier(), scoring=""accuracy"",', '#                               verbose=1, n_iter=N_ITER, cv=N_FOLDS)', '# # Fit to data', ""# print(f'Fitting xgb...')    "", '# xgb.fit(X_train, y_train)', ""# print(f'Best parameters found for {name}: {xgb.best_params_}')"", ""# print(f'Best accuracy found {name}: {xgb.best_score_}')"", '# pred = xgb.predict(X_test)', ""# pred = MODELS[max(MODELS, key=lambda k: MODELS[k]['best_score'])]['best_estimator'].predict(x_test)""]",89,"['pd.read_csv', 'pd.read_csv', 'print', 'print', 'df_train_raw.describe', 're.search', 'title_search.group', 'df_train_raw.copy', 'df_test_raw.copy', 'dataset.apply', 'dataset.astype', 'dataset.astype', 'dataset.astype', 'dataset.apply', 'dataset.apply', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.map', 'dataset.fillna', 'dataset.apply', 'dataset.astype', 'dataset.fillna', 'dataset.map', 'dataset.fillna', 'pd.qcut', 'dataset.fillna', 'pd.qcut', 'dataset.map', 'dataset.drop', 'df_train.describe', 'print', 'pd.concat', 'train_data.copy', 'test_data.copy', 'datafeature_name.max', 'datafeature_name.min', 'pd.concat', 'train_data.copy', 'test_data.copy', 'df.copy', 'dffeature_name.max', 'dffeature_name.min', 'list', 'df_train.select_dtypes', 'None.columns.tolist', 'print', 'df_train.drop', 'df_trainlabel_column.astype', 'min_max_scale', 'x_train.describe', 'plt.figure', 'plt.title', 'sns.heatmap', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'MODELS.items', 'print', 'model', 'None.fit', 'cross_val_score', 'sum', 'len', 'print', 'print', 'print', 'RandomizedSearchCV', 'print', 'searcher.fit', 'print', 'print', 'pd.DataFrame', 'MODELS.items', 'MODELSname.predict', 'MODELSname.predict', 'np.reshape', 'plt.figure', 'plt.title', 'sns.heatmap', 'np.vstack', 'np.vstack', 'np.vstack', 'print', 'MODELS.predict', 'pd.DataFrame', 'submission.to_csv']","['read_csv', 'read_csv', 'print', 'print', 'describe', 'search', 'group', 'copy', 'copy', 'apply', 'astype', 'astype', 'astype', 'apply', 'apply', 'replace', 'replace', 'replace', 'replace', 'map', 'fillna', 'apply', 'astype', 'fillna', 'map', 'fillna', 'qcut', 'fillna', 'qcut', 'map', 'drop', 'describe', 'print', 'concat', 'copy', 'copy', 'max', 'min', 'concat', 'copy', 'copy', 'copy', 'max', 'min', 'list', 'select_dtypes', 'columns', 'print', 'drop', 'astype', 'min_max_scale', 'describe', 'figure', 'title', 'heatmap', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'range', 'items', 'print', 'model', 'fit', 'cross_val_score', 'sum', 'len', 'print', 'print', 'print', 'RandomizedSearchCV', 'print', 'fit', 'print', 'print', 'DataFrame', 'items', 'predict', 'predict', 'reshape', 'figure', 'title', 'heatmap', 'vstack', 'vstack', 'vstack', 'print', 'predict', 'DataFrame', 'to_csv']","['read_csv', 'print', 'describe', 'search', 'group', 'copy', 'apply', 'astype', 'replace', 'map', 'fillna', 'qcut', 'drop', 'concat', 'max', 'min', 'list', 'select_dtypes', 'columns', 'min_max_scale', 'figure', 'title', 'heatmap', 'range', 'items', 'model', 'fit', 'cross_val_score', 'sum', 'len', 'RandomizedSearchCV', 'DataFrame', 'predict', 'reshape', 'vstack', 'to_csv']",36,"[1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv print print describe search group copy copy apply astype astype astype apply apply replace replace replace replace map fillna apply astype fillna map fillna qcut fillna qcut map drop describe print concat copy copy max min concat copy copy copy max min list select dtypes columns print drop astype min max scale describe figure title heatmap range range range range range range range range range range range range range range range items print model fit cross val score sum len print print print randomizedsearchcv print fit print print dataframe items predict predict reshape figure title heatmap vstack vstack vstack print predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14804975081842336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16237966251652308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07473833046206692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07614738914740113, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2828197869860418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05480695535313237, 0.0, 0.0, 0.05851089533772138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04887428023757094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1046267407325934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04992001944362204, 0.0, 0.0, 0.07473833046206692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08615127750493227, 0.0, 0.0, 0.0, 0.10155773512266704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042987649162090885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06794052220094571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09381855167117353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1780855515562833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0455393936959814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05000481847439975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10247093582146034, 0.0, 0.0, 0.0, 0.19741099422161304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2110892741535447, 0.0, 0.0, 0.0, 0.0, 0.06911140066920708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06690084797513232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2496705804997706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0991754705808524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08051581978676607, 0.6594120824634953, 0.0, 0.0, 0.0, 0.03885052621355421, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15406484843395568, 0.0, 0.0, 0.0, 0.08051581978676607, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08573503984947224, 0.0, 0.0, 0.0327999111030551, 0.0, 0.06794052220094571, 0.0, 0.0717075818902137, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.034512721759297094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0732094559489043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05480695535313237, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29493101230587787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
panditdandgule_complete-beginner-your-first-titanic-submission.py,"['pandas', 'sklearn', 'export_graphviz\n', 'Image,', 'a']","[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,210,[],0,"['pd.read_csv', 'pd.read_csv', 'train.drop', 'test.drop', 'train.head', 'df.map', 'train.fillna', 'test.fillna', 'trainfeatures.head', 'traintarget.head', 'traintarget.head', 'DecisionTreeClassifier', 'clf.fit', 'clf.predict', 'pd.DataFrame', 'submission.head', 'submission.to_csv', 'print']","['read_csv', 'read_csv', 'drop', 'drop', 'head', 'map', 'fillna', 'fillna', 'head', 'head', 'head', 'DecisionTreeClassifier', 'fit', 'predict', 'DataFrame', 'head', 'to_csv', 'print']","['read_csv', 'drop', 'head', 'map', 'fillna', 'DecisionTreeClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']",11,"[1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",read csv read csv drop drop head map fillna fillna head head head decisiontreeclassifier fit predict dataframe head csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3466284975361837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14476977517715217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.253494806911436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29573468730642144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3008226496583184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12733307323073717, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6884036619753007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20235175186834273, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13211066807111713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12325758262357468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23015712632947136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
mamunalbd4_mamun-titanic.py,"['numpy', 'pandas', 'os\n', 'seaborn']","[1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,234,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.']",8,[''],[''],[''],1,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
kerneler_starter-survivedtitanic-29986389-6.py,"['libraries', 'mpl_toolkits', 'sklearn', 'matplotlib', 'numpy', 'os', 'pandas']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",7,151,"['import matplotlib.pyplot as plt # plotting', 'import numpy as np # linear algebra', 'import os # accessing directory structure', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Distribution graphs (histogram/bar graph) of column data', '    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values', '# Correlation matrix', ""    df = df.dropna('columns') # drop columns with NaN"", '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '# Scatter and density plots', '    df = df.select_dtypes(include =[np.number]) # keep only numerical columns', '    # Remove rows and columns that would lead to df being singular', '    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values', '    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots', ""nRowsRead = 1000 # specify 'None' if want to read whole file"", '# survivedTitanic.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows']",16,"['os.walk', 'print', 'df.nunique', 'list', 'plt.figure', 'range', 'plt.subplot', 'np.issubdtype', 'columnDf.value_counts', 'valueCounts.plot.bar', 'columnDf.hist', 'plt.ylabel', 'plt.xticks', 'plt.title', 'plt.tight_layout', 'plt.show', 'df.dropna', 'dfcol.nunique', 'print', 'df.corr', 'plt.figure', 'plt.matshow', 'plt.xticks', 'plt.yticks', 'plt.gca', 'None.xaxis.tick_bottom', 'plt.colorbar', 'plt.title', 'plt.show', 'df.select_dtypes', 'df.dropna', 'dfcol.nunique', 'list', 'len', 'pd.plotting.scatter_matrix', 'df.corr', 'df.corr', 'zip', 'axij.annotate', 'plt.suptitle', 'plt.show', 'pd.read_csv', 'print', 'df1.head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['walk', 'print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'nunique', 'print', 'corr', 'figure', 'matshow', 'xticks', 'yticks', 'gca', 'xaxis', 'colorbar', 'title', 'show', 'select_dtypes', 'dropna', 'nunique', 'list', 'len', 'plotting', 'corr', 'corr', 'zip', 'annotate', 'suptitle', 'show', 'read_csv', 'print', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']","['walk', 'print', 'nunique', 'list', 'figure', 'range', 'subplot', 'issubdtype', 'value_counts', 'plot', 'hist', 'ylabel', 'xticks', 'title', 'tight_layout', 'show', 'dropna', 'corr', 'matshow', 'yticks', 'gca', 'xaxis', 'colorbar', 'select_dtypes', 'len', 'plotting', 'zip', 'annotate', 'suptitle', 'read_csv', 'head', 'plotPerColumnDistribution', 'plotCorrelationMatrix', 'plotScatterMatrix']",34,"[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print nunique list figure range subplot issubdtype value counts plot hist ylabel xticks title tight layout show dropna nunique print corr figure matshow xticks yticks gca xaxis colorbar title show select dtypes dropna nunique list len plotting corr corr zip annotate suptitle show read csv print head plotpercolumndistribution plotcorrelationmatrix plotscattermatrix,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1543884081863955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29549374335041534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719323031194817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03841763880099134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16746437717682094, 0.0, 0.14721720635317656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16969806951294641, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04577842287583891, 0.0, 0.0, 0.0910257746807462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16887817770593153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1385989983982722, 0.0, 0.0, 0.08970206154581574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1969958289002769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.41579699519481655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0737274898474115, 0.0, 0.16887817770593153, 0.16887817770593153, 0.16887817770593153, 0.0, 0.0, 0.15062322702083364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12294830892833276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08659260829584371, 0.0, 0.0, 0.0, 0.03826327066145258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1412473333957713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2511965657652314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12585280241810667, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15859752262274054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14410775310320456, 0.0, 0.14420567755261537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08719323031194817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08159805194038416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16887817770593153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22765714759109046, 0.0, 0.09531927208129282, 0.0, 0.0, 0.0, 0.14721720635317656, 0.0, 0.0, 0.1385989983982722, 0.0]"
ssandorov_titanic-competition.py,"['numpy', 'pandas', 'os\n', 'sklearn']","[1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",4,190,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# Because Sex has no missing values I can transform it directly', '# I will change the missing values form Emarked with the most frequent value', '# Now I transform it to a numerical feature', '# Imputation', '# Imputation removed column names; put them back']",13,"['os.walk', 'print', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'gender_submission.head', 'train_data.head', 'train_data.info', 'test_data.info', 'train_data.describe', 'train_data.describe', 'train_data.Cabin.count', 'len', 'print', 'dataset.map', 'None.astype', 'train_data.head', 'train_data.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_data.describe', 'train_data.unique', 'dataset.map', 'None.astype', 'train_data.head', 'SimpleImputer', 'pd.DataFrame', 'pd.DataFrame', 'imputed_X.describe', 'RandomForestClassifier', 'model.fit', 'model.predict', 'pd.DataFrame', 'output.to_csv', 'print']","['walk', 'print', 'read_csv', 'read_csv', 'read_csv', 'head', 'head', 'info', 'info', 'describe', 'describe', 'Cabin', 'len', 'print', 'map', 'astype', 'head', 'Embarked', 'mode', 'fillna', 'describe', 'unique', 'map', 'astype', 'head', 'SimpleImputer', 'DataFrame', 'DataFrame', 'describe', 'RandomForestClassifier', 'fit', 'predict', 'DataFrame', 'to_csv', 'print']","['walk', 'print', 'read_csv', 'head', 'info', 'describe', 'Cabin', 'len', 'map', 'astype', 'Embarked', 'mode', 'fillna', 'unique', 'SimpleImputer', 'DataFrame', 'RandomForestClassifier', 'fit', 'predict', 'to_csv']",20,"[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print read csv read csv read csv head head info info describe describe cabin len print map astype head embarked mode fillna describe unique map astype head simpleimputer dataframe dataframe describe randomforestclassifier fit predict dataframe csv print,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22001658001544663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20030345487123183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2642647666244792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24833356180363775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47254722497048424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14994478694397834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08600363343504507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07280772885108618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3148976515810263, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21786021203972375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15425918341139677, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23140526037372347, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19359262210407546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07553950796293098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21143221694419845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1068288787428562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19740218179501556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31533489103121015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20030345487123183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1403228492564288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
inshalkhan_titanic-analysis.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn', 'the', 'pycaret']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",8,411,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', ' #   Column       Non-Null Count  Dtype  ', ' #   Column       Non-Null Count  Dtype  ', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# import the classification module ', '# setup the environment ', '# compare performance of different classification models', '# evaluate model', '# Random Forest']",13,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'train_df.head', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'get_ipython', 'None.system', 'classification.setup', 'classification.compare_models', 'classification.create_model', 'classification.evaluate_model', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'head', 'info', 'print', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'get_ipython', 'system', 'setup', 'compare_models', 'create_model', 'evaluate_model', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'head', 'info', 'print', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'system', 'setup', 'compare_models', 'create_model', 'evaluate_model', 'RandomForestClassifier', 'score', 'to_csv']",45,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv head info print info describe groupby mean sort values facetgrid map add legend groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values get ipython system setup compare models create model evaluate model randomforestclassifier fit predict score round dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.04439408491902046, 0.0, 0.04651224695646336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13744321339323612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11179918866185543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04274776661872901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08775205063458194, 0.0, 0.0, 0.0, 0.05335872296466319, 0.06190680954975989, 0.0, 0.0, 0.0, 0.051199676392796864, 0.0, 0.0, 0.0, 0.051710894886927004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03689972425909903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2640866387857406, 0.04497580463823774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046834864326355904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07740586099193666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09567316911369085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08058903384901721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04548260959448674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05418856506859796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.357702642884354, 0.0, 0.0, 0.0, 0.0, 0.2704830224173643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06804807076623315, 0.0, 0.0, 0.0, 0.0, 0.061141739916090926, 0.0, 0.0, 0.0, 0.0, 0.06838336166000361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0396018930801458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03470358534399011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06491764941858987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03453142919759991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03453142919759991, 0.0, 0.0, 0.1806970784862561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3709460188881745, 0.051612494059344365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06046815214866649, 0.14624511534990878, 0.0, 0.11179918866185543, 0.0, 0.0, 0.0, 0.0, 0.051199676392796864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04718913779970704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044026868807836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05246575816195452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03336772250660312, 0.0, 0.0, 0.18604898782585344, 0.0, 0.0, 0.0, 0.041105372141859935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1630066191136317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1015911005468913, 0.0, 0.03436080334830903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03470358534399011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.050399757248062955, 0.0, 0.11179918866185543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38237942065876074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09421072998562764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38237942065876074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0666638783239087, 0.0, 0.0]"
mantej_titanic-waley-bhaiya.py,"['numpy', 'pandas', 'os\n', 'matplotlib', 'seaborn', 'warnings\n', 'sklearn', 'tpot', 'xgboost']","[1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",9,463,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# Filling the missing values in Embarked with S bcoz 78.3 is very close to 80']",9,"['os.walk', 'print', 'sns.set', 'warnings.filterwarnings', 'pd.read_csv', 'pd.read_csv', 'print', 'df_train.describe', 'df_train.describe', 'df_train.head', 'df_train.isnull', 'None.sum', 'df_test.isnull', 'None.sum', 'pd.concat', 'None.reset_index', 'df_concat.isnull', 'df_concatdf_concat.groupby', 'None.median', 'df_concat.fillna', 'df_concat.median', 'df_concat.corr', 'None.abs', 'None.unstack', 'None.sort_values', 'None.reset_index', 'df_concat_corr.rename', 'df_concat.groupby', 'None.median', 'range', 'print', 'print', 'df_concat.groupby', 'None.apply', 'df_concat.corr', 'df_concat.apply', 'df_concat.groupby', 'None.count', 'None.drop', 'None.rename', 'None.transpose', 'df_concat.groupby', 'None.count', 'None.drop', 'None.rename', 'None.transpose', 'df_concat.replace', 'df_concat.replace', 'df_concat.value_counts', 'df_concat.drop', 'df_concat.isnull', 'df_concat.groupby', 'None.Fare.median', 'df_concat.fillna', 'df_concat.loc.drop', 'print', 'df_train.isnull', 'None.sum', 'print', 'df_test.isnull', 'None.sum', 'pd.concat', 'None.reset_index', 'pd.qcut', 'df_concat.groupby', 'None.count', 'None.transpose', 'df_concat.groupby', 'None.count', 'None.transpose', 'pd.qcut', 'df_concat.groupby', 'None.count', 'None.transpose', 'df_concat.groupby', 'None.count', 'None.transpose', 'df_concat.value_counts', 'df_concat.map', 'df_concat.groupby', 'None.transform', 'df_concat.str.split', 'None.str.split', 'df_concat.replace', 'df_concat.replace', 'LabelEncoder', 'None.fit_transform', 'OneHotEncoder', 'None.fit_transform', 'None.toarray', 'dffeature.nunique', '.format', 'range', 'pd.DataFrame', 'encoded_features.append', 'pd.concat', 'pd.concat', 'pd.concat', 'None.reset_index', 'df_concat.drop', 'df_concat.head', 'StandardScaler', 'None.fit_transform', 'StandardScaler', 'None.fit_transform', 'print', 'print', 'print', 'TPOTClassifier', 'tpot.fit', 'do_tpot', 'XGBClassifier', 'clf.fit', 'clf.predict', 'clf.score', 'round', 'pd.DataFrame', 'submission.to_csv']","['walk', 'print', 'set', 'filterwarnings', 'read_csv', 'read_csv', 'print', 'describe', 'describe', 'head', 'isnull', 'sum', 'isnull', 'sum', 'concat', 'reset_index', 'isnull', 'groupby', 'median', 'fillna', 'median', 'corr', 'abs', 'unstack', 'sort_values', 'reset_index', 'rename', 'groupby', 'median', 'range', 'print', 'print', 'groupby', 'apply', 'corr', 'apply', 'groupby', 'count', 'drop', 'rename', 'transpose', 'groupby', 'count', 'drop', 'rename', 'transpose', 'replace', 'replace', 'value_counts', 'drop', 'isnull', 'groupby', 'Fare', 'fillna', 'loc', 'print', 'isnull', 'sum', 'print', 'isnull', 'sum', 'concat', 'reset_index', 'qcut', 'groupby', 'count', 'transpose', 'groupby', 'count', 'transpose', 'qcut', 'groupby', 'count', 'transpose', 'groupby', 'count', 'transpose', 'value_counts', 'map', 'groupby', 'transform', 'str', 'str', 'replace', 'replace', 'LabelEncoder', 'fit_transform', 'OneHotEncoder', 'fit_transform', 'toarray', 'nunique', 'format', 'range', 'DataFrame', 'append', 'concat', 'concat', 'concat', 'reset_index', 'drop', 'head', 'StandardScaler', 'fit_transform', 'StandardScaler', 'fit_transform', 'print', 'print', 'print', 'TPOTClassifier', 'fit', 'do_tpot', 'XGBClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'to_csv']","['walk', 'print', 'set', 'filterwarnings', 'read_csv', 'describe', 'head', 'isnull', 'sum', 'concat', 'reset_index', 'groupby', 'median', 'fillna', 'corr', 'abs', 'unstack', 'sort_values', 'rename', 'range', 'apply', 'count', 'drop', 'transpose', 'replace', 'value_counts', 'Fare', 'loc', 'qcut', 'map', 'transform', 'str', 'LabelEncoder', 'fit_transform', 'OneHotEncoder', 'toarray', 'nunique', 'format', 'DataFrame', 'append', 'StandardScaler', 'TPOTClassifier', 'fit', 'do_tpot', 'XGBClassifier', 'predict', 'score', 'round', 'to_csv']",49,"[1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0
 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0
 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0
 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",walk print set filterwarnings read csv read csv print describe describe head isnull sum isnull sum concat reset index isnull groupby median fillna median corr abs unstack sort values reset index rename groupby median range print print groupby apply corr apply groupby count drop rename transpose groupby count drop rename transpose replace replace value counts drop isnull groupby fare fillna loc print isnull sum print isnull sum concat reset index qcut groupby count transpose groupby count transpose qcut groupby count transpose groupby count transpose value counts map groupby transform str str replace replace labelencoder fit transform onehotencoder fit transform toarray nunique format range dataframe append concat concat concat reset index drop head standardscaler fit transform standardscaler fit transform print print print tpotclassifier fit tpot xgbclassifier fit predict score round dataframe csv,"[0.0, 0.0808016590503102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.041687536224584786, 0.07211778307143354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1854640369750941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09743310289487936, 0.0, 0.0, 0.32700008373914835, 0.0, 0.0, 0.0, 0.08625062802747516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05700348746221658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04761513910642769, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06795417126033944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09726787416406454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05393885820708771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049470658817827556, 0.0, 0.05090141841156902, 0.0, 0.0, 0.0, 0.12564049341054787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07449745742641473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.362307928544074, 0.0, 0.0, 0.0, 0.0, 0.045283535304545146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20360567364627608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2027966803993628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049558373473022194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05977585408814711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.033276997224905173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14257359631693256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06855033706780729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07844150217209354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.021725763647666804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18242876463079505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09662042703643937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0856564990347678, 0.0, 0.0, 0.0, 0.03784962563181142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23532450651628062, 0.0, 0.15009569765396283, 0.0, 0.0, 0.2277672413600744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04677229426306272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03195489165792063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03415652799851519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03912145560194561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11660418139646593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10573464555485051, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13449430166724752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09069282415459647, 0.0, 0.0, 0.0, 0.10294414613709939, 0.10294414613709939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19325048214533047, 0.0, 0.458158177599279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06855033706780729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08625062802747516, 0.03912145560194561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04035796816161921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05286732277742526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
sabirul_titanic-using-naive-bayes.py,['csv\n'],"[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",1,122,[],0,"['columcolumvals.count', 'float', 'len', 'range', 'temp.index', 'temp.append', 'len', 'range', 'float', 'getFeatures', 'getProb', 'range', 'float', 'len', 'range', 'getProbFeature', 'open', 'f.readlines', 'x.strip', 'None.split', 'range', 'valsicol.strip', 'None.split', 'valsi.append', 'getList', 'probability', 'probability', 'max', 'open', 'csv.DictWriter', 'getList', 'writer.writeheader', 'range', 'writer.writerow']","['count', 'float', 'len', 'range', 'index', 'append', 'len', 'range', 'float', 'getFeatures', 'getProb', 'range', 'float', 'len', 'range', 'getProbFeature', 'open', 'readlines', 'strip', 'split', 'range', 'strip', 'split', 'append', 'getList', 'probability', 'probability', 'max', 'open', 'DictWriter', 'getList', 'writeheader', 'range', 'writerow']","['count', 'float', 'len', 'range', 'index', 'append', 'getFeatures', 'getProb', 'getProbFeature', 'open', 'readlines', 'strip', 'split', 'getList', 'probability', 'max', 'DictWriter', 'writeheader', 'writerow']",19,"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
 0 0 0 0 0]",count float len range index append len range float getfeatures getprob range float len range getprobfeature open readlines strip split range strip split append getlist probability probability max open dictwriter getlist writeheader range writerow,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13730666904515917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08975362970565708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1695340992045398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37726008154481694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1695340992045398, 0.3390681984090796, 0.1695340992045398, 0.1695340992045398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08382726403059444, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21919396314168785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10557720757854694, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.27511130678308676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3390681984090796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.42319154463239095, 0.0, 0.0, 0.0, 0.0, 0.1695340992045398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10904231129328314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2583635866635114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1695340992045398, 0.1695340992045398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
yuta12345_titanic-machine-learning-from-disaster.py,"['numpy', 'pandas', 'matplotlib', 'sklearn', 'os\n']","[1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",5,335,"['# This Python 3 environment comes with many helpful analytics libraries installed', '# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python', ""# For example, here's several helpful packages to load in "", 'import numpy as np # linear algebra', 'import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)', '# Input data files are available in the ""../input/"" directory.', '# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory', '# Any results you write to the current directory are saved as output.', '# Break off validation set from training data', '# Save test predictions to file']",10,"['get_ipython', 'None.run_line_magic', 'os.walk', 'print', 'pd.set_option', 'pd.read_csv', 'pd.read_csv', 'pd.read_csv', 'raw_train_data.head', 'raw_train_data.isnull', 'None.sum', 'raw_train_data.describe', 'set', 'list', 'dict', 'sorted', 'range', 'datadatakeyi.count', 'datadatakeyi.sum', 'survived_counted_by_key.append', 'not_survived_counted_by_key.append', 'survived_rate_by_key.append', 'survived_count_by_key', 'plt.title', 'plt.scatter', 'plt.show', 'plt.title', 'plt.scatter', 'plt.show', 'plt.title', 'plt.scatter', 'plt.show', 'dkey.dropna', 'plt.title', 'plt.hist', 'plt.show', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_scatter_survived_counted_by_key', 'plot_scatter_survived_counted_by_key', 'raw_train_data.drop', 'raw_test_data.copy', 'train_test_split', 'X_train.drop', 'X_valid.drop', 'datakey.mean', 'np.isnan', 'pd.isnull', 'reduced_X_train.copy', 'reduced_X_valid.copy', 'impute_missing_num_to_mean', 'impute_missing_num_to_mean', 'impute_missing_str_to_dummy', 'impute_missing_str_to_dummy', 'imputed_X_train.isnull', 'None.sum', 'LabelEncoder', 'label_encoder.fit_transform', 'imputed_X_train.copy', 'imputed_X_valid.copy', 'label_encode', 'label_encode', 'label_X_train.describe', 'list', 'range', 'len', 'range', 'RandomForestClassifier', 't_model.fit', 't_model.predict', 'evaluate_model', 'preds_valid_list.append', 'print', 'RandomForestClassifier', 'model.fit', 'model.predict', 'evaluate_model', 'X_test.isnull', 'None.sum', 'X_test.drop', 'impute_missing_num_to_mean', 'impute_missing_num_to_mean', 'label_encode', 'label_X_test.head', 'model.predict', 'pd.DataFrame', 'output.to_csv']","['get_ipython', 'run_line_magic', 'walk', 'print', 'set_option', 'read_csv', 'read_csv', 'read_csv', 'head', 'isnull', 'sum', 'describe', 'set', 'list', 'dict', 'sorted', 'range', 'count', 'sum', 'append', 'append', 'append', 'survived_count_by_key', 'title', 'scatter', 'show', 'title', 'scatter', 'show', 'title', 'scatter', 'show', 'dropna', 'title', 'hist', 'show', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_hist', 'plot_scatter_survived_counted_by_key', 'plot_scatter_survived_counted_by_key', 'drop', 'copy', 'train_test_split', 'drop', 'drop', 'mean', 'isnan', 'isnull', 'copy', 'copy', 'impute_missing_num_to_mean', 'impute_missing_num_to_mean', 'impute_missing_str_to_dummy', 'impute_missing_str_to_dummy', 'isnull', 'sum', 'LabelEncoder', 'fit_transform', 'copy', 'copy', 'label_encode', 'label_encode', 'describe', 'list', 'range', 'len', 'range', 'RandomForestClassifier', 'fit', 'predict', 'evaluate_model', 'append', 'print', 'RandomForestClassifier', 'fit', 'predict', 'evaluate_model', 'isnull', 'sum', 'drop', 'impute_missing_num_to_mean', 'impute_missing_num_to_mean', 'label_encode', 'head', 'predict', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'walk', 'print', 'set_option', 'read_csv', 'head', 'isnull', 'sum', 'describe', 'set', 'list', 'dict', 'sorted', 'range', 'count', 'append', 'survived_count_by_key', 'title', 'scatter', 'show', 'dropna', 'hist', 'plot_hist', 'plot_scatter_survived_counted_by_key', 'drop', 'copy', 'train_test_split', 'mean', 'isnan', 'impute_missing_num_to_mean', 'impute_missing_str_to_dummy', 'LabelEncoder', 'fit_transform', 'label_encode', 'len', 'RandomForestClassifier', 'fit', 'predict', 'evaluate_model', 'DataFrame', 'to_csv']",42,"[1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0
 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0
 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 1 1 1 1 1]",get ipython run line magic walk print set option read csv read csv read csv head isnull sum describe set list dict sorted range count sum append append append survived count key title scatter show title scatter show title scatter show dropna title hist show plot hist plot hist plot hist plot hist plot hist plot hist plot hist plot scatter survived counted key plot scatter survived counted key drop copy train test split drop drop mean isnan isnull copy copy impute missing num mean impute missing num mean impute missing str dummy impute missing str dummy isnull sum labelencoder fit transform copy copy label encode label encode describe list range len range randomforestclassifier fit predict evaluate model append print randomforestclassifier fit predict evaluate model isnull sum drop impute missing num mean impute missing num mean label encode head predict dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12779725503751713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15083486663961762, 0.0, 0.0, 0.0, 0.08353758477866971, 0.15779271803959144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05824993819088318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018246113308449673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052080054027630496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06011754091562914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07454606608636229, 0.0317392932132546, 0.0, 0.0, 0.0, 0.15779271803959144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2202117204611857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1092501774324573, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04814541597315038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.019120355592877135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03470528624633901, 0.0, 0.0, 0.2760318392495223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3840869866098716, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024128968720991073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04092188826529904, 0.10361553849147451, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23668907705938713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2202117204611857, 0.0, 0.037981520782711005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03400221684436092, 0.0, 0.0, 0.0, 0.0, 0.024490218232753005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07467269733015726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024368728145967612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13088775792319618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3607052454937748, 0.0, 0.0, 0.10320474829594664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24047016366251656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053540825885676505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2515224565169581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.049951853885195886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03106963198531344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047095007505221505, 0.0, 0.0, 0.09847066813142022, 0.0, 0.0, 0.0, 0.043511910555389215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024248317985349835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30963182177150383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05235510316927847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1269571728530184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06401449776831193, 0.0, 0.0, 0.02537259872942664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08103499683621142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10307638762017765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14520071707367446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026456861559978777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10932441537762494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026040027013815248, 0.0, 0.0, 0.0, 0.02962142092039157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.030930333242533914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
dnfinal_titanic-data-science-solutions.py,"['pandas', 'numpy', 'random', 'seaborn', 'matplotlib', 'sklearn']","[1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]",6,938,"['# data analysis and wrangling', '# visualization', '# machine learning', '# preview the data', '# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.', '# Review Parch distribution using `percentiles=[.75, .8]`', '# SibSp distribution `[.68, .69]`', '# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`', ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')"", ""# grid = sns.FacetGrid(train_df, col='Embarked')"", ""# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})"", ""# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')"", '            # age_mean = guess_df.mean()', '            # age_std = guess_df.std()', '            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)', '            # Convert random age float to nearest .5 age', '# Logistic Regression', '# Support Vector Machines', '# Gaussian Naive Bayes', '# Perceptron', '# Linear SVC', '# Stochastic Gradient Descent', '# Decision Tree', '# Random Forest']",24,"['get_ipython', 'None.run_line_magic', 'pd.read_csv', 'pd.read_csv', 'print', 'train_df.head', 'train_df.tail', 'train_df.info', 'print', 'test_df.info', 'train_df.describe', 'train_df.describe', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'None.sort_values', 'sns.FacetGrid', 'g.map', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'print', 'train_df.drop', 'test_df.drop', 'dataset.Name.str.extract', 'pd.crosstab', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'dataset.replace', 'train_df.groupby', 'None.mean', 'dataset.map', 'dataset.fillna', 'train_df.head', 'train_df.drop', 'test_df.drop', 'dataset.map', 'None.astype', 'train_df.head', 'sns.FacetGrid', 'grid.map', 'grid.add_legend', 'np.zeros', 'range', 'range', 'datasetdatasetidatasetj.dropna', 'guess_df.median', 'int', 'range', 'range', 'dataset.Age.isnull', 'dataset.astype', 'train_df.head', 'pd.cut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.head', 'train_df.drop', 'train_df.head', 'train_df.groupby', 'None.mean', 'None.sort_values', 'train_df.groupby', 'None.mean', 'train_df.drop', 'test_df.drop', 'train_df.head', 'train_df.loc.head', 'train_df.Embarked.dropna', 'None.mode', 'dataset.fillna', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.map', 'None.astype', 'train_df.head', 'test_df.fillna', 'test_df.head', 'pd.qcut', 'train_df.groupby', 'None.mean', 'None.sort_values', 'dataset.astype', 'train_df.drop', 'train_df.head', 'test_df.head', 'train_df.drop', 'test_df.drop', 'None.copy', 'LogisticRegression', 'logreg.fit', 'logreg.predict', 'round', 'pd.DataFrame', 'pd.Series', 'coeff_df.sort_values', 'SVC', 'svc.fit', 'svc.predict', 'round', 'KNeighborsClassifier', 'knn.fit', 'knn.predict', 'round', 'GaussianNB', 'gaussian.fit', 'gaussian.predict', 'round', 'Perceptron', 'perceptron.fit', 'perceptron.predict', 'round', 'LinearSVC', 'linear_svc.fit', 'linear_svc.predict', 'round', 'SGDClassifier', 'sgd.fit', 'sgd.predict', 'round', 'DecisionTreeClassifier', 'decision_tree.fit', 'decision_tree.predict', 'round', 'RandomForestClassifier', 'random_forest.fit', 'random_forest.predict', 'random_forest.score', 'round', 'pd.DataFrame', 'models.sort_values', 'pd.DataFrame', 'submission.to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'read_csv', 'print', 'head', 'tail', 'info', 'print', 'info', 'describe', 'describe', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'FacetGrid', 'map', 'add_legend', 'print', 'drop', 'drop', 'Name', 'crosstab', 'replace', 'replace', 'replace', 'replace', 'groupby', 'mean', 'map', 'fillna', 'head', 'drop', 'drop', 'map', 'astype', 'head', 'FacetGrid', 'map', 'add_legend', 'zeros', 'range', 'range', 'dropna', 'median', 'int', 'range', 'range', 'Age', 'astype', 'head', 'cut', 'groupby', 'mean', 'sort_values', 'head', 'drop', 'head', 'groupby', 'mean', 'sort_values', 'groupby', 'mean', 'drop', 'drop', 'head', 'loc', 'Embarked', 'mode', 'fillna', 'groupby', 'mean', 'sort_values', 'map', 'astype', 'head', 'fillna', 'head', 'qcut', 'groupby', 'mean', 'sort_values', 'astype', 'drop', 'head', 'head', 'drop', 'drop', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'sort_values', 'SVC', 'fit', 'predict', 'round', 'KNeighborsClassifier', 'fit', 'predict', 'round', 'GaussianNB', 'fit', 'predict', 'round', 'Perceptron', 'fit', 'predict', 'round', 'LinearSVC', 'fit', 'predict', 'round', 'SGDClassifier', 'fit', 'predict', 'round', 'DecisionTreeClassifier', 'fit', 'predict', 'round', 'RandomForestClassifier', 'fit', 'predict', 'score', 'round', 'DataFrame', 'sort_values', 'DataFrame', 'to_csv']","['get_ipython', 'run_line_magic', 'read_csv', 'print', 'head', 'tail', 'info', 'describe', 'groupby', 'mean', 'sort_values', 'FacetGrid', 'map', 'add_legend', 'drop', 'Name', 'crosstab', 'replace', 'fillna', 'astype', 'zeros', 'range', 'dropna', 'median', 'int', 'Age', 'cut', 'loc', 'Embarked', 'mode', 'qcut', 'copy', 'LogisticRegression', 'fit', 'predict', 'round', 'DataFrame', 'Series', 'SVC', 'KNeighborsClassifier', 'GaussianNB', 'Perceptron', 'LinearSVC', 'SGDClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'score', 'to_csv']",48,"[1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0
 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0
 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]",get ipython run line magic read csv read csv print head tail info print info describe describe groupby mean sort values groupby mean sort values groupby mean sort values groupby mean sort values facetgrid map facetgrid map add legend facetgrid map add legend facetgrid map add legend print drop drop name crosstab replace replace replace replace groupby mean map fillna head drop drop map astype head facetgrid map add legend zeros range range dropna median int range range age astype head cut groupby mean sort values head drop head groupby mean sort values groupby mean drop drop head loc embarked mode fillna groupby mean sort values map astype head fillna head qcut groupby mean sort values astype drop head head drop drop copy logisticregression fit predict round dataframe series sort values svc fit predict round kneighborsclassifier fit predict round gaussiannb fit predict round perceptron fit predict round linearsvc fit predict round sgdclassifier fit predict round decisiontreeclassifier fit predict round randomforestclassifier fit predict score round dataframe sort values dataframe csv,"[0.0, 0.0, 0.0, 0.0, 0.0, 0.14739731056786123, 0.0, 0.0386075088739669, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11408479331718284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.035482800489506514, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044290428976480785, 0.05138577160738971, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.06438397294899055, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03757921331973189, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0612572612591073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21920521835808165, 0.03733218432362304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03887529754869338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19853387909934528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.066892959232493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16988786089570734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04630997037753964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022489619870565202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2969112193682155, 0.0, 0.0, 0.0, 0.0, 0.22451453910645058, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05648332789475356, 0.0, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.028380818116478954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038344146661578926, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1314862676876251, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.053884920424318535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028662826382586534, 0.0, 0.0, 0.239980289670821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30790388882723707, 0.042840970987036014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05019161346595868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.042498311520606, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1762621307304402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05481677964674111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04354922319089523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027696891186176718, 0.0, 0.0, 0.1544300354958676, 0.0, 0.0, 0.0, 0.034119530308222235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1353037082864551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3794657982870925, 0.0, 0.02852119832929571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028805724659586324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04183433832000622, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0561117545919202, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03661327812332207, 0.0, 0.0, 0.0, 0.050750725257151574, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35266020940257115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.055334378413763305, 0.0, 0.0]"